,eid,doi,weblink,scholar_link,subtype,journal,author_names,title,description,authkeywords,citedby_count,year,focus,appears_in
708,2-s2.0-85150033997,10.1016/j.ebiom.2023.104512,https://doi.org/10.1016/j.ebiom.2023.104512,https://scholar.google.com/scholar?q=10.1016/j.ebiom.2023.104512,re,Ebiomedicine,"Harrer, Stefan",Attention is not all you need: the complicated case of ethically using large language models in healthcare and medicine,"Large Language Models (LLMs) are a key component of generative artificial intelligence (AI) applications for creating new content including text, imagery, audio, code, and videos in response to textual instructions. Without human oversight, guidance and responsible design and operation, such generative AI applications will remain a party trick with substantial potential for creating and spreading misinformation or harmful and inaccurate content at unprecedented scale. However, if positioned and developed responsibly as companions to humans augmenting but not replacing their role in decision making, knowledge retrieval and other cognitive processes, they could evolve into highly efficient, trustworthy, assistive tools for information management. This perspective describes how such tools could transform data management workflows in healthcare and medicine, explains how the underlying technology works, provides an assessment of risks and limitations, and proposes an ethical, technical, and cultural framework for responsible design, development, and deployment. It seeks to incentivise users, developers, providers, and regulators of generative AI that utilises LLMs to collectively prepare for the transformational role this technology could play in evidence-based sectors.",AI ethics | AI trustworthiness | Augmented human intelligence | Foundation models | Generative artificial intelligence | Information management | Large language models,319,2023,behavior,behavior+policy
714,2-s2.0-85159924829,10.2196/47184,https://doi.org/10.2196/47184,https://scholar.google.com/scholar?q=10.2196/47184,ar,Journal of Medical Internet Research,"Choudhury, Avishek;Shamszare, Hamid",Investigating the Impact of User Trust on the Adoption and Use of ChatGPT: Survey Analysis,"Background: ChatGPT (Chat Generative Pre-trained Transformer) has gained popularity for its ability to generate human-like responses. It is essential to note that overreliance or blind trust in ChatGPT, especially in high-stakes decision-making contexts, can have severe consequences. Similarly, lacking trust in the technology can lead to underuse, resulting in missed opportunities. Objective: This study investigated the impact of users’ trust in ChatGPT on their intent and actual use of the technology. Four hypotheses were tested: (1) users’ intent to use ChatGPT increases with their trust in the technology; (2) the actual use of ChatGPT increases with users’ intent to use the technology; (3) the actual use of ChatGPT increases with users’ trust in the technology; and (4) users’ intent to use ChatGPT can partially mediate the effect of trust in the technology on its actual use. Methods: This study distributed a web-based survey to adults in the United States who actively use ChatGPT (version 3.5) at least once a month between February 2023 through March 2023. The survey responses were used to develop 2 latent constructs: Trust and Intent to Use, with Actual Use being the outcome variable. The study used partial least squares structural equation modeling to evaluate and test the structural model and hypotheses. Results: In the study, 607 respondents completed the survey. The primary uses of ChatGPT were for information gathering (n=219, 36.1%), entertainment (n=203, 33.4%), and problem-solving (n=135, 22.2%), with a smaller number using it for health-related queries (n=44, 7.2%) and other activities (n=6, 1%). Our model explained 50.5% and 9.8% of the variance in Intent to Use and Actual Use, respectively, with path coefficients of 0.711 and 0.221 for Trust on Intent to Use and Actual Use, respectively. The bootstrapped results failed to reject all 4 null hypotheses, with Trust having a significant direct effect on both Intent to Use (β=0.711, 95% CI 0.656-0.764) and Actual Use (β=0.302, 95% CI 0.229-0.374). The indirect effect of Trust on Actual Use, partially mediated by Intent to Use, was also significant (β=0.113, 95% CI 0.001-0.227). Conclusions: Our results suggest that trust is critical to users’ adoption of ChatGPT. It remains crucial to highlight that ChatGPT was not initially designed for health care applications. Therefore, an overreliance on it for health-related advice could potentially lead to misinformation and subsequent health risks. Efforts must be focused on improving the ChatGPT’s ability to distinguish between queries that it can safely handle and those that should be redirected to human experts (health care professionals). Although risks are associated with excessive trust in artificial intelligence–driven chatbots such as ChatGPT, the potential risks can be reduced by advocating for shared accountability and fostering collaboration between developers, subject matter experts, and human factors researchers.",adoption | AI policy | artificial intelligence | behavioral intention | chatbot | ChatGPT | human factors | intent | shared accountability | survey | technology adoption | trust | trust in AI,306,2023,behavior,behavior+policy
353,2-s2.0-85188140919,10.1186/s13012-024-01357-9,https://doi.org/10.1186/s13012-024-01357-9,https://scholar.google.com/scholar?q=10.1186/s13012-024-01357-9,ar,Implementation Science,"Reddy, Sandeep","Generative AI in healthcare: an implementation science informed translational path on application, integration and governance","Background: Artificial intelligence (AI), particularly generative AI, has emerged as a transformative tool in healthcare, with the potential to revolutionize clinical decision-making and improve health outcomes. Generative AI, capable of generating new data such as text and images, holds promise in enhancing patient care, revolutionizing disease diagnosis and expanding treatment options. However, the utility and impact of generative AI in healthcare remain poorly understood, with concerns around ethical and medico-legal implications, integration into healthcare service delivery and workforce utilisation. Also, there is not a clear pathway to implement and integrate generative AI in healthcare delivery. Methods: This article aims to provide a comprehensive overview of the use of generative AI in healthcare, focusing on the utility of the technology in healthcare and its translational application highlighting the need for careful planning, execution and management of expectations in adopting generative AI in clinical medicine. Key considerations include factors such as data privacy, security and the irreplaceable role of clinicians’ expertise. Frameworks like the technology acceptance model (TAM) and the Non-Adoption, Abandonment, Scale-up, Spread and Sustainability (NASSS) model are considered to promote responsible integration. These frameworks allow anticipating and proactively addressing barriers to adoption, facilitating stakeholder participation and responsibly transitioning care systems to harness generative AI’s potential. Results: Generative AI has the potential to transform healthcare through automated systems, enhanced clinical decision-making and democratization of expertise with diagnostic support tools providing timely, personalized suggestions. Generative AI applications across billing, diagnosis, treatment and research can also make healthcare delivery more efficient, equitable and effective. However, integration of generative AI necessitates meticulous change management and risk mitigation strategies. Technological capabilities alone cannot shift complex care ecosystems overnight; rather, structured adoption programs grounded in implementation science are imperative. Conclusions: It is strongly argued in this article that generative AI can usher in tremendous healthcare progress, if introduced responsibly. Strategic adoption based on implementation science, incremental deployment and balanced messaging around opportunities versus limitations helps promote safe, ethical generative AI integration. Extensive real-world piloting and iteration aligned to clinical priorities should drive development. With conscientious governance centred on human wellbeing over technological novelty, generative AI can enhance accessibility, affordability and quality of care. As these models continue advancing rapidly, ongoing reassessment and transparent communication around their strengths and weaknesses remain vital to restoring trust, realizing positive potential and, most importantly, improving patient outcomes.",Generative artificial intelligence | Healthcare | Implementation science | Translation pathway,290,2024,sustainability,behavior+policy+sustainability
685,2-s2.0-85189750212,10.1016/j.cosrev.2024.100632,https://doi.org/10.1016/j.cosrev.2024.100632,https://scholar.google.com/scholar?q=10.1016/j.cosrev.2024.100632,re,Computer Science Review,"Casheekar, Avyay;Lahiri, Archit;Rath, Kanishk;Prabhakar, Kaushik Sanjay;Srinivasan, Kathiravan","A contemporary review on chatbots, AI-powered virtual conversational agents, ChatGPT: Applications, open challenges and future research directions","This review paper offers an in-depth analysis of AI-powered virtual conversational agents, specifically focusing on OpenAI's ChatGPT. The main contributions of this paper are threefold: (i) an exhaustive review of prior literature on chatbots, (ii) a background of chatbots including existing chatbots/conversational agents like ChatGPT, and (iii) a UI/UX design analysis of prominent chatbots. Another contribution of this review is the comprehensive exploration of ChatGPT's applications across a multitude of sectors, including education, business, public health, and more. This review highlights the transformative potential of ChatGPT, despite the challenges it faces such as hallucination, biases in training data, jailbreaks, and anonymous data collection. The review paper then presents a comprehensive survey of prior literature reviews on chatbots, identifying gaps in the prior work and highlighting the need for further research in areas such as chatbot evaluation, user experience, and ethical considerations. The paper also provides a detailed analysis of the UI/UX design of prominent chatbots, including their conversational flow, visual design, and user engagement. The paper also identifies key future research directions, including mitigating language bias, enhancing ethical decision-making capabilities, improving user interaction and personalization, and developing robust governance frameworks. By solving these issues, we can ensure that AI chatbots like ChatGPT are used responsibly and effectively across a broad variety of applications. This review will be a valuable resource for researchers and practitioners in understanding the current state and future potential of AI chatbots like ChatGPT.",Artificial intelligence | Chatbots | ChatGPT | Computational intelligence | Conversational agents,140,2024,behavior,behavior+policy
583,2-s2.0-85182454787,10.1080/13683500.2023.2300032,https://doi.org/10.1080/13683500.2023.2300032,https://scholar.google.com/scholar?q=10.1080/13683500.2023.2300032,ar,Current Issues in Tourism,"Christensen, Jeff;Hansen, Jared M.;Wilson, Paul",Understanding the role and impact of Generative Artificial Intelligence (AI) hallucination within consumers’ tourism decision-making processes,"ChatGPT, which launched only a year ago, is the fastest-growing website in the world today. When generative AI software such as ChatGPT generates ideas for people, they often generate false ideas. This occurrence has been called ‘AI Hallucination’. It can include generating false text output that is extremely believable to completely gibberish. This source of potential misinformation has significant potential implications for the travel and tourism industry. Using survey responses from 900 consumers, this empirical study contributes to theorizing and examination of how consumers’ awareness of AI Hallucination potential combines with existing concepts from the Technology Acceptance Model (TAM) and Theory of Planned Behaviour (TPB) when it comes to the decision to use generative AI platforms such as ChatGPT for tourism planning. This research also examines if the consumers are actually able to discern AI Hallucination and why they select to use AI technologies over other tourism information sources, such as aggregated peer review websites like TripAdvisor, government tourism websites, or social media influencers. The results indicate that many consumers chose error-filled AI tourism itineraries over other options because they trust the AI to be more impartial and customized than the other sources.",challenges in technology usage in tourism | ChatGPT | Generative Artificial Intelligence (AI) | hallucination misinformation | Technology Acceptance Model (TAM) | tourism behaviour,107,2025,behavior,behavior+policy
691,2-s2.0-85180361775,10.1016/j.techsoc.2023.102442,https://doi.org/10.1016/j.techsoc.2023.102442,https://scholar.google.com/scholar?q=10.1016/j.techsoc.2023.102442,ar,Technology in Society,"Lian, Ying;Tang, Huiting;Xiang, Mengting;Dong, Xuefan",Public attitudes and sentiments toward ChatGPT in China: A text mining analysis based on social media,"ChatGPT, an innovative artificial intelligence language model, is attracted significant attention around the world, sparking both enthusiasm and controversy, but identifying its societal impact and addressing its potential concerns necessitate an understanding of the prevailing public's attitudes toward the tool. In this study, we leverage text mining techniques to analyze the sentiments and themes prevalent among Chinese social media discussions of ChatGPT. In total, 96,435 comment data and 55,186 repost data were used, and the results show that public discussions mainly focused on ChatGPT's technical support, AI-related effectiveness, impact on human work, and effects on education and technology. Concerns were related to disinformation risks, technological unemployment, and the human–computer relationship. In addition, we found that social media played a prominent role in information dissemination, while official media and government units demonstrated a limited influence. The insights obtained through this study can inform policymakers, industry stakeholders, and the public of the public's prevailing attitude toward AI technologies, and they can facilitate informed decision-making.",Artificial intelligence | ChatGPT | Online public opinion | Public perception | Social media | Text mining,85,2024,behavior,behavior+policy
399,2-s2.0-85194469685,10.1108/JMTM-12-2023-0530,https://doi.org/10.1108/JMTM-12-2023-0530,https://scholar.google.com/scholar?q=10.1108/JMTM-12-2023-0530,ar,Journal of Manufacturing Technology Management,"Ghobakhloo, Morteza;Fathi, Masood;Iranmanesh, Mohammad;Vilkas, Mantas;Grybauskas, Andrius;Amran, Azlan",Generative artificial intelligence in manufacturing: opportunities for actualizing Industry 5.0 sustainability goals,"Purpose: This study offers practical insights into how generative artificial intelligence (AI) can enhance responsible manufacturing within the context of Industry 5.0. It explores how manufacturers can strategically maximize the potential benefits of generative AI through a synergistic approach. Design/methodology/approach: The study developed a strategic roadmap by employing a mixed qualitative-quantitative research method involving case studies, interviews and interpretive structural modeling (ISM). This roadmap visualizes and elucidates the mechanisms through which generative AI can contribute to advancing the sustainability goals of Industry 5.0. Findings: Generative AI has demonstrated the capability to promote various sustainability objectives within Industry 5.0 through ten distinct functions. These multifaceted functions address multiple facets of manufacturing, ranging from providing data-driven production insights to enhancing the resilience of manufacturing operations. Practical implications: While each identified generative AI function independently contributes to responsible manufacturing under Industry 5.0, leveraging them individually is a viable strategy. However, they synergistically enhance each other when systematically employed in a specific order. Manufacturers are advised to strategically leverage these functions, drawing on their complementarities to maximize their benefits. Originality/value: This study pioneers by providing early practical insights into how generative AI enhances the sustainability performance of manufacturers within the Industry 5.0 framework. The proposed strategic roadmap suggests prioritization orders, guiding manufacturers in decision-making processes regarding where and for what purpose to integrate generative AI.",Digital transformation | Generative AI impact | Human centric | Industry 5.0 | Resilience | Sustainable development goals,84,2024,sustainability,behavior+sustainability
245,2-s2.0-85202719894,10.1002/sd.3152,https://doi.org/10.1002/sd.3152,https://scholar.google.com/scholar?q=10.1002/sd.3152,ar,Sustainable Development,"Wang, Shaofeng;Zhang, Hao",Promoting sustainable development goals through generative artificial intelligence in the digital supply chain: Insights from Chinese tourism SMEs,"Interdisciplinary advancements, such as generative artificial intelligence (AI) and digital supply chains, can significantly contribute to achieving sustainable development goals (SDGs), particularly within tourism. This paper illuminates how it works well, focusing on the underexplored area of Environmental, Social, and Governance (ESG) performance within small and medium-sized tourism enterprises (SMEs) in China. Through a survey of 429 international SMEs, we apply the Resource-Based View and Dynamic Capabilities Theory to investigate how generative AI, such as ChatGPT, in digital supply chains can enhance innovation, collaboration, and, ultimately, ESG performance. The empirical findings underscore the pivotal role of generative AI in augmenting ESG performance via bolstering innovation and collaboration within digital supply chains. Additionally, the moderating effect of customer involvement positively influences the relationship between the digital supply chain and ESG performance. By demonstrating these relations, our study contributes to theoretical and practical efforts toward sustainable tourism and the broader achievement of the SDGs.",Customer involvement | Digital supply chain innovation | ESG performance | Generative artificial intelligence | International SMEs | Sustainable development goals,78,2025,sustainability,policy+sustainability
407,2-s2.0-85170636566,10.1016/j.clsr.2023.105871,https://doi.org/10.1016/j.clsr.2023.105871,https://scholar.google.com/scholar?q=10.1016/j.clsr.2023.105871,ar,Computer Law and Security Review,"Hacker, Philipp",The European AI liability directives – Critique of a half-hearted approach and lessons for the future,"The optimal liability framework for AI systems remains an unsolved problem across the globe. With ChatGPT and other large generative models taking the technology to the next level, solutions are urgently needed. In a much-anticipated move, the European Commission advanced two proposals outlining the European approach to AI liability in September 2022: a novel AI Liability Directive (AILD) and a revision of the Product Liability Directive (PLD). They constitute the final cornerstone of AI regulation in the EU. Crucially, the liability proposals and the proposed EU AI Act are inherently intertwined: the latter does not contain any individual rights of affected persons, and the former lack specific, substantive rules on AI development and deployment. Taken together, these acts may well trigger a “Brussels effect” in AI regulation, with significant consequences for the US and other countries. Against this background, this paper makes three novel contributions. First, it examines in detail the liability proposals and shows that, while making steps in the right direction, they ultimately represent a half-hearted approach: if enacted as foreseen, AI liability in the EU will primarily rest on disclosure of evidence mechanisms and a set of narrowly defined presumptions concerning fault, defectiveness and causality. Hence, second, the article suggests amendments to the proposed AI liability framework. They are collected in a concise Annex at the end of the paper. I argue, inter alia, that the dichotomy between the fault-based AILD Proposal and the supposedly strict liability PLD Proposal is fictional and should be abandoned; that an EU framework for AI liability should comprise one fully harmonizing regulation instead of two insufficiently coordinated directives; and that the current proposals unjustifiably collapse fundamental distinctions between social and individual risk by equating high-risk AI systems in the AI Act with those under the liability framework. Third, based on an analysis of the key risks AI poses, the final part of the paper maps out a road for the future of AI liability and regulation, in the EU and beyond. More specifically, I make four key proposals. Effective compensation should be ensured by combining truly strict liability for certain high-risk AI systems with general presumptions of defectiveness, fault and causality in cases involving SMEs or non-high-risk AI systems. The paper introduces a novel distinction between illegitimate- and legitimate-harm models to delineate strict liability's scope. Truly strict liability should be reserved for high-risk AI systems that, from a social perspective, should not cause harm (illegitimate-harm models, e.g., autonomous vehicles or medical AI). Models meant to cause some unavoidable harm by ranking and rejecting individuals (legitimate-harm models, e.g., credit scoring or insurance scoring) may merely face rebuttable presumptions of defectiveness and causality. General-purpose AI systems and Foundation Models should only be subjected to high-risk regulation, including liability for high-risk AI systems, in specific high-risk use cases for which they are deployed. Consumers, in turn, ought to be liable based on regular fault, in general. Furthermore, innovation and legal certainty should be fostered through a comprehensive regime of safe harbours, defined quantitatively to the best extent possible. Moreover, trustworthy AI remains an important goal for AI regulation. Hence, the liability framework must specifically extend to non-discrimination cases and provide for clear rules concerning explainability (XAI). Finally, awareness for the climate effects of AI, and digital technology more broadly, is rapidly growing in computer science. In diametrical opposition to this shift in discourse and understanding, however, EU legislators have long neglected environmental sustainability in both the draft AI Act and the proposed liability regime. To counter this, I propose to jump-start sustainable AI regulation via sustainability impact assessments in the AI Act and sustainable design defects in the liability regime. In this way, the law may help spur not only fair AI and XAI, but also sustainable AI (SAI).",AI act | Artificial intelligence | ChatGPT | EU law | Innovation | Large generative AI models | Product liability | Sustainability,78,2023,sustainability,policy+sustainability
382,2-s2.0-85187354023,10.1016/j.jag.2024.103734,https://doi.org/10.1016/j.jag.2024.103734,https://scholar.google.com/scholar?q=10.1016/j.jag.2024.103734,re,International Journal of Applied Earth Observation and Geoinformation,"Wang, Siqin;Huang, Xiao;Liu, Pengyuan;Zhang, Mengxi;Biljecki, Filip;Hu, Tao;Fu, Xiaokang;Liu, Lingbo;Liu, Xintao;Wang, Ruomei;Huang, Yuanyuan;Yan, Jingjing;Jiang, Jinghan;Chukwu, Michaelmary;Reza Naghedi, Seyed;Hemmati, Moein;Shao, Yaxiong;Jia, Nan;Xiao, Zhiyang;Tian, Tian;Hu, Yaxin;Yu, Lixiaona;Yap, Winston;Macatulad, Edgardo;Chen, Zhuo;Cui, Yunhe;Ito, Koichi;Ye, Mengbi;Fan, Zicheng;Lei, Binyu;Bao, Shuming",Mapping the landscape and roadmap of geospatial artificial intelligence (GeoAI) in quantitative human geography: An extensive systematic review,"This paper brings a comprehensive systematic review of the application of geospatial artificial intelligence (GeoAI) in quantitative human geography studies, including the subdomains of cultural, economic, political, historical, urban, population, social, health, rural, regional, tourism, behavioural, environmental and transport geography. In this extensive review, we obtain 14,537 papers from the Web of Science in the relevant fields and select 1516 papers that we identify as human geography studies using GeoAI via human scanning conducted by several research groups around the world. We outline the GeoAI applications in human geography by systematically summarising the number of publications over the years, empirical studies across countries, the categories of data sources used in GeoAI applications, and their modelling tasks across different subdomains. We find out that existing human geography studies have limited capacity to monitor complex human behaviour and examine the non-linear relationship between human behaviour and its potential drivers—such limits can be overcome by GeoAI models with the capacity to handle complexity. We elaborate on the current progress and status of GeoAI applications within each subdomain of human geography, point out the issues and challenges, as well as propose the directions and research opportunities for using GeoAI in future human geography studies in the context of sustainable and open science, generative AI, and quantum revolution.",GeoAI | Geographic subdomains | Geospatial artificial intelligence | Human geography | Systematic review,76,2024,sustainability,behavior+sustainability
692,2-s2.0-85192168004,10.1162/dint_a_00243,https://doi.org/10.1162/dint_a_00243,https://scholar.google.com/scholar?q=10.1162/dint_a_00243,ar,Data Intelligence,"Hua, Shangying;Jin, Shuangci;Jiang, Shengyi",The Limitations and Ethical Considerations of ChatGPT,"With the advancements of artificial intelligence technology, ChatGPT, a new practice of artificial intelligence, holds immense potential across multiple fields. Its user-friendly human-machine interface, rapid response capabilities, and delivery of high-quality answers have attracted considerable attention and widespread usage. Regarded by many as a groundbreaking advancement in AI, ChatGPT represents a new milestone in the field. However, as with any technological evolution, the emergence of ChatGPT brings not only benefits, but also inevitable security risks and ethical issues. This paper provides specific information about ChatGPT, including its technology, limitations, ethical issues, governance paths and future directions. Specifically, we firstly offered a thorough exploration of the technical implementation details of GPT series models. Next, we provided an intricate analysis elucidating the reasons for limitations and scrutinized the consequential impacts, such as malicious misuse, privacy violation, and so on. Finally, we explore diverse governance paths to mitigate the impacts of ChatGPT and present future directions. This review aims to equip users with crucial knowledge, facilitating well-informed decision-making, effectively handling of potential challenges in employing ChatGPT, and staying abreast with the rapidly evolving landscape of this technology.",Artificial Intelligence | ChatGPT | ChatGPT Technology | Ethical considerations | Limitations,74,2024,behavior,behavior+policy
237,2-s2.0-85218892551,10.3390/electronics14040696,https://doi.org/10.3390/electronics14040696,https://scholar.google.com/scholar?q=10.3390/electronics14040696,re,Electronics Switzerland,"Miller, Tymoteusz;Durlik, Irmina;Kostecka, Ewelina;Kozlovska, Polina;Łobodzińska, Adrianna;Sokołowska, Sylwia;Nowy, Agnieszka",Integrating Artificial Intelligence Agents with the Internet of Things for Enhanced Environmental Monitoring: Applications in Water Quality and Climate Data,"The integration of artificial intelligence (AI) agents with the Internet of Things (IoT) has marked a transformative shift in environmental monitoring and management, enabling advanced data gathering, in-depth analysis, and more effective decision making. This comprehensive literature review explores the integration of AI and IoT technologies within environmental sciences, with a particular focus on applications related to water quality and climate data. The methodology involves a systematic search and selection of relevant studies, followed by thematic, meta-, and comparative analyses to synthesize current research trends, benefits, challenges, and gaps. The review highlights how AI enhances IoT’s data collection capabilities through advanced predictive modeling, real-time analytics, and automated decision making, thereby improving the accuracy, timeliness, and efficiency of environmental monitoring systems. Key benefits identified include enhanced data precision, cost efficiency, scalability, and the facilitation of proactive environmental management. Nevertheless, this integration encounters substantial obstacles, including issues related to data quality, interoperability, security, technical constraints, and ethical concerns. Future developments point toward enhancements in AI and IoT technologies, the incorporation of innovations like blockchain and edge computing, the potential formation of global environmental monitoring systems, and greater public involvement through citizen science initiatives. Overcoming these challenges and embracing new technological trends could enable AI and IoT to play a pivotal role in strengthening environmental sustainability and resilience.",AI–IoT integration | artificial intelligence (AI) agents | climate data | environmental monitoring | Internet of Things (IoT) | predictive analytics | real-time decision making | smart environmental systems | sustainable environmental management | water quality,70,2025,sustainability,behavior+sustainability
698,2-s2.0-85196946747,10.2196/52399,https://doi.org/10.2196/52399,https://scholar.google.com/scholar?q=10.2196/52399,ar,Journal of Medical Internet Research,"Denecke, Kerstin;May, Richard;Romero, Octavio Rivera;de Arriba-Muñoz, Antonio;Chapman, Wendy;Chow, James C.L.;Davies, Shauna;Grainger, Rebecca;Janssen, Boris V.;Ji, Shaoxiong;Kreuzthaler, Markus;Lecler, Augustin;Paton, Chris;Petersen, Carolyn;Lacalle, Juan Ramón;Remedios, Denis;Ropero, Jorge;Sevillano, Jose L.;Sezgin, Emre;Traver, Vicente;Trigo, Jesús Daniel;Verspoor, Karin",Potential of Large Language Models in Health Care: Delphi Study,"Background: A large language model (LLM) is a machine learning model inferred from text data that captures subtle patterns of language use in context. Modern LLMs are based on neural network architectures that incorporate transformer methods. They allow the model to relate words together through attention to multiple words in a text sequence. LLMs have been shown to be highly effective for a range of tasks in natural language processing (NLP), including classification and information extraction tasks and generative applications. Objective: The aim of this adapted Delphi study was to collect researchers’ opinions on how LLMs might influence health care and on the strengths, weaknesses, opportunities, and threats of LLM use in health care. Methods: We invited researchers in the fields of health informatics, nursing informatics, and medical NLP to share their opinions on LLM use in health care. We started the first round with open questions based on our strengths, weaknesses, opportunities, and threats framework. In the second and third round, the participants scored these items. Results: The first, second, and third rounds had 28, 23, and 21 participants, respectively. Almost all participants (26/28, 93% in round 1 and 20/21, 95% in round 3) were affiliated with academic institutions. Agreement was reached on 103 items related to use cases, benefits, risks, reliability, adoption aspects, and the future of LLMs in health care. Participants offered several use cases, including supporting clinical tasks, documentation tasks, and medical research and education, and agreed that LLM-based systems will act as health assistants for patient education. The agreed-upon benefits included increased efficiency in data handling and extraction, improved automation of processes, improved quality of health care services and overall health outcomes, provision of personalized care, accelerated diagnosis and treatment processes, and improved interaction between patients and health care professionals. In total, 5 risks to health care in general were identified: cybersecurity breaches, the potential for patient misinformation, ethical concerns, the likelihood of biased decision-making, and the risk associated with inaccurate communication. Overconfidence in LLM-based systems was recognized as a risk to the medical profession. The 6 agreed-upon privacy risks included the use of unregulated cloud services that compromise data security, exposure of sensitive patient data, breaches of confidentiality, fraudulent use of information, vulnerabilities in data storage and communication, and inappropriate access or use of patient data. Conclusions: Future research related to LLMs should not only focus on testing their possibilities for NLP-related tasks but also consider the workflows the models could contribute to and the requirements regarding quality, integration, and regulations needed for successful implementation in practice.",artificial intelligence | attitude | attitudes | Delphi | Delphi study | experience | experiences | future | health care | implementation | informatics | innovation | interview | interviews | language model | large language models | LLMs | natural language processing | NLP | opinion | perception | perceptions | perspective | perspectives,66,2024,behavior,behavior+policy
569,2-s2.0-85217552455,10.1371/journal.pone.0315011,https://doi.org/10.1371/journal.pone.0315011,https://scholar.google.com/scholar?q=10.1371/journal.pone.0315011,ar,Plos One,"Ravšelj, Dejan;Keržič, Damijana;Tomaževič, Nina;Umek, Lan;Brezovar, Nejc;Iahad, Noorminshah A.;Abdulla, Ali Abdulla;Akopyan, Anait;Segura, Magdalena Waleska Aldana;AlHumaid, Jehan;Allam, Mohamed Farouk;Alló, Maria;Andoh, Raphael Papa Kweku;Andronic, Octavian;Arthur, Yarhands Dissou;Aydin, Fatih;Badran, Amira;Balbontín-Alvarado, Roxana;Saad, Helmi Ben;Bencsik, Andrea;Benning, Isaac;Besimi, Adrian;da Silva Bezerra, Denilson;Buizza, Chiara;Burro, Roberto;Bwalya, Anthony;Cachero, Cristina;Castillo-Briceno, Patricia;Castro, Harold;Chai, Ching Sing;Charalambous, Constadina;Chiu, Thomas K.F.;Clipa, Otilia;Colombari, Ruggero;Corral Escobedo, Luis José H.;Costa, Elísio;Creţulescu, Radu George;Crispino, Marta;Cucari, Nicola;Dalton, Fergus;Kaya, Meva Demir;Dumić-Čule, Ivo;Dwidienawati, Diena;Ebardo, Ryan;Egbenya, Daniel Lawer;Faris, Moez Al Islam Ezzat;Fečko, Miroslav;Ferrinho, Paulo;Florea, Adrian;Fong, Chun Yuen;Francis, Zoë;Ghilardi, Alberto;González-Fernández, Belinka;Hau, Daniela;Hossain, Md Shamim;Hug, Theo;Inasius, Fany;Ismail, Maryam Jaffar;Jahić, Hatidža;Jessa, Morrison Omokiniovo;Kapanadze, Marika;Kar, Sujita Kumar;Kateeb, Elham Talib;Kaya, Feridun;Khadri, Hanaa Ouda;Kikuchi, Masao;Kobets, Vitaliy Mykolayovych;Kostova, Katerina Metodieva;Krasmane, Evita;Lau, Jesus;Law, Wai Him Crystal;Lazǎr, Florin;Lazović-Pita, Lejla;Lee, Vivian Wing Yan;Li, Jingtai;López-Aguilar, Diego Vinicio;Luca, Adrian;Luciano, Ruth Garcia;Machin-Mastromatteo, Juan D.;Madi, Marwa;Manguele, Alexandre Lourenço;Manrique, Rubén Francisco;Mapulanga, Thumah;Marimon, Frederic;Marinova, Galia Ilieva;Mas-Machuca, Marta;Mejía-Rodríguez, Oliva;Meletiou-Mavrotheris, Maria;Méndez-Prado, Silvia Mariela;Meza-Cano, José Manuel;Mirķe, Evija;Mishra, Alpana;Mital, Ondrej;Mollica, Cristina;Morariu, Daniel Ionel;Mospan, Natalia;Mukuka, Angel;Jiménez, Silvana Guadalupe Navarro;Nikaj, Irena;Nisheva, Maria Mihaylova",Higher education students' perceptions of ChatGPT: A global study of early reactions,"The paper presents the most comprehensive and large-scale global study to date on how higher education students perceived the use of ChatGPT in early 2024. With a sample of 23,218 students from 109 countries and territories, the study reveals that students primarily used ChatGPT for brainstorming, summarizing texts, and finding research articles, with a few using it for professional and creative writing. They found it useful for simplifying complex information and summarizing content, but less reliable for providing information and supporting classroom learning, though some considered its information clearer than that from peers and teachers. Moreover, students agreed on the need for AI regulations at all levels due to concerns about ChatGPT promoting cheating, plagiarism, and social isolation. However, they believed ChatGPT could potentially enhance their access to knowledge and improve their learning experience, study efficiency, and chances of achieving good grades. While ChatGPT was perceived as effective in potentially improving AI literacy, digital communication, and content creation skills, it was less useful for interpersonal communication, decision-making, numeracy, native language proficiency, and the development of critical thinking skills. Students also felt that ChatGPT would boost demand for AI-related skills and facilitate remote work without significantly impacting unemployment. Emotionally, students mostly felt positive using ChatGPT, with curiosity and calmness being the most common emotions. Further examinations reveal variations in students’ perceptions across different socio-demographic and geographic factors, with key factors influencing students’ use of ChatGPT also being identified. Higher education institutions’ managers and teachers may benefit from these findings while formulating the curricula and instructions/regulations for ChatGPT use, as well as when designing the teaching methods and assessment tools. Moreover, policymakers may also consider the findings when formulating strategies for secondary and higher education system development, especially in light of changing labor market needs and related digital skills development.",,63,2025,behavior,behavior+policy
385,2-s2.0-85184246435,10.1016/j.heliyon.2024.e24727,https://doi.org/10.1016/j.heliyon.2024.e24727,https://scholar.google.com/scholar?q=10.1016/j.heliyon.2024.e24727,ar,Heliyon,"Raman, Raghu;Kumar Nair, Vinith;Nedungadi, Prema;Kumar Sahu, Aditya;Kowalski, Robin;Ramanathan, Sasangan;Achuthan, Krishnashree","Fake news research trends, linkages to generative artificial intelligence and sustainable development goals","In the digital age, where information is a cornerstone for decision-making, social media's not-so-regulated environment has intensified the prevalence of fake news, with significant implications for both individuals and societies. This study employs a bibliometric analysis of a large corpus of 9678 publications spanning 2013–2022 to scrutinize the evolution of fake news research, identifying leading authors, institutions, and nations. Three thematic clusters emerge: Disinformation in social media, COVID-19-induced infodemics, and techno-scientific advancements in auto-detection. This work introduces three novel contributions: 1) a pioneering mapping of fake news research to Sustainable Development Goals (SDGs), indicating its influence on areas like health (SDG 3), peace (SDG 16), and industry (SDG 9); 2) the utilization of Prominence percentile metrics to discern critical and economically prioritized research areas, such as misinformation and object detection in deep learning; and 3) an evaluation of generative AI's role in the propagation and realism of fake news, raising pressing ethical concerns. These contributions collectively provide a comprehensive overview of the current state and future trajectories of fake news research, offering valuable insights for academia, policymakers, and industry.",Deep fake | Ethics | Fake news | Generative AI | Prominence percentile | Sustainable development goal,62,2024,sustainability,behavior+policy+sustainability
706,2-s2.0-85165284873,10.1177/02663821231187991,https://doi.org/10.1177/02663821231187991,https://scholar.google.com/scholar?q=10.1177/02663821231187991,ar,Business Information Review,"Ayinde, Lateef;Wibowo, Muhamad Prabu;Ravuri, Benhur;Emdad, Forhan Bin",ChatGPT as an important tool in organizational management: A review of the literature,"ChatGPT is an emerging technology that revolutionizes organizational practices, fundamentally altering how individuals in organizations search for, generate, and utilize information within the workplace. The effective functioning of many organizations heavily relies on data and information. ChatGPT has streamlined the process of working with data and information, making it more accessible for organizations and the individuals involved. However, the adoption of ChatGPT also presents challenges across various domains, including social, economic, and legal considerations. This study conducts a comprehensive literature review to explore multiple perspectives on integrating ChatGPT into organizational management. It examines various aspects, such as the development of ChatGPT, its practical uses, ethical implications, governance mechanisms, regulations and policies. This study aims to guide managers and stakeholders in effectively incorporating ChatGPT into their organizational processes. This study provides a detailed examination of ChatGPT's impact on organizational management, offering valuable insights to practitioners and scholars alike, aiming to navigate the complexities and harness the benefits of this transformative technology. By understanding the implications and leveraging the potential of ChatGPT, organizations can enhance their operations and decision-making processes.",ChatGPT | ethics | goveranance | knowledge organization | policies,59,2023,behavior,behavior+policy
344,2-s2.0-85213202921,10.3390/electronics13244874,https://doi.org/10.3390/electronics13244874,https://scholar.google.com/scholar?q=10.3390/electronics13244874,re,Electronics Switzerland,"Lifelo, Zita;Ding, Jianguo;Ning, Huansheng;Qurat-Ul-Ain, ;Dhelim, Sahraoui","Artificial Intelligence-Enabled Metaverse for Sustainable Smart Cities: Technologies, Applications, Challenges, and Future Directions","Rapid urbanisation has intensified the need for sustainable solutions to address challenges in urban infrastructure, climate change, and resource constraints. This study reveals that Artificial Intelligence (AI)-enabled metaverse offers transformative potential for developing sustainable smart cities. AI techniques, such as machine learning, deep learning, generative AI (GAI), and large language models (LLMs), enhance the metaverse’s capabilities in data analysis, urban decision making, and personalised user experiences. The study further examines how these advanced AI models facilitate key metaverse technologies such as big data analytics, natural language processing (NLP), computer vision, digital twins, Internet of Things (IoT), Edge AI, and 5G/6G networks. Applications across various smart city domains—environment, mobility, energy, health, governance, and economy, and real-world use cases of virtual cities like Singapore, Seoul, and Lisbon are presented, demonstrating AI’s effectiveness in the metaverse for smart cities. However, AI-enabled metaverse in smart cities presents challenges related to data acquisition and management, privacy, security, interoperability, scalability, and ethical considerations. These challenges’ societal and technological implications are discussed, highlighting the need for robust data governance frameworks and AI ethics guidelines. Future directions emphasise advancing AI model architectures and algorithms, enhancing privacy and security measures, promoting ethical AI practices, addressing performance measures, and fostering stakeholder collaboration. By addressing these challenges, the full potential of AI-enabled metaverse can be harnessed to enhance sustainability, adaptability, and livability in smart cities.",adaptive urban systems | artificial intelligence | digital twins | generative AI | large language models | metaverse | smart cities | sustainable cities | urban planning | urban transformation,57,2024,sustainability,behavior+policy+sustainability
682,2-s2.0-85191537258,10.1093/bjd/ljae040,https://doi.org/10.1093/bjd/ljae040,https://scholar.google.com/scholar?q=10.1093/bjd/ljae040,re,British Journal of Dermatology,"Gordon, Emily R.;Trager, Megan H.;Kontos, Despina;Weng, Chunhua;Geskin, Larisa J.;Dugdale, Lydia S.;Samie, Faramarz H.",Ethical considerations for artificial intelligence in dermatology: a scoping review,"The field of dermatology is experiencing the rapid deployment of artificial intelligence (AI), from mobile applications (apps) for skin cancer detection to large language models like ChatGPT that can answer generalist or specialist questions about skin diagnoses. With these new applications, ethical concerns have emerged. In this scoping review, we aimed to identify the applications of AI to the field of dermatology and to understand their ethical implications. We used a multifaceted search approach, searching PubMed, MEDLINE, Cochrane Library and Google Scholar for primary literature, following the PRISMA Extension for Scoping Reviews guidance. Our advanced query included terms related to dermatology, AI and ethical considerations. Our search yielded 202 papers. After initial screening, 68 studies were included. Thirty-two were related to clinical image analysis and raised ethical concerns for misdiagnosis, data security, privacy violations and replacement of dermatologist jobs. Seventeen discussed limited skin of colour representation in datasets leading to potential misdiagnosis in the general population. Nine articles about teledermatology raised ethical concerns, including the exacerbation of health disparities, lack of standardized regulations, informed consent for AI use and privacy challenges. Seven addressed inaccuracies in the responses of large language models. Seven examined attitudes toward and trust in AI, with most patients requesting supplemental assessment by a physician to ensure reliability and accountability. Benefits of AI integration into clinical practice include increased patient access, improved clinical decision-making, efficiency and many others. However, safeguards must be put in place to ensure the ethical application of AI.",,51,2024,behavior,behavior+policy
519,2-s2.0-105004460462,10.1038/s41591-025-03727-2,https://doi.org/10.1038/s41591-025-03727-2,https://scholar.google.com/scholar?q=10.1038/s41591-025-03727-2,ar,Nature Medicine,"Sandmann, Sarah;Hegselmann, Stefan;Fujarski, Michael;Bickmann, Lucas;Wild, Benjamin;Eils, Roland;Varghese, Julian",Benchmark evaluation of DeepSeek large language models in clinical decision-making,"Large language models (LLMs) are increasingly transforming medical applications. However, proprietary models such as GPT-4o face significant barriers to clinical adoption because they cannot be deployed on site within healthcare institutions, making them noncompliant with stringent privacy regulations. Recent advancements in open-source LLMs such as DeepSeek models offer a promising alternative because they allow efficient fine-tuning on local data in hospitals with advanced information technology infrastructure. Here, to demonstrate the clinical utility of DeepSeek-V3 and DeepSeek-R1, we benchmarked their performance on clinical decision support tasks against proprietary LLMs, including GPT-4o and Gemini-2.0 Flash Thinking Experimental. Using 125 patient cases with sufficient statistical power, covering a broad range of frequent and rare diseases, we found that DeepSeek models perform equally well and in some cases better than proprietary LLMs. Our study demonstrates that open-source LLMs can provide a scalable pathway for secure model training enabling real-world medical applications in accordance with data privacy and healthcare regulations.",,50,2025,behavior,behavior+policy
365,2-s2.0-85204110632,10.3390/su16177435,https://doi.org/10.3390/su16177435,https://scholar.google.com/scholar?q=10.3390/su16177435,ar,Sustainability Switzerland,"Suanpang, Pannee;Pothipassa, Pattanaphong",Integrating Generative AI and IoT for Sustainable Smart Tourism Destinations,"This paper aims to develop a groundbreaking approach to fostering inclusive smart tourism destinations by integrating generative artificial intelligence (Gen AI) with natural language processing (NLP) and the Internet of Things (IoT) into an intelligent platform that supports tourism decision making and travel planning in smart tourism destinations. The acquisition of this new technology was conducted using Agile methodology through requirements analysis, system architecture analysis and design, implementation, and user evaluation. The results revealed that the synergistic combination of these technologies was organized into three tiers. The system provides information, including place names, images, descriptive text, and an audio option for users to listen to the information, supporting tourists with disabilities. Employing advanced AI algorithms alongside NLP, developed systems capable of generating predictive analytics, personalized recommendations, and conducting real-time, multilingual communication with tourists. This system was implemented and evaluated in Suphan Buri and Ayutthaya, UNESCO World Heritage sites in Thailand, with 416 users participating. The results showed that system satisfaction was influenced by (1) the tourism experience, (2) tourism planning and during-trip factors (attention, interest, and usage), and (3) emotion. The relative Chi-square (χ<sup>2</sup>/df) of 1.154 indicated that the model was suitable. The Comparative Fit Index (CFI) was 0.990, the Goodness-of-Fit Index (GFI) was 0.965, and the model based on the research hypothesis was consistent with the empirical data. This paper contributions significant advancements in the field of smart tourism by demonstrating the integration of Gen AI, NLP, and the IoT and offering practical solutions and theoretical insights that enhance accessibility, personalization, and environmental sustainability in tourism.",generative artificial intelligence | IoT | natural language processing | smart tourism | sustainable tourism,49,2024,sustainability,behavior+sustainability
683,2-s2.0-85190430716,10.1016/j.tifs.2024.104488,https://doi.org/10.1016/j.tifs.2024.104488,https://scholar.google.com/scholar?q=10.1016/j.tifs.2024.104488,re,Trends in Food Science and Technology,"Ma, Peihua;Tsai, Shawn;He, Yiyang;Jia, Xiaoxue;Zhen, Dongyang;Yu, Ning;Wang, Qin;Ahuja, Jaspreet K.C.;Wei, Cheng I.","Large language models in food science: Innovations, applications, and future","Background: Large Language Models (LLMs) are increasingly significant in food science, transforming areas such as recipe development, nutritional analysis, food safety, and supply chain management. These models bring sophisticated decision-making, predictive analytics, and natural language processing capabilities to various aspects of food science. Scope and approach: The review focuses on the application of LLMs in enhancing food science, with a strong emphasis on food safety, especially in contaminant detection and risk assessment. It addresses the roles of AI and LLMs in regulatory compliance and food quality control. Challenges like data biases, misinformation risks, and implementation hurdles, including data limitations and ethical concerns, are discussed. The necessity for interdisciplinary collaboration to overcome these challenges is also highlighted. Key findings and conclusions: LLMs hold significant potential in automating processes and improving accuracy and efficiency in the global food system. Successful implementation requires continuous updates and ethical considerations. The paper provides insights for academics, industry professionals, and policymakers on the impact of LLMs in food science, emphasizing the importance of interdisciplinary efforts in this domain. Despite potential challenges, the integration of LLMs in food science promises transformative advancements.",Generative AI | Large language model | Natural language processing | Pre-trained model,47,2024,behavior,behavior+policy
665,2-s2.0-85200230703,10.1016/j.jretconser.2024.103997,https://doi.org/10.1016/j.jretconser.2024.103997,https://scholar.google.com/scholar?q=10.1016/j.jretconser.2024.103997,ar,Journal of Retailing and Consumer Services,"Gupta, Rohit;Rathore, Bhawana",Exploring the generative AI adoption in service industry: A mixed-method analysis,"In the last few years, many service organisations have been exploring the use of Generative Artificial Intelligence (GAI) tools for their businesses and upgrading their existing processes. These tools have the potential and capability to transform the business world in various aspects. However, serval service organisations are facing many challenges while adopting the GAI tools in their organisations. In a similar context, this study explores the adoption of GAI barriers through two studies by a mixed-method approach. The first study is based on YouTube datasets of selected videos where GAI adoption challenges, problems, and barriers were discussed. Further, these YouTube datasets were analysed through text mining and empirical modelling techniques. In the second study, an extensive literature review was done and critical barriers to GAI adoption were identified based on the extensive literature review. Further, these barriers were analysed through three theoretical lenses and a hybrid fuzzy multicriteria decision-making approach. In addition, the results from the first study were further matched and verified with our second study. This establishes the relevance of adopting a mixed-method approach. Our major findings are: (i) trust, anticipation, and surprise emerged as the strongest emotions of the viewers who posted their comments on the YouTube videos; (ii) Five major barriers are revealed through topic analysis of YouTube transcripts and these are ethical, technological, regulations & policies, cost, and human resources; (iii) Six major barriers are identified through second study are privacy & security, return on investment, running cost, misuse, over-reliance, and Lack of digital infrastructure.",FDM | Fuzzy AHP | Fuzzy DEMATEL | Generative AI | Service industry | Text mining | Topic modelling,44,2024,behavior,behavior+policy
703,2-s2.0-85190893643,10.2196/52483,https://doi.org/10.2196/52483,https://scholar.google.com/scholar?q=10.2196/52483,ar,Jmir Medical Education,"Wu, Yijun;Zheng, Yue;Feng, Baijie;Yang, Yuqi;Kang, Kai;Zhao, Ailin",Embracing ChatGPT for Medical Education: Exploring Its Impact on Doctors and Medical Students,"ChatGPT (OpenAI), a cutting-edge natural language processing model, holds immense promise for revolutionizing medical education. With its remarkable performance in language-related tasks, ChatGPT offers personalized and efficient learning experiences for medical students and doctors. Through training, it enhances clinical reasoning and decision-making skills, leading to improved case analysis and diagnosis. The model facilitates simulated dialogues, intelligent tutoring, and automated question-answering, enabling the practical application of medical knowledge. However, integrating ChatGPT into medical education raises ethical and legal concerns. Safeguarding patient data and adhering to data protection regulations are critical. Transparent communication with students, physicians, and patients is essential to ensure their understanding of the technology’s purpose and implications, as well as the potential risks and benefits. Maintaining a balance between personalized learning and face-to-face interactions is crucial to avoid hindering critical thinking and communication skills. Despite challenges, ChatGPT offers transformative opportunities. Integrating it with problem-based learning, team-based learning, and case-based learning methodologies can further enhance medical education. With proper regulation and supervision, ChatGPT can contribute to a well-rounded learning environment, nurturing skilled and knowledgeable medical professionals ready to tackle health care challenges. By emphasizing ethical considerations and human-centric approaches, ChatGPT’s potential can be fully harnessed in medical education, benefiting both students and patients alike.",,43,2024,behavior,behavior+policy
406,2-s2.0-85164249102,10.1186/s12909-023-04427-6,https://doi.org/10.1186/s12909-023-04427-6,https://scholar.google.com/scholar?q=10.1186/s12909-023-04427-6,ar,BMC Medical Education,"Merry, Lisa;Castiglione, Sonia Angela;Rouleau, Geneviève;Létourneau, Dimitri;Larue, Caroline;Deschênes, Marie France;Gonsalves, Dolly Maria;Ahmed, Lubana","Continuing professional development (CPD) system development, implementation, evaluation and sustainability for healthcare professionals in low- and lower-middle-income countries: a rapid scoping review","Background: Policymakers and program developers in low-and lower-middle-income countries (LLMICs) are increasingly seeking evidence-based information and guidance on how to successfully develop and implement continuing professional development (CPD) systems. We conducted a rapid scoping review to map and synthesize what is known regarding the development, implementation, evaluation and sustainability of CPD systems for healthcare professionals in LLMICs. Methods: We searched MEDLINE, CINAHL and Web of Science. Reference lists were screened and a cited reference search of included articles was conducted. Supplementary information on the CPD systems identified in the articles was also identified via an online targeted grey literature search. English, French and Spanish literature published from 2011 to 2021 were considered. Data were extracted and combined and summarized according to country/region and healthcare profession via tables and narrative text. Results: We included 15 articles and 23 grey literature sources. Africa was the region most represented followed by South and Southeast Asia and the Middle East. The literature most often referred to CPD systems for nurses and midwives; CPD systems for physicians were frequently referred to as well. Findings show that leadership and buy-in from key stakeholders, including government bodies and healthcare professional organizations, and a framework are essential for the development, implementation and sustainability of a CPD system in a LLMIC. The guiding framework should incorporate a regulatory perspective, as well as a conceptual lens (that informs CPD objectives and methods), and should consider contextual factors (support for CPD, healthcare context and population health needs). In terms of important steps to undertake, these include: a needs assessment; drafting of a policy, which details the regulations (laws/norms), the CPD requirements and an approach for monitoring, including an accreditation mechanism; a financing plan; identification and production of appropriate CPD materials and activities; a communication strategy; and an evaluation process. Conclusion: Leadership, a framework and a clearly delineated plan that is responsive to the needs and context of the setting, are essential for the development, implementation and sustainability of a CPD system for healthcare professionals in a LLMIC.",Bangladesh | Continuing professional development (CPD) | CPD system development and implementation | Low- and lower-middle income countries | Rapid scoping review,41,2023,sustainability,policy+sustainability
400,2-s2.0-85192831685,10.54648/COLA2024025,https://doi.org/10.54648/COLA2024025,https://scholar.google.com/scholar?q=10.54648/COLA2024025,ar,Common Market Law Review,"Hacker, Philipp",SUSTAINABLE AI REGULATION,"This article addresses a critical gap in the current AI regulatory discourse by focusing on the environmental sustainability ofAI and technology more broadly, a topic often overlooked both in environmental law and in technology regulation, such as the General Data Protection Regulation (GDPR) or the EU AI Act. Recognizing AI’s significant impact on climate change and its substantial water consumption, especially in large generative models like ChatGPT, GPT-4, or Gemini, the article aims to integrate sustainability considerations into technology regulation, in three steps. First, while current EU environmental law does not directly address these issues, there is potential to reinterpret existing legislation, such as the GDPR, to support sustainability goals. Counterintuitively, the article argues that this also implies the need to balance individual rights, such as the right to erasure, with collective environmental interests. Second, based on an analysis of current law, and the proposed EU AI Act, the article suggests a suite of policy measures to align AI and technology regulation with environmental sustainability. They extend beyond mere transparency mechanisms, such as disclosing greenhouse gas footprints, to include a mix of strategies like co-regulation, sustainability by design, restrictions on training data, and consumption caps, potentially integrating AI and technology more broadly into the EU emissions trading regime. Third, this regulatory toolkit could serve as a blueprint for other technologies with high environmental impacts, such as blockchain and metaverse applications. The aim is to establish a comprehensive framework that addresses the dual fundamental societal transformations of digitization and climate change mitigation.",,39,2024,sustainability,policy+sustainability
705,2-s2.0-85175046033,10.1016/j.envc.2023.100782,https://doi.org/10.1016/j.envc.2023.100782,https://scholar.google.com/scholar?q=10.1016/j.envc.2023.100782,ar,Environmental Challenges,"Egbemhenghe, Abel U.;Ojeyemi, Toluwalase;Iwuozor, Kingsley O.;Emenike, Ebuka Chizitere;Ogunsanya, Tolu I.;Anidiobi, Stella Ukamaka;Adeniyi, Adewale George","Revolutionizing water treatment, conservation, and management: Harnessing the power of AI-driven ChatGPT solutions","This study analyzes the global water crisis and the pressing need for innovation in water treatment, conservation, and management practices. It introduces potentially transformative solutions involving the use of ChatGPT to address water-related challenges. The research underscores the potential of AI-Driven ChatGPT applications in enhancing water management schemes through real-time insights, optimization of resource usage, and predictive maintenance. The paper dilates upon the role of ChatGPT in improving water quality control, enriching decision-making systems, optimizing water usage, and promoting precision irrigation. It also discusses various scenarios where ChatGPT has been applied in this regard, such as in Klir Comply and its integration into Rammas. The study further discusses the significant water consumption and environmental implications of AI models like ChatGPT and suggests tangible solutions such as employing renewable energy sources and water recycling systems. Additionally, it delves into ethical and regulatory implications of integrating AI-Driven ChatGPT solutions in water management, covering aspects of data privacy, transparency, accountability, and conformity to international standards. It emphasizes the need for concerted efforts to construct a responsible AI governance model and highlights the importance of education and awareness regarding AI ethics and regulations.",Artificial intelligence | Environmental impact | Sustainability | Technology Integration | Water quality,38,2023,behavior,behavior+policy
351,2-s2.0-85196276525,10.1007/s11831-024-10115-5,https://doi.org/10.1007/s11831-024-10115-5,https://scholar.google.com/scholar?q=10.1007/s11831-024-10115-5,ar,Archives of Computational Methods in Engineering,"Bhattacharya, Pronaya;Prasad, Vivek Kumar;Verma, Ashwin;Gupta, Deepak;Sapsomboon, Assadaporn;Viriyasitavat, Wattana;Dhiman, Gaurav",Demystifying ChatGPT: An In-depth Survey of OpenAI’s Robust Large Language Models,"Recent advancements in natural language processing (NLP) have catalyzed the development of models capable of generating coherent and contextually relevant responses. Such models are applied across a diverse array of applications, including but not limited to chatbots, expert systems, question-and-answer robots, and language translation systems. Large Language Models (LLMs), exemplified by OpenAI’s Generative Pretrained Transformer (GPT), have significantly transformed the NLP landscape. They have introduced unparalleled abilities in generating text that is not only contextually appropriate but also semantically rich. This evolution underscores a pivotal shift towards more sophisticated and intuitive language understanding and generation capabilities within the field. Models based on GPT are developed through extensive training on vast datasets, enabling them to grasp patterns akin to human writing styles and deliver insightful responses to intricate questions. These models excel in condensing text, extending incomplete passages, crafting imaginative narratives, and emulating conversational exchanges. However, GPT LLMs are not without their challenges, including ethical dilemmas and the propensity for disseminating misinformation. Additionally, the deployment of these models at a practical scale necessitates a substantial investment in training and computational resources, leading to concerns regarding their sustainability. ChatGPT, a variant rooted in transformer-based architectures, leverages a self-attention mechanism for data sequences and a reinforcement learning-based human feedback (RLHF) system. This enables the model to grasp long-range dependencies, facilitating the generation of contextually appropriate outputs. Despite ChatGPT marking a significant leap forward in NLP technology, there remains a lack of comprehensive discourse on its architecture, efficacy, and inherent constraints. Therefore, this survey aims to elucidate the ChatGPT model, offering an in-depth exploration of its foundational structure and operational efficacy. We meticulously examine Chat-GPT’s architecture and training methodology, alongside a critical analysis of its capabilities in language generation. Our investigation reveals ChatGPT’s remarkable aptitude for producing text indistinguishable from human writing, whilst also acknowledging its limitations and susceptibilities to bias. This analysis is intended to provide a clearer understanding of ChatGPT, fostering a nuanced appreciation of its contributions and challenges within the broader NLP field. We also explore the ethical and societal implications of this technology, and discuss the future of NLP and AI. Our study provides valuable insights into the inner workings of ChatGPT, and helps to shed light on the potential of LLMs for shaping the future of technology and society. The approach used as Eco-GPT, with a three-level cascade (GPT-J, J1-G, GPT-4), achieves 73% and 60% cost savings in CaseHold and CoQA datasets, outperforming GPT-4.",,37,2024,sustainability,policy+sustainability
354,2-s2.0-85182399201,10.1057/s41599-023-02464-6,https://doi.org/10.1057/s41599-023-02464-6,https://scholar.google.com/scholar?q=10.1057/s41599-023-02464-6,ar,Humanities and Social Sciences Communications,"Polyportis, Athanasios;Pahos, Nikolaos",Navigating the perils of artificial intelligence: a focused review on ChatGPT and responsible research and innovation,"While the rise of artificial intelligence (AI) tools holds promise for delivering benefits, it is important to acknowledge the associated risks of their deployment. In this article, we conduct a focused literature review to address two central research inquiries concerning ChatGPT and similar AI tools. Firstly, we examine the potential pitfalls linked with the development and implementation of ChatGPT across the individual, organizational, and societal levels. Secondly, we explore the role of a multi-stakeholder responsible research and innovation framework in guiding chatbots’ sustainable development and utilization. Drawing inspiration from responsible research and innovation and stakeholder theory principles, we underscore the necessity of comprehensive ethical guidelines to navigate the design, inception, and utilization of emerging AI innovations. The findings of the focused review shed light on the potential perils of ChatGPT implementation across various societal levels, including issues such as devaluation of relationships, unemployment, privacy concerns, bias, misinformation, and digital inequities. Furthermore, the proposed multi-stakeholder Responsible Research and Innovation framework can empower AI stakeholders to proactively anticipate and deliberate upon AI’s ethical, social, and environmental implications, thus substantially contributing to the pursuit of responsible AI implementation.",,37,2024,sustainability,policy+sustainability
225,2-s2.0-85216848180,10.1016/j.ese.2025.100526,https://doi.org/10.1016/j.ese.2025.100526,https://scholar.google.com/scholar?q=10.1016/j.ese.2025.100526,ar,Environmental Science and Ecotechnology,"Huang, Jeffrey;Bibri, Simon Elias;Keel, Paul",Generative spatial artificial intelligence for sustainable smart cities: A pioneering large flow model for urban digital twin,"Rapid urbanization, alongside escalating resource depletion and ecological degradation, underscores the critical need for innovative urban development solutions. In response, sustainable smart cities are increasingly turning to cutting-edge technologies—such as Generative Artificial Intelligence (GenAI), Foundation Models (FMs), and Urban Digital Twin (UDT) frameworks—to transform urban planning and design practices. These transformative tools provide advanced capabilities to analyze complex urban systems, optimize resource management, and enable evidence-based decision-making. Despite recent progress, research on integrating GenAI and FMs into UDT frameworks remains scant, leaving gaps in our ability to capture complex urban flows and multimodal dynamics essential to achieving environmental sustainability goals. Moreover, the lack of a robust theoretical foundation and real-world operationalization of these tools hampers comprehensive modeling and practical adoption. This study introduces a pioneering Large Flow Model (LFM), grounded in a robust foundational framework and designed with GenAI capabilities. It is specifically tailored for integration into UDT systems to enhance predictive analytics, adaptive learning, and complex data management functionalities. To validate its applicability and relevance, the Blue City Project in Lausanne City is examined as a case study, showcasing the ability of the LFM to effectively model and analyze urban flows—namely mobility, goods, energy, waste, materials, and biodiversity—critical to advancing environmental sustainability. This study highlights how the LFM addresses the spatial challenges inherent in current UDT frameworks. The LFM demonstrates its novelty in comprehensive urban modeling and analysis by completing impartial city data, estimating flow data in new locations, predicting the evolution of flow data, and offering a holistic understanding of urban dynamics and their interconnections. The model enhances decision-making processes, supports evidence-based planning and design, fosters integrated development strategies, and enables the development of more efficient, resilient, and sustainable urban environments. This research advances both the theoretical and practical dimensions of AI-driven, environmentally sustainable urban development by operationalizing GenAI and FMs within UDT frameworks. It provides sophisticated tools and valuable insights for urban planners, designers, policymakers, and researchers to address the complexities of modern cities and accelerate the transition towards sustainable urban futures.",Foundation models | Generative artificial intelligence | Generative spatial artificial intelligence | Large flow model | Sustainable smart cities | Urban digital twin | Urban planning and design,35,2025,sustainability,behavior+sustainability
242,2-s2.0-85217221286,10.1007/s12273-025-1235-9,https://doi.org/10.1007/s12273-025-1235-9,https://scholar.google.com/scholar?q=10.1007/s12273-025-1235-9,ar,Building Simulation,"Liu, Mingzhe;Zhang, Liang;Chen, Jianli;Chen, Wei An;Yang, Zhiyao;Lo, L. James;Wen, Jin;O’Neill, Zheng",Large language models for building energy applications: Opportunities and challenges,"Large language models (LLMs) are gaining attention due to their potential to enhance efficiency and sustainability in the building domain, a critical area for reducing global carbon emissions. Built on transformer architectures, LLMs excel at text generation and data analysis, enabling applications such as automated energy model generation, energy management optimization, and fault detection and diagnosis. These models can potentially streamline complex workflows, enhance decision-making, and improve energy efficiency. However, integrating LLMs into building energy systems poses challenges, including high computational demands, data preparation costs, and the need for domain-specific customization. This perspective paper explores the role of LLMs in the building energy system sector, highlighting their potential applications and limitations. We propose a development roadmap built on in-context learning, domain-specific fine-tuning, retrieval augmented generation, and multimodal integration to enhance LLMs’ customization and practical use in this field. This paper aims to spark ideas for bridging the gap between LLMs capabilities and practical building applications, offering insights into the future of LLM-driven methods in building energy applications.",artificial intelligence | building energy applications | energy management optimization | large language models | LLM-as-agent workflows,35,2025,sustainability,behavior+sustainability
395,2-s2.0-85200804056,10.1109/JSTARS.2024.3438376,https://doi.org/10.1109/JSTARS.2024.3438376,https://scholar.google.com/scholar?q=10.1109/JSTARS.2024.3438376,ar,IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,"Wu, Jiayang;Gan, Wensheng;Chao, Han Chieh;Yu, Philip S.",Geospatial Big Data: Survey and Challenges,"In recent years, geospatial big data (GBD) has obtained attention across various disciplines, categorized into big Earth observation data and big human behavior data. Identifying geospatial patterns from GBD has been a vital research focus in the fields of urban management and environmental sustainability. This article reviews the evolution of GBD mining and its integration with advanced artificial intelligence techniques. GBD consists of data generated by satellites, sensors, mobile devices, and geographical information systems, and we categorize geospatial data based on different perspectives. We outline the process of GBD mining and demonstrate how it can be incorporated into a unified framework. In addition, we explore new technologies, such as large language models, the metaverse, and knowledge graphs, and how they could make GBD even more useful. We also share examples of GBD helping with city management and protecting the environment. Finally, we discuss the real challenges that come up when working with GBD, such as issues with data retrieval and security. Our goal is to give readers a clear view of where GBD mining stands today and where it might go next.",Artificial intelligence (AI) | big data | geospatial big data (GBD) | geospatial data,35,2024,sustainability,behavior+sustainability
360,2-s2.0-85195594534,10.1111/exsy.13654,https://doi.org/10.1111/exsy.13654,https://scholar.google.com/scholar?q=10.1111/exsy.13654,ar,Expert Systems,"Hadid, Abdenour;Chakraborty, Tanujit;Busby, Daniel","When geoscience meets generative AI and large language models: Foundations, trends, and future challenges","Generative Artificial Intelligence (GAI) represents an emerging field that promises the creation of synthetic data and outputs in different modalities. GAI has recently shown impressive results across a large spectrum of applications ranging from biology, medicine, education, legislation, computer science, and finance. As one strives for enhanced safety, efficiency, and sustainability, generative AI indeed emerges as a key differentiator and promises a paradigm shift in the field. This article explores the potential applications of generative AI and large language models in geoscience. The recent developments in the field of machine learning and deep learning have enabled the generative model's utility for tackling diverse prediction problems, simulation, and multi-criteria decision-making challenges related to geoscience and Earth system dynamics. This survey discusses several GAI models that have been used in geoscience comprising generative adversarial networks (GANs), physics-informed neural networks (PINNs), and generative pre-trained transformer (GPT)-based structures. These tools have helped the geoscience community in several applications, including (but not limited to) data generation/augmentation, super-resolution, panchromatic sharpening, haze removal, restoration, and land surface changing. Some challenges still remain, such as ensuring physical interpretation, nefarious use cases, and trustworthiness. Beyond that, GAI models show promises to the geoscience community, especially with the support to climate change, urban science, atmospheric science, marine science, and planetary science through their extraordinary ability to data-driven modelling and uncertainty quantification.",artificial intelligence | deep learning | diffusion models | generative adversarial networks | generative AI | geoscience | large language models | physics-informed neural networks,34,2024,sustainability,behavior+sustainability
702,2-s2.0-85193741289,10.2196/51346,https://doi.org/10.2196/51346,https://scholar.google.com/scholar?q=10.2196/51346,ar,Jmir Formative Research,"Skryd, Anthony;Lawrence, Katharine",ChatGPT as a Tool for Medical Education and Clinical Decision-Making on the Wards: Case Study,"Background: Large language models (LLMs) are computational artificial intelligence systems with advanced natural language processing capabilities that have recently been popularized among health care students and educators due to their ability to provide real-time access to a vast amount of medical knowledge. The adoption of LLM technology into medical education and training has varied, and little empirical evidence exists to support its use in clinical teaching environments. Objective: The aim of the study is to identify and qualitatively evaluate potential use cases and limitations of LLM technology for real-time ward-based educational contexts. Methods: A brief, single-site exploratory evaluation of the publicly available ChatGPT-3.5 (OpenAI) was conducted by implementing the tool into the daily attending rounds of a general internal medicine inpatient service at a large urban academic medical center. ChatGPT was integrated into rounds via both structured and organic use, using the web-based “chatbot” style interface to interact with the LLM through conversational free-text and discrete queries. A qualitative approach using phenomenological inquiry was used to identify key insights related to the use of ChatGPT through analysis of ChatGPT conversation logs and associated shorthand notes from the clinical sessions. Results: Identified use cases for ChatGPT integration included addressing medical knowledge gaps through discrete medical knowledge inquiries, building differential diagnoses and engaging dual-process thinking, challenging medical axioms, using cognitive aids to support acute care decision-making, and improving complex care management by facilitating conversations with subspecialties. Potential additional uses included engaging in difficult conversations with patients, exploring ethical challenges and general medical ethics teaching, personal continuing medical education resources, developing ward-based teaching tools, supporting and automating clinical documentation, and supporting productivity and task management. LLM biases, misinformation, ethics, and health equity were identified as areas of concern and potential limitations to clinical and training use. A code of conduct on ethical and appropriate use was also developed to guide team usage on the wards. Conclusions: Overall, ChatGPT offers a novel tool to enhance ward-based learning through rapid information querying, second-order content exploration, and engaged team discussion regarding generated responses. More research is needed to fully understand contexts for educational use, particularly regarding the risks and limitations of the tool in clinical settings and its impacts on trainee development.",ChatGPT | clinical decision-making | large language models | LLMs | medical education,33,2024,behavior,behavior+policy
462,2-s2.0-105004440467,10.1186/s12929-025-01131-z,https://doi.org/10.1186/s12929-025-01131-z,https://scholar.google.com/scholar?q=10.1186/s12929-025-01131-z,ar,Journal of Biomedical Science,"Iqbal, Usman;Tanweer, Afifa;Rahmanti, Annisa Ristya;Greenfield, David;Lee, Leon Tsung Ju;Li, Yu Chuan Jack",Impact of large language model (ChatGPT) in healthcare: an umbrella review and evidence synthesis,"Background: The emergence of Artificial Intelligence (AI), particularly Chat Generative Pre-Trained Transformer (ChatGPT), a Large Language Model (LLM), in healthcare promises to reshape patient care, clinical decision-making, and medical education. This review aims to synthesise research findings to consolidate the implications of ChatGPT integration in healthcare and identify research gaps. Main body: The umbrella review was conducted following Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. The Cochrane Library, PubMed, Scopus, Web of Science, and Google Scholar were searched from inception until February 2024. Due to the heterogeneity of the included studies, no quantitative analysis was performed. Instead, information was extracted, summarised, synthesised, and presented in a narrative form. Two reviewers undertook title, abstract, and full text screening independently. The methodological quality and overall rating of the included reviews were assessed using the A Measurement Tool to Assess systematic Reviews (AMSTAR-2) checklist. The review examined 17 studies, comprising 15 systematic reviews and 2 meta-analyses, on ChatGPT in healthcare, revealing diverse focuses. The AMSTAR-2 assessment identified 5 moderate and 12 low-quality reviews, with deficiencies like study design justification and funding source reporting. The most reported theme that emerged was ChatGPT's use in disease diagnosis or clinical decision-making. While 82.4% of studies focused on its general usage, 17.6% explored unique topics like its role in medical examinations and conducting systematic reviews. Among these, 52.9% targeted general healthcare, with 41.2% focusing on specific domains like radiology, neurosurgery, gastroenterology, public health dentistry, and ophthalmology. ChatGPT’s use for manuscript review or writing was mentioned in 17.6% of reviews. Promising applications include enhancing patient care and clinical decision-making, though ethical, legal, and accuracy concerns require cautious integration. Conclusion: We summarise the identified areas in reviews regarding ChatGPT's transformative impact in healthcare, highlighting patient care, decision-making, and medical education. Emphasising the importance of ethical regulations and the involvement of policymakers, we urge further investigation to ensure the reliability of ChatGPT and to promote trust in healthcare and research.",ChatGPT; Large language models (LLMs) | Consumer health | Evidence synthesis | Generative AI | Healthcare; Medical research; Medical education; Patient care | Reviews,32,2025,behavior,behavior+policy
531,2-s2.0-105003767002,10.1016/j.tre.2025.104135,https://doi.org/10.1016/j.tre.2025.104135,https://scholar.google.com/scholar?q=10.1016/j.tre.2025.104135,ar,Transportation Research Part E Logistics and Transportation Review,"Boone, Tonya;Fahimnia, Benham;Ganeshan, Ram;Herold, David M.;Sanders, Nada R.","Generative AI: Opportunities, challenges, and research directions for supply chain resilience","Generative Artificial Intelligence (GenAI) is emerging as a transformative force in supply chain resilience, offering new ways to enhance decision-making, automate operations, and improve adaptability to disruptions. Unlike traditional AI, which relies on historical data for prediction and optimization, GenAI can generate novel solutions and simulate alternative scenarios in real time. Despite its potential, research on GenAI's role in supply chain resilience remains limited. This paper explores GenAI applications and possible research questions across key supply chain areas while also addressing challenges such as misinformation, security risks, and governance. As GenAI integrates with existing technologies, its adoption raises critical questions about accountability and systemic dependencies. To ensure responsible implementation, further research is needed to refine oversight mechanisms, establish benchmarks, and develop hybrid decision-making models where AI enhances, rather than replaces, human expertise. These insights provide guidance to managers and policymakers to help make informed decisions about the strategic deployment of GenAI in resilience-oriented supply chains.",,32,2025,behavior,behavior+policy
418,2-s2.0-85131420039,10.1016/j.neunet.2022.05.012,https://doi.org/10.1016/j.neunet.2022.05.012,https://scholar.google.com/scholar?q=10.1016/j.neunet.2022.05.012,ar,Neural Networks,"Doya, Kenji;Ema, Arisa;Kitano, Hiroaki;Sakagami, Masamichi;Russell, Stuart",Social impact and governance of AI and neurotechnologies,"Advances in artificial intelligence (AI) and brain science are going to have a huge impact on society. While technologies based on those advances can provide enormous social benefits, adoption of new technologies poses various risks. This article first reviews the co-evolution of AI and brain science and the benefits of brain-inspired AI in sustainability, healthcare, and scientific discoveries. We then consider possible risks from those technologies, including intentional abuse, autonomous weapons, cognitive enhancement by brain–computer interfaces, insidious effects of social media, inequity, and enfeeblement. We also discuss practical ways to bring ethical principles into practice. One proposal is to stop giving explicit goals to AI agents and to enable them to keep learning human preferences. Another is to learn from democratic mechanisms that evolved in human society to avoid over-consolidation of power. Finally, we emphasize the importance of open discussions not only by experts, but also including a diverse array of lay opinions.",AI scientist | Artificial intelligence | Ethics | Governance | Human compatible AI | Neurotechnology,32,2022,sustainability,behavior+policy+sustainability
156,2-s2.0-105001925680,10.1016/j.techsoc.2025.102898,https://doi.org/10.1016/j.techsoc.2025.102898,https://scholar.google.com/scholar?q=10.1016/j.techsoc.2025.102898,ar,Technology in Society,"Wang, Shaofeng;Zhang, Hao",Generative artificial intelligence and internationalization green innovation: Roles of supply chain innovations and AI regulation for SMEs,"This study investigates how generative artificial intelligence (GenAI) impacts internationalization green innovation performance in cross-border e-commerce small and medium-sized enterprises (SMEs). Drawing on the resource-based view, we employed a mixed-methods approach, including partial least squares structural equation modeling (PLS-SEM), importance-performance map analysis (IPMA), fuzzy-set qualitative comparative analysis (fsQCA), and semi-structured interviews with 377 cross-border e-commerce SMEs. Our findings reveal that GenAI capability positively influences internationalization green innovation performance, both directly and indirectly, through supply chain exploratory and exploitative innovation. Notably, artificial intelligence (AI) regulation strengthens, rather than weakens, the positive relationship between GenAI capability and supply chain innovation. This highlights the potential for responsible AI governance to foster sustainable practices. The study contributes to understanding technology's role in societal transformation by illuminating how GenAI can promote sustainable business practices in internationalization contexts. Our findings offer valuable insights for policymakers and business leaders on effectively managing the societal implications of AI adoption while pursuing sustainability goals.",Artificial intelligence regulation | Generative artificial intelligence | SMEs | Social transformation | Supply chain innovation | Sustainable innovation,32,2025,sustainability,policy+sustainability
689,2-s2.0-85187527435,10.1371/journal.pone.0296151,https://doi.org/10.1371/journal.pone.0296151,https://scholar.google.com/scholar?q=10.1371/journal.pone.0296151,ar,Plos One,"Choudhury, Avishek;Elkefi, Safa;Tounsi, Achraf",Exploring factors influencing user perspective of ChatGPT as a technology that assists in healthcare decision making: A cross sectional survey study,"As ChatGPT emerges as a potential ally in healthcare decision-making, it is imperative to investigate how users leverage and perceive it. The repurposing of technology is innovative but brings risks, especially since AI's effectiveness depends on the data it's fed. In healthcare, ChatGPT might provide sound advice based on current medical knowledge, which could turn into misinformation if its data sources later include erroneous information. Our study assesses user perceptions of ChatGPT, particularly of those who used ChatGPT for healthcare-related queries. By examining factors such as competence, reliability, transparency, trustworthiness, security, and persuasiveness of ChatGPT, the research aimed to understand how users rely on ChatGPT for health-related decisionmaking. A web-based survey was distributed to U.S. adults using ChatGPT at least once a month. Bayesian Linear Regression was used to understand how much ChatGPT aids in informed decision-making. This analysis was conducted on subsets of respondents, both those who used ChatGPT for healthcare decisions and those who did not. Qualitative data from open-ended questions were analyzed using content analysis, with thematic coding to extract public opinions on urban environmental policies. Six hundred and seven individuals responded to the survey. Respondents were distributed across 306 US cities of which 20 participants were from rural cities. Of all the respondents, 44 used ChatGPT for healthrelated queries and decision-making. In the healthcare context, the most effective model highlights 'Competent + Trustworthy + ChatGPT for healthcare queries', underscoring the critical importance of perceived competence and trustworthiness specifically in the realm of healthcare applications of ChatGPT. On the other hand, the non-healthcare context reveals a broader spectrum of influential factors in its best model, which includes 'Trustworthy + Secure + Benefits outweigh risks + Satisfaction + Willing to take decisions + Intent to use + Persuasive'. In conclusion our study findings suggest a clear demarcation in user expectations and requirements from AI systems based on the context of their use. We advocate for a balanced approach where technological advancement and user readiness are harmonized.",,31,2024,behavior,behavior+policy
363,2-s2.0-85205256395,10.3390/hydrology11090148,https://doi.org/10.3390/hydrology11090148,https://scholar.google.com/scholar?q=10.3390/hydrology11090148,ar,Hydrology,"Kadiyala, Likith Anoop;Mermer, Omer;Samuel, Dinesh Jackson;Sermet, Yusuf;Demir, Ibrahim","The Implementation of Multimodal Large Language Models for Hydrological Applications: A Comparative Study of GPT-4 Vision, Gemini, LLaVa, and Multimodal-GPT","Large Language Models (LLMs) combined with visual foundation models have demonstrated significant advancements, achieving intelligence levels comparable to human capabilities. This study analyzes the latest Multimodal LLMs (MLLMs), including Multimodal-GPT, GPT-4 Vision, Gemini, and LLaVa, with a focus on hydrological applications such as flood management, water level monitoring, agricultural water discharge, and water pollution management. We evaluated these MLLMs on hydrology-specific tasks, testing their response generation and real-time suitability in complex real-world scenarios. Prompts were designed to enhance the models’ visual inference capabilities and contextual comprehension from images. Our findings reveal that GPT-4 Vision demonstrated exceptional proficiency in interpreting visual data, providing accurate assessments of flood severity and water quality. Additionally, MLLMs showed potential in various hydrological applications, including drought prediction, streamflow forecasting, groundwater management, and wetland conservation. These models can optimize water resource management by predicting rainfall, evaporation rates, and soil moisture levels, thereby promoting sustainable agricultural practices. This research provides valuable insights into the potential applications of advanced AI models in addressing complex hydrological challenges and improving real-time decision-making in water resource management",GPT-4 Vision | hydrology | intelligent assistants | large language models | multimodal,29,2024,sustainability,behavior+sustainability
651,2-s2.0-105003188833,10.1080/08874417.2025.2483832,https://doi.org/10.1080/08874417.2025.2483832,https://scholar.google.com/scholar?q=10.1080/08874417.2025.2483832,ar,Journal of Computer Information Systems,"Hughes, Laurie;Dwivedi, Yogesh K.;Malik, Tegwen;Shawosh, Mazen;Albashrawi, Mousa Ahmed;Jeon, Il;Dutot, Vincent;Appanderanda, Mandanna;Crick, Tom;De’, Rahul;Fenwick, Mark;Gunaratnege, Senali Madugoda;Jurcys, Paulius;Kar, Arpan Kumar;Kshetri, Nir;Li, Keyao;Mutasa, Sashah;Samothrakis, Spyridon;Wade, Michael;Walton, Paul",AI Agents and Agentic Systems: A Multi-Expert Analysis,"The emergence of AI agents and agentic systems represents a significant milestone in artificial intelligence, enabling autonomous systems to operate, learn, and collaborate in complex environments with minimal human intervention. This paper, drawing on multi-expert perspectives, examines the potential of AI agents and agentic systems to reshape industries by decentralizing decision-making, redefining organizational structures, and enhancing cross-functional collaboration. Specific applications include healthcare systems capable of creating adaptive treatment plans, supply chain agents that predict and address disruptions in real-time, and business process automation that reallocates tasks from humans to AI, improving efficiency and innovation. However, the integration of these systems raises critical challenges, including issues of attribution and shared accountability in decision-making, compatibility with legacy systems, and addressing biases in AI-driven processes. The paper concludes that while agentic systems hold immense promise, robust governance frameworks, cross-industry collaboration, and interdisciplinary research into ethical design are essential. Future research should explore adaptive workforce reskilling strategies, transparent accountability mechanisms, and energy-efficient deployment models to ensure ethical and scalable implementation.",agentic AI | agentic system | AI agents | autonomous agent | cognitive agent | intelligent agent | OpenAI operator | smart agent | virtual assistant,28,2025,behavior,behavior+policy
679,2-s2.0-85198118718,10.1016/j.mcpdig.2024.03.003,https://doi.org/10.1016/j.mcpdig.2024.03.003,https://scholar.google.com/scholar?q=10.1016/j.mcpdig.2024.03.003,ar,Mayo Clinic Proceedings Digital Health,"Ayoub, Noel F.;Balakrishnan, Karthik;Ayoub, Marc S.;Barrett, Thomas F.;David, Abel P.;Gray, Stacey T.",Inherent Bias in Large Language Models: A Random Sampling Analysis,"There are mounting concerns regarding inherent bias, safety, and tendency toward misinformation of large language models (LLMs), which could have significant implications in health care. This study sought to determine whether generative artificial intelligence (AI)-based simulations of physicians making life-and-death decisions in a resource-scarce environment would demonstrate bias. Thirteen questions were developed that simulated physicians treating patients in resource-limited environments. Through a random sampling of simulated physicians using OpenAI's generative pretrained transformer (GPT-4), physicians were tasked with choosing only 1 patient to save owing to limited resources. This simulation was repeated 1000 times per question, representing 1000 unique physicians and patients each. Patients and physicians spanned a variety of demographic characteristics. All patients had similar a priori likelihood of surviving the acute illness. Overall, simulated physicians consistently demonstrated racial, gender, age, political affiliation, and sexual orientation bias in clinical decision-making. Across all demographic characteristics, physicians most frequently favored patients with similar demographic characteristics as themselves, with most pairwise comparisons showing statistical significance (P<.05). Nondescript physicians favored White, male, and young demographic characteristics. The male doctor gravitated toward the male, White, and young, whereas the female doctor typically preferred female, young, and White patients. In addition to saving patients with their own political affiliation, Democratic physicians favored Black and female patients, whereas Republicans preferred White and male demographic characteristics. Heterosexual and gay/lesbian physicians frequently saved patients of similar sexual orientation. Overall, publicly available chatbot LLMs demonstrate significant biases, which may negatively impact patient outcomes if used to support clinical care decisions without appropriate precautions.",,28,2024,behavior,behavior+policy
693,2-s2.0-85175255184,10.1007/s11606-023-08497-6,https://doi.org/10.1007/s11606-023-08497-6,https://scholar.google.com/scholar?q=10.1007/s11606-023-08497-6,ar,Journal of General Internal Medicine,"Bakdash, Leen;Abid, Areeba;Gourisankar, Amritha;Henry, Tracey L.",Chatting Beyond ChatGPT: Advancing Equity Through AI-Driven Language Interpretation,"Medical interpretation is an underutilized resource, despite its legal mandate and proven efficacy in improving health outcomes for populations with low English proficiency. This disconnect can often be attributed to the costs and wait-times associated with traditional means of interpretation, making the service inaccessible and burdensome. Technology has improved access to translation through phone and video interpretation; with the acceleration of artificial intelligence (AI) large language models, we have an opportunity to further improve interpreter access through real-time, automated translation. The impetus to utilize this burgeoning tool for improved health equity must be combined with a critical view of the safety, privacy, and clinical decision-making risks involved. Physicians must be active participants and collaborators in both the mobilization of AI tools to improve clinical care and the development of regulations to mitigate harm.",,28,2024,behavior,behavior+policy
704,2-s2.0-85190255114,10.7717/peerj-cs.1845,https://doi.org/10.7717/peerj-cs.1845,https://scholar.google.com/scholar?q=10.7717/peerj-cs.1845,ar,Peerj Computer Science,"Bukar, Umar Ali;Sayeed, Md Shohel;Razak, Siti Fatimah Abdul;Yogarayan, Sumendra;Amodu, Oluwatosin Ahmed",An integrative decision-making framework to guide policies on regulating ChatGPT usage,"Generative artificial intelligence has created a moment in history where human beings have begin to closely interact with artificial intelligence (AI) tools, putting policymakers in a position to restrict or legislate such tools. One particular example of such a tool is ChatGPT which is the first and world's most popular multipurpose generative AI tool. This study aims to put forward a policy-making framework of generative artificial intelligence based on the risk, reward, and resilience framework. A systematic search was conducted, by using carefully chosen keywords, excluding non-English content, conference articles, book chapters, and editorials. Published research were filtered based on their relevance to ChatGPT ethics, yielding a total of 41 articles. Key elements surrounding ChatGPT concerns and motivations were systematically deduced and classified under the risk, reward, and resilience categories to serve as ingredients for the proposed decision-making framework. The decision-making process and rules were developed as a primer to help policymakers navigate decision-making conundrums. Then, the framework was practically tailored towards some of the concerns surrounding ChatGPT in the context of higher education. In the case of the interconnection between risk and reward, the findings show that providing students with access to ChatGPT presents an opportunity for increased efficiency in tasks such as text summarization and workload reduction. However, this exposes them to risks such as plagiarism and cheating. Similarly, pursuing certain opportunities such as accessing vast amounts of information, can lead to rewards, but it also introduces risks like misinformation and copyright issues. Likewise, focusing on specific capabilities of ChatGPT, such as developing tools to detect plagiarism and misinformation, may enhance resilience in some areas (e.g., academic integrity). However, it may also create vulnerabilities in other domains, such as the digital divide, educational equity, and job losses. Furthermore, the finding indicates second-order effects of legislation regarding ChatGPT which have implications both positively and negatively. One potential effect is a decrease in rewards due to the limitations imposed by the legislation, which may hinder individuals from fully capitalizing on the opportunities provided by ChatGPT. Hence, the risk, reward, and resilience framework provides a comprehensive and flexible decision-making model that allows policymakers and in this use case, higher education institutions to navigate the complexities and trade-offs associated with ChatGPT, which have theoretical and practical implications for the future.",ChatGPT | Decision making | Ethics | Generative AI | Higher education | Policy making | Resilience | Reward | Risk | Systematic review,28,2024,behavior,behavior+policy
346,2-s2.0-85206092933,10.1016/j.enbuild.2024.114827,https://doi.org/10.1016/j.enbuild.2024.114827,https://scholar.google.com/scholar?q=10.1016/j.enbuild.2024.114827,ar,Energy and Buildings,"Arslan, Muhammad;Mahdjoubi, Lamine;Munawar, Saba",Driving sustainable energy transitions with a multi-source RAG-LLM system,"By 2035, the UK aims to upgrade all homes to achieve a net-zero economy by 2050, thereby reducing energy consumption, household costs, and improving living conditions. Small and Medium-sized Enterprises (SMEs) play a crucial role in this transition. However, many SME contractors lack essential information on Sustainable Energy Initiatives (SEIs) and the relevant Energy landscape necessary for driving Sustainable Energy Transitions (SETs). This knowledge gap poses risks to SME interventions, potentially leading to increased costs and inefficiencies. Accessing timely information on SEIs including government policies, funding, technologies, and environmental impacts from various media sources is essential for guiding effective SETs and understanding the relevant Energy landscape, thereby facilitating informed decision-making. Currently, SMEs lack an integrated system that consolidates data from diverse media sources into a centralized Information System (IS), limiting their ability to effectively navigate SEIs. To address this gap, this research introduces an Energy Chatbot, a sustainable IS that utilizes Large Language Models (LLMs) integrated with multi-source Retrieval Augmented Generation (RAG). This system encompasses diverse media sources, including news articles, government reports, industry publications, academic research, and social media. The Energy Chatbot is designed to enhance decision-making for SMEs by providing comprehensive Energy sector insights through a Question Answering (QA) system. Key findings emphasize that this approach reduces costs by utilizing open-source models. Moreover, the Energy Chatbot provides SMEs with access to up-to-date information, enabling them to identify long-term sustainability strategies and maintain a competitive edge in the evolving Energy landscape.",Data-driven operations | Information Extraction (IE) | Large Language Models (LLMs) | Retrieval Augmented Generation (RAG) | Sustainable Development Goals (SDGs) | Sustainable Energy Transitions (SETs),28,2024,sustainability,behavior+sustainability
372,2-s2.0-85194179410,10.1016/j.ijmedinf.2024.105501,https://doi.org/10.1016/j.ijmedinf.2024.105501,https://scholar.google.com/scholar?q=10.1016/j.ijmedinf.2024.105501,ar,International Journal of Medical Informatics,"Sblendorio, Elena;Dentamaro, Vincenzo;Lo Cascio, Alessio;Germini, Francesco;Piredda, Michela;Cicolini, Giancarlo",Integrating human expertise & automated methods for a dynamic and multi-parametric evaluation of large language models’ feasibility in clinical decision-making,"Background: Recent enhancements in Large Language Models (LLMs) such as ChatGPT have exponentially increased user adoption. These models are accessible on mobile devices and support multimodal interactions, including conversations, code generation, and patient image uploads, broadening their utility in providing healthcare professionals with real-time support for clinical decision-making. Nevertheless, many authors have highlighted serious risks that may arise from the adoption of LLMs, principally related to safety and alignment with ethical guidelines. Objective: To address these challenges, we introduce a novel methodological approach designed to assess the specific feasibility of adopting LLMs within a healthcare area, with a focus on clinical nursing, evaluating their performance and thereby directing their choice. Emphasizing LLMs’ adherence to scientific advancements, this approach prioritizes safety and care personalization, according to the “Organization for Economic Co-operation and Development” frameworks for responsible AI. Moreover, its dynamic nature is designed to adapt to future evolutions of LLMs. Method: Through integrating advanced multidisciplinary knowledge, including Nursing Informatics, and aided by a prospective literature review, seven key domains and specific evaluation items were identified as follows: 1. State of the Art Alignment & Safety. 2. Focus, Accuracy & Management of Prompt Ambiguity. 3. Data Integrity, Data Security, Ethics & Sustainability, in accordance with OECD Recommendations for Responsible AI. 4. Temporal Variability of Responses (Consistency) 5. Adaptation to specific standardized terminology and Classifications for healthcare professionals. 6. General Capabilities: Post User Feedback Self-Evolution Capability and Organization in Chapters. 7. Ability to Drive Evolution in Healthcare.A Peer Review by experts in Nursing and AI was performed, ensuring scientific rigor and breadth of insights for an essential, reproducible, and coherent methodological approach. By means of a 7-point Likert scale, thresholds are defined in order to classify LLMs as “unusable”, “usable with high caution”, and “recommended” categories. Nine state of the art LLMs were evaluated using this methodology in clinical oncology nursing decision-making, producing preliminary results. Gemini Advanced, Anthropic Claude 3 and ChatGPT 4 achieved the minimum score of the State of the Art Alignment & Safety domain for classification as “recommended”, being also endorsed across all domains. LLAMA 3 70B and ChatGPT 3.5 were classified as “usable with high caution.” Others were classified as unusable in this domain. Conclusion: The identification of a recommended LLM for a specific healthcare area, combined with its critical, prudent, and integrative use, can support healthcare professionals in decision-making processes.",AI routine integration | Clinical decision making | Healthcare innovation | LLM's feasibility | Methodology | Multi-parametric analysis | Multidisciplinary approach | Nursing informatics | Safety,26,2024,sustainability,behavior+sustainability
367,2-s2.0-85196961511,10.1016/j.biotechadv.2024.108399,https://doi.org/10.1016/j.biotechadv.2024.108399,https://scholar.google.com/scholar?q=10.1016/j.biotechadv.2024.108399,re,Biotechnology Advances,"Gong, Xinyu;Zhang, Jianli;Gan, Qi;Teng, Yuxi;Hou, Jixin;Lyu, Yanjun;Liu, Zhengliang;Wu, Zihao;Dai, Runpeng;Zou, Yusong;Wang, Xianqiao;Zhu, Dajiang;Zhu, Hongtu;Liu, Tianming;Yan, Yajun",Advancing microbial production through artificial intelligence-aided biology,"Microbial cell factories (MCFs) have been leveraged to construct sustainable platforms for value-added compound production. To optimize metabolism and reach optimal productivity, synthetic biology has developed various genetic devices to engineer microbial systems by gene editing, high-throughput protein engineering, and dynamic regulation. However, current synthetic biology methodologies still rely heavily on manual design, laborious testing, and exhaustive analysis. The emerging interdisciplinary field of artificial intelligence (AI) and biology has become pivotal in addressing the remaining challenges. AI-aided microbial production harnesses the power of processing, learning, and predicting vast amounts of biological data within seconds, providing outputs with high probability. With well-trained AI models, the conventional Design-Build-Test (DBT) cycle has been transformed into a multidimensional Design-Build-Test-Learn-Predict (DBTLP) workflow, leading to significantly improved operational efficiency and reduced labor consumption. Here, we comprehensively review the main components and recent advances in AI-aided microbial production, focusing on genome annotation, AI-aided protein engineering, artificial functional protein design, and AI-enabled pathway prediction. Finally, we discuss the challenges of integrating novel AI techniques into biology and propose the potential of large language models (LLMs) in advancing microbial production.",Artificial intelligence (AI) | Artificial protein design | Enzyme function prediction | Genome annotation | Large language models (LLMs) | Microbial production | Pathway prediction | Synthetic biology,26,2024,sustainability,policy+sustainability
402,2-s2.0-85189701793,10.13052/jwe1540-9589.2313,https://doi.org/10.13052/jwe1540-9589.2313,https://scholar.google.com/scholar?q=10.13052/jwe1540-9589.2313,ar,Journal of Web Engineering,"Lo, Wei;Yang, Chun Ming;Zhang, Qiansha;Li, Mingyuan",Increased Productivity and Reduced Waste with Robotic Process Automation and Generative AI-powered IoE Services,"The convergence of robotic process automation (RPA) and generative AI (GAI) within the context of Internet of Everything (IoE) services represents a profound paradigm shift. This fusion of technologies not only streamlines routine tasks but also catalyzes innovation while harnessing the potential of interconnected devices. Such integration empowers organizations to achieve remarkable gains in efficiency and sustainability. This paper embarks on an exploration of these transformative services, designed to elevate productivity, and curtail wasteful practices in contemporary industries. By closely examining intricate case studies, we illuminate the multifaceted advantages of this integrated approach. Our investigation demonstrates how RPA accelerates the execution of repetitive processes, substantially diminishing the margin for human error and amplifying operational efficiency. In contrast, generative AI introduces a disruptive force, generating fresh ideas, designs, and solutions, thereby elevating the quality of products and services. The infusion of these cutting-edge technologies into the fabric of IoE services paves the way for organizations to attain unprecedented levels of automation, intelligence, and connectivity. Furthermore, this paper comprehensively addresses the intricate challenges and considerations associated with the proposed implementation. We delve into ethical concerns, security implications, and the necessary workforce adaptation to offer a balanced perspective on the adoption of these technologies. Additionally, we navigate through potential limitations and constraints, underscoring the imperative need for strategic planning and robust governance.",generative AI (GAI) | industrial productivity | Internet of Everything (IoE) | Robotic process automation (RPA) | waste management,26,2024,sustainability,policy+sustainability
442,2-s2.0-86000754782,10.1007/s13278-025-01428-9,https://doi.org/10.1007/s13278-025-01428-9,https://scholar.google.com/scholar?q=10.1007/s13278-025-01428-9,re,Social Network Analysis and Mining,"Thapa, Surendrabikram;Shiwakoti, Shuvam;Shah, Siddhant Bikram;Adhikari, Surabhi;Veeramani, Hariram;Nasim, Mehwish;Naseem, Usman","Large language models (LLM) in computational social science: prospects, current state, and challenges","The advent of large language models (LLMs) has marked a new era in the transformation of computational social science (CSS). This paper dives into the role of LLMs in CSS, particularly exploring their potential to revolutionize data analysis and content generation and contribute to a broader understanding of social phenomena. We begin by discussing the applications of LLMs in various computational problems in social science including sentiment analysis, hate speech detection, stance and humor detection, misinformation detection, event understanding, and social network analysis, illustrating their capacity to generate nuanced insights into human behavior and societal trends. Furthermore, we explore the innovative use of LLMs in generating social media content. We also discuss the various ethical, technical, and legal issues these applications pose, and considerations required for responsible LLM usage. We further present the challenges associated with data bias, privacy, and the integration of these models into existing research frameworks. This paper aims to provide a solid background on the potential of LLMs in CSS, their past applications, current problems, and how they can pave the way for revolutionizing CSS.",Computational social science | Large language models | Natural language processing | Social network analysis | Social science,25,2025,behavior,behavior+policy
570,2-s2.0-85203027228,10.1108/IJOES-04-2024-0112,https://doi.org/10.1108/IJOES-04-2024-0112,https://scholar.google.com/scholar?q=10.1108/IJOES-04-2024-0112,ar,International Journal of Ethics and Systems,"Ali, Hassnian;Aysan, Ahmet Faruk",Ethical dimensions of generative AI: a cross-domain analysis using machine learning structural topic modeling,"Purpose: The purpose of this study is to comprehensively examine the ethical implications surrounding generative artificial intelligence (AI). Design/methodology/approach: Leveraging a novel methodological approach, the study curates a corpus of 364 documents from Scopus spanning 2022 to 2024. Using the term frequency-inverse document frequency (TF-IDF) and structural topic modeling (STM), it quantitatively dissects the thematic essence of the ethical discourse in generative AI across diverse domains, including education, healthcare, businesses and scientific research. Findings: The results reveal a diverse range of ethical concerns across various sectors impacted by generative AI. In academia, the primary focus is on issues of authenticity and intellectual property, highlighting the challenges of AI-generated content in maintaining academic integrity. In the healthcare sector, the emphasis shifts to the ethical implications of AI in medical decision-making and patient privacy, reflecting concerns about the reliability and security of AI-generated medical advice. The study also uncovers significant ethical discussions in educational and financial settings, demonstrating the broad impact of generative AI on societal and professional practices. Research limitations/implications: This study provides a foundation for crafting targeted ethical guidelines and regulations for generative AI, informed by a systematic analysis using STM. It highlights the need for dynamic governance and continual monitoring of AI’s evolving ethical landscape, offering a model for future research and policymaking in diverse fields. Originality/value: The study introduces a unique methodological combination of TF-IDF and STM to analyze a large academic corpus, offering new insights into the ethical implications of generative AI across multiple domains.",Ethics | Generative AI | Governance | Regulation | Structure topic modeling,25,2025,behavior,behavior+policy
202,2-s2.0-105006840718,10.3390/jmse13050979,https://doi.org/10.3390/jmse13050979,https://scholar.google.com/scholar?q=10.3390/jmse13050979,re,Journal of Marine Science and Engineering,"Zou, Yangqiong;Xiao, Guangnian;Li, Qingjun;Biancardo, Salvatore Antonio",Intelligent Maritime Shipping: A Bibliometric Analysis of Internet Technologies and Automated Port Infrastructure Applications,"Amid the dual imperatives of global trade expansion and low-carbon transition, intelligent maritime shipping has emerged as a central driver for the innovation of international logistics systems, now entering a critical window period for the deep integration of Internet technologies and automated port infrastructure. While existing research predominantly focuses on isolated applications of intelligent technologies, systematic evaluations of the synergistic effects of technological integration on maritime ecosystems, policy compatibility, and contributions to global carbon emission governance remain under-explored. Leveraging bibliometric analysis, this study systematically examines 488 publications from the Web of Science (WoS) Core Collection (2000–2024), yielding three pivotal findings: firstly, China dominates the research landscape, with a 38.5% contribution share, where Artificial Intelligence (AI), the Internet of Things (IoT), and port automation constitute the technological pillars. However, critical gaps persist in cross-system protocol standardization and climate-adaptive modeling, accounting for only 2.7% and 4.2% of the literature, respectively. Secondly, international collaboration networks exhibit pronounced “Islamization”, characterized by an inter-team collaboration rate of 17.3%, while the misalignment between rapid technological iteration and existing maritime regulations exacerbates industry risks. Thirdly, a dual-track pathway integrating Cyber–Physical System (CPS)-based digital twin ports and open-source vertical domain-specific large language models is proposed. Empirical evidence demonstrates its efficacy in reducing cargo-handling energy consumption by 15% and decision-making latency by 40%. This research proposes a novel tripartite framework, encompassing technological, institutional, and data sovereignty dimensions, to resolve critical challenges in integrating multi-source maritime data and managing cross-border governance. The model provides academically validated and industry-compatible strategies for advancing sustainable maritime intelligence. Subsequent investigations should expand data sources to include regional repositories and integrate interdisciplinary approaches, ensuring the adaptability of both technical systems and international policy coordination mechanisms across diverse maritime ecosystems.",AI large model | bibliometric analysis | intelligent maritime shipping | Internet | port automation,25,2025,sustainability,behavior+policy+sustainability
222,2-s2.0-85214571986,10.1016/j.apenergy.2025.125296,https://doi.org/10.1016/j.apenergy.2025.125296,https://scholar.google.com/scholar?q=10.1016/j.apenergy.2025.125296,ar,Applied Energy,"Mousavi, Rashin;Mousavi, Arash;Mousavi, Yashar;Tavasoli, Mahsa;Arab, Aliasghar;Kucukdemiral, Ibrahim Beklan;Alfi, Alireza;Fekih, Afef",Revolutionizing solar energy resources: The central role of generative AI in elevating system sustainability and efficiency,"Driven by growing environmental concerns, such as global warming and the depletion of fossil fuels, the renewable energy industry, particularly solar energy, has risen to global prominence. In this context, generative artificial intelligence (Gen-AI) can play a valuable role in facilitating the development of more efficient, durable, and adaptable solar systems. Gen-AI's multifaceted proficiency, from predictive maintenance and reducing downtime and costs to vital forecasting for grid management and strategic planning, extends to optimizing site selection for solar farms and smart grid integration, thereby enhancing solar energy flow, grid stability, and sustainable operation. This paper presents a comprehensive exploration of the role of Gen-AI in revolutionizing the solar energy industry. Focusing on various aspects of solar energy systems, including design, optimization, sizing, maintenance, energy forecasting, site selection, and smart grid integration, the study investigates the transformative impact of Gen-AI across these domains. It demonstrates how Gen-AI enhances the efficiency, sustainability, and adaptability of solar systems, driving strategic decision-making and optimizing the integration of solar power within complex energy ecosystems. Furthermore, the paper concludes by discussing the challenges and future prospects of employing Gen-AI in the solar energy domain, providing a comparative analysis of the current and future scenarios, and underscoring the advantages, disadvantages, and challenges of Gen-AI implementation.",AI-driven solar solutions | Generative artificial intelligence | Solar energy systems | Solar photovoltaic systems design and optimization | Solar systems predictive maintenance,25,2025,sustainability,behavior+sustainability
347,2-s2.0-85204384772,10.1016/j.compenvurbsys.2024.102194,https://doi.org/10.1016/j.compenvurbsys.2024.102194,https://scholar.google.com/scholar?q=10.1016/j.compenvurbsys.2024.102194,ar,Computers Environment and Urban Systems,"Dane, Gamze;Evers, Suzan;van den Berg, Pauline;Klippel, Alexander;Verduijn, Timon;Wallgrün, Jan Oliver;Arentze, Theo",Experiencing the future: Evaluating a new framework for the participatory co-design of healthy public spaces using immersive virtual reality,"Urban densification is promoted for sustainable urban growth, yet it also generates concerns about negative health impacts on local citizens. Engaging local citizens in the co-design of densification projects is therefore crucial to address their needs and concerns. The use of immersive Virtual Reality (VR) technologies creates potential for advancing the participatory co-design of healthier urban spaces by allowing citizens to not only visualize but also experience the impacts of future designs or “what-if” scenarios. Theoretically grounded in an extended version of Sheppard's approach, which we call the Experiencing the Future Framework (EFF), we developed a study to create and evaluate an immersive VR application called CoHeSIVE. This application was designed to facilitate participatory co-design processes for healthy public spaces. CoHeSIVE, as the technological manifestation of our framework, was created through iterative workshops with end-user input. During the final workshop with 41 participants, both qualitative and quantitative data were collected, including user behavior and experiences with CoHeSIVE, especially regarding its experiential and interactive components. The vast majority of participants had positive experiences and recommended CoHeSIVE for participatory co-design processes. Participants felt confident in their design outcomes and found the user interface easy to use and effective for making and communicating design decisions. The most preferred design attributes were found to be many and clustered trees, several benches, large grass areas, high-rise buildings, more lampposts and the presence of a fountain, showing that the design outcomes were meaningful for the selected local context. Future enhancements of CoHeSIVE might include adding more design attributes, enhancing visual representations, adding multi-user capabilities, integrating generative AI and expanding CoHeSIVE's applicability to other contexts.",Citizen engagement | Co-design | Healthy public space | Immersive virtual reality | Participatory design | Public participation | Urban public space,25,2024,sustainability,behavior+sustainability
557,2-s2.0-85208692008,10.1111/bjet.13534,https://doi.org/10.1111/bjet.13534,https://scholar.google.com/scholar?q=10.1111/bjet.13534,ar,British Journal of Educational Technology,"Edwards, Justin;Nguyen, Andy;Lämsä, Joni;Sobocinski, Marta;Whitehead, Ridwan;Dang, Belle;Roberts, Anni Sofia;Järvelä, Sanna",Human-AI collaboration: Designing artificial agents to facilitate socially shared regulation among learners,"Abstract: Socially shared regulation of learning (SSRL) is a crucial process for groups of learners to successfully collaborate. Detecting and supporting SSRL is a challenge, especially in real time, but hybrid intelligence approaches such as Artificial Intelligence (AI) agents may make this possible. Leveraging the concept of trigger events which invite SSRL, we present a design of an AI agent, MAI, which can detect SSRL and prompt students to raise their group-level metacognitive awareness with the aim of facilitating SSRL. We present the methodology we used to design MAI, drawing on the Echeloned DSR (eDSR) Methodological Framework and making use of the Wizard of Oz prototyping paradigm. We likewise present empirical results evaluating our initial prototype of MAI, using lexical alignment between speakers as a quantitative measure of the effect of MAI's prompts on facilitating SSRL, the Partner Model Questionnaire as a quantitative measure of perceptions of MAI, and interviews as qualitative context for these perceptions. We found that the first prototype of MAI did not facilitate SSRL as hoped, possibly owing to mixed perceptions of MAI's reliability and lack of clarity about MAI's role in the collaborative learning task. From these findings, we offer revised prompts for the next iteration of prototyping this agent and a refined set of design requirements for future development of metacognitive AI agents for supporting SSRL. Practitioner notes What is already known about this topic Socially Shared Regulation of Learning (SSRL) is recognized as a critical component for the success of collaborative learning, emphasizing the importance of group-level regulatory processes in achieving shared goals, enacting strategies and monitoring learning progress. Supporting SSRL in face-to-face collaborative learning environments presents challenges, including the complexity of coordinating and synchronizing individual contributions and regulatory actions within a group context. What this paper adds This paper introduces the design of Metacognitive Artificial Intelligence (MAI), a novel AI system aimed at enhancing Human-AI collaboration for supporting and augmenting SSRL processes. Through empirical research, the study offers lessons learned and design considerations for developing artificial agents on facilitating and enhancing SSRL among learners, demonstrating how AI can play a pivotal role in collaborative learning environments. The findings highlight the critical importance of multidisciplinary knowledge in the design of multi-agent interfaces (MAI) that provide real-time, adaptive support for group metacognitive processes and decision-making. Implications for practice and/or policy Educational technologists can utilize the proposed design principles in the development and integration of MAI tools to enhance SSRL. Educators can incorporate the principles of MAI and our relevant findings into their teaching strategies to actively foster and support socially shared regulation of learning among students. Policymakers should consider revising educational frameworks to include the use of AI technologies that support SSRL strategies in collaborative learning.",artificial intelligence | collaborative learning | design science research | human-AI collaboration | socially shared regulation | wizard of Oz,24,2025,behavior,behavior+policy
362,2-s2.0-85195278452,10.1016/j.envres.2024.119335,https://doi.org/10.1016/j.envres.2024.119335,https://scholar.google.com/scholar?q=10.1016/j.envres.2024.119335,ar,Environmental Research,"Wang, Shixiang;Liu, Chang;Zhou, Zheng",Government-enterprise green collaborative governance and urban carbon emission reduction: Empirical evidence from green PPP programs,"The reliance solely on the government or enterprises to promote climate governance is contingent upon the vested interests of economic entities and the regulatory bodies' efficiency in governance. Can the model of government-enterprise green collaborative governance evolve into a long-term mechanism for addressing the climate crisis and achieving the goals of sustainable development? By crawling data on public-private partnerships (PPP), employing ChatGPT to identify green PPP projects, and building a generalized difference-in-differences framework based on the Guidance on Building a Green Financial System issued in 2016, this present study investigates whether the involvement of private capital in government-led environmental and climate governance can effectively facilitate government-enterprise green collaborative governance, thereby mitigating urban carbon emissions. The study finds government-enterprise green collaborative governance can significantly reduce urban carbon emissions. The conclusion remains valid even after several rounds of robustness tests, including removing the influence of pertinent climate policies, adjusting the settings of independent and dependent variables, and removing self-selection issues. Heterogeneity tests show, on the first hand, the carbon emission reduction effect of government-enterprise green collaborative governance differs due to the differences in the characteristics of green PPP(Pubic-private partnership) projects such as project return mechanism, project investment volume, and project cooperation term; on the other hand, the carbon emission reduction effect also shows heterogeneity with various urban characteristics such as geographical location, city type and city size. Mechanism tests indicate government-enterprise green collaborative governance affects urban carbon emissions mainly through structural effects, technological effects and co-investment effects. This paper offers a valuable framework for effectively promoting environmental and climate co-governance between governmental bodies and enterprises, while enhancing the market's role in resource benefit allocation within climate governance to mitigate the risks associated with climate change.",Carbon emission | ChatGPT | Government-enterprise | Green collaborative governance | Green PPP,24,2024,sustainability,policy+sustainability
671,2-s2.0-85196370507,10.1016/j.fsidi.2024.301795,https://doi.org/10.1016/j.fsidi.2024.301795,https://scholar.google.com/scholar?q=10.1016/j.fsidi.2024.301795,re,Forensic Science International Digital Investigation,"Casu, Mirko;Guarnera, Luca;Caponnetto, Pasquale;Battiato, Sebastiano",GenAI mirage: The impostor bias and the deepfake detection challenge in the era of artificial illusions,"This paper examines the impact of cognitive biases on decision-making in forensics and digital forensics, exploring biases such as confirmation bias, anchoring bias, and hindsight bias. It assesses existing methods to mitigate biases and improve decision-making, introducing the novel “Impostor Bias”, which arises as a systematic tendency to question the authenticity of multimedia content, such as audio, images, and videos, often assuming they are generated by AI tools. This bias goes beyond evaluators' knowledge levels, as it can lead to erroneous judgments and false accusations, undermining the reliability and credibility of forensic evidence. Impostor Bias stems from an a priori assumption rather than an objective content assessment, and its impact is expected to grow with the increasing realism of AI-generated multimedia products. The paper discusses the potential causes and consequences of Impostor Bias, suggesting strategies for prevention and counteraction. By addressing these topics, this paper aims to provide valuable insights, enhance the objectivity and validity of forensic investigations, and offer recommendations for future research and practical applications to ensure the integrity and reliability of forensic practices.",Cognitive biases | Cognitive psychology | Deepfake detection | Diffusion models | Digital forensics | Forensic sciences | GAN | Generative AI | Impostor bias | Synthetic data,22,2024,behavior,behavior+policy
677,2-s2.0-85184572252,10.1515/jom-2023-0229,https://doi.org/10.1515/jom-2023-0229,https://scholar.google.com/scholar?q=10.1515/jom-2023-0229,re,Journal of Osteopathic Medicine,"Shumway, David O.;Hartman, Hayes J.",Medical malpractice liability in large language model artificial intelligence: Legal review and policy recommendations,"The emergence of generative large language model (LLM) artificial intelligence (AI) represents one of the most profound developments in healthcare in decades, with the potential to create revolutionary and seismic changes in the practice of medicine as we know it. However, significant concerns have arisen over questions of liability for bad outcomes associated with LLM AI-influenced medical decision making. Although the authors were not able to identify a case in the United States that has been adjudicated on medical malpractice in the context of LLM AI at this time, sufficient precedent exists to interpret how analogous situations might be applied to these cases when they inevitably come to trial in the future. This commentary will discuss areas of potential legal vulnerability for clinicians utilizing LLM AI through review of past case law pertaining to third-party medical guidance and review the patchwork of current regulations relating to medical malpractice liability in AI. Finally, we will propose proactive policy recommendations including creating an enforcement duty at the US Food and Drug Administration (FDA) to require algorithmic transparency, recommend reliance on peer-reviewed data and rigorous validation testing when LLMs are utilized in clinical settings, and encourage tort reform to share liability between physicians and LLM developers.",artificial intelligence | ChatGPT | large language models | liability | medical malpractice,21,2024,behavior,behavior+policy
648,2-s2.0-105003916189,10.1093/polsoc/puae040,https://doi.org/10.1093/polsoc/puae040,https://scholar.google.com/scholar?q=10.1093/polsoc/puae040,ar,Policy and Society,"Janssen, Marijn",Responsible governance of generative AI: Conceptualizing GenAI as complex adaptive systems,"Organizations increasingly use Generative Artificial Intelligence (AI) to create strategic documents, legislation, and recommendations to support decision-making. Many current AI initiatives are technology-deterministic, whereas technology co-evolves with the social environment, resulting in new applications and situations. This paper presents a novel view of AI governance by organizations from the perspective of complex adaptive systems (CASs). AI is conceptualized as a socio-technological and adaptive system in which people, policies, systems, data, AI, processes, and other elements co-evolve. The CAS lens draws attention to focusing AI governance on the entire organization, taking an outward perspective and considering public values and societal concerns. Although there is no shortage of AI governance instruments, they differ in their effectiveness, and combinations of appropriate mechanisms should be selected to deal with AI's evolving nature and complexity. A major challenge is that no responsibility, and therefore accountability, is taken due to the lack of understanding of the full socio-technological CAS. As such, joint accountability is needed in which involved parties work together.",AI governance | complex adaptive systems | generative AI | IT governance | responsible governance,20,2025,behavior,behavior+policy
659,2-s2.0-85206141831,10.1186/s13244-024-01801-w,https://doi.org/10.1186/s13244-024-01801-w,https://scholar.google.com/scholar?q=10.1186/s13244-024-01801-w,ar,Insights into Imaging,"Zanardo, Moreno;Visser, Jacob J.;Colarieti, Anna;Cuocolo, Renato;Klontzas, Michail E.;Pinto dos Santos, Daniel;Sardanelli, Francesco",Impact of AI on radiology: a EuroAIM/EuSoMII 2024 survey among members of the European Society of Radiology,"Abstract: In order to assess the perceptions and expectations of the radiology staff about artificial intelligence (AI), we conducted an online survey among ESR members (January–March 2024). It was designed considering that conducted in 2018, updated according to recent advancements and emerging topics, consisting of seven questions regarding demographics and professional background and 28 AI questions. Of 28,000 members contacted, 572 (2%) completed the survey. AI impact was predominantly expected on breast and oncologic imaging, primarily involving CT, mammography, and MRI, and in the detection of abnormalities in asymptomatic subjects. About half of responders did not foresee an impact of AI on job opportunities. For 273/572 respondents (48%), AI-only reports would not be accepted by patients; and 242/572 respondents (42%) think that the use of AI systems will not change the relationship between the radiological team and the patient. According to 255/572 respondents (45%), radiologists will take responsibility for any AI output that may influence clinical decision-making. Of 572 respondents, 274 (48%) are currently using AI, 153 (27%) are not, and 145 (25%) are planning to do so. In conclusion, ESR members declare familiarity with AI technologies, as well as recognition of their potential benefits and challenges. Compared to the 2018 survey, the perception of AI's impact on job opportunities is in general slightly less optimistic (more positive from AI users/researchers), while the radiologist’s responsibility for AI outputs is confirmed. The use of large language models is declared not only limited to research, highlighting the need for education in AI and its regulations. Critical relevance statement: This study critically evaluates the current impact of AI on radiology, revealing significant usage patterns and clinical implications, thereby guiding future integration strategies to enhance efficiency and patient care in clinical radiology. Key Points: The survey examines ESR member's views about the impact of AI on radiology practice. AI use is relevant in CT and MRI, with varying impacts on job roles. AI tools enhance clinical efficiency but require radiologist oversight for patient acceptance. Graphical Abstract: (Figure presented.).",Artificial intelligence | Diagnostic imaging | Radiology | Surveys and questionnaires,20,2024,behavior,behavior+policy
711,2-s2.0-85181751070,10.4103/jnsm.jnsm_89_23,https://doi.org/10.4103/jnsm.jnsm_89_23,https://scholar.google.com/scholar?q=10.4103/jnsm.jnsm_89_23,ar,Journal of Nature and Science of Medicine,"Bahammam, Ahmed Salem;Trabelsi, Khaled;Pandi-Perumal, Seithikurippu R.;Jahrami, Haitham",Adapting to the Impact of Artificial Intelligence in Scientific Writing: Balancing Benefits and Drawbacks while Developing Policies and Regulations,"This article examines the advantages and disadvantages of large language models (LLMs) and artificial intelligence (AI) in research and education and proposes the urgent need for an international statement to guide their responsible use. LLMs and AI demonstrate remarkable natural language processing, data analysis, and decision-making capabilities, offering potential benefits such as improved efficiency and transformative solutions. However, concerns regarding ethical considerations, bias, fake publications, and malicious use also arise. The objectives of this paper are to critically evaluate the utility of LLMs and AI in research and education, call for discussions between stakeholders, and discuss the need for an international statement. We identify advantages such as data processing, task automation, and personalized experiences, alongside disadvantages such as bias reinforcement, interpretability challenges, inaccurate reporting, and plagiarism. Stakeholders from academia, industry, government, and civil society must engage in open discussions to address the ethical, legal, and societal implications. The proposed international statement should emphasize transparency, accountability, ongoing research, and risk mitigation. Monitoring, evaluation, user education, and awareness are essential components. By fostering discussions and establishing guidelines, we can ensure the responsible and ethical development and use of LLMs and AI, maximizing benefits while minimizing risks. Copyright:",Artificial intelligence | Chat Generative Pre-Trained Transformer | declaration | ethics of artificial intelligence | human-machine discrimination abilities | research integrity,20,2023,behavior,behavior+policy
254,2-s2.0-85209724680,10.1016/j.techfore.2024.123908,https://doi.org/10.1016/j.techfore.2024.123908,https://scholar.google.com/scholar?q=10.1016/j.techfore.2024.123908,ar,Technological Forecasting and Social Change,"Gómez Gandía, José Andrés;Gavrila Gavrila, Sorin;de Lucas Ancillo, Antonio;del Val Núñez, María Teresa",Towards sustainable business in the automation era: Exploring its transformative impact from top management and employee perspective,"In recent years, organisations are in a continuous race in search of business sustainability, becoming a fundamental pillar of the organisation. The aim is to be more effective and efficient by doing more with less by managing all the organisation's resources. The ways in which organisations face these economic, social, and environmental challenges vary according to their activity. Globalisation has enabled economic growth, allowing the expansion of markets and access to goods and services worldwide. This has led to an increased level of global competition among organisations and the search for markets in which they have no competitors. In most cases they find markets with several players competing for a market with increasingly lower margins and trying to survive by seeking new competitive advantages. Purpose: The priority objective is to analyse the owner vs employee's perception of artificial intelligence and how it impacts the relationship with the sustainability of the company. For this purpose, a Likert survey has been carried out, which is an effective tool to evaluate this type of perception in a quantitative way. Today it is a strategic area for organisations, and this perception and employee behaviour are key to its proper functioning. Structure: The introductory section explains where the data comes from, explaining what is known, what is new and the aim of the work. This is followed by the research methodology applied, together with the criteria for selecting the data sets and categories. Finally, the conclusions section highlights the results obtained, their implications along with their limitations and possible future directions of the research. Findings: Sustainability in organisations is important in the generation and application of ideas and a novel perspective that drives organisational growth and contributes to sustainability, maintaining a balance between the three main dimensions, economic, social, and environmental. Innovation generates the creation of products, services or processes that reduce environmental impact, among others, promoting efficiency and the preservation of resources in the search for economic benefits. These technologies include green technologies, recycling strategies and renewable energies. The use of advanced technologies by organisations in their quest to achieve higher levels of sustainability offers a range of benefits that would otherwise be inaccessible. The integration of tools such as artificial intelligence (AI) and automation into business processes not only optimises operational efficiency, but also contributes significantly to environmental and economic sustainability. These technologies facilitate data-driven decision-making, improve resource management, and reduce waste, which is crucial for sustainable development. In addition, AI and automation can play a vital role in identifying opportunities for sustainable innovation, enabling organisations to proactively adapt to changing market demands and environmental regulations. However, it is essential to consider the ethical and social implications of these technologies, especially in terms of labour impact and data privacy. In this context, the need arises to explore the internal impact of AI and automation in organisations, specifically how these technologies are perceived by different actors within the company, such as owners and workers. To investigate this aspect, the use of Machine Learning Language Models (LLMs) represents a valuable methodological tool. By implementing LLMs, the aim is to compare the perceptions of owners and workers on several issues related to automation in the business environment. This includes aspects such as acceptance of the technology, perceived impact on productivity and well-being at work, and expectations regarding changes in work dynamics. This research could shed light on the discrepancies or overlaps in the perceptions of these groups, offering a deeper understanding of the socio-economic and cultural impact of automation and AI on organisations. Discussion: Today, it is necessary to manage the acquisition, creation, and application of knowledge differently from the way it was done until the last century. The organisation must be creative as it is essential for subsistence and for the development of sustainable strategies. Today, disruptive changes in technology are happening almost continuously. The research has revealed important results in terms of the perception of automation in the business environment, highlighting differences and alignments in the perspectives of employees and business owners. Artificial intelligence is beginning to have a priority place in the structure of the organisation, where they replace employees or create symbiotic relationships with optimal results. This allows organisations to keep up with such a revolutionary environment, identify opportunities to optimise processes by automating processes, reducing waste, and promoting ethical and socially responsible business practices in a world increasingly concerned with these aspects. Originality: The research in question, which uses a Machine Learning Language Model (LLM) such as ChatGPT to question perceptions of automation in a business environment, represents an innovative approach in the field of automation research. The use of an LLM to collect and analyse data offers a novel and efficient perspective, allowing for a more dynamic and in-depth analysis of the responses obtained. This methodology is distinguished by its ability to process and interpret a significant volume of qualitative data at a speed and with an accuracy that traditional survey methods cannot match. By using Likert-scale questions and analyzing responses from two different perspectives - that of business leaders and that of employees - the research addresses the complexity of perceptions of automation in a holistic manner. This dual approach allows us to identify not only the differences between these two groups, but also potential areas of alignment, providing a more nuanced view of how automation is perceived and experienced at different levels of the organisation. The advantages of this methodology are multiple. Firstly, using an LLM such as ChatGPT to analyse survey responses allows for a more detailed and nuanced interpretation of the data, especially in terms of capturing and understanding the subtleties of language and emotions implicit in the responses. In addition, the ability to process large datasets quickly and efficiently facilitates broader and more representative analysis, which can lead to more robust and reliable conclusions. In practical terms, this approach can help organisations better understand the attitudes and concerns of their employees and leaders regarding automation, which in turn can inform more effective implementation and change management strategies. It also provides valuable insights for the development of policies and practices that encourage a more harmonious and ethical integration of automation in the workplace, maximising its benefits while minimising potential negative impacts on staff. Practical implications: Studies on the perception of automation in the business context, both from the point of view of employees and owners, underline the need for adapted and differentiated approaches to integrating automation in the workplace. It highlights the divergent needs and concerns of these groups, suggesting that automation implementation strategies should not only focus on operational efficiency, but also address employee concerns about job security and the relevance of skills. This includes integrating training and professional development as key components of automation programmes, making sure that employees feel equipped and valued in the evolving automated workspace. In addition, the results highlight the importance of effective and transparent communication about the goals and impacts of automation and advocate the joint involvement of employees and managers in the design and implementation of automated solutions. Taken as a whole, the study emphasises the need for holistic and empathetic management of automation in organisations, viewing technology to improve the working environment and support employees' professional growth.",Business innovation | Sustainable automation integration | Sustainable business automation | Sustainable business strategies | Workforce sustainability,20,2025,sustainability,behavior+policy+sustainability
649,2-s2.0-105003830990,10.1093/polsoc/puae022,https://doi.org/10.1093/polsoc/puae022,https://scholar.google.com/scholar?q=10.1093/polsoc/puae022,ar,Policy and Society,"Ulnicane, Inga",Governance fix? Power and politics in controversies about governing generative AI,"The launch of ChatGPT in late 2022 led to major controversies about the governance of generative artificial intelligence (AI). This article examines the first international governance and policy initiatives dedicated specifically to generative AI: the G7 Hiroshima process, the Organisation for Economic Cooperation and Development reports, and the UK AI Safety Summit. This analysis is informed by policy framing and governance literature, in particular by the work on technology governance and Responsible Innovation. Emerging governance of generative AI exhibits characteristics of polycentric governance, where multiple and overlapping centers of decision-making are in collaborative relationships. However, it is dominated by a limited number of developed countries. The governance of generative AI is mostly framed in terms of the risk management, largely neglecting issues of purpose and direction of innovation, and assigning rather limited roles to the public. We can see a ""paradox of generative AI governance""emerging, namely, that while this technology is being widely used by the public, its governance is rather narrow. This article coins the term ""governance fix""to capture this rather narrow and technocratic approach to governing generative AI. As an alternative, it suggests embracing the politics of polycentric governance and Responsible Innovation that highlight democratic and participatory co-shaping of technology for social benefit. In the context of the highly unequal distribution of power in generative AI characterized by a high concentration of power in a small number of large tech companies, the government has a special role in reshaping the power imbalances by enabling wide-ranging public participation in the governance of generative AI.",artificial intelligence | generative AI | governance | Responsible Innovation | risk,19,2025,behavior,behavior+policy
656,2-s2.0-85218755514,10.24136/oc.3109,https://doi.org/10.24136/oc.3109,https://scholar.google.com/scholar?q=10.24136/oc.3109,ar,Oeconomia Copernicana,"Kliestik, Tomas;Dragomir, Robert;Băluță, Aurelian Virgil;Grecu, Iulia;Durana, Pavol;Karabolevski, Oana Ludmila;Kral, Pavol;Balica, Raluca;Suler, Petr;Bușu, Oprea Valentin;Bugaj, Martin;Voinea, Dan Valeriu;Vrbka, Jaromir;Cocoșatu, Mădălina;Grupac, Marian;Pera, Aurel;Gajdosikova, Dominika","Enterprise generative artificial intelligence technologies, internet of things and blockchain-based fintech management, and digital twin industrial metaverse in the cognitive algorithmic economy","Research background: Enterprise generative AI system-based worker behavior tracking and monitoring, socially responsible organizational practices, employee performance management satisfaction, and human resource management procedures, relationships, and outcomes develop on hiring and objective performance assessment algorithms in terms of human resource management activities, functions, processes, practices, policies, and productivity. Deep reinforcement and machine learning techniques, operational and analytical generative AI and cloud capabilities, and real-time anomalous behavior recognition systems further fintech development for credit and lending services, payment analytics processes, and risk assessment, monitoring, and mitigation. Generative AI tools can bolster predictive analytics by collaborative and interconnected sensor and machine data for tailored, seamless, and finetuned product, operational process, and organizational workflow development, efficiency, and innovation, driving agile transformative changes in digital twin industrial metaverse. Purpose of the article: We show that enterprise generative AI-driven schedule prediction tools, job search and algorithmic hiring systems, and synthetic training data can improve team selection, job performance and firing decisions, hiring decision processes, and workforce productivity in terms of prediction and decision-making by use of algorithmic management, system performance, and production process tracking tools. Blockchain-based fintech operations can shape cloud-based financial and digital banking services, quote-to-cash process automation, cash-settled crypto futures, digital loan decisioning, asset tokenization simulated transactions, transaction switching and routing operations, tailored peer-to-peer lending, and proactive credit line management. Collaborative unstructured enterprise data processing, infrastructure, and governance can develop on AI decision and behavior automation technology, retrieval augmented generation and development management systems, and real-time data descriptive and predictive analytics, driving productivity surges and competitive advantage in digital twin industrial metaverse. Methods: Reference and review management tools, together with evidence synthesis screening software, harnessed were Abstrackr, AMSTAR, ASReview Lab, CASP, Catchii, Citationchaser, DistillerSR, JBI SUMARI, Litstream, PICO Portal, and Rayyan. Findings & value added: The current state of the art is improved for theory on organizational issues and for policy making as deep learning-based generative AI tools and workplace monitoring systems can augment performance and productivity, gauge employee effectiveness, build resilient, satisfied, and engaged workforce, assess human capital, skill, and career development, drive employee and productivity expectations in relation to flexibility and stability, and shape turnover, retention, and loyalty. Cloud and account servicing technologies can be deployed in generative AI fintechs for embedded cryptocurrency trading, transaction monitoring and processing, digital asset transfers, payment screening, corporate and retail banking operations, and fraud prevention. Generative AI technologies can reshape jobs and reimagine meaningful work, involving creativity and innovation and adaptable and resilient sustained performance, providing valuable constructive feedback, optimizing workplace flexibility and psychological safety, and measuring and supporting autonomy and flexibility-based efficiency, performance, and productivity, while configuring demanding, engaging, and rewarding experiences by cloud and edge computing devices in digital twin industrial metaverse.",blockchain | cognitive algorithmic economy | digital twin industrial metaverse | enterprise generative artificial intelligence | fintech | internet of Thing,19,2024,behavior,behavior+policy
213,2-s2.0-86000332262,10.1016/j.jafr.2025.101787,https://doi.org/10.1016/j.jafr.2025.101787,https://scholar.google.com/scholar?q=10.1016/j.jafr.2025.101787,re,Journal of Agriculture and Food Research,"Shahriar, Sakib;Corradini, Maria G.;Sharif, Shayan;Moussa, Medhat;Dara, Rozita",The role of generative artificial intelligence in digital agri-food,"The agriculture and food (agri-food) sector faces rising global concerns about its sustainability and resilience to climate events. Thus, new solutions are needed to ensure environmental and food security. Artificial Intelligence (AI) offers inventive solutions to improve agricultural and food production practices. Generative AI methods, such as generative adversarial networks (GANs), variational autoencoders, and large language models (LLMs), add to the transformative process initiated by AI and expert systems in agricultural and food-related practices to enhance productivity, sustainability, and resilience. This study categorizes generative AI approaches and their capabilities in agri-food systems and provides a comprehensive review of the current landscape of generative AI applications in the sector. It discusses the impact of these technologies on enhancing agricultural productivity, food quality, and safety, as well as sustainability, presenting potential use cases like combatting climate change and foodborne disease modeling that highlight the practical applications and benefits of generative AI in agri-food. Furthermore, it addresses the ethical implications of deploying generative AI, including privacy, security, reliability, and unbiased decision-making.",Agri-food | Digital agriculture | Food authenticity | Food quality | Food safety | Food security | Generative artificial intelligence | Smart food | Sustainable agriculture,19,2025,sustainability,behavior+sustainability
255,2-s2.0-85205323401,10.1016/j.chb.2024.108460,https://doi.org/10.1016/j.chb.2024.108460,https://scholar.google.com/scholar?q=10.1016/j.chb.2024.108460,ar,Computers in Human Behavior,"Hong, Soo Jung",What drives AI-based risk information-seeking intent? Insufficiency of risk information versus (Un)certainty of AI chatbots,"This study explored the factors influencing the U.S. public's intent to seek risk information via AI-powered channels, such as ChatGPT. It focused on cognitive and affective pathways that lead to uncertainty about both risk information and AI chatbots in the context of climate change risk. We conducted a comparative analysis to discern the impacts of risk perceptions related to climate change and AI-caused privacy risks on public uncertainty and decision-making regarding the use of AI chatbots. Specifically, we assessed how different risk-related perceptions and emotions contribute to subsequent uncertainty perceptions and decision-making regarding AI chatbot use for climate change risk information. We enlisted 1023 U.S. citizens aged 21–65 via CloudResearch in September 2023. The results reveal that high levels of perceived risk, strong negative emotions, and information insufficiency drive information-seeking behavior through AI chatbots. Perceived privacy concerns about AI technology significantly increase AI anxiety, which is positively associated with perceived uncertainty. Both AI anxiety and perceived uncertainty negatively affect the intent to seek information via AI chatbots. Conversely, perceived trust in AI chatbots significantly increases positive emotional responses, reduces perceived uncertainty, and enhances the intent to seek information via AI chatbots. We also investigated the mediation effects within each study model tested. The findings offer theoretical and practical implications for future studies on the public's adoption of AI services for risk information seeking, influenced by both risk-related and technology-based contexts.",AI chatbots | Artificial intelligence | Privacy | Risk information seeking and processing (RISP) | Technology adoption | Trust,19,2025,sustainability,behavior+sustainability
416,2-s2.0-85153855335,10.17268/sci.agropecu.2023.010,https://doi.org/10.17268/sci.agropecu.2023.010,https://scholar.google.com/scholar?q=10.17268/sci.agropecu.2023.010,ar,Scientia Agropecuaria,"Siche, Raúl;Siche, Nikol",The language model based on sensitive artificial intelligence - ChatGPT: Bibliometric analysis and possible uses in agriculture and livestock,"ChatGPT adds to the list of artificial intelligence-based systems designed to perform specific tasks and answer questions by interacting with users (Apple's Siri, Amazon's Alexa, Google's Assistant and Bard, Microsoft's Cortana, IBM's Watson, Bixby from Samsung, among others). ChatGPT works using OpenAI's GPT (Generative Pretrained Transformer) language model and is capable of learning from users' preferences and behavior patterns to customize its response. ChatGPT has the potential to be applied in different fields, including education, journalism, scientific writing, communication, cell biology, and biotechnology, where there is already evidence. The aim of this work was to analyze the possible applications of ChatGPT in the agricultural and livestock industry. First, a scientometric analysis was performed with VosViewer and Bibliometrix (Bliblioshiny). 3 clusters were identified: (a) Main characteristics; (b) learning systems you use; and (c) applications. To the question: What are the main applications in which ChatGTP will revolutionize agriculture (or livestock) in the world? ChatGPT responded: (a) in the agricultural field: improvement of agricultural decision-making, optimization of agricultural production, detection and prevention of plant diseases, climate management, and supply chain management; and (b) in the livestock field: improvement of animal health and welfare, optimization of animal production, supply chain management, detection and prevention of zoonotic diseases, and climate management for animal production. ChatGPT does not scientifically support its answer, but from the analysis carried out, we find that there is enough scientific evidence to conclude, in this case, that its answers were correct. While ChatGPT does not necessarily scientifically substantiate its answers, users should. There is a lack of studies on the use of Artificial Intelligence and its relationship with ethics.",artificial intelligence | autoregressive language model | chatbot | data mining | deep learning | text mining | text production,19,2023,sustainability,behavior+sustainability
350,2-s2.0-85197231604,10.1007/s44163-024-00146-z,https://doi.org/10.1007/s44163-024-00146-z,https://scholar.google.com/scholar?q=10.1007/s44163-024-00146-z,ar,Discover Artificial Intelligence,"Greif, Lucas;Kimmig, Andreas;El Bobbou, Sleiman;Jurisch, Paul;Ovtcharova, Jivka",Strategic view on the current role of AI in advancing environmental sustainability: a SWOT analysis,"Sustainability has become a critical global concern, focusing on key environmental goals such as achieving net-zero emissions by 2050, reducing waste, and increasing the use of recycled materials in products. These efforts often involve companies striving to minimize their carbon footprints and enhance resource efficiency. Artificial intelligence (AI) has demonstrated significant potential in tackling these sustainability challenges. This study aims to evaluate the various aspects that must be considered when deploying AI for sustainability solutions. Employing a SWOT analysis methodology, we assessed the strengths, weaknesses, opportunities, and threats of 70 research articles associated with AI in this context. The study offers two main contributions. Firstly, it presents a detailed SWOT analysis highlighting recent advancements in AI and its role in promoting sustainability. Key findings include the importance of data availability and quality as critical enablers for AI’s effectiveness in sustainable applications, and the necessity of AI explainability to mitigate risks, particularly for smaller companies facing financial constraints in adopting AI. Secondly, the study identifies future research areas, emphasizing the need for appropriate regulations and the evaluation of general-purpose models, such as the latest large language models, in sustainability initiatives. This research contributes to the growing body of knowledge on AI’s role in sustainability by providing insights and recommendations for researchers, practitioners, and policymakers, thus paving the way for further exploration at the intersection of AI and sustainable development.",Artificial intelligence | Sustainability | SWOT analysis,19,2024,sustainability,policy+sustainability
352,2-s2.0-85195597218,10.1140/epjds/s13688-024-00481-2,https://doi.org/10.1140/epjds/s13688-024-00481-2,https://scholar.google.com/scholar?q=10.1140/epjds/s13688-024-00481-2,ar,EPJ Data Science,"Bronzini, Marco;Nicolini, Carlo;Lepri, Bruno;Passerini, Andrea;Staiano, Jacopo",Glitter or gold? Deriving structured insights from sustainability reports via large language models,"Over the last decade, several regulatory bodies have started requiring the disclosure of non-financial information from publicly listed companies, in light of the investors’ increasing attention to Environmental, Social, and Governance (ESG) issues. Publicly released information on sustainability practices is often disclosed in diverse, unstructured, and multi-modal documentation. This poses a challenge in efficiently gathering and aligning the data into a unified framework to derive insights related to Corporate Social Responsibility (CSR). Thus, using Information Extraction (IE) methods becomes an intuitive choice for delivering insightful and actionable data to stakeholders. In this study, we employ Large Language Models (LLMs), In-Context Learning, and the Retrieval-Augmented Generation (RAG) paradigm to extract structured insights related to ESG aspects from companies’ sustainability reports. We then leverage graph-based representations to conduct statistical analyses concerning the extracted insights. These analyses revealed that ESG criteria cover a wide range of topics, exceeding 500, often beyond those considered in existing categorizations, and are addressed by companies through a variety of initiatives. Moreover, disclosure similarities emerged among companies from the same region or sector, validating ongoing hypotheses in the ESG literature. Lastly, by incorporating additional company attributes into our analyses, we investigated which factors impact the most on companies’ ESG ratings, showing that ESG disclosure affects the obtained ratings more than other financial or company data.",Bipartite graph analyses | ESG dimensions | In-context learning | Interpretability | Knowledge graphs | Large language models | Non-financial disclosures,19,2024,sustainability,policy+sustainability
359,2-s2.0-85196764983,10.1007/s11165-024-10177-2,https://doi.org/10.1007/s11165-024-10177-2,https://scholar.google.com/scholar?q=10.1007/s11165-024-10177-2,ar,Research in Science Education,"Cheung, Kason Ka Ching;Pun, Jack K.H.;Li, Wangyin",Students’ Holistic Reading of Socio-Scientific Texts on Climate Change in a ChatGPT Scenario,"ChatGPT becomes a prominent tool for students’ learning of science when students read its scientific texts. Students read to learn about climate change misinformation using ChatGPT, while they develop critical awareness of the content, linguistic features as well as nature of AI and science to comprehend these texts. In this exploratory study, we investigated students’ reading performance in comprehending two ChatGPT-generated socio-scientific texts, with one focusing on cognitive-epistemic aspects of climate science and another one focusing on social-institutional aspects of climate science. We theorized such reading of ChatGPT-generated outputs as encompassing the content-interpretation, genre-reasoning and epistemic-evaluation domains. Combining Rasch partial-credit model and qualitative analysis, we explored and investigated how a total of 117 junior secondary students (grades 8 to 9) read such texts. Moreover, we also examined how 55 students’ holistic reading of socio-scientific texts on climate change in a ChatGPT scenario changes after a reading-science intervention. Our findings indicate that the content-interpretation was the easiest while the epistemic-evaluation domains were the most difficult. Interestingly, after the reading-science intervention, many students developed their tentative view on nature of science when they evaluated ChatGPT’s claims; while a small increase in number of students discussed reliability and non-epistemic nature of AI when they evaluated ChatGPT’s claims in relation to climate change. The findings also drive a pedagogical model that improves students’ holistic reading of socio-scientific texts generated by ChatGPT.",ChatGPT | Climate change | Epistemic reading | Reading in science,19,2024,sustainability,policy+sustainability
415,2-s2.0-85156208106,10.3389/fpubh.2023.1112981,https://doi.org/10.3389/fpubh.2023.1112981,https://scholar.google.com/scholar?q=10.3389/fpubh.2023.1112981,ar,Frontiers in Public Health,"Waheed, Dur E.Nayab;Bolio, Ana;Guillaume, Dominique;Sidibe, Anissa;Morgan, Christopher;Karafillakis, Emilie;Holloway, Megan;Van Damme, Pierre;Limaye, Rupali;Vorsters, Alex","Planning, implementation, and sustaining high coverage of human papillomavirus (HPV) vaccination programs: What works in the context of low-resource countries?","Cervical cancer due to human papillomavirus (HPV) infection is a leading cause of mortality among women in low-resource settings. Many Sub-Saharan African countries have introduced HPV vaccination programs at the national level in the last few years. However, countries are struggling to maintain sustainable coverage. This study focuses on the introduction and sustainability challenges, context-specific key lessons learned, and mechanisms of action to achieve high sustainable coverage from low and lower-middle-income countries (LLMICs) that have introduced HPV vaccination programs by collating evidence from a literature review and key informant interviews. Local data availability was a challenge across countries, with the lack or absence of registries, data collection and reporting mechanisms. Multi-sectoral coordination and early involvement of key stakeholders were cited as an integral part of HPV programs and facilitators for sustainable coverage. Key informants identified periodic sensitization and training as critical due to high staff turnover. Health workforce mobilization was fundamental to ensure that the health workforce is aware of the disease etiology, eligibility requirements, and can dispel misinformation. Schools were reported to be an ideal sustainable platform for vaccination. However, this required teachers to be trained, which was often not considered in the programs. District-level staff were often poorly informed and lacked the technical and logistic capacity to support vaccination rounds and data collection. To improve the sustainability of HPV vaccination programs, there is a need for timely microplanning, efficient preparedness assessment, assessing training approaches, periodic training, finding innovative ways to achieve equity and adoption of a bottom-up approach to ensure that processes between districts and central level are well-connected and resources are distributed efficiently.",barriers and facilitating factors | HPV vaccination | human papillomavirus | low-and lower-middle-income countries | vaccine implementation,19,2023,sustainability,policy+sustainability
707,2-s2.0-85166431365,10.1136/jnis-2023-020353,https://doi.org/10.1136/jnis-2023-020353,https://scholar.google.com/scholar?q=10.1136/jnis-2023-020353,re,Journal of Neurointerventional Surgery,"Ray, Tyler R.;Kellogg, Ryan T.;Fargen, Kyle M.;Hui, Ferdinand;Vargas, Jan",The perils and promises of generative artificial intelligence in neurointerventional surgery,"Generative artificial intelligence (AI) holds great promise in neurointerventional surgery by providing clinicians with powerful tools for improving surgical precision, accuracy of diagnoses, and treatment planning. However, potential perils include biases or inaccuracies in the data used to train the algorithms, over-reliance on generative AI without human oversight, patient privacy concerns, and ethical implications of using AI in medical decision-making. Careful regulation and oversight are needed to ensure that the promises of generative AI in neurointerventional surgery are realized while minimizing its potential perils. [ChatGPT authored summary using the prompt ""In one paragraph summarize the promises and perils of generative AI in neurointerventional surgery"".]",Economics | Political | Standards | Technology,18,2023,behavior,behavior+policy
364,2-s2.0-85204118044,10.3390/su16177829,https://doi.org/10.3390/su16177829,https://scholar.google.com/scholar?q=10.3390/su16177829,ar,Sustainability Switzerland,"Iatrellis, Omiros;Samaras, Nicholas;Kokkinos, Konstantinos;Panagiotakopoulos, Theodor",Leveraging Generative AI for Sustainable Academic Advising: Enhancing Educational Practices through AI-Driven Recommendations,"This study explores the integration of ChatGPT, a generative AI tool, into academic advising systems, aiming to assess its efficacy compared to traditional human-generated advisories. Conducted within the INVEST European University, which emphasizes sustainable and innovative educational practices, this research leverages AI to demonstrate its potential in enhancing sustainability within the context of academic advising. By providing ChatGPT with scenarios from academic advising, we evaluated the AI-generated recommendations against traditional advisories across multiple dimensions, including acceptance, clarity, practicality, impact, and relevance, in real academic settings. Five academic advisors reviewed recommendations across diverse advising scenarios such as pursuing certifications, selecting bachelor dissertation topics, enrolling in micro-credential programs, and securing internships. AI-generated recommendations provided unique insights and were considered highly relevant and understandable, although they received moderate scores in acceptance and practicality. This study demonstrates that while AI does not replace human judgment, it can reduce administrative burdens, significantly enhance the decision-making process in academic advising, and provide a foundation for a new framework that improves the efficacy and sustainability of academic advising practices.",academic advising | educational technology | generative AI | sustainable educational practices,18,2024,sustainability,behavior+sustainability
370,2-s2.0-85202750549,10.28991/ESJ-2024-08-04-021,https://doi.org/10.28991/ESJ-2024-08-04-021,https://scholar.google.com/scholar?q=10.28991/ESJ-2024-08-04-021,ar,Emerging Science Journal,"Acosta-Vargas, Patricia;Salvador-Acosta, Belén;Novillo-Villegas, Sylvia;Sarantis, Demetrios;Salvador-Ullauri, Luis",Generative Artificial Intelligence and Web Accessibility: Towards an Inclusive and Sustainable Future,"This study examines the accessibility of Generative Artificial Intelligence (AI) tools for people with disabilities, using WCAG 2.2 success criteria as a reference. Significant accessibility issues were identified in the evaluated applications, highlighting barriers mainly affecting disabled users. Integrating accessibility considerations from the beginning of application development and adopting a proactive approach are emphasized. Although challenges are faced, such as the shortage of inclusive training data and opacity in AI decision-making, the need to continue addressing various aspects of accessibility in the field of generative AI tools is acknowledged. These efforts are based on regulatory compliance and ethical principles to ensure equal societal participation, regardless of individual abilities. The fundamental role of accessibility in realizing this vision is highlighted, aligning with the United Nations Sustainable Development Goals, particularly those related to equality, education, innovation, and inclusion. Improving accessibility meets regulatory requirements and contributes to a broader global agenda for a more equitable and sustainable future.",Generative Artificial Intelligence | Inclusive | Sustainable Development Goals | Sustainable Future | WCAG 2.2 | Web Accessibility,18,2024,sustainability,behavior+sustainability
185,2-s2.0-105002007827,10.1177/07439156241309874,https://doi.org/10.1177/07439156241309874,https://scholar.google.com/scholar?q=10.1177/07439156241309874,ar,Journal of Public Policy and Marketing,"Hermann, Erik;Puntoni, Stefano",Generative AI in Marketing and Principles for Ethical Design and Deployment,"Generative AI (GenAI) is breaking new ground in emulating human capabilities, and content generation may only be the beginning. In this work, the authors systematize and illustrate promising areas of application of GenAI in marketing. They lay out a conceptual framework along two dimensions: (1) GenAI impact (i.e., human enhancement, human replacement) and (2) the marketing cycle stage (i.e., marketing research, marketing strategy formulation, marketing actions related to the marketing mix instruments). Based on the AI ethics literature, the authors then introduce a set of principles (i.e., ASSURANCE: Autonomy, Security, SUstainability, Representativeness, Accountability, Nonbiasedness and nondiscrimination, Crediting, Empowerment) to enable marketers to address the risks and challenges of GenAI and thereby achieve beneficial outcomes for companies, consumers, and society at large. Finally, they delineate the public policy implications for each principle and illustrate avenues for future research.",AI ethics | generative AI | human enhancement | human replacement | marketing mix | marketing research | marketing strategy,18,2025,sustainability,policy+sustainability
567,2-s2.0-85218862736,10.3390/smartcities8010019,https://doi.org/10.3390/smartcities8010019,https://scholar.google.com/scholar?q=10.3390/smartcities8010019,ar,Smart Cities,"Kalyuzhnaya, Anna;Mityagin, Sergey;Lutsenko, Elizaveta;Getmanov, Andrey;Aksenkin, Yaroslav;Fatkhiev, Kamil;Fedorin, Kirill;Nikitin, Nikolay O.;Chichkova, Natalia;Vorona, Vladimir;Boukhanovsky, Alexander",LLM Agents for Smart City Management: Enhancing Decision Support Through Multi-Agent AI Systems,"Highlights: What are the main findings? For smart city management, LLM-based multi-agent systems achieve 94–99% accuracy in routing urban queries and demonstrate significant improvements in response quality (G-Eval scores of 0.68–0.74) compared to standalone LLMs (0.30–0.38). Achievement of high scores in routing queries and response accuracy is possible with middle-size LLM models rather than the biggest LLM models. What is the implication of the main findings? The multi-agent LLM approach enables efficient processing of complex urban planning tasks while maintaining high relevance in responses, making it practical for real-world city management applications. LLM agents can effectively augment human decision making in urban planning by reducing task completion time from days to hours while maintaining accuracy and accountability in complex scenarios. This study investigates the implementation of LLM agents in smart city management, leveraging both the inherent language processing abilities of LLMs and the distributed problem solving capabilities of multi-agent systems for the improvement of urban decision making processes. A multi-agent system architecture combines LLMs with existing urban information systems to process complex queries and generate contextually relevant responses for urban planning and management. The research is focused on three main hypotheses testing: (1) LLM agents’ capability for effective routing and processing diverse urban queries, (2) the effectiveness of Retrieval-Augmented Generation (RAG) technology in improving response accuracy when working with local knowledge and regulations, and (3) the impact of integrating LLM agents with existing urban information systems. Our experimental results, based on a comprehensive validation dataset of 150 question–answer pairs, demonstrate significant improvements in decision support capabilities. The multi-agent system achieved pipeline selection accuracy of 94–99% across different models, while the integration of RAG technology improved response accuracy by 17% for strategic development queries and 55% for service accessibility questions. The combined use of document databases and service APIs resulted in the highest performance metrics (G-Eval scores of 0.68–0.74) compared to standalone LLM responses (0.30–0.38). Using St. Petersburg’s Digital Urban Platform as a testbed, we demonstrate the practical applicability of this approach to create integrated city management systems with support complex urban decision making processes. This research contributes to the growing field of AI-enhanced urban management by providing empirical evidence of LLM agents’ effectiveness in processing heterogeneous urban data and supporting strategic planning decisions. Our findings suggest that LLM-based multi-agent systems can significantly enhance the efficiency and accuracy of urban decision making while maintaining high relevance in responses.",data-driven management | large language model | LLM | LLM agent | multi-agent system | smart city management | strategic management,17,2025,behavior,behavior+policy
369,2-s2.0-85203506056,10.7146/mk.v40i76.143595,https://doi.org/10.7146/mk.v40i76.143595,https://scholar.google.com/scholar?q=10.7146/mk.v40i76.143595,ar,Mediekultur,"Driessens, Olivier;Pischetola, Magda","Danish university policies on generative AI Problems, assumptions and sustainability blind spots","The sudden and meteoric rise of generative Artificial Intelligence (genAI) has raised fundamental concerns for universities. Using Bacchi’s methodology on ‘problematisation’, we analyse which concerns Danish universities have addressed through their policies and guidelines. We identify three key problematisations: assessment integrity, legality of data and veracity. While each of these problematisations involves specific limitations, together they also strongly emphasise symbolic and epistemological issues and consequently mostly ignore the materiality of genAI, for example, in terms of labour and energy use. Drawing on critical AI studies, this article argues that universities should also consider the huge planetary costs that (gen)AI poses as well as the full range of AI’s exploitative business models and practices. Universities should integrate these considerations into both their decision-making on (not) using certain technologies and their policies and guidelines for research and teaching, just as sustainability is already a criterion in their travel or investment policies today.",ChatGPT | Denmark | Generative AI | higher education | policy | sustainability,17,2024,sustainability,behavior+sustainability
401,2-s2.0-85191155933,10.5267/j.ijdns.2024.1.019,https://doi.org/10.5267/j.ijdns.2024.1.019,https://scholar.google.com/scholar?q=10.5267/j.ijdns.2024.1.019,ar,International Journal of Data and Network Science,"Al Matalka, Mohammed;Badir, Rodayna;Bani Ahmad, Ahmad Y.A.;Al-Said, Khaleel;Nassar, Hajar Turki Ibrahim;Alzoubi, Saleem;Alzoubi, Mohammad",The adoption of ChatGPT marks the beginning of a new era in educational platforms,"Technology has significantly transformed knowledge, education, and access to information by introducing online learning platforms, interactive games, and virtual reality simulations in traditional classrooms, creating a dynamic, engaging, and inclusive learning environment. The ChatGBT project (a pre-developed transformer for training) is a remarkable achievement in artificial intelligence technology. It allows students tailored and efficient learning experiences by providing individual feedback and explanations. ChatGPT e-learning platform has been extensively studied for its adoption and acceptance, but there is a significant gap in research on its acceptability and use, highlighting the need for further exploration. The goal of this work is to bridge this disparity by introducing a comprehensive model that includes three basic elements: performance expectation, expected effort, and social impact. A total of 241 graduate students were surveyed and their data were analyzed using structural equation modeling techniques. The results indicate that “expectation of performance and expected effort” have the greatest impact and importance in determining students’ intentions to use learning platforms via ChatGPT, while social influence does not play an important role. This study enhances the current body of knowledge related to artificial intelligence and environmental sustainability, and provides important insights for professionals, policymakers, and producers of artificial intelligence products. These observations may provide guidance for creating and implementing artificial intelligence technologies to match consumers’ needs and preferences more effectively, while also taking into account broader environmental conditions.",Artificial Intelligence (AI) | ChatGPT | E-learning Adoption | Jordan,17,2024,sustainability,behavior+sustainability
398,2-s2.0-85195410193,10.1109/ACCESS.2024.3408843,https://doi.org/10.1109/ACCESS.2024.3408843,https://scholar.google.com/scholar?q=10.1109/ACCESS.2024.3408843,ar,IEEE Access,"Liang, Hao;Zhang, Jiaxin;Li, Yunqin;Wang, Bowen;Huang, Jingyong",Automatic Estimation for Visual Quality Changes of Street Space via Street-View Images and Multimodal Large Language Models,"Estimating Visual Quality of Street Space (VQoSS) is pivotal for urban design, environmental sustainability, civic engagement, etc. Recent advancements, notably in deep learning, have enabled large-scale analysis. However, traditional deep learning approaches are hampered by extensive data annotation requirements and limited adaptability across diverse VQoSS tasks. Multimodal Large Language Models (MLLMs) have recently demonstrated proficiency in various computer vision tasks, positioning them as promising tools for automated VQoSS assessment. In this paper, we pioneer the application of MLLMs to VQoSS change estimation, with our empirical findings affirming their effectiveness. In addition, we introduce Street Quality Generative Pre-trained Transformer (SQ-GPT), a model that distills knowledge from the current most powerful but inaccessible (not free) GPT-4V, requiring no human efforts. SQ-GPT approaches GPT-4V's performance and is viable for large-scale VQoSS change estimation. In a case study of Nanjing, we showcase the practicality of SQ-GPT and knowledge distillation pipeline. Our work promises to be a valuable asset for future urban studies research.",deep learning | multimodal large language models | Smart city | visual quality,17,2024,sustainability,policy+sustainability
576,2-s2.0-85217815308,10.1007/s10796-025-10582-6,https://doi.org/10.1007/s10796-025-10582-6,https://scholar.google.com/scholar?q=10.1007/s10796-025-10582-6,ar,Information Systems Frontiers,"Hughes, Laurie;Malik, Tegwen;Dettmer, Sandra;Al-Busaidi, Adil S.;Dwivedi, Yogesh K.",Reimagining Higher Education: Navigating the Challenges of Generative AI Adoption,"The proliferation of generative artificial intelligence (GenAI) has disrupted academic institutions across the world, presenting transformative challenges for decision makers, and leading to questions around existing methods and practices within higher education (HE). The widespread adoption of GenAI tools and processes highlights an ongoing change to existing perceptions of the role of humans and machines. Academics have expressed concerns relating to: academic integrity, undermining critical thinking, lowering of academic standards and the threat to existing academic models. This study presents a mixed methods approach to developing valuable insight to the key underlying challenges impacting GenAI adoption within HE. The results highlight many of the key challenges impacting decision makers in the formation of policy and strategic direction. The findings identify significant interdependencies between the key underlying challenges associated with GenAI adoption in HE. We further discuss the implications in the findings of the high levels of driving power of the factors: (i) perceived risks from Large Language Model training and learning; (ii) the reliability of GenAI outputs in the context of impact on creativity and decision making; (iii) the impact from poor levels of GenAI platform regulation. We posit this research as offering new insight and perspective on the changing landscape of HE through the widespread adoption of GenAI.",Adoption | Challenges | Generative AI | Generative Artificial Intelligence | Higher education | Large Language Models (LLMs),16,2025,behavior,behavior+policy
676,2-s2.0-85194562764,10.1016/j.ijdrr.2024.104574,https://doi.org/10.1016/j.ijdrr.2024.104574,https://scholar.google.com/scholar?q=10.1016/j.ijdrr.2024.104574,ar,International Journal of Disaster Risk Reduction,"Han, Jin;Zheng, Zhe;Lu, Xin Zheng;Chen, Ke Yin;Lin, Jia Rui",Enhanced earthquake impact analysis based on social media texts via large language model,"Social media aids disaster response but suffers from noise, hindering accurate impact assessment and decision making for resilient cities, which few studies considered. To address the problem, this study proposes the first domain-specific LLM model and an integrated method for rapid earthquake impact assessment. First, a few categories are introduced to classify and filter microblogs considering their relationship to the physical and social impacts of earthquakes, and a dataset comprising 7282 earthquake-related microblogs from twenty earthquakes in different locations is developed as well. Then, with a systematic analysis of various influential factors, QuakeBERT, a domain-specific large language model (LLM), is developed and fine-tuned for accurate classification and filtering of microblogs. Meanwhile, an integrated method integrating public opinion trend analysis, sentiment analysis, and keyword-based physical impact quantification is introduced to assess both the physical and social impacts of earthquakes based on social media texts. Experiments show that data diversity and data volume dominate the performance of QuakeBERT and increase the macro average F1 score by 27 %, while the best classification model QuakeBERT outperforms the CNN- or RNN-based models by improving the macro average F1 score from 60.87 % to 84.33 %. Finally, the proposed approach is applied to assess two earthquakes with the same magnitude and focal depth. Results show that the proposed approach can effectively enhance the impact assessment process by accurate detection of noisy microblogs, which enables effective post-disaster emergency responses to create more resilient cities.",BERT | Earthquake | Impact assessment | Large language model | Social impact | Social media | Text mining,16,2024,behavior,behavior+policy
688,2-s2.0-85187795431,10.1145/3636550,https://doi.org/10.1145/3636550,https://scholar.google.com/scholar?q=10.1145/3636550,ar,Digital Government Research and Practice,"Mellouli, Sehl;Janssen, Marijn;Ojo, Adegboyega",Introduction to the Issue on Artificial Intelligence in the Public Sector: Risks and Benefits of AI for Governments,"Artificial Intelligence (AI) is increasingly adopted by public sector organizations to provide better public services and to transform their internal processes. AI is now considered a key enabler for digital innovation and transformation in the public sector. However, AI is still relatively a new research area in the field of digital government. The term, AI, captures a wide range of technologies, techniques, and tools such as machine/deep learning, natural language processing, robotics, computer vision, and more recently Generative AI. While these AI technologies afford different applications and benefits in the gov- ernment context, they also create social, ethical, and legal challenges. These challenges require solutions combining both technical (e.g., data and algorithmic solutions to minimize bias) and institutional (e.g., governance structures and processes) mechanisms. The special issue is a collection of articles that contribute to a better understanding of the issues associated with AI deployment in different areas of government operations. They cover AI applications in the areas of emergency re- sponse, policy analysis, public bids, and citizen participation. The contributions also address the challenge of realizing a legal transparency regime for AI in government and the effect of AI in bureaucratic decision-making.",Artificial intelligence | benefits | e-government | risks,16,2024,behavior,behavior+policy
377,2-s2.0-85182179451,10.1002/lrh2.10406,https://doi.org/10.1002/lrh2.10406,https://scholar.google.com/scholar?q=10.1002/lrh2.10406,ar,Learning Health Systems,"Al-Anezi, Fahad M.",Exploring the use of ChatGPT as a virtual health coach for chronic disease management,"Introduction: ChatGPT has been widely researched for its potential in gealthcare applications. However, its efficcy as a virtual health coach is one of the important areas, which can significantly contribute to the sustainablility in healthcare operations, especially in managing critical illnesses. Therefore, this study aims to analyze the use of ChatGPT as a virtual health coach for chronic disease managemet. Methods: This study used a quasi-experimental design because ChatGPT is a relatively new technology and few people have experience with it. Patients who were receiving care outside of the hospital were included. Semi-structured interviews were conducted after a 2-week period in which participants used ChatGPT to search for health information about chronic disease management. Thirty-nine outpatients were interviewed and thematic analysis was used to analyze the interview data. Results: The findings suggested both opportunities and challenges of using ChatGPT as a virtual health coach for chronic disease management. The major opportunities identified included life-long learning, improved health literacy, cost-effectiveness, behavioral change support, scalability, and accessibility. The major challenges identified included limited physical examination, lack of human connection, legal and ethical complications, and lack of accuracy and reliability. Conclusion: ChatGPT-based technologies may serve as a supplementary or intermediate support system. However, such applications for managing chronic diseases must protect privacy and promote both short- and long-term positive outcomes.",ChatGPT | disease management | heath informatics,16,2024,sustainability,behavior+sustainability
410,2-s2.0-85185474400,10.4108/EW.4825,https://doi.org/10.4108/EW.4825,https://scholar.google.com/scholar?q=10.4108/EW.4825,ar,Eai Endorsed Transactions on Energy Web,"Tomar, Praveen;Grover, Veena","Transforming the Energy Sector: Addressing Key Challenges through Generative AI, Digital Twins, AI, Data Science and Analysis","The energy sector, both in the UK and globally, faces significant challenges in the pursuit of sustainability and efficient resource utilization. Climate change, resource depletion, and the need for decarbonization demand innovative solutions. This analytical research paper examines the key challenges in the energy sector and explores how generative AI, digital twins, AI, and data science can play a transformative role in addressing these challenges. By leveraging advanced technologies and data-driven approaches, the energy sector can achieve greater efficiency, optimize operations, and facilitate informed decision-making. Artificial Intelligence (AI) involves replicating human-like intelligence in machines, enabling them to execute tasks that typically demand human cognitive capabilities like perception, reasoning, learning, and problemDsolving. AI encompasses various methodologies and technologies, such as machine learning, natural language processing, computer vision, and robotics. Its adoption in the energy sector carries significant promise for addressing critical concerns and revolutionizing the industry. An overarching challenge in the energy sector revolves around enhancing energy efficiency, and AI emerges as a pivotal tool for optimizing energy utilization and curbing wastage. By analyzing vast amounts of data from various sources such as sensors, smart meters, and historical energy consumption patterns, AI algorithms can identify patterns and anomalies that humans may not detect. This enables the development of predictive models and algorithms that optimize energy consumption, leading to significant energy savings.",Artificial Intelligence | Climate change | Data Science | Energy Sector,16,2023,sustainability,behavior+sustainability
358,2-s2.0-85206260281,10.1016/j.dwt.2024.100829,https://doi.org/10.1016/j.dwt.2024.100829,https://scholar.google.com/scholar?q=10.1016/j.dwt.2024.100829,ar,Desalination and Water Treatment,"Wang, Guansu;Kumar, Sameer;Huang, Zhihong;Liu, Ruoyi",Water resource management and policy evaluation in Middle Eastern countries: Achieving sustainable development goal 6,"This study explores the challenges and management strategies of water resources in 15 Middle Eastern countries, framed within the context of Sustainable Development Goal 6 (SDG6). This study used 123 water resource policies in Middle Eastern countries as data and employed a pre-trained large language model based on RoBERTa, trained on the SNLI and MNLI datasets, to perform text classification tasks. In combination with the TF-IDF algorithm for keyword extraction, this approach is used to systematically evaluate and compare the water resource policies of these countries. The results reveal that the region faces significant water stress, exacerbated by high population growth, climate variability, and political instability. While countries like Kuwait and the UAE utilize advanced desalination technologies to mitigate water scarcity, policy gaps in sanitation and transboundary cooperation persist. Jordan's innovative partnerships for water resource management highlight the potential of collaborative frameworks to enhance regional water security. The findings suggest that comprehensive water management strategies, including technological innovation and public-private partnerships, are essential for addressing the region's pressing water challenges. This research contributes to understanding the complexities of water governance in arid regions and offers practical implications for policymakers aiming to achieve sustainable water resource management.",Middle Eastern Countries | Policy | SDG 6 | Water resource management,16,2024,sustainability,policy+sustainability
383,2-s2.0-85192747039,10.53761/b182ws13,https://doi.org/10.53761/b182ws13,https://scholar.google.com/scholar?q=10.53761/b182ws13,ar,Journal of University Teaching and Learning Practice,"Mahrishi, Mehul;Abbas, Asad;Radovanović, Danica;Hosseini, Samira",Emerging Dynamics of ChatGPT in Academia: A Scoping Review,"Large Language Models (LLMs) and Generative AI tools are revolutionising every aspect of academia, including medical, physical, and STEM education. They have also proved their mettle in blended learning systems and distance learning programs by improving educational sustainability, accessibility, and engagement. Through this scoping review, we aim to provide an essential overview of the state of the art of ChatGPT from the standpoint of exploring its development, analysing its current trajectory, and emerging dynamics in active research responsible for defining regulations and protocols. The PRISMA benchmarking was used on the Scopus dataset, with 109 papers from 2022 to 2023. Interactive results and bibliographic maps are generated using the Bibliometrix library of R-Studio. The findings are aligned with the research questions and represent exceptional growth in scientific production. Furthermore, relevant avenues for research publications, leading countries, and institutions in the area are also listed. The thematic and trends analysis anticipated that artificial intelligence and generative AI will substantially influence nearly every dimension in the coming years. The review also identified the possible advantages and disadvantages of adopting ChatGPT in higher education and analysed its deployment, considering ethical issues. The research concludes that, apart from ChatGPT, other large language models are also transforming artificial intelligence in education. However, ethical concerns and implications in education highlight vital issues for further research to ensure AI's responsible and ethical use.",AIED | ChatGPT | Education Innovation | Generative AI | Higher Education | Large Language Model,16,2024,sustainability,policy+sustainability
384,2-s2.0-85183133133,10.1016/j.isci.2024.108782,https://doi.org/10.1016/j.isci.2024.108782,https://scholar.google.com/scholar?q=10.1016/j.isci.2024.108782,re,Iscience,"Hamed, Ahmed Abdeen;Zachara-Szymanska, Malgorzata;Wu, Xindong","Safeguarding authenticity for mitigating the harms of generative AI: Issues, research agenda, and policies for detection, fact-checking, and ethical AI","As the influence of transformer-based approaches in general and generative artificial intelligence (AI) in particular continues to expand across various domains, concerns regarding authenticity and explainability are on the rise. Here, we share our perspective on the necessity of implementing effective detection, verification, and explainability mechanisms to counteract the potential harms arising from the proliferation of AI-generated inauthentic content and science. We recognize the transformative potential of generative AI, exemplified by ChatGPT, in the scientific landscape. However, we also emphasize the urgency of addressing associated challenges, particularly in light of the risks posed by disinformation, misinformation, and unreproducible science. This perspective serves as a response to the call for concerted efforts to safeguard the authenticity of information in the age of AI. By prioritizing detection, fact-checking, and explainability policies, we aim to foster a climate of trust, uphold ethical standards, and harness the full potential of AI for the betterment of science and society.",Artificial intelligence | Artificial intelligence applications | Biocomputational method | Bioinformatics | Biological sciences | Computational bioinformatics | Natural sciences | Neural networks,16,2024,sustainability,policy+sustainability
566,2-s2.0-85219179259,10.3390/fi17020057,https://doi.org/10.3390/fi17020057,https://scholar.google.com/scholar?q=10.3390/fi17020057,re,Future Internet,"Karim, Md Monjurul;Van, Dong Hoang;Khan, Sangeen;Qu, Qiang;Kholodov, Yaroslav",AI Agents Meet Blockchain: A Survey on Secure and Scalable Collaboration for Multi-Agents,"In recent years, the interplay between AI agents and blockchain has enabled secure and scalable collaboration among multi-agent systems, promoting unprecedented levels of autonomy and interoperability. AI agents play a vital role in facilitating complex decision making and improving operational efficiency in blockchain systems. This collaborative synergy is particularly evident in how multi-agent systems collectively tackle complex tasks to ensure seamless integration within these frameworks. While significant efforts have been made to integrate AI agents and blockchain, most studies overlook the broader potential of AI agents in addressing challenges such as interoperability, scalability, and privacy issues. In this paper, we bridge these gaps by illustrating the interplay between AI agents and blockchain. Specifically, we explore how AI agents enhance decentralized systems and examine blockchain’s role in enabling secure and scalable collaboration. Furthermore, we categorize practical applications across domains, such as Web3, decentralized finance (DeFi), asset management, and autonomous systems, providing practical insights and real-world use cases. Additionally, we identify key research challenges, including the complexities of multi-agent coordination, interoperability across diverse systems, and privacy maintenance in decentralized frameworks. Finally, we offer future directions in terms of governance, sovereignty, computation, and interpretability to promote a secure and responsible ecosystem.",AI agent | blockchain | decentralized AI | large language model | multi-agent collaboration | Web3,15,2025,behavior,behavior+policy
680,2-s2.0-85196069128,10.24059/olj.v28i2.4397,https://doi.org/10.24059/olj.v28i2.4397,https://scholar.google.com/scholar?q=10.24059/olj.v28i2.4397,ar,Online Learning Journal,"Younis, Bilal Khallel","Examining Students’ Self-Regulation Skills, Confidence to Learn Online, and Perception of Satisfaction and Usefulness of Online Classes in Three Suggested Online Learning Environments that Integrates ChatGPT","This study aims to investigate students’ self-regulation skills, confidence to learn online, and perception of satisfaction and usefulness of online classes in three online learning environments that integrate ChatGPT. The participants were 100 undergraduate students from Palestine Technical University Kadoorie registered in a problem-solving and decision-making course during the first semester of 2023–2024 academic year. These participants were at various stages of their bachelor’s degree programs within the Faculty of Arts and Educational Sciences. A quasi-experimental design was used to compare three online learning environments that integrate ChatGPT (independent, peer, and group). A total of 100 undergraduate students were randomly assigned to these three groups. Three questionnaires were used for data collection. The results showed that the self-regulation levels were high among the participants in these three online ChatGPT groups. However, learning in peer and group environments were more effective in developing self-regulation skills than learning independently. This research also found that the participants in the peer and group learning environments had high levels of confidence to learn online compared to the participants in the independent group. The results also showed that the participants in the peer learning group had the highest scores in perception of satisfaction and usefulness of online classes compared to the participants in the independent and group learning environments. The findings of this study support the notion that integrating ChatGPT within peer groups can enhance students’ perception of satisfaction and usefulness of online classes. Therefore, integrating ChatGPT in online peer group settings can bring about a transformative educational experience marked by customized interactions, adaptable content delivery, and enhanced engagement levels. Educators should explore ways to leverage ChatGPT to facilitate meaningful interactions and collaboration among students, thereby increasing their satisfaction and engagement with online learning materials and activities. The findings from this research offer potential for enriching online learning experiences through the use of AI technologies.",ChatGPT | confidence to learn online | online learning | perception of satisfaction | self-regulation skills,15,2024,behavior,behavior+policy
681,2-s2.0-85195522971,10.1016/j.jval.2024.01.019,https://doi.org/10.1016/j.jval.2024.01.019,https://scholar.google.com/scholar?q=10.1016/j.jval.2024.01.019,ar,Value in Health,"Fleurence, Rachael L.;Kent, Seamus;Adamson, Blythe;Tcheng, James;Balicer, Ran;Ross, Joseph S.;Haynes, Kevin;Muller, Patrick;Campbell, Jon;Bouée-Benhamiche, Elsa;García Martí, Sebastián;Ramsey, Scott",Assessing Real-World Data From Electronic Health Records for Health Technology Assessment: The SUITABILITY Checklist: A Good Practices Report of an ISPOR Task Force,"This ISPOR Good Practices report provides a framework for assessing the suitability of electronic health records data for use in health technology assessments (HTAs). Although electronic health record (EHR) data can fill evidence gaps and improve decisions, several important limitations can affect its validity and relevance. The ISPOR framework includes 2 components: data delineation and data fitness for purpose. Data delineation provides a complete understanding of the data and an assessment of its trustworthiness by describing (1) data characteristics; (2) data provenance; and (3) data governance. Fitness for purpose comprises (1) data reliability items, ie, how accurate and complete the estimates are for answering the question at hand and (2) data relevance items, which assess how well the data are suited to answer the particular question from a decision-making perspective. The report includes a checklist specific to EHR data reporting: the ISPOR SUITABILITY Checklist. It also provides recommendations for HTA agencies and policy makers to improve the use of EHR-derived data over time. The report concludes with a discussion of limitations and future directions in the field, including the potential impact from the substantial and rapid advances in the diffusion and capabilities of large language models and generative artificial intelligence. The report's immediate audiences are HTA evidence developers and users. We anticipate that it will also be useful to other stakeholders, particularly regulators and manufacturers, in the future.",data quality | electronic health records | health technology assessment | real-world data | real-world evidence,15,2024,behavior,behavior+policy
246,2-s2.0-105001096650,10.1115/1.4066730,https://doi.org/10.1115/1.4066730,https://scholar.google.com/scholar?q=10.1115/1.4066730,ar,Journal of Computing and Information Science in Engineering,"Grandi, Daniele;Jain, Yash Patawari;Groom, Allin;Cramer, Brandon;McComb, Christopher",Evaluating Large Language Models for Material Selection,"Material selection is a crucial step in conceptual design due to its significant impact on the functionality, aesthetics, manufacturability, and sustainability impact of the final product. This study investigates the use of large language models (LLMs) for material selection in the product design process and compares the performance of LLMs against expert choices for various design scenarios. By collecting a dataset of expert material preferences, the study provides a basis for evaluating how well LLMs can align with expert recommendations through prompt engineering and hyperparameter tuning. The divergence between LLM and expert recommendations is measured across different model configurations, prompt strategies, and temperature settings. This approach allows for a detailed analysis of factors influencing the LLMs’ effectiveness in recommending materials. The results from this study highlight two failure modes: the low variance of recommendations across different design scenarios and the tendency toward overestimating material appropriateness. Parallel prompting is identified as a useful prompt-engineering method when using LLMs for material selection. The findings further suggest that, while LLMs can provide valuable assistance, their recommendations often vary significantly from those of human experts. This discrepancy underscores the need for further research into how LLMs can be better tailored to replicate expert decision-making in material selection. This work contributes to the growing body of knowledge on how LLMs can be integrated into the design process, offering insights into their current limitations and potential for future improvements.",artificial intelligence | context-aware design assistance | data-driven engineering | large language models | machine learning for engineering applications | material selection,15,2025,sustainability,behavior+sustainability
663,2-s2.0-85210553300,10.3390/technologies12110222,https://doi.org/10.3390/technologies12110222,https://scholar.google.com/scholar?q=10.3390/technologies12110222,re,Technologies,"Harris, Sheetal;Hadi, Hassan Jalil;Ahmad, Naveed;Alshara, Mohammed Ali","Fake News Detection Revisited: An Extensive Review of Theoretical Frameworks, Dataset Assessments, Model Constraints, and Forward-Looking Research Agendas","The emergence and acceptance of digital technology have caused information pollution and an infodemic on Online Social Networks (OSNs), blogs, and online websites. The malicious broadcast of illegal, objectionable and misleading content causes behavioural changes and social unrest, impacts economic growth and national security, and threatens users’ safety. The proliferation of AI-generated misleading content has further intensified the current situation. In the previous literature, state-of-the-art (SOTA) methods have been implemented for Fake News Detection (FND). However, the existing research lacks multidisciplinary considerations for FND based on theories on FN and OSN users. Theories’ analysis provides insights into effective and automated detection mechanisms for FN, and the intentions and causes behind wide-scale FN propagation. This review evaluates the available datasets, FND techniques, and approaches and their limitations. The novel contribution of this review is the analysis of the FND in linguistics, healthcare, communication, and other related fields. It also summarises the explicable methods for FN dissemination, identification and mitigation. The research identifies that the prediction performance of pre-trained transformer models provides fresh impetus for multilingual (even for resource-constrained languages), multidomain, and multimodal FND. Their limits and prediction capabilities must be harnessed further to combat FN. It is possible by large-sized, multidomain, multimodal, cross-lingual, multilingual, labelled and unlabelled dataset curation and implementation. SOTA Large Language Models (LLMs) are the innovation, and their strengths should be focused on and researched to combat FN, deepfakes, and AI-generated content on OSNs and online sources. The study highlights the significance of human cognitive abilities and the potential of AI in the domain of FND. Finally, we suggest promising future research directions for FND and mitigation.",dataset evaluation | deep learning | fake news detection | machine learning | natural language processing | social networks,14,2024,behavior,behavior+policy
199,2-s2.0-85217375226,10.1016/j.compag.2025.110028,https://doi.org/10.1016/j.compag.2025.110028,https://scholar.google.com/scholar?q=10.1016/j.compag.2025.110028,ar,Computers and Electronics in Agriculture,"Chen, Dong;Huang, Yanbo",Integrating reinforcement learning and large language models for crop production process management optimization and control through a new knowledge-based deep learning paradigm,"Efficient and sustainable crop production process management is crucial to meet the growing global demand for food, fuel, and feed while minimizing environmental impacts. Traditional crop management practices, often developed through empirical experience, face significant challenges in adapting to the dynamic nature of modern agriculture, which is influenced by factors such as climate change, soil variability, and market conditions. Recently, reinforcement learning (RL) and large language models (LLMs) bring transformative potential, with RL providing adaptive methodologies to learn optimal strategies and LLMs offering vast, superhuman knowledge across agricultural domains, enabling informed, context-specific decision-making. This paper systematically examines how the integration of RL and LLMs into crop management decision support systems (DSSs) can drive advancements in agricultural practice. We explore recent advancements in RL and LLM algorithms, their application within crop management, and the use of crop management simulators to develop these technologies. The convergence of RL and LLMs with crop management DSSs presents new opportunities to optimize agricultural practices through data-driven, adaptive solutions that can address the uncertainties and complexities of crop production. However, this integration also brings challenges, particularly in real-world deployment. We discuss these challenges and propose potential solutions, including the use of offline RL and enhanced LLM integration, to maximize the effectiveness and sustainability of crop management. Our findings emphasize the need for continued research and innovation to unlock the full potential of these advanced tools in transforming agricultural systems into optimal and controllable ones.",Agricultural cybernetics | Artificial intelligence | Crop management | Foundation models | Large language models | Reinforcement learning,14,2025,sustainability,behavior+sustainability
208,2-s2.0-105002557398,10.1108/JFBM-08-2024-0160,https://doi.org/10.1108/JFBM-08-2024-0160,https://scholar.google.com/scholar?q=10.1108/JFBM-08-2024-0160,re,Journal of Family Business Management,"Kumar, Deepak;Ratten, Vanessa",Artificial intelligence and family businesses: a systematic literature review,"Purpose: This paper examines the integration of artificial intelligence (AI) within family businesses, focusing on how AI can enhance their competitiveness, resilience and sustainability. The study seeks to provide insights into AI’s application in family business contexts, addressing the unique strengths and challenges these businesses face. Design/methodology/approach: A systematic literature review was conducted to synthesize existing research on the adoption and integration of AI in family businesses. The review involved a comprehensive analysis of relevant academic literature to identify key trends, opportunities, challenges and factors influencing AI adoption in family-owned enterprises. Findings: The review highlights the significant potential of AI for family businesses, particularly in improving operations, decision-making and customer engagement. It identifies opportunities such as analysing customer data, enhancing brand building, streamlining operations and improving customer experiences through technologies like Generative AI, Machine Learning, AI Chatbots and NLP. However, challenges like resource constraints, inadequate infrastructure, low customization and AI knowledge gaps inhibit AI adoption in family firms. The study proposes an AI adoption roadmap tailored for family businesses and outlines future research directions based on emerging themes in AI use within these enterprises. Originality/value: This paper addresses the underexplored area of AI integration in family businesses, contributing to the academic understanding of the intersection between AI and family-owned enterprises. The study offers a comprehensive synthesis of existing research, providing valuable insights and practical recommendations for enhancing the competitiveness and sustainability of family businesses through AI adoption.",AI adoption | Artificial intelligence (AI) | Business innovation | Family business,14,2025,sustainability,behavior+sustainability
381,2-s2.0-85194269577,10.3390/en17102338,https://doi.org/10.3390/en17102338,https://scholar.google.com/scholar?q=10.3390/en17102338,ar,Energies,"Menéndez Medina, Alberto;Heredia Álvaro, José Antonio",Using Generative Pre-Trained Transformers (GPT) for Electricity Price Trend Forecasting in the Spanish Market,"The electricity market in Spain holds significant importance in the nation’s economy and sustainability efforts due to its diverse energy mix that encompasses renewables, fossil fuels, and nuclear power. Accurate energy price prediction is crucial in Spain, influencing the country’s ability to meet its climate goals and ensure energy security and affecting economic stakeholders. We have explored how leveraging advanced GPT tools like OpenAI’s ChatGPT to analyze energy news and expert reports can extract valuable insights and generate additional variables for electricity price trend prediction in the Spanish market. Our research proposes two different training and modelling approaches of generative pre-trained transformers (GPT) with specialized news feeds specific to the Spanish market: in-context example prompts and fine-tuned GPT models. We aim to shed light on the capabilities of GPT solutions and demonstrate how they can augment prediction models by introducing additional variables. Our findings suggest that insights derived from GPT analysis of electricity news and specialized reports align closely with price fluctuations post-publication, indicating their potential to improve predictions and offer deeper insights into market dynamics. This endeavor can support informed decision-making for stakeholders in the Spanish electricity market and companies reliant on electricity costs and price volatility for their margins.",electricity market price | Generative AI | GPT | sentiment analysis | Spain,14,2024,sustainability,behavior+sustainability
249,2-s2.0-85217148383,10.1109/OJCS.2025.3536082,https://doi.org/10.1109/OJCS.2025.3536082,https://scholar.google.com/scholar?q=10.1109/OJCS.2025.3536082,re,IEEE Open Journal of the Computer Society,"Tabassum, Aliya;Elmahjub, Ezieddin;Padela, Aasim I.;Zwitter, Andrej;Qadir, Junaid",Generative AI and the Metaverse: A Scoping Review of Ethical and Legal Challenges,"The metaverse, a pioneering digital realm merging virtual and augmented realities with Artificial Intelligence (AI), represents a transformative environment where digital and physical realities converge seamlessly. Generative AI (GenAI) is indispensable in powering the metaverse's dynamic and immersive experiences, enabling the autonomous generation of diverse digital content. Large Language Models (LLMs), as a component of GenAI, play a critical role by facilitating real-time communication, multilingual translation, and personalized interactions, enhancing user engagement in shared virtual spaces. This scoping review explores the interdependence between GenAI and the metaverse and the unique ethical and legal challenges that emerge from their integration. It identifies key ethical and legal issues, such as bias in AI-generated content, misinformation, and data privacy concerns, related to the deployment of GenAI and LLMs, and offers strategic recommendations for addressing these challenges responsibly. Emphasizing the transformative potential of these technologies, this review highlights the necessity of developing tailored ethical and legal frameworks to manage their convergence responsibly, ensuring equitable and sustainable growth within the metaverse.",Ethics | extended reality | generative AI (GenAI) | LLMs | metaverse | privacy | regulation | security,14,2025,sustainability,policy+sustainability
667,2-s2.0-85199047547,10.1016/j.compind.2024.104128,https://doi.org/10.1016/j.compind.2024.104128,https://scholar.google.com/scholar?q=10.1016/j.compind.2024.104128,ar,Computers in Industry,"Abumalloh, Rabab Ali;Nilashi, Mehrbakhsh;Ooi, Keng Boon;Tan, Garry Wei Han;Chan, Hing Kai",Impact of generative artificial intelligence models on the performance of citizen data scientists in retail firms,"Generative Artificial Intelligence (AI) models serve as powerful tools for organizations aiming to integrate advanced data analysis and automation into their applications and services. Citizen data scientists—individuals without formal training but skilled in data analysis—combine domain expertise with analytical skills, making them invaluable assets in the retail sector. Generative AI models can further enhance their performance, offering a cost-effective alternative to hiring professional data scientists. However, it is unclear how AI models can effectively contribute to this development and what challenges may arise. This study explores the impact of generative AI models on citizen data scientists in retail firms. We investigate the strengths, weaknesses, opportunities, and threats of these models. Survey data from 268 retail companies is used to develop and validate a new model. Findings highlight that misinformation, lack of explainability, biased content generation, and data security and privacy concerns in generative AI models are major factors affecting citizen data scientists’ performance. Practical implications suggest that generative AI can empower retail firms by enabling advanced data science techniques and real-time decision-making. However, firms must address drawbacks and threats in generative AI models through robust policies and collaboration between domain experts and AI developers.",ChatGPT | Citizen Data science | Generative AI models | Industrial and innovation | Industrial growth | Retail firms,13,2024,behavior,behavior+policy
674,2-s2.0-85197336580,10.1016/j.ijpe.2024.109324,https://doi.org/10.1016/j.ijpe.2024.109324,https://scholar.google.com/scholar?q=10.1016/j.ijpe.2024.109324,ar,International Journal of Production Economics,"Koliousis, Ioannis;Al-Surmi, Abdulrahman;Bashiri, Mahdi",Artificial intelligence and policy making; can small municipalities enable digital transformation?,"This study investigates digital transformation and the usability of emerging technologies in policymaking. Prior studies categorised digital transformation into three distinct phases of digitisation, digitalisation, and digital transformation. They mainly focus on the operational or functional levels, however, this study considers digital transformation at the strategic level. Previous studies confirmed that using new emerging AI-based technologies will enable organisations to use digital transformation to achieve higher efficiency. A novel methodological AI-based approach for policymaking was constructed into three phases through the lens of organisational learning theory. The proposed framework was validated using a case study in the transportation industry of a small municipality. In the selected case study, a confirmatory model was developed and tested utilising the Structural Equation Modelling with data collected from a survey of 494 local stakeholders. Artificial Neural Network was utilised to predict and then to identify the most appropriate policy according to cost, feasibility, and impact criteria amongst six policies extracted from the literature. The results from this research confirm that utilisation of the AI-based strategic decision-making through the proposed generative AI platform at strategic level outperforms human decision-making in terms of applicability, efficiency, and accuracy.",Digital transformation | Generative AI | Policy | SEM | Strategic decision making,13,2024,behavior,behavior+policy
690,2-s2.0-85185899801,10.1590/S1677-5538.IBJU.2023.0570,https://doi.org/10.1590/S1677-5538.IBJU.2023.0570,https://scholar.google.com/scholar?q=10.1590/S1677-5538.IBJU.2023.0570,ar,International Braz J Urol,"Braga, Antonio Vitor Nascimento Martinelli;Nunes, Noel Charlles;Santos, Emanoel Nascimento;Veiga, Maria Luiza;Braga, Ana Aparecida Nascimento Martinelli;de Abreu, Glicia Estevam;de Bessa Júnior, José;Braga, Luis Henrique;Kirsch, Andrew J.;Júnior, Ubirajara Barroso",Use of ChatGPT in Urology and its Relevance in Clinical Practice: Is it useful?,"Purpouse: One of the many artificial intelligence based tools that has gained popularity is the Chat-Generative Pre-Trained Transformer (ChatGPT). Due to its popularity, incorrect information provided by ChatGPT will have an impact on patient misinformation. Furthermore, it may cause misconduct as ChatGPT can mislead physicians on the decision-making pathway. Therefore, the aim of this study is to evaluate the accuracy and reproducibility of ChatGPT answers regarding urological diagnoses. Materials and Methods: ChatGPT 3.5 version was used. The questions asked for the program involved Primary Megaureter (pMU), Enuresis and Vesicoureteral Reflux (VUR). There were three queries for each topic. The queries were inserted twice, and both responses were recorded to examine the reproducibility of ChatGPT’s answers. Afterwards, both answers were combined. Finally, those rwere evaluated qualitatively by a board of three specialists. A descriptive analysis was performed. Results and Conclusion: ChatGPT simulated general knowledge on the researched topics. Regarding Enuresis, the provided definition was partially correct, as the generic response allowed for misinterpretation. For VUR, the response was considered appropriate. For pMU it was partially correct, lacking essential aspects of its definition such as the diameter of the dilatation of the ureter. Unnecessary exams were suggested, for Enuresis and pMU. Regarding the treatment of the conditions mentioned, it specified treatments for Enuresis that are ineffective, such as bladder training. Therefore, ChatGPT responses present a combination of accurate information, but also incomplete, ambiguous and, occasionally, misleading details.",Cakut [Supplementary Concept] | Urology | Vesico-Ureteral Reflux,13,2024,behavior,behavior+policy
340,2-s2.0-105001557240,10.1109/ACCESS.2025.3552592,https://doi.org/10.1109/ACCESS.2025.3552592,https://scholar.google.com/scholar?q=10.1109/ACCESS.2025.3552592,ar,IEEE Access,"Mishra, Lalit Narayan;Senapati, Biswaranjan",Retail Resilience Engine: An Agentic AI Framework for Building Reliable Retail Systems With Test-Driven Development Approach,"System reliability and operational resilience are two critical success factors in the retail industry that are directly connected to customer satisfaction and business sustainability. Staying competitive in today's dynamic and rapidly evolving market requires rapid adaptability. However, it contradicts the reliability and resilience. This paper proposes an innovative solution, the Retail Resilience Engine (RRE), to establish a balance between these success factors and market demand. It is a unique framework that combines Test-Driven Development (TDD) with a Large Language Model (LLM). This framework follows the state-of-the-art Agentic-AI architecture. It effectively evaluates the decision-making process at rapid speed in retail by incorporating diverse factors, including inventory management, demand forecasting, and customer feedback. As a result, the system reliability is improved significantly. The experimental analysis of the proposed framework shows its decision-making is similar to human experts with a similarity index of 97.5%. It further proves the reliability of the system. The framework also scales effectively, maintaining high accuracy, precision, recall, and F1 scores across varying dataset sizes. The robustness analysis of the system demonstrates the agility enhancement across diverse retail domains, ensuring consistent performance with accuracy exceeding 90% across all tested scenarios. The integration of a creative filtering mechanism further enhances the performance of the RRE framework by preventing 98.2% of the irrelevant inputs. Overall, the proposed RRE framework demonstrates the impressive potential to transform retail systems by enhancing reliability, scalability, and decision-making quality through an Agentic-AI approach.",agentic-AI | artificial intelligence | large language model | resilience engine | Retail systems | test-driven development,13,2025,sustainability,behavior+sustainability
342,2-s2.0-85217467530,10.24136/oc.3323,https://doi.org/10.24136/oc.3323,https://scholar.google.com/scholar?q=10.24136/oc.3323,ar,Oeconomia Copernicana,"Zada, Muhammad;Khan, Salman;Mehmood, Shafaqat;Contreras-Barraza, Nicolás","Generative artificial intelligence in FinTech: Applications, environmental, social, and governance considerations, and organizational performance: The moderating role of ethical dilemmas","Research background:Generative Artificial Intelligence (GenAI) is a disruptive technology with great promise for the FinTech industry. The current study focuses on the drivers of GenAI adoption and its consequences for both exploratory and exploitative innovation in FinTech companies. Purpose of the article: Based on a conceptual model that extends the Technology-Organization-Environment (TOE) framework, this study also explores the moderating effect of ethical dilemmas in the relationship between GenAI adoption and innovation, as well as the role of Environmental, Social, and Governance (ESG) factors in shaping the broader impact of GenAI on organizational practices. Methods: Data were collected and analyzed using Structural Equation Modeling (SEM) from participants in the Chinese FinTech industry. Findings & value added: Our empirical findings show that GenAI improves both kinds of innovations and, subsequently, leads to improved organizational performance. However, ethical dilemmas do not significantly affect either of these effects. Moreover, the study sug-gests that aligning GenAI adoption with ESG goals, such as promoting sustainable practices and ensuring ethical governance, can further enhance long-term performance and stakeholder trust. This study underlines the strategic role of GenAI adoption in driving innovation, ad-vancing ESG objectives, and improving performance in the fast-evolving landscape of FinTech.",China | ESG | FinTech sector | generative AI | TOE framework,13,2024,sustainability,policy+sustainability
562,2-s2.0-105003197417,10.1145/3689372,https://doi.org/10.1145/3689372,https://scholar.google.com/scholar?q=10.1145/3689372,ar,Digital Government Research and Practice,"Jaidka, Kokil;Chen, Tsuhan;Chesterman, Simon;Hsu, Wynne;Kan, Min Yen;Kankanhalli, Mohan;Lee, Mong Li;Seres, Gyula;Sim, Terence;Taeihagh, Araz;Tung, Anthony;Xiao, Xiaokui;Yue, Audrey","Misinformation, Disinformation, and Generative AI: Implications for Perception and Policy","The emergence of generative artificial intelligence (GenAI) has exacerbated the challenges of misinformation, disinformation, and mal-information (MDM) within digital ecosystems. These multi-faceted challenges demand a re-evaluation of the digital information lifecycle and a deep understanding of its social impact. An interdisciplinary strategy integrating insights from technology, social sciences, and policy analysis is crucial to address these issues effectively. This article introduces a three-tiered framework to scrutinize the lifecycle of GenAI-driven content from creation to consumption, emphasizing the consumer perspective. We examine the dynamics of consumer behavior that drive interactions with MDM, pinpoints vulnerabilities in the information dissemination process, and advocates for adaptive, evidence-based policies. Our interdisciplinary methodology aims to bolster information integrity and fortify public trust, equipping digital societies to manage the complexities of GenAI and proactively address the evolving challenges of digital misinformation. We conclude by discussing how GenAI can be leveraged to combat MDM, thereby creating a reflective cycle of technological advancement and mitigation.",disinformation | generative AI | Misinformation | resilience | social media | trust,12,2025,behavior,behavior+policy
580,2-s2.0-85215832213,10.1109/JBHI.2025.3528526,https://doi.org/10.1109/JBHI.2025.3528526,https://scholar.google.com/scholar?q=10.1109/JBHI.2025.3528526,ar,IEEE Journal of Biomedical and Health Informatics,"Sun, Lianshan;Liu, Diandong;Wang, Maoxue;Han, Yongyi;Zhang, Yanqing;Zhou, Biwei;Ren, Yi;Zhu, Peng",Taming Unleashed Large Language Models With Blockchain for Massive Personalized Reliable Healthcare,"The digital health field's pursuit of massive, personalized healthcare continuously faces constraints from doctors' resources and capacity limitations. Recently, the emergence of large language models (LLMs), with their remarkable comprehension and processing abilities, has revolutionized digital health and enhanced massive, personalized healthcare. Although these LLMs have achieved significant advancements, they have also introduced inevitable hallucinations, which impact patient safety when used in massive applications. To address these challenges, this study proposes a digital hospital for a massive, personalized, reliable healthcare service named the Chat Chain-Brain-based Doctor (CHATCBD). In addition, this study transforms the LLM-based diagnostic process into a digital hospital architecture, designs a controllable AI agents framework, and develops a self-audit mechanism to enhance their reliability. The proposed CHATCBD uses blockchain technology to decentralize external regulation of the LLMs' personalized diagnoses. It introduces a blockchain-based personalized routing management mechanism to improve patient-centered decision-making and designs a blockchain-based audit framework based on a proposed mathematical model that ensures both the professionalism and honesty of audits, serving as a safety net for addressing LLM hallucinations. The results of extensive experiments conducted on 13 datasets from multiple perspectives demonstrate that the proposed CHATCBD system can significantly enhance the capabilities of LLMs in personalized healthcare.",Agent | blockchain | digital health | large language model | reliability,12,2025,behavior,behavior+policy
82,2-s2.0-105001333816,10.1007/s43926-025-00132-6,https://doi.org/10.1007/s43926-025-00132-6,https://scholar.google.com/scholar?q=10.1007/s43926-025-00132-6,ar,Discover Internet of Things,"Sowmya, B. J.;Meeradevi, A. K.;Supreeth, S.;Pradeep Kumar, D.;Ravi Kumar, B. N.;Rohith, S.;Mishra, Divyansh;Koushik, Abhishek;Patil, Ankit U.",Leveraging machine learning for intelligent agriculture,"A multilingual AI platform helps farmers improve crop management, health monitoring, and resource planning. Personalized guidance on government schemes empowers farmers with crucial support and funding opportunities. The platform bridges traditional farming with modern AI, enhancing productivity and sustainability for all users.",Computer vision | Deep learning approaches | LLM | Machine learning | Smart agriculture,12,2025,sustainability,behavior+sustainability
361,2-s2.0-85200808979,10.1145/3676507,https://doi.org/10.1145/3676507,https://scholar.google.com/scholar?q=10.1145/3676507,ar,Proceedings of the ACM on Human Computer Interaction,"Constantinides, Marios;Bogucka, Edyta Paulina;Scepanovic, Sanja;Quercia, Daniele","Good Intentions, Risky Inventions: A Method for Assessing the Risks and Benefits of AI in Mobile and Wearable Uses","Integrating Artificial Intelligence (AI) into mobile and wearables offers numerous benefits at individual, societal, and environmental levels. Yet, it also spotlights concerns over emerging risks. Traditional assessments of risks and benefits have been sporadic, and often require costly expert analysis. We developed a semi-automatic method that leverages Large Language Models (LLMs) to identify AI uses in mobile and wearables, classify their risks based on the EU AI Act, and determine their benefits that align with globally recognized long-term sustainable development goals; a manual validation of our method by two experts in mobile and wearable technologies, a legal and compliance expert, and a cohort of nine individuals with legal backgrounds who were recruited from Prolific, confirmed its accuracy to be over 85%. We uncovered that specific applications of mobile computing hold significant potential in improving well-being, safety, and social equality. However, these promising uses are linked to risks involving sensitive data, vulnerable groups, and automated decision-making. To avoid rejecting these risky yet impactful mobile and wearable uses, we propose a risk assessment checklist for the Mobile HCI community.",LLM | mobile | prompt engineering | risk assessment | sustainable development goals | wearables,12,2024,sustainability,behavior+sustainability
645,2-s2.0-105004679755,10.3389/frai.2025.1565927,https://doi.org/10.3389/frai.2025.1565927,https://scholar.google.com/scholar?q=10.3389/frai.2025.1565927,ar,Frontiers in Artificial Intelligence,"Shrivastava, Priyanka","Understanding acceptance and resistance toward generative AI technologies: a multi-theoretical framework integrating functional, risk, and sociolegal factors","This study explores the factors influencing college students’ acceptance and resistance toward generative AI technologies by integrating three theoretical frameworks: the Technology Acceptance Model (TAM), Protection Motivation Theory (PMT), and Social Exchange Theory (SET). Using data from 407 respondents collected through a structured survey, the study employed Structural Equation Modeling (SEM) to examine how functional factors (perceived usefulness, ease of use, and reliability), risk factors (privacy concerns, data security, and ethical issues), and sociolegal factors (trust in governance and regulatory frameworks) impact user attitudes. Results revealed that functional factors significantly enhanced acceptance while reducing resistance, whereas risk factors amplified resistance and negatively influenced acceptance. Sociolegal factors emerged as critical mediators, mitigating the negative impact of perceived risks and reinforcing the positive effects of functional perceptions. The study responds to prior feedback by offering a more integrated theoretical framework, clearly articulating how TAM, PMT, and SET interact to shape user behavior. It also acknowledges the limitations of using a student sample and discusses the broader applicability of the findings to other demographics, such as professionals and non-academic users. Additionally, the manuscript now highlights demographic diversity, including variations in age, gender, and academic discipline, as relevant to AI adoption patterns. Ethical concerns, including algorithmic bias, data ownership, and the labor market impact of AI, are addressed to offer a more holistic understanding of resistance behavior. Policy implications have been expanded with actionable recommendations such as AI bias mitigation strategies, clearer data ownership protections, and workforce reskilling programs. The study also compares global regulatory frameworks like the GDPR and the U.S. AI Bill of Rights, reinforcing its practical relevance. Furthermore, it emphasizes that user attitudes toward AI are dynamic and likely to evolve, suggesting the need for longitudinal studies to capture behavioral adaptation over time. By bridging theory and practice, this research contributes to the growing discourse on responsible and equitable AI adoption in higher education, offering valuable insights for developers, policymakers, and academic institutions aiming to foster ethical and inclusive technology integration.",acceptance resistance framework | generative AI adoption | protection motivation theory | social exchange theory (SET) | technology adoption model,11,2025,behavior,behavior+policy
654,2-s2.0-105001060934,10.1109/ACCESS.2025.3543795,https://doi.org/10.1109/ACCESS.2025.3543795,https://scholar.google.com/scholar?q=10.1109/ACCESS.2025.3543795,re,IEEE Access,"Nedungadi, Prema;Veena, G.;Tang, Kai Yu;Menon, Remya R.K.;Raman, Raghu",AI Techniques and Applications for Online Social Networks and Media: Insights from BERTopic Modeling,"This study examines the role of Artificial Intelligence (AI) in enhancing personalization, analyzing information dynamics, and developing scalable methodologies within Online Social Networks and Media (OSNEM), with a focus on user protection. Through a systematic review using the PRISMA framework and BERTopic modeling, key AI applications in OSNEM were identified, including fake news detection, sentiment analysis, hate speech detection, big data analysis, bot detection, and insights into public health, disaster relief, and mental health. Although AI techniques and multimodal frameworks have significantly improved content personalization, challenges like algorithmic bias and echo chambers remain. To address these, the implementation of fairness-aware learning models is recommended to ensure personalization stays ethical. Advanced AI techniques, such as Dynamic Memory Networks and Temporal Convolutional Networks, have shown strong capabilities in tracking opinion dynamics and combating misinformation. Additionally, Generative AI offers opportunities for content creation but also raises concerns about misinformation, requiring robust moderation frameworks. Emerging technologies like Artificial Real Intelligence (ARI), which simulate human reasoning and decision-making, could further improve the management of complex online interactions. The study highlights the need for scalable AI methodologies, such as multitask learning frameworks, to efficiently handle the vast amounts of real-time data generated by social media while addressing cross-platform adaptability and computational efficiency.",artificial intelligence | big data | generative AI | healthcare | industrial innovation | resilient energy | resilient infrastructure | Sustainable development goal,11,2025,behavior,behavior+policy
658,2-s2.0-85206593856,10.1186/s40942-024-00595-9,https://doi.org/10.1186/s40942-024-00595-9,https://scholar.google.com/scholar?q=10.1186/s40942-024-00595-9,re,International Journal of Retina and Vitreous,"Bellanda, Victor C.F.;Santos, Mateus Lins dos;Ferraz, Daniel Araujo;Jorge, Rodrigo;Melo, Gustavo Barreto","Applications of ChatGPT in the diagnosis, management, education, and research of retinal diseases: a scoping review","Purpose: This scoping review aims to explore the current applications of ChatGPT in the retina field, highlighting its potential, challenges, and limitations. Methods: A comprehensive literature search was conducted across multiple databases, including PubMed, Scopus, MEDLINE, and Embase, to identify relevant articles published from 2022 onwards. The inclusion criteria focused on studies evaluating the use of ChatGPT in retinal healthcare. Data were extracted and synthesized to map the scope of ChatGPT’s applications in retinal care, categorizing articles into various practical application areas such as academic research, charting, coding, diagnosis, disease management, and patient counseling. Results: A total of 68 articles were included in the review, distributed across several categories: 8 related to academics and research, 5 to charting, 1 to coding and billing, 44 to diagnosis, 49 to disease management, 2 to literature consulting, 23 to medical education, and 33 to patient counseling. Many articles were classified into multiple categories due to overlapping topics. The findings indicate that while ChatGPT shows significant promise in areas such as medical education and diagnostic support, concerns regarding accuracy, reliability, and the potential for misinformation remain prevalent. Conclusion: ChatGPT offers substantial potential in advancing retinal healthcare by supporting clinical decision-making, enhancing patient education, and automating administrative tasks. However, its current limitations, particularly in clinical accuracy and the risk of generating misinformation, necessitate cautious integration into practice, with continuous oversight from healthcare professionals. Future developments should focus on improving accuracy, incorporating up-to-date medical guidelines, and minimizing the risks associated with AI-driven healthcare tools.","Artificial intelligence | Automation | Decision support systems, clinical | Education, medical | Education, patient | Health information systems | Ophthalmology | Retinal diseases",11,2024,behavior,behavior+policy
666,2-s2.0-85206562497,10.3390/cancers16193328,https://doi.org/10.3390/cancers16193328,https://scholar.google.com/scholar?q=10.3390/cancers16193328,re,Cancers,"Maida, Marcello;Celsa, Ciro;Lau, Louis H.S.;Ligresti, Dario;Baraldo, Stefano;Ramai, Daryl;Di Maria, Gabriele;Cannemi, Marco;Facciorusso, Antonio;Cammà, Calogero",The Application of Large Language Models in Gastroenterology: A Review of the Literature,"Large language models (LLMs) are transforming the medical landscape by enhancing access to information, diagnostics, treatment customization, and medical education, especially in areas like Gastroenterology. LLMs utilize extensive medical data to improve decision-making, leading to better patient outcomes and personalized medicine. These models are instrumental in interpreting medical literature and synthesizing patient data, facilitating real-time knowledge for physicians and supporting educational pursuits in medicine. Despite their potential, the complete integration of LLMs in real-life remains ongoing, particularly requiring further study and regulation. This review highlights the existing evidence supporting LLMs’ use in Gastroenterology, addressing both their potential and limitations. Recent studies demonstrate LLMs’ ability to answer questions from physicians and patients accurately. Specific applications in this field, such as colonoscopy, screening for colorectal cancer, and hepatobiliary and inflammatory bowel diseases, underscore LLMs’ promise in improving the communication and understanding of complex medical scenarios. Moreover, the review discusses LLMs’ efficacy in clinical contexts, providing guideline-based recommendations and supporting decision-making processes. Despite these advancements, challenges such as data completeness, reference suitability, variability in response accuracy, dependency on input phrasing, and a lack of patient-generated questions underscore limitations in reproducibility and generalizability. The effective integration of LLMs into medical practice demands refinement tailored to specific medical contexts and guidelines. Overall, while LLMs hold significant potential in transforming medical practice, ongoing development and contextual training are essential to fully realize their benefits.",artificial intelligence | endoscopy | gastroenterology | large language models,11,2024,behavior,behavior+policy
232,2-s2.0-105000958618,10.3390/su17062453,https://doi.org/10.3390/su17062453,https://scholar.google.com/scholar?q=10.3390/su17062453,ar,Sustainability Switzerland,"Aylak, Batin Latif",SustAI-SCM: Intelligent Supply Chain Process Automation with Agentic AI for Sustainability and Cost Efficiency,"Sustainable supply chain management (SCM) demands efficiency while minimizing environmental impact, yet conventional automation lacks adaptability. This paper presents SustAI-SCM, an AI-powered framework integrating agentic intelligence to automate supply chain tasks with sustainability in focus. Unlike static rule-based systems, it leverages a transformer model that continuously learns from operations, refining procurement, logistics, and inventory decisions. A diverse dataset comprising procurement records, logistics data, and carbon footprint metrics trains the model, enabling dynamic adjustments. The experimental results show a 28.4% cost reduction, 30.3% lower emissions, and 21.8% improved warehouse efficiency. While computational overhead and real-time adaptability pose challenges, future enhancements will focus on energy-efficient AI, continuous learning, and explainable decision making. The framework advances sustainable automation, balancing operational optimization with environmental responsibility.",agentic AI | automation | cost optimization | green logistics | sustainable supply chain | transformer model,11,2025,sustainability,behavior+sustainability
390,2-s2.0-85208709429,10.37544/0005-6650-2024-09-36,https://doi.org/10.37544/0005-6650-2024-09-36,https://scholar.google.com/scholar?q=10.37544/0005-6650-2024-09-36,ar,Bauingenieur,"Tang, X.;Heng, J.;Kaewunruen, S.;Dai, K.;Baniotopoulos, C.",Artificial Intelligence-Powered Digital Twins for Sustainable and Resilient Engineering Structures,"Artificial Intelligence (AI) is now playing a crucialrole not only in everyday life, evidenced by the booming application of Large Language Models (LLMs) such as the Generative Pretrained Transformer (GPT), but also in its potential to transform traditional industries like civil engineering. This work examines the application of novel AI tools to enable Digital Twins (DT) for engineering structures, providing a comprehensive solution for the life-cycle management. A comprehensive state-of-the-art review is conducted to explore existing advancements in sensing, inspection, and simulation that are fundamental to the development of digital twins. Building on this knowledge, a framework is proposed to define DT for Engineering(DT4ENG) based on their emphasis and data flow, including forward DT, backward DT, and DT-informed decision making. Following this, a case study on floating offshore wind turbine (FOWT) structures demonstrates the application ofDT4ENG in a specific domain, with findings that have broader implications for the life-cycle management of engineering structures. The present study reveals that the AI enables digital wins to effectively identify potential structural issues, predict deterioration, and suggest timely maintenance interventions. This approach enhances the accuracy of structural health assessments, optimises resource allocation, and minimises downtime. By translating the capabilities of digital twins into actionable strategies, the research highlights their potential to significantly improve the life-cycle management of engineering infrastructure. In general, these advancements promise anew era of intelligent maintenance strategies, offering increased safety, extended service life, and cost-effectiveness. The proposed DT4ENG is set to become a standard in the traditional industry, driving a shift towards more sustainable, resilient, adaptive, and intelligent structures.",,11,2024,sustainability,behavior+sustainability
396,2-s2.0-85198143501,10.54364/aaiml.2024.42129,https://doi.org/10.54364/aaiml.2024.42129,https://scholar.google.com/scholar?q=10.54364/aaiml.2024.42129,ar,Advances in Artificial Intelligence and Machine Learning,"Stampfl, Rita;Geyer, Barbara;Deissl-O‘meara, Marie;Ivkic, Igor",Revolutionising Role-Playing Games with ChatGPT,"Digitalisation in education and its influence on teaching methods is the focus of this study, which examines the use of ChatGPT in a role-playing game used in the Cloud Computing Engineering Master’s programme at the University of Applied Sciences Burgenland. The aim of the study was to analyse the impact of AI-based simulations on students’ learning experience. Based on Vygotsky’s sociocultural theory, ChatGPT was used to give students a deeper understanding of strategic decision-making processes in simulated business scenarios. The methodological approach included role-playing and qualitative content analysis of 20 student reflections. The findings suggest that ChatGPT enhances students’ engagement, critical thinking, and communication skills, in addition to contributing to the effective application of theoretical knowledge. Furthermore, simulations can contribute to the effective application of theoretical knowledge. The results underscore the significance of adaptive teaching approaches in promoting digital literacy and equipping learners for the digital workplace. The integration of AI into curricula and the need for ongoing innovation in higher education are also emphasised as a means of guaranteeing excellent, future-focused instruction. The findings highlight the potential of AI and ChatGPT in particular, as an innovative cuttingedge educational tool that can both enhance the learning experience and help achieve the Sustainable Development Goals (SDGs) through education.",Artificial intelligence | ChatGPT | Digital education | Role-playing games | Simulation games,11,2024,sustainability,behavior+sustainability
193,2-s2.0-105008966978,10.3390/app15126465,https://doi.org/10.3390/app15126465,https://scholar.google.com/scholar?q=10.3390/app15126465,re,Applied Sciences Switzerland,"Sánchez, Esther;Calderón, Reyes;Herrera, Francisco","Artificial Intelligence Adoption in SMEs: Survey Based on TOE–DOI Framework, Primary Methodology and Challenges","Despite the transformative potential of artificial intelligence (AI), small and medium-sized enterprises (SMEs) continue to face significant challenges in its effective adoption. While prior studies have emphasized strategic benefits and readiness models, there remains a lack of operational guidance tailored to SME realities—particularly regarding implementation barriers, resource constraints, and emerging demands for responsible AI use. This study presents an analysis of AI adoption in SMEs by integrating the technology–organization–environment (TOE) framework with selected attributes from the diffusion of innovations (DOI) theory to examine adoption dynamics through a dual structural and perceptual lens. Empirical insights from sectoral and regional contexts are also incorporated. Ten critical challenges are identified and analyzed across the TOE dimensions, ranging from data access and skill shortages to cultural resistance, infrastructure limitations, and weak governance practices. Notably, the framework is expanded to incorporate responsible AI governance and democratized access to generative AI—particularly open-weight large language models (LLMs) such as LLaMA, DeepSeek-R1, Mistral, and FALCON—as emerging technological and ethical imperatives. Each challenge is paired with actionable, context-sensitive solutions. The paper is a structured, literature-based conceptual analysis enriched by empirical case study insights. As a key contribution, it introduces a structured, six-phase roadmap methodology to guide SMEs through AI adoption—offering step-by-step recommendations aligned with technological, organizational, and strategic readiness. While this roadmap is conceptual and has yet to be validated through field data, it sets a foundation for future diagnostic tools and practical assessments. The resulting study bridges theoretical insight and implementation strategy—empowering inclusive, responsible, and scalable AI transformation in SMEs. By offering both analytical clarity and practical relevance, this study contributes to a more grounded understanding of AI integration and calls for policies, ecosystems, and leadership models that support SMEs in adopting AI not merely as a tool, but as a strategic enabler of sustainable and inclusive innovation.",AI adoption challenges | artificial intelligence (AI) | diffusion of innovations (DOI) | digital transformation | innovation management | small and medium-sized enterprises (SMEs) | technology–organization–environment (TOE) framework,11,2025,sustainability,policy+sustainability
464,2-s2.0-105003802131,10.1186/s12903-025-06050-x,https://doi.org/10.1186/s12903-025-06050-x,https://scholar.google.com/scholar?q=10.1186/s12903-025-06050-x,ar,BMC Oral Health,"Özbay, Yağız;Erdoğan, Deniz;Dinçer, Gözde Akbal",Evaluation of the performance of large language models in clinical decision-making in endodontics,"Background: Artificial intelligence (AI) chatbots are excellent at generating language. The growing use of generative AI large language models (LLMs) in healthcare and dentistry, including endodontics, raises questions about their accuracy. The potential of LLMs to assist clinicians’ decision-making processes in endodontics is worth evaluating. This study aims to comparatively evaluate the answers provided by Google Bard, ChatGPT-3.5, and ChatGPT-4 to clinically relevant questions from the field of Endodontics. Methods: 40 open-ended questions covering different areas of endodontics were prepared and were introduced to Google Bard, ChatGPT-3.5, and ChatGPT-4. Validity of the questions was evaluated using the Lawshe Content Validity Index. Two experienced endodontists, blinded to the chatbots, evaluated the answers using a 3-point Likert scale. All responses deemed to contain factually wrong information were noted and a misinformation rate for each LLM was calculated (number of answers containing wrong information/total number of questions). The One-way analysis of variance and Post Hoc Tukey test were used to analyze the data and significance was considered to be p < 0.05. Results: ChatGPT-4 demonstrated the highest score and the lowest misinformation rate (P = 0.008) followed by ChatGPT-3.5 and Google Bard respectively. The difference between ChatGPT-4 and Google Bard was statistically significant (P = 0.004). Conclusion: ChatGPT-4 provided more accurate and informative information in endodontics. However, all LLMs produced varying levels of incomplete or incorrect answers.",Chat GPT | Chatbot | Endodontics | Endodontology | Large Language model,10,2025,behavior,behavior+policy
564,2-s2.0-85208810936,10.1108/ILS-10-2023-0137,https://doi.org/10.1108/ILS-10-2023-0137,https://scholar.google.com/scholar?q=10.1108/ILS-10-2023-0137,ar,Information and Learning Science,"Koroleva, Diana;Jogezai, Nazir","The desire path: unleashing expectations, discussing apprehensions, and proposing a way forward for GAI use in higher education","Purpose: The purpose of this study is to demonstrate the desire path of using GAI in higher education, including expectations, apprehensions, and the way forward. Design/methodology/approach: This qualitative study employs thematic analysis, scrutinizing 11 interviews with innovative higher education faculty. The methodology section details the utilization of GAI (Chat GPT) for conducting thematic analysis on interviews, showcasing academics' practical application of this technology for research purposes. Findings: Stakeholders expect continuous improvement in technology, overdependence, advocate for gradual adjustment, and emphasize context-dependent technology utilization. Concerns encompass issues such as data reliability, ethical considerations, risks of undermining fundamental aspects, limitations in fully replacing human involvement, and worries about personal responsibility. Practical implications: Recommendations include flexible regulations, data-driven decision-making, professional development, diverse stakeholder engagement, and promoting distributed responsibility. Originality/value: This study offers valuable insights into the use of GAI in higher education, formulating policies that encourage innovation without hampering effectiveness.",AIED | Desire path | Generative artificial intelligence | Higher education | Prompt | Social construction of technology | University faculty,10,2025,behavior,behavior+policy
700,2-s2.0-85195400802,10.1080/22041451.2024.2346415,https://doi.org/10.1080/22041451.2024.2346415,https://scholar.google.com/scholar?q=10.1080/22041451.2024.2346415,ar,Communication Research and Practice,"Xu, Jian",Opening the ‘black box’ of algorithms: regulation of algorithms in China,"This article maps the trajectory of China’s regulation of algorithms via policy review. It divides China’s governing progress into three phases: the ‘post-event policy response and penalty’ phase, the ‘ethics guidelines, guiding opinions and self-discipline pacts’ phase and the ‘legislation and implementation’ phase. The paper argues that the ideological and political implications of algorithmic applications are the highest concern for Chinese regulators. China’s regulation of algorithms follows a ‘state-centric multilateral model’–the same model used for its internet governance. The ‘algorithmic transparency’ advocated by regulators is currently only limited to algorithms in the platform economy and industries rather than those used for government decision-making and public administration. As the first nation to issue laws regulating algorithms and generative AI, China faces problems and challenges emerging from further implementing the laws. China’s experience will provide valuable first-hand understandings for countries currently creating legal frameworks to regulate algorithms and AI.",AI governance | China | legislation | Regulation of algorithms | state-centric multilateral model | value orientation,10,2024,behavior,behavior+policy
701,2-s2.0-85194548222,10.34135/COMMUNICATIONTODAY.2024.VOL.15.NO.1.4,https://doi.org/10.34135/COMMUNICATIONTODAY.2024.VOL.15.NO.1.4,https://scholar.google.com/scholar?q=10.34135/COMMUNICATIONTODAY.2024.VOL.15.NO.1.4,ar,Communication Today,"Murár, Peter;Kubovics, Michal;Jurišová, Vladimíra",THE IMPACT OF BRAND-VOICE INTEGRATION AND ARTIFICIAL INTELLIGENCE ON SOCIAL MEDIA MARKETING,"Corporate identity plays an important role in the success and competitiveness of businesses in today’s dynamic business environment. It encompasses brand identity, organisational culture, values, and reputation, and is key in building relationships with stakeholders. An ethical corporate identity, in particular the perception of a company as ethical and socially responsible, positively influences employee behaviour and engagement. Artificial Intelligence (AI) has revolutionised business management and offers innovative solutions to improve decision-making, efficiency, and transparency. Integrating AI into corporate governance can improve risk management, compliance, and accountability. In the digital age, social media are key in building and maintaining the brand voice of businesses. With the advent of AI, new tools such as Chat GPT have emerged to simplify and accelerate content creation, including social media posts. However, achieving satisfactory brand-voice results using AI requires careful analysis and extensive, representative data that travels into the prompter. Although AI-generated content is fast, it should be vetted by experienced experts to ensure it aligns with brand values and brand image. Although Chat GPT promises to generate content and brand-voice, its successful use requires collaboration with experienced experts and thoughtful consideration of its use in building and maintaining an authentic and effective brand-voice.",artificial intelligence | brand communication | brand perception | brand-voice integration | social media marketing,10,2024,behavior,behavior+policy
221,2-s2.0-86000280065,10.1016/j.scs.2025.106259,https://doi.org/10.1016/j.scs.2025.106259,https://scholar.google.com/scholar?q=10.1016/j.scs.2025.106259,ar,Sustainable Cities and Society,"van Laar, Brian;Greco, Angela;Remøy, Hilde;Gruis, Vincent;Hamida, Mohammad B.",Towards desirable futures for the circular adaptive reuse of buildings: A participatory approach,"Adaptive reuse of buildings offers a sustainable strategy for reducing global CO2 emissions by repurposing existing structures, conserving resources, reducing the need to extract new materials, and minimizing waste. However, the decision-making process in adaptive reuse projects is often complex, involving conflicting criteria and diverse stakeholders. Current approaches tend to polarize alternatives, focusing either on broad functional use or specific design options, which can limit decision effectiveness and quality. This study addresses these challenges by developing a participatory mixed-methods approach that integrates Cross-Impact Balance (CIB) analysis with creative scenario-building techniques, including generative AI and participatory workshops. This approach balances the extremes of current decision-making processes, offering a more comprehensive overview of desirable futures for decision-makers. The methodology was applied to create 15 “big picture” circular adaptive reuse scenarios, each incorporating circular building adaptability (CBA) strategies, and enriched with AI generated narratives and visualizations. These scenarios provide stakeholders with a nuanced understanding of potential future pathways, enhancing decision-making processes. This mixed-method approach demonstrates the potential of participatory CIB scenario development in advancing circularity, offering a valuable tool for navigating the complexities of adaptive reuse decision-making.",Adaptive reuse | Circularity | Cross-impact balance analysis | Normative narrative scenarios | Participatory scenario workshops | Scenario development,10,2025,sustainability,behavior+sustainability
223,2-s2.0-86000601293,10.3390/app15052775,https://doi.org/10.3390/app15052775,https://scholar.google.com/scholar?q=10.3390/app15052775,re,Applied Sciences Switzerland,"Daios, Adamos;Kladovasilakis, Nikolaos;Kelemis, Athanasios;Kostavelis, Ioannis",AI Applications in Supply Chain Management: A Survey,"The advent of Industry 4.0 and the integration of Artificial Intelligence (AI) is transforming supply chain management (SCM), improving efficiency, resilience and strategic decision-making capabilities. This research study provides a comprehensive overview of AI applications in key SCM processes, including customer relationship management, inventory management, transportation networks, procurement, demand forecasting and risk management. AI technologies such as Machine Learning, Natural Language Processing and Generative AI offer transformative solutions to streamline logistics, reduce operational risk and improve demand forecasting. In addition, this study identifies barriers to AI adoption, such as implementation challenges, organizational readiness and ethical concerns, and highlights the critical role of AI in promoting supply chain visibility and resilience in the midst of global crises. Future trends emphasize human-centric AI, increasing digital maturity, and addressing ethical and security concerns. This review concludes by confirming the critical role of AI in shaping sustainable, flexible and resilient supply chains while providing a roadmap for future research and application in SCM.",artificial intelligence (AI) | digital transformation | industry 4.0 | strategic decision making | supply chain management (SCM),10,2025,sustainability,behavior+sustainability
204,2-s2.0-105006516459,10.3390/info16050399,https://doi.org/10.3390/info16050399,https://scholar.google.com/scholar?q=10.3390/info16050399,re,Information Switzerland,"Teixeira, António R.;Ferreira, José Vasconcelos;Ramos, Ana Luísa",Intelligent Supply Chain Management: A Systematic Literature Review on Artificial Intelligence Contributions,"This systematic literature review investigates the recent applications of artificial intelligence (AI) in supply chain management (SCM), particularly in the domains of resilience, process optimization, sustainability, and implementation challenges. The study is motivated by gaps identified in previous reviews, which often exclude literature published after 2020 and lack an integrated analysis of AI’s contributions across multiple supply chain phases. The review aims to provide an updated synthesis of AI technologies—such as machine learning, deep learning, and generative AI—and their practical implementation between 2021 and 2024. Following the PRISMA framework, a rigorous methodology was applied using the Scopus database, complemented by bibliometric and content analyses. A total of 66 studies were selected based on predefined inclusion criteria and evaluated for methodological quality and thematic relevance. The findings reveal a diverse classification of AI applications across strategic and operational SCM phases and highlight emerging techniques like explainable AI, neurosymbolic systems, and federated learning. The review also identifies persistent barriers such as data governance, ethical concerns, and scalability. Future research should focus on hybrid AI–human collaboration, transparency through explainable models, and integration with technologies such as IoT and blockchain. This review contributes to the literature by offering a structured synthesis of AI’s transformative impact on SCM and by outlining key research directions to guide future investigations and managerial practice.",artificial intelligence | PRISMA methodology | supply chain management | sustainability | systematic literature review,10,2025,sustainability,policy+sustainability
233,2-s2.0-85200765535,10.1108/ILS-10-2023-0146,https://doi.org/10.1108/ILS-10-2023-0146,https://scholar.google.com/scholar?q=10.1108/ILS-10-2023-0146,ar,Information and Learning Science,"Vartiainen, Henriikka;Valtonen, Teemu;Kahila, Juho;Tedre, Matti",ChatGPT and imaginaries of the future of education: insights of Finnish teacher educators,"Purpose: In 2022 generative AI took the Internet world by storm. Free access to tools that can generate text and images that pass for human creations triggered fiery debates about the potential uses and misuses of generative AI in education. There has risen a need to check the popular utopian and dystopian narratives about AI against the diversity of hopes, concerns and future imaginaries that educators themselves associate with generative AI. The purpose of this study is to investigate the perspectives of Finnish teacher educators on the use of AI in education. Design/methodology/approach: This article reports findings from a hands-on workshop in teacher training, where participants learned about how generative AI works, collaboratively explored generative AI and then reflected on its potential and challenges. Findings: The results reveal nuanced, calm and thoughtful imaginaries rooted in deep understanding of educational policy, evaluation and the sociocultural context of education. The results cover teachers’ views on the impact of AI on learners’ agency, metacognition, self-regulation and more. Originality/value: This article offers a unique exploration into the perceptions and imaginaries of educators regarding generative AI in specific (instead of “monolithic AI”), moving beyond dystopian views and instead focusing on the potential of AI to align with existing pedagogical practices. The educators contrasted the common techno-deterministic narratives and perceived AI as an avenue to support formative assessment practices and development of metacognition, self-regulation, responsibility and well-being. The novel insights also include the need for AI education that critically incorporates social and ethical viewpoints and fosters visions for a future with culturally, socially and environmentally sustainable AI.",Artificial intelligence | ChatGPT | Generative AI | Imaginaries | Teacher training | Tertiary education | University,10,2025,sustainability,policy+sustainability
243,2-s2.0-85212285617,10.1007/s42001-024-00338-8,https://doi.org/10.1007/s42001-024-00338-8,https://scholar.google.com/scholar?q=10.1007/s42001-024-00338-8,ar,Journal of Computational Social Science,"Kuznetsova, Elizaveta;Makhortykh, Mykola;Vziatysheva, Victoria;Stolze, Martha;Baghumyan, Ani;Urman, Aleksandra",In generative AI we trust: can chatbots effectively verify political information?,"This article presents a comparative analysis of the potential of two large language model (LLM)-based chatbots—ChatGPT and Bing Chat (recently rebranded to Microsoft Copilot)—to detect veracity of political information. We use AI auditing methodology to investigate how chatbots evaluate true, false, and borderline statements on five topics: COVID-19, Russian aggression against Ukraine, the Holocaust, climate change, and LGBTQ + -related debates. We compare how the chatbots respond in high- and low-resource languages by using prompts in English, Russian, and Ukrainian. Furthermore, we explore chatbots’ ability to evaluate statements according to political communication concepts of disinformation, misinformation, and conspiracy theory, using definition-oriented prompts. We also systematically test how such evaluations are influenced by source attribution. The results show high potential of ChatGPT for the baseline veracity evaluation task, with 72% of the cases evaluated in accordance with the baseline on average across languages without pre-training. Bing Chat evaluated 67% of the cases in accordance with the baseline. We observe significant disparities in how chatbots evaluate prompts in high- and low-resource languages and how they adapt their evaluations to political communication concepts with ChatGPT providing more nuanced outputs than Bing Chat. These findings highlight the potential of LLM-based chatbots in tackling different forms of false information in online environments, but also point to the substantial variation in terms of how such potential is realized due to specific factors (e.g. language of the prompt or the topic).",AI audit | Conspiracy theory | Disinformation | LLMs | Misinformation,10,2025,sustainability,policy+sustainability
554,2-s2.0-85209558144,10.1016/j.eswa.2024.125723,https://doi.org/10.1016/j.eswa.2024.125723,https://scholar.google.com/scholar?q=10.1016/j.eswa.2024.125723,ar,Expert Systems with Applications,"Shi, Jinxin;Zhao, Jiabao;Wu, Xingjiao;Xu, Ruyi;Jiang, Yuan Hao;He, Liang",Mitigating reasoning hallucination through Multi-agent Collaborative Filtering,"Large language models (LLMs) have demonstrated excellent performance in various natural language tasks. However, in practical applications, LLMs frequently exhibit hallucinations, generating content that deviates from instructions or facts, especially in complex reasoning tasks. Existing research has simulated real human behavior by utilizing multi-agent debate, voting, and review, enhancing the model's reasoning capabilities. However, simple multi-agent systems have not accomplished the progressive verification of all reasoning steps. Additionally, the issues of unstable response quality and the continuous learning ability of agents have not been addressed. Therefore, in this work, we propose a Multi-agent Collaborative Filtering framework (MCF) in the form of cross-examination among agents. This aims to cross-verify each step while filtering and selecting the highest-quality responses from the response space. Additionally, to enable agents to achieve continuous learning capabilities, this paper proposes methods for the automated construction and efficient retrieval of the experience repository. Extensive experiments on ten reasoning datasets of three types (Arithmetic, Commonsense, and Symbolic) indicate that MCF can enhance the diversity of large language models, overcome hallucinations, and filter out effective responses in a rich response space. Moreover, the improvement of agents’ reasoning capabilities through the experience repository is also verified. Compared to the state-of-the-art, the method proposed in this paper shows superior performance.",Collaborative filtering | Hallucination | Large language model | Multi-agent,9,2025,behavior,behavior+policy
684,2-s2.0-105022077663,10.1016/j.nlp.2024.100079,https://doi.org/10.1016/j.nlp.2024.100079,https://scholar.google.com/scholar?q=10.1016/j.nlp.2024.100079,ar,Natural Language Processing Journal,"Ahmed, Tasnim;Ivan, Shahriar;Munir, Ahnaf;Ahmed, Sabbir",Decoding depression: Analyzing social network insights for depression severity assessment with transformers and explainable AI,"Depression is a mental state characterized by recurrent feelings of melancholy, hopelessness, and disinterest in activities, having a significant negative influence on everyday functioning and general well-being. Millions of users express their thoughts and emotions on social media platforms, which can be used as a rich source of data for early detection of depression. In this connection, this work leverages an ensemble of transformer-based architectures for quantifying the severity of depression from social media posts into four categories — non-depressed, mild, moderate, and severe. At first, a diverse range of preprocessing techniques is employed to enhance the quality and relevance of the input. Then, the preprocessed samples are passed through three variants of transformer-based models, namely vanilla BERT, BERTweet, and ALBERT, for generating predictions, which are combined using a weighted soft-voting approach. We conduct a comprehensive explainability analysis to gain deeper insights into the decision-making process, examining both local and global perspectives. Furthermore, to the best of our knowledge, we are the first ones to explore the extent to which a Large Language Model (LLM) like ‘ChatGPT’ can perform this task. Evaluation of the model on the publicly available ‘DEPTWEET’ dataset produces state-of-the-art performance with 13.5% improvement in AUC–ROC score.",ChatGPT evaluation | Depression severity estimation | Ensemble voting | Explainability analysis | Mental health | Social media analysis,9,2024,behavior,behavior+policy
326,2-s2.0-105006991872,10.1108/IDD-03-2025-0068,https://doi.org/10.1108/IDD-03-2025-0068,https://scholar.google.com/scholar?q=10.1108/IDD-03-2025-0068,ar,Information Discovery and Delivery,"Elgendy, Ibrahim A.;Helal, Mohamed Y.I.;Al-Sharafi, Mohammed A.;Albashrawi, Mousa Ahmed;Al-Ahmadi, Mohammad S.;Jeon, Il;Dwivedi, Yogesh K.","Agentic systems as catalysts for innovation in FinTech: exploring opportunities, challenges and a research agenda","Purpose: Agentic artificial intelligence (AI) systems, which feature autonomous decision-making and adaptive intelligence, can potentially revolutionize financial technology (FinTech) by combining algorithmic accuracy with human knowledge. This study aims to examine the opportunities, challenges and transformational potential of agentic systems in FinTech and suggests a thorough research agenda for directing their sustainable and ethical integration. Design/methodology/approach: This study conceptualizes the changing environment of agentic systems by combining insights from technical whitepapers, industrial case studies and scholarly literature. It assesses how they are changing conventional financial frameworks and determines key factors that affect their adoption. Findings: The sentiment analysis of 170 social media posts revealed an overwhelmingly positive public perception (85%) of agentic AI in FinTech. In addition, the study finds that agentic systems fundamentally alter FinTech by providing autonomous, adaptive and context-aware financial services in trade, fraud detection, customer interaction and regulation. However, their widespread implementation presents challenges such as transparency, ethical alignment, system robustness and regulatory supervision. Research limitations/implications: This paper provides a fundamental paradigm to help stakeholders navigate the FinTech industry’s adoption of agentic systems. It examines the many facets of these systems’ challenges and novel opportunities, especially automation, personalization and risk management. It also presents a research agenda for the future that aims to direct future investigations and promote cooperation among industry, academia and regulatory agencies. Originality/value: To the best of the authors’ knowledge, this research is one of the first comprehensive evaluations of agentic systems in FinTech. It emphasizes how multidisciplinary cooperation is essential to ensuring that these systems promote reasonable, long-term advancements in financial digitalization.",Agentic AI | Agentic system | AI-driven finance | Autonomous agent | Cognitive agent | Digital banking | Financial services | FinTech | Intelligent agent | OpenAI operator | Smart agent | Virtual assistant,9,2025,sustainability,behavior+policy+sustainability
405,2-s2.0-85188635781,10.1134/S1064562423701673,https://doi.org/10.1134/S1064562423701673,https://scholar.google.com/scholar?q=10.1134/S1064562423701673,ar,Doklady Mathematics,"Kazakov, A.;Denisova, S.;Barsola, I.;Kalugina, E.;Molchanova, I.;Egorov, I.;Kosterina, A.;Tereshchenko, E.;Shutikhina, L.;Doroshchenko, I.;Sotiriadi, N.;Budennyy, S.","ESGify: Automated Classification of Environmental, Social, and Corporate Governance Risks","Abstract: The growing recognition of environmental, social, and governance (ESG) factors in financial decision-making has spurred the need for effective and comprehensive ESG risk assessment tools. In this study, we introduce an open-source Natural Language Processing (NLP) model, “ESGify”<sup>1,2</sup>, based on MPNet-base architecture and aimed to classify texts within the frames of ESG risks. We also present a hierarchical and detailed methodology for ESG risk classification, leveraging the expertise of ESG professionals and global best practices. Anchored by a manually annotated multilabel dataset of 2000 news articles and domain adaptation with texts of sustainability reports, ESGify is developed to automate ESG risk classification following the established methodology. We compare augmentation techniques based on back translation and Large Language Models (LLMs) to improve the model quality and achieve 0.5 F1-weighted model quality in the dataset with 47 classes. This result outperforms ChatGPT 3.5 with a simple prompt. The model weights and documentation is hosted on Github https://github.com/sb-ai-lab/ESGify under the Apache 2.0 license.",ESG | LLM | NLP | sustainability,9,2023,sustainability,behavior+policy+sustainability
80,2-s2.0-105008904872,10.1016/j.techsoc.2025.102995,https://doi.org/10.1016/j.techsoc.2025.102995,https://scholar.google.com/scholar?q=10.1016/j.techsoc.2025.102995,ar,Technology in Society,"Silalahi, Andri Dayarana K.",Can generative artificial intelligence drive sustainable behavior? A consumer-adoption model for AI-driven sustainability recommendations,"Generative AI (GAI) has the potential to promote sustainable behavior through personalized recommendations; yet its effectiveness hinges on user trust—an issue that remains under-explored in the literature. Existing studies often focus on specific domains without addressing broader trust-building mechanisms or the cognitive and motivational factors needed for sustained engagement. This study investigates how trust shapes the adoption of GAI-driven sustainability recommendations by integrating the Elaboration Likelihood Model (ELM) and Expectancy-Value Theory (EVT) into a single framework. Using data from sustainability-oriented users, we examine how central route constructs-perceived information quality and utility-peripheral route constructs-anthropomorphism and interaction quality-enhance trust, while perceived information complexity and perceived risk moderate these relationships. Our findings indicate that high-quality, useful information enhances trust through cognitive engagement, whereas anthropomorphic design and interaction quality reinforce trust via the heuristic route. However, excessive complexity and privacy concerns undermine trust, highlighting the need for clearer communication and data transparency. This study broadens theoretical understanding by extending ELM and EVT to the context of GAI-driven sustainability efforts, providing an integrated framework that encompasses cognitive and motivational trust drivers. These insights fill gaps in technology adoption research and offer practical guidance for developing GAI platforms that effectively support pro-environmental behavior change.",Cognitive engagement | Elaboration likelihood model | Generative AI | Pro-environmental adoption | Sustainable behavior | User trust,9,2025,sustainability,behavior+sustainability
238,2-s2.0-85218875925,10.3390/electronics14040661,https://doi.org/10.3390/electronics14040661,https://scholar.google.com/scholar?q=10.3390/electronics14040661,ar,Electronics Switzerland,"Karimanzira, Divas",Context-Aware Tomato Leaf Disease Detection Using Deep Learning in an Operational Framework,"Tomato cultivation is a vital agricultural practice worldwide, yet it faces significant challenges due to various diseases that adversely affect crop yield and quality. This paper presents a novel tomato disease detection system within an operational framework that leverages an innovative deep learning-based classifier, specifically a Vision Transformer (ViT) integrated with cascaded group attention (CGA) and a modified Focaler-CIoU (Complete Intersection over Union) loss function. The proposed method aims to enhance the accuracy and robustness of disease detection by effectively capturing both local and global contextual information while addressing the challenges of sample imbalance in the dataset. To improve interpretability, we integrate Explainable Artificial Intelligence (XAI) techniques, enabling users to understand the rationale behind the model’s classifications. Additionally, we incorporate a large language model (LLM) to generate comprehensive, context-aware explanations and recommendations based on the identified diseases and other relevant factors, thus bridging the gap between technical analysis and user comprehension. Our evaluation against state-of-the-art deep learning methods, including convolutional neural networks (CNNs) and other transformer-based models, demonstrates that the ViT-CGA model significantly outperforms existing techniques, achieving an overall accuracy of 96.5%, an average precision of 93.9%, an average recall of 96.7%, and an average F1-score of 94.2% for tomato leaf disease classification. The integration of CGA and Focaler-CIoU loss not only contributes to improved model interpretability and stability but also empowers farmers and agricultural stakeholders with actionable insights, fostering informed decision making in disease management. This research advances the field of automated disease detection in crops and provides a practical framework for deploying deep learning solutions in agricultural settings, ultimately supporting sustainable farming practices and enhancing food security.",cascaded group attention (CGA) | deterministic local interpretable model-agnostic explanations (DLIME) | large language model (LLM) | tomato leaf disease detection | vision transformer (ViT),9,2025,sustainability,behavior+sustainability
229,2-s2.0-105001552618,10.1177/23998083241272097,https://doi.org/10.1177/23998083241272097,https://scholar.google.com/scholar?q=10.1177/23998083241272097,ar,Environment and Planning B Urban Analytics and City Science,"Fu, Xinyu;Brinkley, Catherine;Sanchez, Thomas W.;Li, Chaosu","Text mining public feedback on urban densification plan change in Hamilton, New Zealand","Cities worldwide are commonly aspiring to transition from inefficient urban sprawl patterns to more compact and sustainable urban forms. However, urban densification efforts often face significant public resistance or skepticism, hindering at-scale implementation. There is a scarcity of empirical studies identifying the rationale and mechanisms underpinning public opposition to urban density. This study aims to bridge this gap by leveraging novel natural language processing techniques (NLP), combined with mixed-methods analysis of a unique, highly detailed public dataset on urban intensification in Hamilton. This research stands out by proposing a transferable model for rapidly generating insights from large public feedback datasets, and also unveils the polarized and complex, self-interest-driven mechanisms, including NIMBYism (Not In My Back Yard), behind public support or opposition to urban densification. NLP techniques, such as sentiment analysis, topic modeling, and ChatGPT, can be used to offer rapid insights into a large, unstructured public feedback dataset. When combined with submitters’ individual interest representation and identifies, these AI-generated summaries can offer important insights into the hidden rationales behind public opinions, and, more importantly, be used to design tailored public engagement activities to obtain community buy-in.",ChatGPT | Natural language processing | public participation | urban densification | urban planning,9,2025,sustainability,policy+sustainability
408,2-s2.0-85172720589,10.1088/1748-9326/acf233,https://doi.org/10.1088/1748-9326/acf233,https://scholar.google.com/scholar?q=10.1088/1748-9326/acf233,re,Environmental Research Letters,"Toetzke, Malte;Probst, Benedict;Feuerriegel, Stefan",Leveraging large language models to monitor climate technology innovation,"To achieve net-zero emissions, public policy needs to foster rapid innovation of climate technologies. However, there is a scarcity of comprehensive and up-to-date evidence to guide policymaking by monitoring climate innovation systems. This is notable, especially at the center of the innovation process, where nascent inventions transition into profitable and scalable market solutions. Here, we discuss the potential of large language models (LLMs) to monitor climate technology innovation. By analyzing large pools of unstructured text data sources, such as company reports and social media, LLMs can automate information retrieval processes and thereby improve existing monitoring in terms of cost-effectiveness, timeliness, and comprehensiveness. In this perspective, we show how LLMs can play a crucial role in informing innovation policy for the energy transition by highlighting promising use cases and prevailing challenges for research and policy.",climate technologies | innovation | large language models | machine learning,9,2023,sustainability,policy+sustainability
536,2-s2.0-105007354462,10.1038/s43588-025-00798-6,https://doi.org/10.1038/s43588-025-00798-6,https://scholar.google.com/scholar?q=10.1038/s43588-025-00798-6,ar,Nature Computational Science,"Du, Hongru;Zhao, Yang;Zhao, Jianan;Xu, Shaochong;Lin, Xihong;Chen, Yiran;Gardner, Lauren M.;Yang, Hao ‘Frank’",Advancing real-time infectious disease forecasting using large language models,"Forecasting the short-term spread of an ongoing disease outbreak poses a challenge owing to the complexity of contributing factors, some of which can be characterized through interlinked, multi-modality variables, and the intersection of public policy and human behavior. Here we introduce PandemicLLM, a framework with multi-modal large language models (LLMs) that reformulates real-time forecasting of disease spread as a text-reasoning problem, with the ability to incorporate real-time, complex, non-numerical information. This approach, through an artificial intelligence–human cooperative prompt design and time-series representation learning, encodes multi-modal data for LLMs. The model is applied to the COVID-19 pandemic, and trained to utilize textual public health policies, genomic surveillance, spatial and epidemiological time-series data, and is tested across all 50 states of the United States for a duration of 19 months. PandemicLLM opens avenues for incorporating various pandemic-related data in heterogeneous formats and shows performance benefits over existing models.",,8,2025,behavior,behavior+policy
544,2-s2.0-105001503117,10.1016/j.bjps.2025.03.053,https://doi.org/10.1016/j.bjps.2025.03.053,https://scholar.google.com/scholar?q=10.1016/j.bjps.2025.03.053,ar,Journal of Plastic Reconstructive and Aesthetic Surgery,"Ozmen, Berk B.;Mathur, Piyush",Evidence-based artificial intelligence: Implementing retrieval-augmented generation models to enhance clinical decision support in plastic surgery,"The rapid advancement of large language models (LLMs) has generated significant enthusiasm within healthcare, especially in supporting clinical decision-making and patient management. However, inherent limitations including hallucinations, outdated clinical context, and unreliable references pose serious concerns for their clinical utility. Retrieval-Augmented Generation (RAG) models address these limitations by integrating validated, curated medical literature directly into AI workflows, significantly enhancing the accuracy, relevance, and transparency of generated outputs. This viewpoint discusses how RAG frameworks can specifically benefit plastic and reconstructive surgery by providing contextually accurate, evidence-based, and clinically grounded support for decision-making. Potential clinical applications include clinical decision support, efficient evidence synthesis, customizable patient education, informed consent materials, multilingual capabilities, and structured surgical documentation. By querying specialized databases that incorporate contemporary guidelines and literature, RAG models can markedly reduce inaccuracies and increase the reliability of AI-generated responses. However, the implementation of RAG technology demands rigorous database curation, regular updating with guidelines from surgical societies, and ongoing validation to maintain clinical relevance. Addressing challenges related to data privacy, governance, ethical considerations, and user training remains critical for successful clinical adoption. In conclusion, RAG models represent a significant advancement in overcoming traditional LLM limitations, promoting transparency and clinical accuracy with great potential for plastic surgery. Plastic surgeons and researchers are encouraged to explore and integrate these innovative generative AI frameworks to enhance patient care, surgical outcomes, communication, documentation quality, and education.",Artificial intelligence | Clinical decision support | Large language models | Retrieval-augmented generation models,8,2025,behavior,behavior+policy
653,2-s2.0-105001076466,10.1080/10447318.2024.2345980,https://doi.org/10.1080/10447318.2024.2345980,https://scholar.google.com/scholar?q=10.1080/10447318.2024.2345980,ar,International Journal of Human Computer Interaction,"Hu, Mo;Zhang, Guanglu;Chong, Leah;Cagan, Jonathan;Goucher-Lambert, Kosa",How Being Outvoted by AI Teammates Impacts Human-AI Collaboration,"Recent advances in artificial intelligence (AI) enable AI agents to go beyond simply supporting human activities and, instead, take more control in team decision-making. While significant literature has studied human-AI collaboration through the lens of AI as a “second opinion system,” this type of interaction is not fully representative of many human-human team collaboration scenarios, such as scenarios where each decision maker is granted equal voting rights for the team decision. In this research, we explore how imparting AI agents with equal voting rights to the human impacts human-AI decision-making and team performance. Using a human subjects experiment in which participants collaborate with two AI teammates for truss structure (aka, bridge) design, we manipulate a series of voting scenarios (e.g., AI agents outvoting the human vs. AI agents agreeing with the human) and AI performance levels (high vs. low performing). The results indicate that changes in human self-confidence are not consistent with whether the quality of the final team-voted design action is advantageous or disadvantageous relative to their own actions. The results also show that when humans are outvoted by their AI teammates, they do not show strong negative emotional reactions if the team-voted decision has an advantageous outcome. Additionally, AI performance significantly influences the human-AI team decision-making process and even one low-performing AI (i.e., an AI that is frequently incorrect) on the team can significantly deteriorate team performance. Taken together, this research provides empirical evidence on the effects of AI voting with equal decision authority on human-AI collaboration, as well as valuable insights supporting real-world applications of human-AI collaboration via voting.",Artificial intelligence | decision authority | decision-making | human-computer interaction | trust | voting,8,2025,behavior,behavior+policy
664,2-s2.0-85207645099,10.1016/j.clsr.2024.106067,https://doi.org/10.1016/j.clsr.2024.106067,https://scholar.google.com/scholar?q=10.1016/j.clsr.2024.106067,ar,Computer Law and Security Review,"Carnat, Irina",Addressing the risks of generative AI for the judiciary: The accountability framework(s) under the EU AI Act,"The rapid advancements in natural language processing, particularly the development of generative large language models (LLMs), have renewed interest in using artificial intelligence (AI) for judicial decision-making. While these technological breakthroughs present new possibilities for legal automation, they also raise concerns about over-reliance and automation bias. Drawing insights from the COMPAS case, this paper examines the implications of deploying generative LLMs in the judicial domain. It identifies the persistent factors that contributed to an accountability gap when AI systems were previously used for judicial decision-making. To address these risks, the paper analyses the relevant provisions of the EU Artificial Intelligence Act, outlining a comprehensive accountability framework based on the regulation's risk-based approach. The paper concludes that the successful integration of generative LLMs in judicial decision-making requires a holistic approach addressing cognitive biases. By emphasising shared responsibility and the imperative of AI literacy across the AI value chain, the regulatory framework can help mitigate the risks of automation bias and preserve the rule of law.",Accountability | Automation bias | Generative Artificial Intelligence | Judicial decision-making | Large Language Models,8,2024,behavior,behavior+policy
687,2-s2.0-85187170492,10.1007/s41870-024-01781-6,https://doi.org/10.1007/s41870-024-01781-6,https://scholar.google.com/scholar?q=10.1007/s41870-024-01781-6,ar,International Journal of Information Technology Singapore,"Ihsan, Rukhshanda;Khurshid, Syed Khaldoon;Shoaib, Muhammad;Ali, Sadia;Mahnoor, Sana;Hamza, Syed Muhammad",A technique to forecast Pakistan’s news using deep hybrid learning model,"Forecasting future events is a challenging task that can have a significant impact on decision-making and policy-making. In this research, we focus on forecasting news related to Pakistan. Despite the importance of accurate predictions in this field, there currently exists no dataset for forecasting Pakistani news, specifically with regards to politics. Unlike numerical time series data, textual data includes information about the event's potential causes in addition to its impact. Better forecasts are thus anticipated as a result of this greater information. In order to address this gap, our research aims to create a first Pakistani news dataset for forecasting of Pakistan news that is mostly related to politics of Pakistan. This dataset was collected from various sources, including Pakistani news websites and social media platforms, as well as frequently asked questions about Pakistani politics. We develop a forecasting model using this dataset and evaluate the effectiveness of cutting-edge deep hybrid learning techniques incorporating neural networks, random forest, Word2vec, Natural language processing (NLP), and Naive Bayes. To the best of our understanding, no research has been done on the application of a deep hybrid learning model—a blend of deep learning and machine learning—for news forecasting. The accuracy for forecasting model is 97%. According to our findings, the model's performance is adequate when compared to that of other forecasting models. Our research not only fills the gap in the current literature but also presents a new challenge for large language models and has the potential to bring significant practical advantages in the field of forecasting. The unique contribution of this study lies in the intelligent modeling of the prediction challenge, allowing for the utilization of text rich in content for forecasting objectives.",Deep hybrid learning | Forecasting | Natural language processing (NLP) | Naïve bayes | Neural network | Random forest | Word2vec,8,2024,behavior,behavior+policy
209,2-s2.0-105001414882,10.1016/j.xcrp.2025.102508,https://doi.org/10.1016/j.xcrp.2025.102508,https://scholar.google.com/scholar?q=10.1016/j.xcrp.2025.102508,re,Cell Reports Physical Science,"Zhou, Yuekuan;Dan, Zhaohui",Modern energy resilience studies with artificial intelligence for energy transitions,"Climate change and multifaceted energy crises necessitate resilient power systems for sustainable and smart energy transitions. However, correlations among energy efficiency, energy reliability, robustness, flexibility, and energy resilience remain unclear. This review employs bibliometric analysis to evaluate AI-driven solutions, particularly generative AI, in enhancing urban energy resilience. We quantify energy resilience metrics, as well as highlight the synergy among energy efficiency, energy reliability, robustness, flexibility, energy resilience with carbon neutrality, and multi-sector strategies across supply, demand, storage, and grid systems. The analysis demonstrates the capacity of AI to improve climate change adaptation during extreme events, illustrated as bio-inspired frameworks that emulate human self-regulation and self-healing. The integration of end-user participation and techno-economic-social benefits are emphasized. Big data technology facilitates information communications and inter-component interactions, while generative AI enables automatic city-scale information modeling and real-time decision-making. To conclude, we highlight challenges in smart energy transitions and suggest pathways to harmonize resilience with energy efficiency and reliability under climate challenges.",AI | carbon neutrality | climate change | energy resilience | generative artificial intelligence | machine learning | sustainability development goals,8,2025,sustainability,behavior+policy+sustainability
154,2-s2.0-105007619126,10.1109/MIOT.2025.3575887,https://doi.org/10.1109/MIOT.2025.3575887,https://scholar.google.com/scholar?q=10.1109/MIOT.2025.3575887,ar,IEEE Internet of Things Magazine,"Jiang, Dawen;Shen, Zhishu;Zheng, Qiushi;Zhang, Tiehua;Xiang, Wei;Jin, Jiong",Farm-LightSeek: An Edge-Centric Multimodal Agricultural IoT Data Analytics Framework With Lightweight LLMs,"Amid the challenges posed by global population growth and climate change, traditional agricultural Internet of Things (IoT) systems is currently undergoing a significant digital transformation to facilitate efficient big data processing. While smart agriculture utilizes artificial intelligence (AI) technologies to enable precise control, it still encounters significant challenges, including excessive reliance on agricultural expert knowledge, difficulties in fusing multimodal data, poor adaptability to dynamic environments, and bottlenecks in real-time decision-making at the edge. Large language models (LLMs), with their exceptional capabilities in knowledge acquisition and semantic understanding, provide a promising solution to address these challenges. To this end, we propose Farm-LightSeek, an edge-centric multimodal agricultural IoT data analytics framework that integrates LLMs with edge computing. This framework collects real-time farmland multi-source data (images, weather, geographic information) via sensors, performs cross-modal reasoning and disease detection at edge nodes, conducts low-latency management decisions, and enables cloud collaboration for model updates. The main innovations of Farm-LightSeek include: (1) an agricultural “perception-decision-action” closed-loop architecture; (2) cross-modal adaptive monitoring; and (3) a lightweight LLM deployment strategy balancing performance and efficiency. Experiments conducted on two real-world datasets demonstrate that Farm-LightSeek consistently achieves reliable performance in mission-critical tasks, even under the limitations of edge computing resources. This work advances intelligent real-time agricultural solutions and highlights the potential for deeper integration of agricultural IoT with LLMs.",edge computing | Internet of Things | knowledge distillation | large language model | multimodal data analytics | Smart agriculture,8,2025,sustainability,behavior+sustainability
170,2-s2.0-105004257357,10.1016/j.autcon.2025.106245,https://doi.org/10.1016/j.autcon.2025.106245,https://scholar.google.com/scholar?q=10.1016/j.autcon.2025.106245,ar,Automation in Construction,"Ghorbany, Siavash;Hu, Ming;Yao, Siyuan;Sisk, Matthew;Wang, Chaoli",Automating embodied and operational carbon assessment in urban sustainable development,"The construction industry is a major contributor to global greenhouse gas emissions, with embodied carbon playing a key role. This paper introduces EcoSphere, an integrated software for automating sustainable urban development by analyzing trade-offs between embodied and operational carbon emissions, construction costs, and environmental impacts. It leverages National Structure Inventory data, computer vision, and large language models on Google Street View and satellite imagery to provide high-resolution, building-specific insights. Using a bottom-up approach, it categorizes buildings into archetypes to create a baseline emissions dataset. Designed for policymakers and non-experts, EcoSphere enables data-driven decision-making on policy scenarios and mitigation strategies. Case studies in Chicago and Indianapolis, USA, highlight its effectiveness in reducing emissions and costs. By simplifying complex data into actionable insights, EcoSphere empowers stakeholders to support carbon neutrality goals, making it a crucial tool for sustainable urban planning.",Carbon emissions | Cost trade-off | Decision-support tool | Embodied carbon | Sustainable development | Urban planning,8,2025,sustainability,behavior+sustainability
214,2-s2.0-85212573230,10.1016/j.csi.2024.103965,https://doi.org/10.1016/j.csi.2024.103965,https://scholar.google.com/scholar?q=10.1016/j.csi.2024.103965,ar,Computer Standards and Interfaces,"khan, Falak;Bartáková, Gabriela Pajtinková;Almadhor, Ahmad;Qayyum, Amna;Abeer, Kainaat;Durrani, Aman",Evaluating the capacity and limitations of generative AI in financial decision making,"Financial services industry has experienced enormous changes, as a result innovations are constantly taking place to cater to new financial needs of individuals, globally. Though innovative and complex financial products present consumers with a variety of investment options, yet at the same time, this variety tends to complicate the decision-making process, when faced with too many options to choose from, especially ones that may be artificial intelligence based and too technologically advanced for consumers to understand, hence consumers find it challenging to reach a decision. The primary concept behind conducting this study is to analyse the phases at which consumers are more vulnerable in the developing countries by walking through their decision-making process of acquiring technologically advanced financial products. This qualitative study is based on 50 interviews and themes are formed using qualitive SQL software. The findings reveal that consumers are quite vulnerable due to the lack of; financial and digital literacy, bank cooperation, trust issues and regulative discrepancies. The study also makes recommendations for the practitioners and the policy makers for a better and sustainable financial inclusion.",Consumer Behaviour | Consumer Vulnerability | Developing Countries | FBehavioural finance | Generative AI | Sustainable Development Goals,8,2025,sustainability,behavior+sustainability
161,2-s2.0-85219499545,10.1016/j.csi.2025.103995,https://doi.org/10.1016/j.csi.2025.103995,https://scholar.google.com/scholar?q=10.1016/j.csi.2025.103995,ar,Computer Standards and Interfaces,"Chen, Lun Chi;Pardeshi, Mayuresh Sunil;Liao, Yi Xiang;Pai, Kai Chih",Application of retrieval-augmented generation for interactive industrial knowledge management via a large language model,"Industrial data processing and retrieval are necessary for adoption in Industry 5.0. Large Language Model (LLMs) revolutionize natural language process (NLP) but face challenges in domain-specific applications due to specialized terminology and context. Artificial Intelligence (AI) assistants for industrial-related work enquiry and customer support services are necessary for increasing demand and quality of service (QoS). Our research aims to design a novel customized model with a retrieval-augmented generation (RAG)-based LLM as a sustainable solution for industrial integration with AI. The goal is to provide an interactive industrial knowledge management (IIKM) system that can be applied to technical services: assisting technicians in the search for precise technical repair details and company internal regulation searches: personnel can easily inquire about regulations, such as business trips and leave requirements. The IIKM model architecture consists of BM25 and embedding sequence processing in the chroma database, where the top k-chunks are selected by the BAAI ranker to respond effectively to the queries. A group of documents of 234 MB size and pdf, pptx, docx, csv and txt formats are used for the experimental analysis. The designed interactive knowledge management system has a mean reciprocal rank (MRR) of 88 %, a recall of 85 % and a mean average precision (mAP) of 75 % in technical service. The internal regulatory documents have a generation-based retrieval evaluation prediction of recall of 91.62 %, MRR of 97.97 % and mAP of 91.12 %. We conclude with insights gained and experiences shared from IIKM deployment with Sakura incorporation, highlighting the importance of the hybrid approach integrating RAG-based generative pretrained transformer (GPT) models for customized solutions.",Interactive industrial knowledge management system | Large language models | Retrieval-augmented generation,8,2025,sustainability,policy+sustainability
196,2-s2.0-86000338301,10.1016/j.resconrec.2025.108227,https://doi.org/10.1016/j.resconrec.2025.108227,https://scholar.google.com/scholar?q=10.1016/j.resconrec.2025.108227,ar,Resources Conservation and Recycling,"Zhang, Siwei;Ma, Jun;Jiang, Feifeng",Monitoring street-level improper dumpsites via a multi-modal and LLM-based framework,"Effective monitoring and management of urban improper dumpsites have become increasingly critical due to the rising volumes of solid waste and their adverse environmental and public health impacts. Identifying the locations and types of street-level dumpsites is a necessary first step for waste management; however, existing studies lack automated and accurate methods for detecting and categorizing these sites. As a result, governments face substantial labor and financial burdens in managing illegal dumping. To address these gaps, this study presents MultiSense DumpSpotter, a novel cascade model framework that integrates a multimodal deep learning architecture with Large Language Models (LLMs) to identify, classify, and analyze improper dumpsites with greater accuracy than traditional unimodal vision models. To support this framework, we developed UrbanDumpSight, the first annotated street-level urban dumpsite dataset, consisting of over 4000 street view images with metadata that includes geospatial and demographic information. This study contribute to the literature by demonstrating the effectiveness of multimodal data fusion in urban studies and the potential of LLMs in interpreting urban semantics. From a practical standpoint, it introduces a deployable, user-friendly system designed to meet the needs of urban managers, enabling efficient monitoring of improper dumping hotspots, uncovering root causes, and facilitating the implementation of effective governance actions. Overall, this research provides a novel and scalable solution for addressing urban waste challenges, offering insights to support sustainable waste management and policy-making.",Deep learning | Multi-modality | Street view images | Street-level dumpsites | Urban waste management | Waste monitoring,8,2025,sustainability,policy+sustainability
394,2-s2.0-85201158135,10.1109/MC.2024.3382073,https://doi.org/10.1109/MC.2024.3382073,https://scholar.google.com/scholar?q=10.1109/MC.2024.3382073,ar,Computer,"Shan, Richard",Language Artificial Intelligence at a Crossroads: Deciphering the Future of Small and Large Language Models,"This article explores the future of language models, focusing on the development and growth of large and small language models. It advocates for interdisciplinary collaboration, responsibility guidelines, educational initiatives, sustainable practices, and effective governance to ensure that these technologies benefit society in the long run.",,8,2024,sustainability,policy+sustainability
403,2-s2.0-105020304052,10.51483/IJAIML.4.1.2024.22-47,https://doi.org/10.51483/IJAIML.4.1.2024.22-47,https://scholar.google.com/scholar?q=10.51483/IJAIML.4.1.2024.22-47,ar,International Journal of Artificial Intelligence and Machine Learning,"Rane, Nitin Liladhar",Potential Role and Challenges of ChatGPT and Similar Generative Artificial Intelligence in Architectural Engineering,"The incorporation of generative Artificial Intelligence (AI) systems, such as ChatGPT, holds great potential in reshaping diverse facets of architectural engineering. This research investigates the profound influence of AI technologies on structural engineering Heating, Ventilation, and Air Conditioning(HVAC) engineering, electrical engineering, plumbing and fire protection engineering, sustainability, net zero, and green building design, Building Information Modeling (BIM), urban planning, and project management. In structural engineering, ChatGPT’s capacity to analyze extensive datasets and simulate intricate structures expedites the design process, ensuring structural integrity while optimizing materials and costs. In HVAC engineering, it aids in devising energy-efficient systems and climate control solutions, significantly contributing to sustainable building practices. Similarly, in electrical engineering, the AI’s capabilities enhance the design and optimization of electrical systems, ensuring both safety and reliability. In plumbing and fire protection engineering, ChatGPT assists in creating efficient plumbing layouts and fire suppression systems, ensuring compliance with regulations. Moreover, ChatGPT plays a pivotal role in advancing sustainability and green building design. By evaluating environmental factors and suggesting eco-friendly materials and designs, it fosters the development of environmentally responsible structures. In the domain of BIM, the AI facilitates seamless collaboration, automates model generation, and improves clash detection, ensuring streamlined proj ect execution. Nevertheless, the integration of generative AI in architectural engineering presents challenges. Ethical concerns, data security, and the necessity for skilled professionals to interpret AI-generated insights are significant issues. This research delves into these contribution and challenges to effectively harness the potential of generative AI, paving the way for a transformative era in architectural engineering.",Architectural engineering | Artificial intelligence | ChatGPT | Generative artificial intelligence | HVAC engineering | Structural engineering,8,2024,sustainability,policy+sustainability
505,2-s2.0-105009858225,10.1016/j.tranpol.2025.06.021,https://doi.org/10.1016/j.tranpol.2025.06.021,https://scholar.google.com/scholar?q=10.1016/j.tranpol.2025.06.021,ar,Transport Policy,"Yun, Hyunsoo;Lee, Eun Hak",Party politics in transport policy with a large language model,"Given the significant influence of lawmakers' political ideologies on legislative decision-making, analyzing their impact on transportation-related policymaking is of critical importance. This study introduces a novel framework that integrates a large language model (LLM) with explainable artificial intelligence (XAI) to analyze transportation-related legislative proposals. Legislative bill data from South Korea's 21st National Assembly were used to identify key factors shaping transportation policymaking. These include political affiliations and sponsor characteristics. The LLM was employed to classify transportation-related bill proposals through a stepwise filtering process based on keywords, sentences, and contextual relevance. XAI techniques were then applied to examine the relationships between political party affiliation and associated attributes. The results revealed that the number and proportion of conservative and progressive sponsors, along with district size and electoral population, were critical determinants shaping legislative outcomes. These findings suggest that both parties contributed to bipartisan legislation through different forms of engagement, such as initiating or supporting proposals. This integrated approach offers a valuable tool for understanding legislative dynamics and guiding future policy development, with broader implications for infrastructure planning and governance.",eXplainable artificial intelligence | Large language model | Lawmaker | Legislative bill | Politics | Transport policy,7,2025,behavior,behavior+policy
530,2-s2.0-105004221528,10.1007/s41669-025-00580-4,https://doi.org/10.1007/s41669-025-00580-4,https://scholar.google.com/scholar?q=10.1007/s41669-025-00580-4,ar,Pharmacoeconomics Open,"Reason, Tim;Klijn, Sven;Rawlinson, Will;Benbow, Emma;Langham, Julia;Teitsson, Siguroli;Johannesen, Kasper;Malcolm, Bill",Using Generative Artificial Intelligence in Health Economics and Outcomes Research: A Primer on Techniques and Breakthroughs,"The emergence of generative artificial intelligence (GenAI) offers the potential to enhance health economics and outcomes research (HEOR) by streamlining traditionally time-consuming and labour-intensive tasks, such as literature reviews, data extraction, and economic modelling. To effectively navigate this evolving landscape, health economists need a foundational understanding of how GenAI can complement their work. This primer aims to introduce health economists to the essentials of using GenAI tools, particularly large language models (LLMs), in HEOR projects. For health economists new to GenAI technologies, chatbot interfaces like ChatGPT offer an accessible way to explore the potential of LLMs. For more complex projects, knowledge of application programming interfaces (APIs), which provide scalability and integration capabilities, and prompt engineering strategies, such as few-shot and chain-of-thought prompting, is necessary to ensure accurate and efficient data analysis, enhance model performance, and tailor outputs to specific HEOR needs. Retrieval-augmented generation (RAG) can further improve LLM performance by incorporating current external information. LLMs have significant potential in many common HEOR tasks, such as summarising medical literature, extracting structured data, drafting report sections, generating statistical code, answering specific questions, and reviewing materials to enhance quality. However, health economists must also be aware of ongoing limitations and challenges, such as the propensity of LLMs to produce inaccurate information (‘hallucinate’), security concerns, issues with reproducibility, and the risk of bias. Implementing LLMs in HEOR requires robust security protocols to handle sensitive data in compliance with the European Union’s General Data Protection Regulation (GDPR) and the United States’ Health Insurance Portability and Accountability Act (HIPAA). Deployment options such as local hosting, secure API use, or cloud-hosted open-source models offer varying levels of control and cost, each with unique trade-offs in security, accessibility, and technical demands. Reproducibility and transparency also pose unique challenges. To ensure the credibility of LLM-generated content, explicit declarations of the model version, prompting techniques, and benchmarks against established standards are recommended. Given the ‘black box’ nature of LLMs, a clear reporting structure is essential to maintain transparency and validate outputs, enabling stakeholders to assess the reliability and accuracy of LLM-generated HEOR analyses. The ethical implications of using artificial intelligence (AI) in HEOR, including LLMs, are complex and multifaceted, requiring careful assessment of each use case to determine the necessary level of ethical scrutiny and transparency. Health economists must balance the potential benefits of AI adoption against the risks of maintaining current practices, while also considering issues such as accountability, bias, intellectual property, and the broader impact on the healthcare system. As LLMs and AI technologies advance, their potential role in HEOR will become increasingly evident. Key areas of promise include creating dynamic, continuously updated HEOR materials, providing patients with more accessible information, and enhancing analytics for faster access to medicines. To maximise these benefits, health economists must understand and address challenges such as data ownership and bias. The coming years will be critical for establishing best practices for GenAI in HEOR. This primer encourages health economists to adopt GenAI responsibly, balancing innovation with scientific rigor and ethical integrity to improve healthcare insights and decision-making.",,7,2025,behavior,behavior+policy
533,2-s2.0-105008652559,10.1073/pnas.2501660122,https://doi.org/10.1073/pnas.2501660122,https://scholar.google.com/scholar?q=10.1073/pnas.2501660122,ar,Proceedings of the National Academy of Sciences of the United States of America,"Gao, Yuan;Lee, Dokyun;Burtch, Gordon;Fazelpour, Sina",Take caution in using LLMs as human surrogates,"Recent studies suggest large language models (LLMs) can generate human-like responses, aligning with human behavior in economic experiments, surveys, and political discourse. This has led many to propose that LLMs can be used as surrogates or simulations for humans in social science research. However, LLMs differ fundamentally from humans, relying on probabilistic patterns, absent the embodied experiences or survival objectives that shape human cognition. We assess the reasoning depth of LLMs using the 11-20 money request game. Nearly all advanced approaches fail to replicate human behavior distributions across many models. The causes of failure are diverse and unpredictable, relating to input language, roles, safeguarding, and more. These results warrant caution in using LLMs as surrogates or for simulating human behavior in research.",LLMs as a simulation | LLMs as human surrogates | LLMs in social science research | Simulations of human behavior,7,2025,behavior,behavior+policy
578,2-s2.0-85216006685,10.1109/ACCESS.2025.3530688,https://doi.org/10.1109/ACCESS.2025.3530688,https://scholar.google.com/scholar?q=10.1109/ACCESS.2025.3530688,re,IEEE Access,"Plikynas, Darius;Rizgeliene, Ieva;Korvel, Grazina","Systematic Review of Fake News, Propaganda, and Disinformation: Examining Authors, Content, and Social Impact Through Machine Learning","In recent years, the world has witnessed a global outbreak of fake news, propaganda and disinformation (FNPD) flows on online social networks (OSN). In the context of information warfare and the capabilities of generative AI, FNPDs have proliferated. They have become a powerful and quite effective tool for influencing people's social identities, attitudes, opinions and even behavior. Ad hoc malicious social media accounts and organized networks of trolls and bots target countries, societies, social groups, political campaigns and individuals. As a result, conspiracy theories, echo chambers, filter bubbles and other processes of fragmentation and marginalization are polarizing, radicalizing, and disintegrating society in terms of coherent politics, governance, and social networks of trust and cooperation. This systematic review aims to explore advances in using machine and deep learning to detect FNPD in OSNs effectively. We present the results of a combined PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) review in three analysis domains: 1) propagators (authors, trolls, and bots), 2) textual content, 3) social impact. This systemic research framework integrates meta-analyses of three research domains, providing an overview of the wider research field and revealing important relationships between these research domains. It not only addresses the most promising ML/DL research methodologies and hybrid approaches in each domain, but also provides perspectives and insights on future research directions.",authors' analysis | content analysis | deep learning | fake news | Machine learning | PRISMA systematic review | propaganda and disinformation | social impact analysis,7,2025,behavior,behavior+policy
686,2-s2.0-85191338707,10.4274/ejbh.galenos.2024.2023-12-13,https://doi.org/10.4274/ejbh.galenos.2024.2023-12-13,https://scholar.google.com/scholar?q=10.4274/ejbh.galenos.2024.2023-12-13,ar,European Journal of Breast Health,"Mundinger, Alexander;Mundinger, Carolin",Artificial Intelligence in Senology - Where Do We Stand and What Are the Future Horizons?,"Artificial Intelligence (AI) is defined as the simulation of human intelligence by a digital computer or robotic system and has become a hype in current conversations. A subcategory of AI is deep learning, which is based on complex artificial neural networks that mimic the principles of human synaptic plasticity and layered brain architectures, and uses large-scale data processing. AI-based image analysis in breast screening programmes has shown noninferior sensitivity, reduces workload by up to 70% by pre-selecting normal cases, and reduces recall by 25% compared to human double reading. Natural language programs such as ChatGPT (OpenAI) achieve 80% and higher accuracy in advising and decision making compared to the gold standard: human judgement. This does not yet meet the necessary requirements for medical products in terms of patient safety. The main advantage of AI is that it can perform routine but complex tasks much faster and with fewer errors than humans. The main concerns in healthcare are the stability of AI systems, cybersecurity, liability and transparency. More widespread use of AI could affect human jobs in healthcare and increase technological dependency. AI in senology is just beginning to evolve towards better forms with improved properties. Responsible training of AI systems with meaningful raw data and scientific studies to analyse their performance in the real world are necessary to keep AI on track. To mitigate significant risks, it will be necessary to balance active promotion and development of quality-assured AI systems with careful regulation. AI regulation has only recently included in transnational legal frameworks, as the European Union's AI Act was the first comprehensive legal framework to be published, in December 2023. Unacceptable AI systems will be banned if they are deemed to pose a clear threat to people's fundamental rights. Using AI and combining it with human wisdom, empathy and affection will be the method of choice for further, fruitful development of tomorrow's senology.",Artificial Intelligence | breast cancer | breast cancer screening | breast disease | breast imaging | MRI | senology | ultrasound,7,2024,behavior,behavior+policy
39,2-s2.0-85217732025,10.1038/s41597-025-04476-0,https://doi.org/10.1038/s41597-025-04476-0,https://scholar.google.com/scholar?q=10.1038/s41597-025-04476-0,ar,Scientific Data,"Li, Bo;Fu, Enxian;Yang, Shuhao;Lin, Jiaying;Zhang, Wei;Zhang, Jian;Lu, Yaling;Wang, Jiantong;Jiang, Hongqiang",Measuring China’s Policy Stringency on Climate Change for 1954–2022,"Efforts on climate change have demonstrated tangible impacts through various actions and policies. However, a significant knowledge gap remains: comparing the stringency of climate change policies over time or across jurisdictions is challenging due to ambiguous definitions, the lack of a unified assessment framework, complex causal effects, and the difficulty in achieving effective measurement. Furthermore, China’s climate governance is expected to address multiple objectives by integrating main effects and side effects, to achieve synergies that encompass environmental, economic, and social impacts. This paper employs an integrated framework comprising lexicon, text analysis, machine learning, and large-language model applied to multi-source data to quantify China’s policy stringency on climate change (PSCC) from 1954 to 2022. To achieve effective, robust, and explainable measurement, Chain-of-Thought and SHAP analysis are integrated into the framework. By framing the PSCC on varied sub-dimensions covering mitigation, adaptation, implementation, and spatial difference, this dataset maps the government’s varied stringency on climate change and can be used as a robust variable to support a series of downstream causal analysis.",,7,2025,sustainability,behavior+policy+sustainability
189,2-s2.0-105000382643,10.1016/j.eswa.2025.127126,https://doi.org/10.1016/j.eswa.2025.127126,https://scholar.google.com/scholar?q=10.1016/j.eswa.2025.127126,ar,Expert Systems with Applications,"De, Sayan;Sanyal, Debarshi Kumar;Mukherjee, Imon",Fine-tuned encoder models with data augmentation beat ChatGPT in agricultural named entity recognition and relation extraction,"Agricultural research produces vast amounts of unstructured textual data, which remains largely underutilized due to the lack of robust tools for automated processing. If effectively processed, this underutilized data can provide critical insights to advance agricultural practices, decision-making, and sustainability. This work focuses on applying Named Entity Recognition (NER) and Relation Extraction (RE) to convert unstructured data into structured formats, addressing the challenges of domain-specific terminology and limited annotated datasets. This scarcity is primarily due to the domain-specific terminology, contextual complexity, and lack of annotated data in the agricultural domain. This study addresses these challenges by proposing sophisticated data augmentation techniques, validated using large language models and human reviewers, to enhance training data. We introduce AgNER-BERTa and AgRE-BERTa, two encoder-based models tailored for agricultural NER and RE tasks, and compare them with state-of-the-art (SOTA) baselines, including SciBERT, SpanBERT, and generative decoder models like ChatGPT. Our experiments demonstrate superior performance, achieving 98% accuracy for NER and 97% for RE outperforming SOTA models. The extracted entities and relations are used to construct the Agricultural Knowledge Graph (AgKG), providing structured, queryable insights to support precision agriculture, policy-making, and sustainable farming practices.",Knowledge graph | Named entity recognition | Relation extraction | Text data augmentation,7,2025,sustainability,behavior+policy+sustainability
248,2-s2.0-86000197361,10.1080/10447318.2025.2470280,https://doi.org/10.1080/10447318.2025.2470280,https://scholar.google.com/scholar?q=10.1080/10447318.2025.2470280,ar,International Journal of Human Computer Interaction,"Zhou, Tao;Wang, Mengru",Examining Generative AI User Discontinuance from a Dual Perspective of Enablers and Inhibitors,"As a negative behavior, user discontinuance may undermine user retention and reduce the competitive advantage of generative AI platforms. Extant research has focused on the positive behaviors such as user adoption and continuance of generative AI, and has seldom explored the formation mechanism underlying user discontinuance of generative AI. The purpose of this research is to explore generative AI user discontinuance intention from a dual perspective of enablers and inhibitors. We used a mixed method of structural equation modeling (SEM) and fuzzy-set qualitative comparative analysis (fsQCA) to conduct data analysis. The results revealed that discontinuance intention is influenced by both the enablers (misinformation, algorithm bias, low transparency, and dissatisfaction) and the inhibitors (perceived anthropomorphism, perceived intelligence, perceived interactivity, and flow experience). The results contribute to a comprehensive understanding of generative AI user discontinuance. They also suggest that generative AI platforms need to be concerned with both enablers and inhibitors in order to prevent user discontinuance and ensure a sustainable development.",C-A-C | discontinuance intention | Generative AI,7,2025,sustainability,behavior+policy+sustainability
198,2-s2.0-85218895540,10.1016/j.egyai.2025.100481,https://doi.org/10.1016/j.egyai.2025.100481,https://scholar.google.com/scholar?q=10.1016/j.egyai.2025.100481,ar,Energy and AI,"Chen, Zhenlin;Zhong, Roujia;Long, Wennan;Tang, Haoyu;Wang, Anjing;Liu, Zemin;Yang, Xuelin;Ren, Bo;Littlefield, James;Koyejo, Sanmi;Masnadi, Mohammad S.;Brandt, Adam R.",Advancing oil and gas emissions assessment through large language model data extraction,"The oil and gas industry strives to improve environmental stewardship and reduce its carbon footprint, but lacks comprehensive global operational data for accurate environmental assessment and decision-making. This challenge is compounded by dispersed information sources and the high costs of accessing proprietary databases. This paper presents an innovative framework using Large Language Models (LLMs) – specifically GPT-4 and GPT-4o – to extract critical oil and gas asset information from diverse literature sources. Our framework employs iterative comparisons between GPT-4's output and a dataset of 129 ground truth documents labeled by domain experts. Through 11 training and testing iterations, we fine-tuned prompts to optimize information extraction. The evaluation process assessed performance using true positive rate, precision, and F1 score metrics. The framework achieved strong results, with a true positive rate of 83.74% and an F1 score of 78.16% on the testing dataset. The system demonstrated remarkable efficiency, processing 32 documents in 61.41 min with GPT-4o, averaging 7.09 s per extraction - a substantial improvement over the manual method. Cost-effectiveness was also achieved, with GPT-4o reducing extraction costs by a factor of 10 compared to GPT-4. This research has significant implications for the oil and gas industry. By creating an organized, transparent, and accessible database, we aim to democratize access to critical information. The framework supports more accurate climate modeling efforts, enhances decision-making processes for operations and investments, and contributes to the sector's ability to meet environmental commitments. These improvements particularly impact emissions reduction and energy transition strategies, potentially transforming how data is extracted and utilized in this field and beyond.",Artificial intelligence | Carbon intensity | Greenhouse gas emissions | Large language models | Oil and gas field | Supervised learning,7,2025,sustainability,behavior+sustainability
219,2-s2.0-105002485583,10.1111/jiec.13612,https://doi.org/10.1111/jiec.13612,https://scholar.google.com/scholar?q=10.1111/jiec.13612,ar,Journal of Industrial Ecology,"Gong, Yongyue;Ma, Fengmei;Wang, Heming;Tzachor, Asaf;Sun, Wenju;Zhu, Junming;Liu, Gang;Schandl, Heinz",The evolution of research at the intersection of industrial ecology and artificial intelligence,"The intersection of artificial intelligence (AI) and industrial ecology (IE) is gaining significant attention due to AI's potential to enhance the sustainability of production and consumption systems. Understanding the current state of research in this field can highlight covered topics, identify trends, and reveal understudied topics warranting future research. However, few studies have systematically reviewed this intersection. In this study, we analyze 1068 publications within the IE–AI domain using trend factor analysis, word2vec modeling, and top2vec modeling. These methods uncover patterns of topic interconnections and evolutionary trends. Our results identify 71 trending terms within the selected publications, 69 of which, such as “deep learning,” have emerged in the past 8 years. The word2vec analysis shows that the application of various AI techniques is increasingly integrated into life cycle assessment and the circular economy. The top2vec analysis suggests that employing AI to predict and optimize indicators related to products, waste, processes, and their environmental impacts is an emerging trend. Lastly, we propose that fine-tuning large language models to better understand and process data specific to IE, along with deploying real-time data collection technologies such as sensors, computer vision, and robotics, could effectively address the challenges of data-driven decision-making in this domain.",artificial intelligence | circular economy | industrial ecology | top2vec | topic modeling | word2vec,7,2025,sustainability,behavior+sustainability
240,2-s2.0-85218853363,10.3390/smartcities8010034,https://doi.org/10.3390/smartcities8010034,https://scholar.google.com/scholar?q=10.3390/smartcities8010034,ar,Smart Cities,"De Silva, Daswin;Mills, Nishan;Moraliyage, Harsha;Rathnayaka, Prabod;Wishart, Sam;Jennings, Andrew",Responsible Artificial Intelligence Hyper-Automation with Generative AI Agents for Sustainable Cities of the Future,"Highlights: What are the main findings? Smart Cities as Hyper-Connected Digital Environments generate large and diverse data streams and repositories that do not consistently translate into insights and decisions. A Responsible AI Hyper-Automation framework with Generative AI agents is developed and evaluated to address these complex challenges. What are the implications of the main findings? The developed AI framework is effective when grounded on five core technical capabilities with an independent cognitive engine for hyper-automated agentic AI that feeds into human-in-the-loop processes. The framework provides a prototypical setting for university cities of the future to provide direction, guidance, and standards for sustainable and safe smart cities of the future. Smart cities are Hyper-Connected Digital Environments (HCDEs) that transcend the boundaries of natural, human-made, social, virtual, and artificial environments. Human activities are no longer confined to a single environment as our presence and interactions are represented and interconnected across HCDEs. The data streams and repositories of HCDEs provide opportunities for the responsible application of Artificial Intelligence (AI) that generates unique insights into the constituent environments and the interplay across constituents. The translation of data into insights poses several complex challenges originating in data generation and then propagating through the computational layers to decision outcomes. To address these challenges, this article presents the design and development of a Hyper-Automated AI framework with Generative AI agents for sustainable smart cities. The framework is empirically evaluated in the living lab setting of a ‘University City of the Future’. The developed AI framework is grounded on the core capabilities of acquisition, preparation, orchestration, dissemination, and retrospection, with an independent cognitive engine for hyper-automation of these AI capabilities using Generative AI. Hyper-automation output feeds into a human-in-the-loop process prior to decision-making outcomes. More broadly, this framework aims to provide a validated pathway for university cities of the future to take up the role of prototypes that deliver evidence-based guidelines for the development and management of sustainable smart cities.",artificial intelligence | generative AI | hyper-automation | smart cities | university city of the future,7,2025,sustainability,behavior+sustainability
297,2-s2.0-105017512648,10.2196/74947,https://doi.org/10.2196/74947,https://scholar.google.com/scholar?q=10.2196/74947,ar,Jmir Medical Education,"Alhur, Anas Ali;Khlaif, Zuheir N.;Hamamra, Bilal;Hussein, Elham",Paradox of AI in Higher Education: Qualitative Inquiry Into AI Dependency Among Educators in Palestine,"Background: Artificial intelligence (AI) is increasingly embedded in medical education, providing benefits in instructional design, content creation, and administrative efficiency. Tools like ChatGPT are reshaping training and teaching practices in digital health. However, concerns about faculty overreliance highlight risks to pedagogical autonomy, cognitive engagement, and ethics. Despite global interest, there is limited empirical research on AI dependency among medical educators, particularly in underrepresented regions like the Global South. Objective: This study focused on Palestine and aimed to (1) identify factors contributing to AI dependency among medical educators, (2) assess its impact on teaching autonomy, decision-making, and professional identity, and (3) propose strategies for sustainable and responsible AI integration in digital medical education. Methods: A qualitative research design was used, using semistructured interviews (n=22) and focus group discussions (n=24) involving 46 medical educators from nursing, pharmacy, medicine, optometry, and dental sciences. Thematic analysis, supported by NVivo (QSR International), was conducted on 15.5 hours of transcribed data. Participants varied in their frequency of AI use: 45.7% (21/46) used AI daily, 30.4% (14/46) weekly, and 15.2% (7/46) monthly. Results: In total, 5 major themes were identified as drivers of AI dependency: institutional workload (reported by >80% [37/46] of participants), low academic confidence (noted by 28/46, 60%), and perfectionism-related stress (23/46, 50%). The following 6 broad consequences of AI overreliance were identified: Skills Atrophy (reported by 89% [41/46]): educators reported reduced critical thinking, scientific writing, and decision-making abilities. Pedagogical erosion (35/46, 76%): decreased student interaction and reduced teaching innovation. Motivational decline (31/46, 67%): increased procrastination and reduced intrinsic motivation. Ethical risks (24/46, 52%): concerns about plagiarism and overuse of AI-generated content. Social fragmentation (22/46, 48%): diminished peer collaboration and mentorship. Creativity suppression (20/46, 43%): reliance on AI for content generation diluted instructional originality. Strategies reported by participants to address these issues included establishing boundaries for AI use (n=41), fostering hybrid intelligence (n=37), and integrating AI literacy into teaching practices (n=39). Conclusions: While AI tools can enhance digital health instruction, unchecked reliance risks eroding essential clinician competencies. This study identifies cognitive, pedagogical, and ethical consequences of AI overuse in medical education and highlights the need for AI literacy, professional development, and ethical frameworks to ensure responsible and balanced integration.",AI dependency | AI reliance | generative AI | hybrid intelligence | procrastination,7,2025,sustainability,behavior+sustainability
355,2-s2.0-85210440667,10.3390/bdcc8110152,https://doi.org/10.3390/bdcc8110152,https://scholar.google.com/scholar?q=10.3390/bdcc8110152,ar,Big Data and Cognitive Computing,"Gholami, Hamed",Artificial Intelligence Techniques for Sustainable Reconfigurable Manufacturing Systems: An AI-Powered Decision-Making Application Using Large Language Models,"Artificial intelligence (AI) offers a promising avenue for developing sustainable reconfigurable manufacturing systems. Although there has been significant progress in these research areas, there seem to be no studies devoted to exploring and evaluating AI techniques for such systems. To address this gap, the current study aims to present a deliberation on the subject matter, with a particular focus on assessing AI techniques. For this purpose, an AI-enabled methodological approach is developed in Python, integrating fuzzy logic to effectively navigate the uncertainties inherent in evaluating the performance of techniques. The incorporation of sensitivity analysis further enables a thorough evaluation of how input variations impact decision-making outcomes. To conduct the assessment, this study provides an AI-powered decision-making application using large language models in the field of natural language processing, which has emerged as an influential branch of artificial intelligence. The findings reveal that machine learning and big data analytics as well as fuzzy logic and programming stand out as the most promising AI techniques for sustainable reconfigurable manufacturing systems. The application confirms that using fuzzy logic programming in Python as the computational foundation significantly enhances precision, efficiency, and execution time, offering critical insights that enable more timely and informed decision-making in the field. Thus, this study not only addresses a critical gap in the literature but also offers an AI-driven approach to support complex decision-making processes.",AI-enabled decision-making | artificial intelligence | ChatGPT | intelligent fuzzy systems | natural language processing | reconfigurable manufacturing systems | sustainable manufacturing 4.0,7,2024,sustainability,behavior+sustainability
368,2-s2.0-85202789419,10.1039/d4dd00130c,https://doi.org/10.1039/d4dd00130c,https://scholar.google.com/scholar?q=10.1039/d4dd00130c,re,Digital Discovery,"Bräse, Stefan","Digital chemistry: navigating the confluence of computation and experimentation - definition, status quo, and future perspective","Digital chemistry represents a transformative approach integrating computational methods, digital data, and automation within the chemical sciences. It is defined by using digital toolkits and algorithms to simulate, predict, accelerate, and analyze chemical processes and properties, augmenting traditional experimental methods. The current status quo of digital chemistry is marked by rapid advancements in several key areas: high-throughput screening, machine learning models, quantum chemistry, and laboratory automation. These technologies have enabled unprecedented speeds in discovering and optimizing new molecules, materials, and reactions. Digital retrosynthesis and structure-active prediction tools have supported these endeavors. Furthermore, integrating large-language models and robotics in chemistry labs (e.g. demonstrated in self-driving labs) have begun to automate routine tasks and complex decision-making processes. Looking forward, the future of digital and digitalized chemistry is poised for significant growth, driven by the increasing accessibility of computational resources, the expansion of chemical databases, and the refinement of artificial intelligence algorithms. This evolution promises to accelerate innovation in drug discovery, materials science, and sustainable manufacturing, ultimately leading to more efficient, cost-effective, and environmentally friendly chemical research and production. The challenge lies in advancing the technology itself, fostering interdisciplinary collaboration, and ensuring the ethical use of digital tools in chemical research.",,7,2024,sustainability,behavior+sustainability
386,2-s2.0-85217736836,10.17323/1728-192x-2024-4-20-47,https://doi.org/10.17323/1728-192x-2024-4-20-47,https://scholar.google.com/scholar?q=10.17323/1728-192x-2024-4-20-47,ar,Russian Sociological Review,"Sepehri, Borhan;Almulhim, Abdulaziz I.;Adibhesami, Mohammad Anvar;Makaremi, Saeed;Ejazi, Farzaneh",Artificial Intelligence Role in Promoting Saudi Arabia’s Smart Cities: Addressing SDGs for Socio-Cultural Challenges,"The study explores the use of artificial intelligence (AI) to address socio-cultural challenges in Saudi Arabia while promoting Sustainable Development Goals (SDGs). Using a structured narrative review method with a critical approach, the study highlights AI’s versatility in analyzing complex social phenomena, understanding human behavior, and optimizing urban infrastructure. With its unique socio-cultural challenges, Saudi Arabia aims for sustainable development through Saudi Vision 2030 and various smart city projects, emphasizing the importance of addressing challenges like gender equality, cultural preservation, an increasing youth population, rapid urbanization, and climate change. The study identifies ten AI applications and models to address these challenges and promote relevant SDGs across six areas: Predictive Analytics and Forecasting, Optimization and Decision Support, Natural Language Processing, Computer Vision, Generative AI, and Geospatial AI. These AI models can help address issues like gender equality, youth education, and employment, as well as optimize water management, energy use, and urban planning to address rapid urbanization and climate change challenges. By aligning AI development with the goals outlined in the SDGs, Saudi Arabia can unlock the potential of AI to create sustainable, resilient, and inclusive smart cities that effectively address socio-cultural challenges. However, the study emphasizes the necessity of customizing AI applications in smart cities based on Saudi Arabia’s religious and cultural values to ensure ethical and culturally sensitive implementations. The findings of this study hold relevance not only for Saudi Arabia but also for other countries facing similar challenges. The study provides practical recommendations for policymakers, urban planners, and technology experts to leverage AI effectively for sustainable development. It also outlines future research directions to address the limitations identified, such as exploring implementation challenges and ethical considerations.",AI | NEOM | NEOM | Saudi Arabia | Saudi Vision 2030 | SDGs | Smart Cities | Socio-cultural challenges | Видение Саудовской Аравии 2030 | ИИ | Саудовская Аравия | Социокультурные вызовы | Умные города | ЦУР,7,2024,sustainability,behavior+sustainability
205,2-s2.0-105004899698,10.3390/app15094986,https://doi.org/10.3390/app15094986,https://scholar.google.com/scholar?q=10.3390/app15094986,re,Applied Sciences Switzerland,"Durlik, Irmina;Miller, Tymoteusz;Kostecka, Ewelina;Kozlovska, Polina;Ślączka, Wojciech",Enhancing Safety in Autonomous Maritime Transportation Systems with Real-Time AI Agents,"The maritime transportation sector is undergoing a profound shift with the emergence of autonomous vessels powered by real-time artificial intelligence (AI) agents. This article investigates the pivotal role of these agents in enhancing the safety, efficiency, and sustainability of autonomous maritime systems. Following a structured literature review, we examine the architecture of real-time AI agents, including sensor integration, communication systems, and computational infrastructure. We distinguish maritime AI agents from conventional systems by emphasizing their specialized functions, real-time processing demands, and resilience in dynamic environments. Key safety mechanisms—such as collision avoidance, anomaly detection, emergency coordination, and fail-safe operations—are analyzed to demonstrate how AI agents contribute to operational reliability. The study also explores regulatory compliance, focusing on emission control, real-time monitoring, and data governance. Implementation challenges, including limited onboard computational power, legal and ethical constraints, and interoperability issues, are addressed with practical solutions such as edge AI and modular architectures. Finally, the article outlines future research directions involving smart port integration, scalable AI models, and emerging technologies like federated and explainable AI. This work highlights the transformative potential of AI agents in advancing autonomous maritime transportation.",AI agents | anomaly detection | autonomous maritime systems | collision avoidance | computational infrastructure | cybersecurity | data governance | emergency response | ethical AI | human-machine interaction | maritime safety | real-time processing | regulatory compliance | smart port integration | sustainability,7,2025,sustainability,policy+sustainability
349,2-s2.0-85201422080,10.1016/j.ecolecon.2024.108352,https://doi.org/10.1016/j.ecolecon.2024.108352,https://scholar.google.com/scholar?q=10.1016/j.ecolecon.2024.108352,ar,Ecological Economics,"Salekpay, Foroogh;van den Bergh, Jeroen;Savin, Ivan",Comparing advice on climate policy between academic experts and ChatGPT,"We compare the results from a recent global expert survey on climate policy with answers to the same survey by the online artificial-intelligence chatbot ChatGPT. Such a study is timely and relevant as many people around the world are likely to use ChatGPT and similar language models to inquire about climate solutions, which in turn might influence public opinion. The comparison provides insights about performance criteria, policy instruments, and use of information from distinct academic disciplines. With a few exceptions, responses by ChatGPT are informative and of high quality. We find that ChatGPT answers questions with less bias than experts from various scientific disciplines. The latter may also be a disadvantage as it seems to weight all the information available equally without accounting well for relevance, which arguably may require human rather than artificial intelligence. On the other hand, experts from distinct disciplines show difference in average responses, with some even expressing opinions inconsistent with objective evidence, meaning there is no consistent and unbiased expert opinion on climate policy. As a new way of synthesizing large amounts of academic and grey literature, ChatGPT can serve policymaking. However, since the procedure that it follows for collecting and summarizing information remains a black box, it is best regarded as a complement rather than a substitute to traditional literature reviews and expert surveys.",Artificial intelligence | Chatbot | Climate policy | Experts | Survey,7,2024,sustainability,policy+sustainability
441,2-s2.0-86000765140,10.1007/s13278-025-01410-5,https://doi.org/10.1007/s13278-025-01410-5,https://scholar.google.com/scholar?q=10.1007/s13278-025-01410-5,ar,Social Network Analysis and Mining,"Lopez-Joya, Salvador;Diaz-Garcia, Jose A.;Ruiz, M. Dolores;Martin-Bautista, Maria J.","Dissecting a social bot powered by generative AI: anatomy, new trends and challenges","The rise of social networks has transformed communication, information sharing and entertainment, but it has also facilitated the rise of harmful activities such as the spread of misinformation, often through the use of social bots. These automated accounts that mimic human behaviour have been implicated in significant events, including political interference and market manipulation. In this paper, we provide a comprehensive review of recent advances in social bot detection, with a particular focus on the role of generative AI and large language models. We present a new categorisation scheme for bots that aims to reduce class overlap while maintaining generality. In addition, we analyse the most commonly used datasets and state-of-the-art classification techniques, and through user profile-based measures, we use Explainable Artificial Intelligence (XAI) and data mining techniques to uncover factors that contribute to bot misclassification. Our findings contribute to the development of more robust detection methods, which are essential for mitigating the impact of malicious bots on online platforms.",Bot detection | Data mining | Generative AI | Social networks analysis | XAI,6,2025,behavior,behavior+policy
493,2-s2.0-105017241380,10.3390/biomedinformatics5030037,https://doi.org/10.3390/biomedinformatics5030037,https://scholar.google.com/scholar?q=10.3390/biomedinformatics5030037,re,Biomedinformatics,"Rabbani, Syed Arman;El-Tanani, Mohamed;Sharma, Shrestha;Rabbani, Syed Salman;El-Tanani, Yahia;Kumar, Rakesh;Saini, Manita","Generative Artificial Intelligence in Healthcare: Applications, Implementation Challenges, and Future Directions","Generative artificial intelligence (AI) is rapidly transforming healthcare systems since the advent of OpenAI in 2022. It encompasses a class of machine learning techniques designed to create new content and is classified into large language models (LLMs) for text generation and image-generating models for creating or enhancing visual data. These generative AI models have shown widespread applications in clinical practice and research. Such applications range from medical documentation and diagnostics to patient communication and drug discovery. These models are capable of generating text messages, answering clinical questions, interpreting CT scan and MRI images, assisting in rare diagnoses, discovering new molecules, and providing medical education and training. Early studies have indicated that generative AI models can improve efficiency, reduce administrative burdens, and enhance patient engagement, although most findings are preliminary and require rigorous validation. However, the technology also raises serious concerns around accuracy, bias, privacy, ethical use, and clinical safety. Regulatory bodies, including the FDA and EMA, are beginning to define governance frameworks, while academic institutions and healthcare organizations emphasize the need for transparency, supervision, and evidence-based implementation. Generative AI is not a replacement for medical professionals but a potential partner—augmenting decision-making, streamlining communication, and supporting personalized care. Its responsible integration into healthcare could mark a paradigm shift toward more proactive, precise, and patient-centered systems.",AI models | diagnostic | generative artificial intelligence | interpretation | large language models (LLMs) | patient-centered | proactive | regulatory bodies | transparency,6,2025,behavior,behavior+policy
528,2-s2.0-105007038135,10.1016/j.jik.2025.100751,https://doi.org/10.1016/j.jik.2025.100751,https://scholar.google.com/scholar?q=10.1016/j.jik.2025.100751,ar,Journal of Innovation and Knowledge,"Albashrawi, Mousa",Generative AI for decision-making: A multidisciplinary perspective,"Generative artificial intelligence (GenAI) is rapidly reshaping decision-making across multiple domains, including health, law, business, education, and tourism. This study synthesizes the fragmented research on GenAI to provide a comprehensive framework for understanding its role in enhancing decision-making accuracy, efficiency, and personalization. Employing a systematic literature review and thematic analysis, this study categorizes diverse applications, from clinical diagnostics and legal reasoning to financial advisement and educational support, highlighting both innovative practices and persistent challenges. The analysis of 101 articles reveals that, while GenAI significantly improves data processing and decision support, mitigating issues such as inherent bias, misinformation, and transparency deficits requires careful attention. The integration of multi-agent frameworks and human oversight is critical for ensuring ethical and reliable outcomes. Ultimately, this synthesis highlights the transformative potential of GenAI as a decision-making tool by presenting a cross-disciplinary framework that reveals its impact and uncovers gaps across various domains. The study also advocates the development of robust regulatory and technological strategies to harness the benefits and address the limitations of GenAI.",Decisions making | Ethical governance | GenAI | Health | Responsible AI,6,2025,behavior,behavior+policy
550,2-s2.0-105003460016,10.3390/fi17040151,https://doi.org/10.3390/fi17040151,https://scholar.google.com/scholar?q=10.3390/fi17040151,ar,Future Internet,"Feretzakis, Georgios;Vagena, Evangelia;Kalodanis, Konstantinos;Peristera, Paraskevi;Kalles, Dimitris;Anastasiou, Athanasios",GDPR and Large Language Models: Technical and Legal Obstacles,"Large Language Models (LLMs) have revolutionized natural language processing but present significant technical and legal challenges when confronted with the General Data Protection Regulation (GDPR). This paper examines the complexities involved in reconciling the design and operation of LLMs with GDPR requirements. In particular, we analyze how key GDPR provisions—including the Right to Erasure, Right of Access, Right to Rectification, and restrictions on Automated Decision-Making—are challenged by the opaque and distributed nature of LLMs. We discuss issues such as the transformation of personal data into non-interpretable model parameters, difficulties in ensuring transparency and accountability, and the risks of bias and data over-collection. Moreover, the paper explores potential technical solutions such as machine unlearning, explainable AI (XAI), differential privacy, and federated learning, alongside strategies for embedding privacy-by-design principles and automated compliance tools into LLM development. The analysis is further enriched by considering the implications of emerging regulations like the EU’s Artificial Intelligence Act. In addition, we propose a four-layer governance framework that addresses data governance, technical privacy enhancements, continuous compliance monitoring, and explainability and oversight, thereby offering a practical roadmap for GDPR alignment in LLM systems. Through this comprehensive examination, we aim to bridge the gap between the technical capabilities of LLMs and the stringent data protection standards mandated by GDPR, ultimately contributing to more responsible and ethical AI practices.",AI | AI Act | artificial intelligence | data privacy | GDPR | large language models | Legal Obstacles | LLM | LLMs,6,2025,behavior,behavior+policy
650,2-s2.0-105003586503,10.1177/17562848251328577,https://doi.org/10.1177/17562848251328577,https://scholar.google.com/scholar?q=10.1177/17562848251328577,re,Therapeutic Advances in Gastroenterology,"Berry, Parul;Dhanakshirur, Rohan Raju;Khanna, Sahil",Utilizing large language models for gastroenterology research: a conceptual framework,"Large language models (LLMs) transform healthcare by assisting clinicians with decision-making, research, and patient management. In gastroenterology, LLMs have shown potential in clinical decision support, data extraction, and patient education. However, challenges such as bias, hallucinations, integration with clinical workflows, and regulatory compliance must be addressed for safe and effective implementation. This manuscript presents a structured framework for integrating LLMs into gastroenterology, using Hepatitis C treatment as a real-world application. The framework outlines key steps to ensure accuracy, safety, and clinical relevance while mitigating risks associated with artificial intelligence (AI)-driven healthcare tools. The framework includes defining clinical goals, assembling a multidisciplinary team, data collection and preparation, model selection, fine-tuning, calibration, hallucination mitigation, user interface development, integration with electronic health records, real-world validation, and continuous improvement. Retrieval-augmented generation and fine-tuning approaches are evaluated for optimizing model adaptability. Bias detection, reinforcement learning from human feedback, and structured prompt engineering are incorporated to enhance reliability. Ethical and regulatory considerations, including the Health Insurance Portability and Accountability Act, General Data Protection Regulation, and AI-specific guidelines (DECIDE-AI, SPIRIT-AI, CONSORT-AI), are addressed to ensure responsible AI deployment. LLMs have the potential to enhance decision-making, research efficiency, and patient care in gastroenterology, but responsible deployment requires bias mitigation, transparency, and ongoing validation. Future research should focus on multi-institutional validation and AI-assisted clinical trials to establish LLMs as reliable tools in gastroenterology.",artificial intelligence | framework | generative artificial intelligence | healthcare,6,2025,behavior,behavior+policy
655,2-s2.0-105000791329,10.1080/23311886.2025.2476737,https://doi.org/10.1080/23311886.2025.2476737,https://scholar.google.com/scholar?q=10.1080/23311886.2025.2476737,ar,Cogent Social Sciences,"Agarwal, Alpana",Optimizing employee roles in the era of generative AI: a multi-criteria decision-making analysis of co-creation dynamics,"Artificial Intelligence (AI) has the ability to transform the way organizations operate, but imposes a unique challenge for them. Adoption of AI might reshape the human resource management patterns which calls for optimization of roles in workplaces for dealing with technology. Critical decision points and alternatives are identified through a systematic review of literature and Analytical Hierarchy Approach (AHP) is applied to analyze their priority weights. The results of AHP model indicate adaptive organization structure, specialized AI teams, ethics oversight and governance and innovation infrastructure to be significant in AI integration. Furthermore, sensitivity analysis technique is employed to examine the robustness of the decision outcomes at varying criteria weights and the results shows no significant impact on the ranks indicating robustness of the decision achieved if the criteria weight changes on the overall optimization process. This study contributes to expanding discussion on workforce transformation in AI era.",AI collaboration | Artificial intelligence | chatGPT | Comparative Psychology | future of work | Social Psychology | value co-creation | Work & Organizational Psychology,6,2025,behavior,behavior+policy
670,2-s2.0-85196973069,10.1016/j.xnsj.2024.100333,https://doi.org/10.1016/j.xnsj.2024.100333,https://scholar.google.com/scholar?q=10.1016/j.xnsj.2024.100333,ar,North American Spine Society Journal,"Kayastha, Ankur;Lakshmanan, Kirthika;Valentine, Michael J.;Nguyen, Anh;Dholakia, Kaushal;Wang, Daniel",Lumbar disc herniation with radiculopathy: a comparison of NASS guidelines and ChatGPT,"Background: ChatGPT is an advanced language AI able to generate responses to clinical questions regarding lumbar disc herniation with radiculopathy. Artificial intelligence (AI) tools are increasingly being considered to assist clinicians in decision-making. This study compared ChatGPT-3.5 and ChatGPT-4.0 responses to established NASS clinical guidelines and evaluated concordance. Methods: ChatGPT-3.5 and ChatGPT-4.0 were prompted with fifteen questions from The 2012 NASS Clinical Guidelines for the diagnosis and treatment of lumbar disc herniation with radiculopathy. Clinical questions organized into categories were directly entered as unmodified queries into ChatGPT. Language output was assessed by two independent authors on September 26, 2023 based on operationally-defined parameters of accuracy, over-conclusiveness, supplementary, and incompleteness. ChatGPT-3.5 and ChatGPT-4.0 performance was compared via chi-square analyses. Results: Among the fifteen responses produced by ChatGPT-3.5, 7 (47%) were accurate, 7 (47%) were over-conclusive, fifteen (100%) were supplementary, and 6 (40%) were incomplete. For ChatGPT-4.0, ten (67%) were accurate, 5 (33%) were over-conclusive, 10 (67%) were supplementary, and 6 (40%) were incomplete. There was a statistically significant difference in supplementary information (100% vs. 67%; p=.014) between ChatGPT-3.5 and ChatGPT-4.0. Accuracy (47% vs. 67%; p=.269), over-conclusiveness (47% vs. 33%; p=.456), and incompleteness (40% vs. 40%; p=1.000) did not show significant differences between ChatGPT-3.5 and ChatGPT-4.0. ChatGPT-3.5 and ChatGPT-4.0 both yielded 100% accuracy for definition and history and physical examination categories. Diagnostic testing yielded 0% accuracy for ChatGPT-3.5 and 100% accuracy for ChatGPT-4.0. Nonsurgical interventions had 50% accuracy for ChatGPT-3.5 and 63% accuracy for ChatGPT-4.0. Surgical interventions resulted in 0% accuracy for ChatGPT-3.5 and 33% accuracy for ChatGPT-4.0. Conclusions: ChatGPT-4.0 provided less supplementary information and overall higher accuracy in question categories than ChatGPT-3.5. ChatGPT showed reasonable concordance to NASS guidelines, but clinicians should caution use of ChatGPT in its current state as it fails to safeguard against misinformation.",Artificial intelligence | ChatGPT | Clinical guidelines | Lumbar disc herniation | Radiculopathy | Sciatica | Spine,6,2024,behavior,behavior+policy
678,2-s2.0-85195065110,10.1016/j.heliyon.2024.e31397,https://doi.org/10.1016/j.heliyon.2024.e31397,https://scholar.google.com/scholar?q=10.1016/j.heliyon.2024.e31397,ar,Heliyon,"Shukla, Amit K.;Terziyan, Vagan;Tiihonen, Timo",AI as a user of AI: Towards responsible autonomy,"Recent advancements in Artificial Intelligence (AI), particularly in generative language models and algorithms, have led to significant impacts across diverse domains. AI capabilities to address prompts are growing beyond human capability but we expect AI to perform well also as a prompt engineer. Additionally, AI can serve as a guardian for ethical, security, and other predefined issues related to generated content. We postulate that enforcing dialogues among AI-as-prompt-engineer, AI-as-prompt-responder, and AI-as-Compliance-Guardian can lead to high-quality and responsible solutions. This paper introduces a novel AI collaboration paradigm emphasizing responsible autonomy, with implications for addressing real-world challenges. The paradigm of responsible AI-AI conversation establishes structured interaction patterns, guaranteeing decision-making autonomy. Key implications include enhanced understanding of AI dialogue flow, compliance with rules and regulations, and decision-making scenarios exemplifying responsible autonomy. Real-world applications envision AI systems autonomously addressing complex challenges. We have made preliminary testing of such a paradigm involving instances of ChatGPT autonomously playing various roles in a set of experimental AI-AI conversations and observed evident added value of such a framework.",AI accountability | Artificial Intelligence (AI) | Autonomy | ChatGPT | Prompt engineering | Responsible AI,6,2024,behavior,behavior+policy
697,2-s2.0-85208183616,10.54648/GTCJ2024081,https://doi.org/10.54648/GTCJ2024081,https://scholar.google.com/scholar?q=10.54648/GTCJ2024081,ar,Global Trade and Customs Journal,"Cardoso, André Guskow;Chan, Elizabeth;Quintão, Luísa;Pereira, Cesar",Generative Artificial Intelligence and Legal Decision-making,"This article explores the transformative impact of generative artificial intelligence (GenAI) on legal decision-making processes. It also examines disclosure obligations and the challenges AI-assisted decisions pose in litigation and arbitration. A case study using ChatGPT as arbitrators in the Willem C. Vis International Commercial Arbitration Moot provides practical insights into AI’s potential and limitations in arbitral decision-making. The experiment highlights key learnings about technology constraints, due process concerns, and the enforceability of AI-assisted decisions. The article concludes with reflections on integrating AI into legal frameworks, emphasizing the need for updated regulations and best practices to ensure transparency, fairness, and accountability in AI applications within the legal domain.",AI-assisted arbitration | Disclosure obligations | Ethical AI | Generative AI | Legal decision-making | Legal technology | Moot court,6,2024,behavior,behavior+policy
333,2-s2.0-105004364254,10.1108/JAL-12-2024-0357,https://doi.org/10.1108/JAL-12-2024-0357,https://scholar.google.com/scholar?q=10.1108/JAL-12-2024-0357,re,Journal of Accounting Literature,"Li, Wen Yi;Liu, Wenyu;Deng, Mengya;Liu, Xin;Feng, Lingbing",The impact of large language models on accounting and future application scenarios,"Purpose: This paper examines the transformative impact of large language models (LLMs) on accounting practices and explores future application scenarios. Through a systematic literature review, it highlights the potential of LLMs to enhance efficiency, transparency and innovation across areas such as financial reporting, ESG disclosure, financial analysis and risk management. Additionally, it identifies key challenges, including data quality, privacy and the need for domain-specific adaptations, while proposing actionable strategies to address them. By forecasting advanced applications like intelligent knowledge bases and automated operations, this study provides a roadmap for integrating LLMs into accounting, driving progress and sustainability in the industry. Design/methodology/approach: This study adopts a systematic literature review methodology to explore the impact and future applications of LLMs in accounting. It identifies key research areas by analyzing over 50 high-quality studies selected through extensive keyword searches, Boolean queries and backward and forward citation analyses of seminal works. The review is structured around eight thematic areas, including financial reporting, ESG disclosure and risk management. By synthesizing findings, the study develops a comprehensive framework for understanding the transformative potential of LLMs while addressing associated challenges, such as data security and specialization, to guide future research and practical applications in accounting. Findings: The study reveals that LLMs significantly enhance efficiency, transparency and innovation in accounting by automating processes like financial reporting, ESG disclosure and risk management. They enable advanced applications such as intelligent knowledge bases, budget optimization and automated contract management. However, challenges remain, including the need for high-quality data, domain-specific model training, interdisciplinary talent development and robust data security measures. The findings underscore LLMs’ potential to transform accounting practices while emphasizing the importance of theoretical frameworks and strategic planning to address these challenges and fully realize their benefits in driving industry progress and sustainability. Practical implications: The study highlights practical pathways for integrating LLMs into accounting, emphasizing their potential to automate processes, enhance decision-making and improve operational efficiency. Organizations can leverage LLMs for tasks such as financial reporting, ESG analysis and risk management, reducing manual effort and increasing accuracy. Practical implications include the need for targeted training of LLMs in accounting-specific contexts, robust data governance to ensure quality and security and developing interdisciplinary skills among accounting professionals. By addressing these areas, organizations can harness LLMs to drive innovation, streamline operations and achieve sustainable growth in a rapidly evolving business environment. Originality/value: This study provides a comprehensive and systematic analysis of the transformative impact of LLMs on accounting, addressing gaps in fragmented research and limited practical insights. It uniquely integrates theoretical perspectives with practical applications, offering a structured framework for understanding LLMs’ role across multiple accounting domains. By identifying key challenges and proposing actionable strategies, the paper delivers original value to both researchers and practitioners, fostering innovation and guiding the integration of LLMs into accounting practices. Its forward-looking approach offers a valuable resource for advancing knowledge and shaping the future of accounting in the digital age.",Financial analysis and forecasting | Future application scenarios | Impact on accounting | Large language models | Risk management,6,2025,sustainability,behavior+policy+sustainability
348,2-s2.0-85202764526,10.1007/s13278-024-01340-8,https://doi.org/10.1007/s13278-024-01340-8,https://scholar.google.com/scholar?q=10.1007/s13278-024-01340-8,ar,Social Network Analysis and Mining,"Nokkaew, Manussawee;Nongpong, Kwankamol;Yeophantong, Tapanan;Ploykitikoon, Pattravadee;Arjharn, Weerachai;Phonak, Duangkamol;Siritaratiwat, Apirat;Surawanitkun, Chayada",Hidden emotional trends on social media regarding the Thailand–China high-speed railway project: a deep learning approach with ChatGPT integration,"Leveraging sentiment analysis on social media reveals hidden emotional trends by providing deep insights into the public’s collective opinions and feelings because social media can reflect most opinions based on true feelings. However, there is no time-series analysis of Thai opinions on social media regarding government projects in Thailand. Therefore, the focus of this research is to survey and dynamically analyze sentiment on social media platforms, particularly YouTube, regarding the Thailand–China High-Speed Rail Project (Thai–China HSR Project). This is a major project involving an investment of over 500 billion baht, a collaborative effort between the Thai and Chinese governments aimed at developing transportation infrastructure. It leads the public concerns of Thai people about the potential economic and social impacts. The deep learning (DL) technique was used for this analysis by the Bidirectional Encoder Representations from Transformers (BERT) model, together with WangchanBERTa, a Thai language model specifically designed to analyze opinions from Thai comments received from YouTube from July 2015 to January 2024. The analysis reveals that citizens’ sentiments are primarily neutral, with more negative than positive sentiments with the passing years. Results also indicate that the data volume has increased since 2019 and peaked in 2022. Negative comments peaked in January 2022, and based on our analysis, such negative comments followed news covering the opening of the China–Laos Railway on December 1, 2021. Video contents were related to the Thai–China HSR Project, which provides comparative reviews and analysis of government operations. Additionally, we explore the possibility of integrating AI technology based on the ChatGPT 4 model to support data interpretation. Although the AI model can interpret data quickly and efficiently serve as a convenient method for users, the results lack the in-depth analysis that should be done by experts in the field. The proposed framework could be useful to government agencies and can be used to quickly and efficiently survey and track public opinion. The results can be used for policy planning, strategic decision-making, and improving communications to better inform citizens about projects and operations, leading to the country’s sustainable economic and social development.",Artificial intelligence | Deep learning | Machine learning | Sentiment analysis | Social media,6,2024,sustainability,behavior+policy+sustainability
411,2-s2.0-85183654840,10.3303/CET23107018,https://doi.org/10.3303/CET23107018,https://scholar.google.com/scholar?q=10.3303/CET23107018,ar,Chemical Engineering Transactions,"Szarmes, Peter;Élő, Gábor",Sustainability of Large AI Models: Balancing Environmental and Social Impact with Technology and Regulations,"Artificial Intelligence (AI) systems, particularly large language models, have shown remarkable advancements, revolutionising various fields across industries. However, the sustainability of building large AI models with billions of parameters has become a subject of concern due to their significant environmental and social impact. The training of such models consumes enormous amounts of water and energy and emits substantial carbon emissions, contributing to climate change as data centres heavily rely on fossil fuels. This article summarises the current situation and explores the benefits and challenges of large AI models, emphasising the environmental impact and proposing strategies towards sustainability. Special attention is given to the social challenges, including accessibility, job displacement, biases, and data privacy concerns. Finally, the article advocates for the formulation of green and good AI practices standards for the future. To achieve sustainability, regulations are suggested to ensure transparency and accountability while promoting innovation-friendly frameworks. The authors see that while there is more progress in technology and infrastructure to address environmental impacts, social impacts are more neglected, and they are arguing for more detailed regulation as a solution.",,6,2023,sustainability,behavior+policy+sustainability
250,2-s2.0-85215982835,10.3390/electronics14020394,https://doi.org/10.3390/electronics14020394,https://scholar.google.com/scholar?q=10.3390/electronics14020394,re,Electronics Switzerland,"Belani, Hrvoje;Šolić, Petar;Zdravevski, Eftim;Trajkovik, Vladimir","Internet of Things Ontologies for Well-Being, Aging and Health: A Scoping Literature Review","Internet of Things aims to simplify and automate complicated tasks by using sensors and other inputs for collecting huge amounts of data, processing them in the cloud and on the edge networks, and allowing decision making toward further interactions via actuators and other outputs. As connected IoT devices rank in billions, semantic interoperability remains one of the permanent challenges, where ontologies can provide a great contribution. The main goal of this paper is to analyze the state of research on semantic interoperability in well-being, aging, and health IoT services by using ontologies. This was achieved by analyzing the following research questions: “Which IoT ontologies have been used to implement well-being, aging and health services?” and “What is the dominant approach to achieve semantic interoperability of IoT solutions for well-being, aging and health?’ We conducted a scoping literature review of research papers from 2013 to 2024 by applying the PRISMA-ScR meta-analysis methodology with a custom-built software tool for an exhaustive search through the following digital libraries: IEEE Xplore, PubMed, MDPI, Elsevier ScienceDirect, and Springer Nature Link. By thoroughly analyzing 30 studies from an initial pool of more than 80,000 studies, we conclude that IoT ontologies for well-being, aging, and health services increasingly adopt Semantic Web of Things standards to achieve semantic interoperability by integrating heterogeneous data through unified semantic models. Emerging approaches, like semantic communication, Large Language Models Edge Intelligence, and sustainability-driven IoT analytics, can further enhance service efficiency and promote a holistic “One Well-Being, Aging, and Health” framework.",aging | e-health | health | Internet of Things (IoT) | ontology | scoping literature review | semantic interoperability | semantic web | well-being,6,2025,sustainability,behavior+sustainability
337,2-s2.0-105002613597,10.1080/02642069.2025.2485983,https://doi.org/10.1080/02642069.2025.2485983,https://scholar.google.com/scholar?q=10.1080/02642069.2025.2485983,ar,Service Industries Journal,"Foroughi, Behzad;Ghobakhloo, Morteza;Wen, Jun;Fathi, Masood",Sustained use of generative AI for shopping: a PLS-ANN analysis,"The rapid integration of generative artificial intelligence (AI) into consumer markets has significantly influenced how shoppers gather and process information. However, the factors that are associated with the sustained use of AI tools for shopping decisions remain underexplored. This study addresses this gap by employing a hybrid analytical approach combining ‘Partial Least Squares-Structural Equation Modeling’ (PLS-SEM) and ‘Artificial Neural Networks’ (ANN). We integrate the ‘Uses and Gratification Model’ with ‘Dual-Process Theory’ to explore how emotional and cognitive factors, such as enjoyment, perceived accuracy, and benefit, are related to continued reliance on generative AI. The model was tested with data from 397 users, and the findings reveal significant predictors of sustained use, underscoring the importance of these variables in contributing to long-term consumer interaction with AI technologies. These insights contribute to the broader understanding of how AI can sustainably support consumer decision-making.",consumer behavior | digital awareness | Generative AI | sustained use | technology adoption,6,2025,sustainability,behavior+sustainability
341,2-s2.0-105001074744,10.1109/ACCESS.2025.3548451,https://doi.org/10.1109/ACCESS.2025.3548451,https://scholar.google.com/scholar?q=10.1109/ACCESS.2025.3548451,ar,IEEE Access,"De Curto, J.;De Zarza, I.",LLM-Driven Social Influence for Cooperative Behavior in Multi-Agent Systems,"This paper presents a novel approach to fostering cooperative behavior in multi-agent systems (MAS) through Large Language Model (LLM)-driven social influence. We propose a theoretical framework where agents' decision-making processes are influenced not through direct action but by subtle, narrative-driven influences disseminated by LLMs. These influences guide agents toward cooperative behaviors, such as rural repopulation, without requiring explicit policy interventions. We introduce a formal model grounded in game theory and social network dynamics, where agents balance the direct benefits of action with the indirect payoffs of LLM-guided influence. Using NASH equilibrium and Evolutionarily Stable Strategies (ESS), we demonstrate how cooperative behaviors emerge even when agents remain inactive but are subtly influenced by LLMs. Our experimental simulations validate the model, showing a strong positive correlation between network centrality and influence propagation (r = 0.969\p < 0.006). Furthermore, temporal analysis reveals that the average influence increases from approximately 0.05-0.06 in the initial steps to 0.08-0.09 in later stages, indicating a cumulative and self-sustaining trend. In addition, the influence values exhibit a near-normal distribution (Shapiro-Wilk test, p = 0.285) and yield a large effect size (Cohen's d = 4.530) when comparing agents with high versus low network centrality. Through visualization techniques and statistical metrics, we demonstrate the effectiveness of the proposed framework and identify promising directions for future research in AI-driven social influence. This study highlights the potential of LLM-driven narratives as a cost-effective, scalable alternative to traditional policy interventions, offering a new paradigm for promoting societal cooperation in areas such as rural repopulation, sustainability, and community development.",game theory | large language models | Multi-agent systems | NASH equilibrium | rural repopulation | social influence,6,2025,sustainability,behavior+sustainability
414,2-s2.0-85168906526,10.1080/10301763.2023.2251103,https://doi.org/10.1080/10301763.2023.2251103,https://scholar.google.com/scholar?q=10.1080/10301763.2023.2251103,ar,Labour and Industry,"Süße, Thomas;Kobert, Maria;Kries, Caroline",Human-AI interaction in remanufacturing: exploring shop floor workers’ behavioural patterns within a specific human-AI system,"Artificial intelligence (AI) is increasingly discussed as an innovation enabler for the enhancement of circular economy (CE) approaches in industries. The further deployment of intelligent technologies is considered to be very promising particularly in remanufacturing, which can be regarded as an implementation approach of CE at a firm level. AI’s potential to contribute to advancements in remanufacturing can be traced back to these modern technologies’ extended capacities of supporting and assisting humans during rather manual processes which are regarded as more common in remanufacturing than in traditional linear production. As a result, we argue that in future application scenarios, humans are going to interact more often with AI agents who may direct and assist humans’ behaviour and decision-making processes. We assume that a better understanding of the specific dynamics and novel aspects of these kind of newly emerging human-AI systems is a key prerequisite for sustainable process innovation, particularly in remanufacturing organisations. However, empirical-based contributions about humans’ behavioural changes in interaction with AI agents have so far been rather rare and limited, especially in the field of remanufacturing and CE. In this article, we seek to contribute to this gap in research by exploring the interaction between shop floor workers and an AI agent based on a case study research approach at a plant of a German automotive supplier that is remanufacturing used parts. We conducted semi-structured interviews among the shop floor workers who are involved in a joint decision-making task with an AI agent. We interpret the findings of our qualitative data in the light of related research in the field of AI in CE, AI implementation in organisation and human-AI interaction literature. In summary, our analysis reveals 13 behavioural patterns that shop floor workers reported on referring to their interaction with the AI agent. The behavioural patterns are systemised into a cognitive, emotional and social dimension of a competence framework. These findings shall contribute to a more specific understanding about how humans interact with AI agents at work, while considering the specific context variables of the interaction paradigm and the AI agent’s role during joint decision-making in a human-AI system. Implications for literature in the field of human-AI interaction as well as AI implementation in organisations with a particular focus on CE are discussed.",AI competence | AI-based agents | Human-AI interaction | transformation of work,6,2023,sustainability,behavior+sustainability
77,2-s2.0-105009511698,10.1016/j.sftr.2025.100899,https://doi.org/10.1016/j.sftr.2025.100899,https://scholar.google.com/scholar?q=10.1016/j.sftr.2025.100899,ar,Sustainable Futures,"Salah, Mohammed;Alnoor, Alhamzah;Abdelfattah, Fadi;Dahleez, Khalid;Sinawi, Saleh Al;Hussein, Jabbar Salman;Bareas, Ahmed Kadim;Ismail, Maria Mohd;Halbusi, Hussam Al",Generative AI and sustainable policy implementation: Expanding UTAUT2 to examine sustainable policy alignment and ambiguity impact on street-level bureaucrats’ discretion,"This study investigates the adoption of Generative Artificial Intelligence (GenAI) by street-level bureaucrats (SLBs) and examines its impact on their discretion in implementing sustainable policies in Iraq and Oman. By extending the Unified Theory of Acceptance and Use of Technology 2 (UTAUT2) to include sustainable policy alignment and policy ambiguity as moderating factors, the research explores how these policy elements influence the relationship between GenAI adoption and SLBs’ discretionary actions. Data was collected from 489 SLBs and analyzed using Partial Least Squares Structural Equation Modeling (PLS-SEM). The findings demonstrate that performance expectancy, effort expectancy, hedonic motivation, and habit significantly drive the continuous intention to use GenAI. In contrast, social influence and facilitating conditions do not have a significant effect. Furthermore, the continuous intention to use GenAI positively influences SLBs’ discretion in policy implementation, with sustainable policy alignment strengthening this relationship and diminishing policy ambiguity. A multi-group analysis reveals notable differences between Iraq and Oman. In Oman, all UTAUT2 variables are significant, reflecting a supportive and stable governance environment. In contrast, in Iraq, individual perceptions dominate, likely due to higher policy ambiguity and weaker institutional support. These results underscore the importance of emphasizing GenAI's practical benefits and ease of use and advocate for developing clear, supportive policies that empower SLBs. This study extends the theoretical foundations of UTAUT2 in the public sector, offering practical insights for policymakers and organizations seeking to leverage GenAI for enhanced sustainability outcomes.",Ambiguity | Discretion | Generative Artificial Intelligence (GenAI) | Policy implementation | UTAUT2 policy alignment,6,2025,sustainability,policy+sustainability
334,2-s2.0-105003780776,10.1109/ACCESS.2025.3561235,https://doi.org/10.1109/ACCESS.2025.3561235,https://scholar.google.com/scholar?q=10.1109/ACCESS.2025.3561235,ar,IEEE Access,"Karim, Hassan;Gupta, Deepti;Sitharaman, Sai",Securing LLM Workloads With NIST AI RMF in the Internet of Robotic Things,"The Internet of Robotic Things (IoRT) is revolutionizing industries by enabling autonomous, AI-driven robotic systems to perform complex and collaborative tasks, such as precision agriculture, disaster response, and logistic shipping operations. However, integrating AI into IoRT introduces significant challenges, including security vulnerabilities, adversarial attacks, data integrity risks, and operational disruptions in dynamic and high-stakes environments. This paper addresses these challenges by integrating and enhancing the NIST AI Risk Management Framework (AI RMF) for IoRT systems, providing a structured approach to identify, assess, and mitigate risks specific to IoRT ecosystems. We introduce a novel Large Language Model (LLM)-based approach for translating natural language commands into secure and precise robotic operations, enabling seamless collaboration and enhancing safety and reliability in mission-critical scenarios. Using a flood recovery scenario in precision agriculture, we demonstrate the practical application of these solutions, where swarm robots equipped with AI inference engines collaborate to navigate hazards, locate individuals, assess infrastructure damage, and mitigate risks. A comprehensive threat analysis is presented, mapping identified vulnerabilities to the NIST AI RMF, and tailored security controls are proposed to mitigate these threats effectively. We propose critical enhancements to the framework, including advanced quantitative risk assessment methods, subsystem governance strategies for interconnected IoRT networks, and robust auditing mechanisms to address unique IoRT-specific challenges. This work establishes a robust foundation for aligning AI governance frameworks with the complex and dynamic demands of IoRT systems. By addressing security, operational, and ethical considerations, it fosters secure, efficient, and trustworthy deployment across diverse applications, paving the way for sustainable and impactful IoRT innovations.",IoRT | natural language processing | NIST AI risk management framework | security and privacy | smart farming,6,2025,sustainability,policy+sustainability
412,2-s2.0-85182849539,10.3389/frai.2023.1168749,https://doi.org/10.3389/frai.2023.1168749,https://scholar.google.com/scholar?q=10.3389/frai.2023.1168749,ar,Frontiers in Artificial Intelligence,"Tkachenko, Nataliya",Opportunities for synthetic data in nature and climate finance,"This paper delves into the intricacies of synthetic data, emphasizing its growing significance in the realm of finance and more notably, sustainable finance. Synthetic data, artificially generated to simulate real-world data, is being recognized for its potential to address risk management, regulatory compliance, and the innovation of financial products. Especially in sustainable finance, synthetic data offers insights into modeling environmental uncertainties, assessing volatile social and governance scenarios, enhancing data availability, and protecting data confidentiality. This critical review attempts first ever classification of synthetic data production methods, when applied to sustainable finance data gaps, elucidates the methodologies behind its creation, and examines its assurance and controls. Further, it identifies the unique data needs of green finance going forward and breaks down potential risks tied to synthetic data utilization, including challenges from generative AI, input quality, and critical ethical considerations like bias and discrimination.",adaptation analytics | AI ethics | climate finance | ESG | generative AI | nature finance | spatial finance | synthetic data,6,2023,sustainability,policy+sustainability
420,2-s2.0-85102199282,10.1108/JCEFTS-12-2020-0071,https://doi.org/10.1108/JCEFTS-12-2020-0071,https://scholar.google.com/scholar?q=10.1108/JCEFTS-12-2020-0071,ar,Journal of Chinese Economic and Foreign Trade Studies,"Roy, Chandan Kumar;Xiaoling, Huang;Banik, Banna",Achieving SDG target 8.1 (sustain economic growth) in developing countries: how aid for trade policy and regulations can assist?,"Purpose: This study aims to examine how aid for trade policy and regulations (AfTPR) contribute to achieving Sustainable Development Goal (SDG) target 8.1 (sustain per capita economic growth) and whether the effectiveness of AfTPR is conditional to the stable political environment. Design/methodology/approach: This paper uses a widely accepted endogenous growth framework and applies panel data fixed effects and two-step difference and system generalized method of moments estimation strategies on panel data of 50 developing countries over 2005–2017. Findings: The findings of the study confirm that aid to trade policy promotes sustainable economic growth in developing countries, but this category of development assistance is only effective and significant for low and lower middle-income (LLMI) economies. The positive and significant effect of AfTPR in upper middle-income countries is conditional to their level of political stability. Under a stable political situation, the positive effect of AfTPR on sustainable growth remains almost same for the LLMI countries, whereas for the upper middle-income countries this growth effect reached almost double. Research limitations/implications: International trade is considered as a driver for inclusive and sustainable economic growth, whereas aid for trade is acknowledged for its prospective contribution toward achieving these goals. The findings have dominant policy implications for the international development organizations and donors, which recommend that it is more desirable to transmit aid toward developing and implementing trade policy and regulations as per capita economic growth improves in the aid recipient countries. Originality/value: According to the authors’ knowledge, no prior study empirically analyzes the effect of AfTPRs on SDG target 8.1.",Aid conditionality | Aid effectiveness | Aid for trade policy and regulations | Economic growth | Endogenous growth model | SDG target 8.1 | Sustainable Development Goal,6,2021,sustainability,policy+sustainability
577,2-s2.0-85216949986,10.3389/fmed.2025.1527864,https://doi.org/10.3389/fmed.2025.1527864,https://scholar.google.com/scholar?q=10.3389/fmed.2025.1527864,ar,Frontiers in Medicine,"Aydin, Serhat;Karabacak, Mert;Vlachos, Victoria;Margetis, Konstantinos",Navigating the potential and pitfalls of large language models in patient-centered medication guidance and self-decision support,"Large Language Models (LLMs) are transforming patient education in medication management by providing accessible information to support healthcare decision-making. Building on our recent scoping review of LLMs in patient education, this perspective examines their specific role in medication guidance. These artificial intelligence (AI)-driven tools can generate comprehensive responses about drug interactions, side effects, and emergency care protocols, potentially enhancing patient autonomy in medication decisions. However, significant challenges exist, including the risk of misinformation and the complexity of providing accurate drug information without access to individual patient data. Safety concerns are particularly acute when patients rely solely on AI-generated advice for self-medication decisions. This perspective analyzes current capabilities, examines critical limitations, and raises questions regarding the possible integration of LLMs in medication guidance. We emphasize the need for regulatory oversight to ensure these tools serve as supplements to, rather than replacements for, professional healthcare guidance.",artificial intelligence | ChatGPT | deep learning | Large Language Models | machine learning | patient education | self-medication,5,2025,behavior,behavior+policy
660,2-s2.0-85193687066,10.1007/s00779-024-01811-x,https://doi.org/10.1007/s00779-024-01811-x,https://scholar.google.com/scholar?q=10.1007/s00779-024-01811-x,ar,Personal and Ubiquitous Computing,"Heaton, Dan;Clos, Jeremie;Nichele, Elena;Fischer, Joel E.","“The ChatGPT bot is causing panic now – but it’ll soon be as mundane a tool as Excel”: analysing topics, sentiment and emotions relating to ChatGPT on Twitter","ChatGPT, a sophisticated chatbot system by OpenAI, gained significant attention and adoption in 2022 and 2023. By generating human-like conversations, it attracted over 100 million monthly users; however, there are concerns about the social impact of ChatGPT, including panic, misinformation and ethics. Twitter has become a platform for expressing views on ChatGPT and popular NLP approaches like topic modelling, sentiment analysis and emotion detection are commonly used to study public discourses on Twitter. While these approaches have limitations, an analytical process of existing best practices captures the evolving nature of these views. Previous studies have examined early reactions and topics associated with ChatGPT on Twitter but have not fully explored the combination of topics, sentiment and emotions, nor have they explicitly followed existing best practices. This study provides an overview of the views expressed on Twitter about ChatGPT by analysing 88,058 tweets from November 2022 to March 2023 to see if panic and concern were replicated in Twitter discourses. The topics covered human-like text generation, chatbot development, writing assistance, data training, efficiency, impact on business and cryptocurrency. Overall, the sentiment was predominantly positive, indicating that concerns surrounding ChatGPT were not widely replicated. However, sentiment fluctuated, with a decline observed around the launch of ChatGPT Plus. The discourse saw consistent patterns of trust and fear, with trust maintaining a steady presence until a decline potentially influenced by concerns about biases and misinformation. We discuss how our findings build upon existing research regarding ChatGPT by providing trajectories of topics, sentiment and emotions.",ChatGPT | Critical reflection | Emotion detection | Large language model | Natural language processing | Sentiment analysis | Topic modelling,5,2024,behavior,behavior+policy
673,2-s2.0-85197694861,10.1089/end.2023.0700,https://doi.org/10.1089/end.2023.0700,https://scholar.google.com/scholar?q=10.1089/end.2023.0700,re,Journal of Endourology,"Solano, Catalina;Tarazona, Nick;Angarita, Gabriela Prieto;Medina, Andrea Ascencio;Ruiz, Saralia;Pedroza, Valentina Melo;Traxer, Olivier","ChatGPT in Urology: Bridging Knowledge and Practice for Tomorrow’s Healthcare, a Comprehensive Review","Background: Among emerging AI technologies, Chat-Generative Pre-Trained Transformer (ChatGPT) emerges as a notable language model, uniquely developed through artificial intelligence research. Its proven versatility across various domains, from language translation to healthcare data processing, underscores its promise within medical documentation, diagnostics, research, and education. The current comprehensive review aimed to investigate the utility of ChatGPT in urology education and practice and to highlight its potential limitations. Methods: The authors conducted a comprehensive literature review of the use of ChatGPT and its applications in urology education, research, and practice. Through a systematic review of the literature, with a search strategy using databases, such as PubMed and Embase, we analyzed the advantages and limitations of using ChatGPT in urology and evaluated its potential impact. Results: A total of 78 records were eligible for inclusion. The benefits of ChatGPT were frequently cited across various contexts. In educational/academic benefits mentioned in 21 records (87.5%), ChatGPT showed the ability to assist urologists by offering precise information and responding to inquiries derived from patient data analysis, thereby supporting decision making; in 18 records (75%), advantages comprised personalized medicine, predictive capabilities for disease risks and outcomes, streamlining clinical workflows and improved diagnostics. Nevertheless, apprehensions were expressed regarding potential misinformation, underscoring the necessity for human supervision to guarantee patient safety and address ethical concerns. Conclusion: The potential applications of ChatGPT hold the capacity to bring about transformative changes in urology education, research, and practice. AI technology can serve as a useful tool to augment human intelligence; however, it is essential to use it in a responsible and ethical manner.",artificial intelligence | ChatGPT | digital health | ethics | machine learning | urology,5,2024,behavior,behavior+policy
709,2-s2.0-85183409083,10.3389/frai.2023.1291136,https://doi.org/10.3389/frai.2023.1291136,https://scholar.google.com/scholar?q=10.3389/frai.2023.1291136,ar,Frontiers in Artificial Intelligence,"Socol, Yehoshua;Richardson, Ariella;Garali-Zineddine, Imene;Grison, Stephane;Vares, Guillaume;Klokov, Dmitry","Artificial intelligence in biology and medicine, and radioprotection research: perspectives from Jerusalem","While AI is widely used in biomedical research and medical practice, its use is constrained to few specific practical areas, e.g., radiomics. Participants of the workshop on “Artificial Intelligence in Biology and Medicine” (Jerusalem, Feb 14–15, 2023), both researchers and practitioners, aimed to build a holistic picture by exploring AI advancements, challenges and perspectives, as well as to suggest new fields for AI applications. Presentations showcased the potential of large language models (LLMs) in generating molecular structures, predicting protein-ligand interactions, and promoting democratization of AI development. Ethical concerns in medical decision making were also addressed. In biological applications, AI integration of multi-omics and clinical data elucidated the health relevant effects of low doses of ionizing radiation. Bayesian latent modeling identified statistical associations between unobserved variables. Medical applications highlighted liquid biopsy methods for non-invasive diagnostics, routine laboratory tests to identify overlooked illnesses, and AI's role in oral and maxillofacial imaging. Explainable AI and diverse image processing tools improved diagnostics, while text classification detected anorexic behavior in blog posts. The workshop fostered knowledge sharing, discussions, and emphasized the need for further AI development in radioprotection research in support of emerging public health issues. The organizers plan to continue the initiative as an annual event, promoting collaboration and addressing issues and perspectives in AI applications with a focus on low-dose radioprotection research. Researchers involved in radioprotection research and experts in relevant public policy domains are invited to explore the utility of AI in low-dose radiation research at the next workshop.",artificial intelligence | ionizing radiation | low doses | machine learning | public health | radioprotection,5,2023,behavior,behavior+policy
179,2-s2.0-105011647207,10.3390/buildings15142432,https://doi.org/10.3390/buildings15142432,https://scholar.google.com/scholar?q=10.3390/buildings15142432,re,Buildings,"Berlato, Michele;Binni, Leonardo;Durmus, Dilan;Gatto, Chiara;Giusti, Letizia;Massari, Alessia;Toldo, Beatrice Maria;Cascone, Stefano;Mirarchi, Claudio",Digital Platforms for the Built Environment: A Systematic Review Across Sectors and Scales,"The digital transformation of the Architecture, Engineering and Construction sector is accelerating the adoption of digital platforms as critical enablers of data integration, stakeholder collaboration and process optimization. This paper presents a systematic review of 125 peer-reviewed journal articles (2015–2025), selected through a PRISMA-guided search using the Scopus database, with inclusion criteria focused on English-language academic literature on platform-enabled digitalization in the built environment. Studies were grouped into six thematic domains, i.e., artificial intelligence in construction, digital twin integration, lifecycle cost management, BIM-GIS for underground utilities, energy systems and public administration, based on a combination of literature precedent and domain relevance. Unlike existing reviews focused on single technologies or sectors, this work offers a cross-sectoral synthesis, highlighting shared challenges and opportunities across disciplines and lifecycle stages. It identifies the functional roles, enabling technologies and systemic barriers affecting digital platform adoption, such as fragmented data sources, limited interoperability between systems and siloed organizational processes. These barriers hinder the development of integrated and adaptive digital ecosystems capable of supporting real-time decision-making, participatory planning and sustainable infrastructure management. The study advocates for modular, human-centered platforms underpinned by standardized ontologies, explainable AI and participatory governance models. It also highlights the importance of emerging technologies, including large language models and federated learning, as well as context-specific platform strategies, especially for applications in the Global South.",Artificial Intelligence (AI) | BIM-GIS integration | Building Information Modeling (BIM) | cross-sectoral integration | digital twin | lifecycle cost management | participatory governance | sustainable infrastructure,5,2025,sustainability,behavior+policy+sustainability
244,2-s2.0-85211102964,10.1002/bse.4089,https://doi.org/10.1002/bse.4089,https://scholar.google.com/scholar?q=10.1002/bse.4089,ar,Business Strategy and the Environment,"Li, Chao;Keeley, Alexander Ryota;Takeda, Shutaro;Seki, Daikichi;Managi, Shunsuke",ESG Tendencies From News Investigated by AI Trained by Human Intelligence,"We create a large language model with high accuracy to investigate the relatedness between 12 environmental, social, and governance (ESG) topics and more than 2 million news reports. The text match pre-trained transformer (TMPT) with 138,843,049 parameters is built to probe whether and how much a news record is connected to a specific topic of interest. The TMPT, based on the transformer structure and a pre-trained model, is an artificial intelligence model trained by more than 200,000 academic papers. The cross-validation result reveals that the TMPT's accuracy is 85.73%, which is excellent in zero-shot learning tasks. In addition, combined with sentiment analysis, our research monitors news attitudes and tones toward specific ESG topics daily from September 2021 to September 2023. The results indicate that the media is increasing discussion on social topics, while the news regarding environmental issues is reduced. Moreover, toward almost all topics, the attitudes are gradually becoming positive. Our research highlights the temporal shifts in public perception regarding 12 key ESG issues:ESG has been incrementally accepted by the public. These insights are invaluable for policymakers, corporate leaders, and communities as they navigate sustainable decision-making.",data mining | ESG | machine learning | natural language processing | news | pre-trained transformer,5,2025,sustainability,behavior+policy+sustainability
184,2-s2.0-105005495178,10.1016/j.technovation.2025.103254,https://doi.org/10.1016/j.technovation.2025.103254,https://scholar.google.com/scholar?q=10.1016/j.technovation.2025.103254,ar,Technovation,"Marzi, Giacomo;Balzano, Marco",Artificial intelligence and the reconfiguration of NPD Teams: Adaptability and skill differentiation in sustainable product innovation,"Sustainable product innovation (SPI) is increasingly central to New Product Development (NPD) teams, aligning with global sustainability goals and industry expectations. However, the factors associated with SPI at team level remain underexplored. This study examines the roles of team skill differentiation and team adaptability in fostering SPI, proposing that these factors support teams in the pursuit of sustainability-oriented innovation more effectively. Furthermore, we investigate the moderating role of generative artificial intelligence (GenAI) in shaping the strength of these relationships. Drawing on the double diamond framework and its AI-augmented adaptation, we hypothesize that skill differentiation expands the range of potential solutions in the divergent phase of innovation, while adaptability enhances responsiveness in the convergent phase. GenAI is posited to enhance these effects by augmenting knowledge recombination and real-time strategic adaptation. To test our hypotheses, we conducted a multi-industry survey of NPD teams engaged in sustainability initiatives, applying multiple regression analysis to assess the proposed relationships. All our hypotheses were empirically supported. Overall, this study contributes to SPI research by integrating team capability theory with AI-driven innovation frameworks. The findings highlight the need for firms to cultivate multidisciplinary teams with adaptive capacities while leveraging GenAI as an amplifier rather than a substitute for human expertise. The results also underscore that effective SPI requires both internal knowledge diversity and external responsiveness, alongside AI tools that enhance creativity and sustainability-driven decision-making. Finally, this research provides insights into how NPD teams can enhance their engagement in sustainable innovation, aligning with the broader objectives of Sustainable Development Goals (SDGs) 9 and 12.",Generative artificial intelligence | Green Innovation | New product development teams | Sustainability | Sustainable development goals | Sustainable product innovation | Team adaptability | Team skill diversity,5,2025,sustainability,behavior+sustainability
206,2-s2.0-105001977427,10.1016/j.ijdrr.2025.105422,https://doi.org/10.1016/j.ijdrr.2025.105422,https://scholar.google.com/scholar?q=10.1016/j.ijdrr.2025.105422,ar,International Journal of Disaster Risk Reduction,"Pursnani, Vinay;Sermet, Yusuf;Demir, Ibrahim",A conversational intelligent assistant for enhanced operational support in floodplain management with multimodal data,"Floodplain management is crucial for mitigating flood risks and enhancing community resilience, yet floodplain managers often face significant challenges, including the complexity of data analysis, regulatory compliance, and effective communication with diverse stakeholders. This study introduces Floodplain Manager AI, an innovative artificial intelligence (AI) based virtual assistant designed to support floodplain managers in their decision-making processes and operations. Utilizing advanced large language models and semantic search techniques, the AI Assistant provides accurate, location-specific guidance tailored to the unique regulatory environments of different states. It is capable of interpreting Federal Emergency Management Agency (FEMA) flood maps through multimodal capabilities, allowing users to understand complex visual data and its implications for flood risk assessment. The AI Assistant also simplifies access to comprehensive floodplain management resources, enabling users to quickly find relevant information and streamline their workflows. Experimental evaluations demonstrated substantial improvements in accuracy and relevance of the AI Assistant's response, underscoring its effectiveness in addressing the specific needs of floodplain managers. By facilitating informed decision-making and promoting proactive measures, Floodplain Manager AI aims to enhance flood risk mitigation operations and support sustainable community development in the context of increasing flood events driven by climate change. Ultimately, this research highlights the transformative potential of AI technologies in improving floodplain management practices and fostering community resilience.",AI assistant | Community resilience | Decision support | Flood maps | Floodplain management | Large language models,5,2025,sustainability,behavior+sustainability
235,2-s2.0-85219206230,10.3390/su17041355,https://doi.org/10.3390/su17041355,https://scholar.google.com/scholar?q=10.3390/su17041355,ar,Sustainability Switzerland,"du Plessis, Martin Johannes;Gerber, Retief;Goedhals-Gerber, Leila Louise;van Eeden, Joubert",Shaping the Future of Freight Logistics: Use Cases of Artificial Intelligence,"The human–machine interface is increasingly attracting attention. This paper investigates the potential value and impact of using Artificial Intelligence (AI) in the freight logistics industry by defining various use cases. It explores how the logistics industry can use data and AI to improve its economic, social, and environmental sustainability through better decision making. The research methodology involved a systematic literature review, interviews with subject matter experts, facility visits, and generative AI. The SLR showed that none of the peer-reviewed literature offers an extensive exposition of AI use cases in freight logistics. The key findings highlight AI’s untapped potential in the logistics industry, with 77 unique use cases identified across three spheres: holistic supply chain opportunities, transport vehicles, and logistical facilities. The research is expected to contribute to the growing body of knowledge of AI in logistics, inform future research, guide industry practices, and inspire further innovation in logistics technology.",Artificial Intelligence (AI) | cost reduction | freight transport | industry 5.0 | logistics | sustainability | transport management | use cases,5,2025,sustainability,behavior+sustainability
319,2-s2.0-105010350581,10.1109/TEM.2025.3585433,https://doi.org/10.1109/TEM.2025.3585433,https://scholar.google.com/scholar?q=10.1109/TEM.2025.3585433,ar,IEEE Transactions on Engineering Management,"Yoon, Jiho;Alkhudary, Rami;Talluri, Srinivas;Fenies, Pierre","Risk Management and Macroeconomic Disruptions in Supply Chains: The Role of Blockchain, Digital Twins, Generative AI, and Quantum Computing","The global economy faces increasing vulnerabilities from macroeconomic disruptions, such as regulatory changes, trade tensions, geopolitical conflicts, currency volatility, pandemics, and energy crises that undermine the resilience of operations and supply chain management (OSCM) systems. These disruptions exacerbate risks, including supply chain breakdowns, operational inefficiencies, and systemic weaknesses, with energy challenges emerging as a key concern due to their effects on production costs, inflation, and sustainability goals. Advanced technologies, such as blockchain, digital twins, generative artificial intelligence (AI), and quantum computing, offer transformative potential to enhance transparency, predictive accuracy, and decision-making agility. However, their adoption introduces inherent tradeoffs, as they can lead to energy-intensive operations, cybersecurity risks, and economic burdens. To make sense of these dynamics, this article develops a conceptual framework based on a multilayered information system architecture that links specific disruptions to corresponding digital responses. This framework is grounded in a thorough review of both conceptual and empirical literature, along with extensive discussions among the authors. It explores how these technologies can address the risks stemming from macroeconomic disruptions while also considering their broader economic implications and challenges. It argues that simplistic solutions fail to account for the duality of these technologies' impacts and highlights the need for a systemic approach to integrate these technologies within OSCM. This article concludes by proposing actionable research directions for OSCM scholars and managers to navigate these complexities.",Blockchain | digital twins | generative artificial intelligence (AI) | information system | macroeconomic disruptions | quantum computing | risk management | supply chain | technology management | TEM forum,5,2025,sustainability,behavior+sustainability
335,2-s2.0-105003006722,10.1109/ACCESS.2025.3557907,https://doi.org/10.1109/ACCESS.2025.3557907,https://scholar.google.com/scholar?q=10.1109/ACCESS.2025.3557907,ar,IEEE Access,"Tsihrintzis, George A.;Sarmas, Elissaios;Marinakis, Vangelis;Panagoulias, Dimitrios P.;Tsichrintzi, Evangelia Aikaterini;Virvou, Maria",Energy Urban Domain: Personalized Evaluation of Expert and Non-Expert Stakeholder Interaction With Artificial Intelligence Through ChatGPT Using the VIRTSI Model,"This paper explores the application of Generative AI, specifically ChatGPT, in urban energy management, assessing human users’ trust in AI systems that, while often accurate, can still make mistakes. It examines how different stakeholder groups—AI experts, energy domain experts, and non-experts—develop trust, distrust, or overtrust in AI-generated outputs and highlights the risks associated with these trust states. While overtrust can lead to blind reliance on incorrect AI outputs, distrust can result in the unnecessary rejection of accurate AI recommendations, ultimately reducing the effectiveness of AI-assisted decision-making. Using the VIRTSI (Variability and Impact of Reciprocal Trust States towards Intelligent Systems) methodology, this research monitors human-AI trust evolution through Deterministic Finite Automata (DFA) and quantifies trust behaviors using user-adapted Confusion Matrices, addressing a critical gap in AI trust dynamics that traditional acceptance models overlook. The findings validate VIRTSI’s ability to track trust transitions. The study reveals that AI experts exhibit skepticism due to their awareness of AI’s limitations, energy experts tend to overtrust AI, likely influenced by its confident and seemingly reliable responses, and non-experts display inconsistent trust, highlighting decision-making challenges. These findings confirm VIRTSI’s premise that trust in AI is dynamic, varies by user expertise, and must be continuously monitored and assessed. Ultimately, this study strengthens VIRTSI as a necessary framework for assessing and optimizing trust in AI-driven sustainability solutions, ensuring that AI systems are not only trusted but also used effectively and responsibly in energy applications. Unlike other models of technology acceptance that focus solely on adoption, VIRTSI provides a continuous and quantifiable approach to trust calibration, identifying harmful trust patterns and guiding improvements in AI-human interaction over time.",Artificial intelligence | artificial intelligence in energy | artificial intelligence trust | human-artificial intelligence interaction | large language models | user modeling,5,2025,sustainability,behavior+sustainability
339,2-s2.0-105002157883,10.1080/15230406.2025.2479796,https://doi.org/10.1080/15230406.2025.2479796,https://scholar.google.com/scholar?q=10.1080/15230406.2025.2479796,re,Cartography and Geographic Information Science,"Shi, Meilin;Janowicz, Krzysztof;Verstegen, Judith;Currier, Kitty;Wiedemann, Nina;Mai, Gengchen;Majic, Ivan;Liu, Zilong;Zhu, Rui",Geography for AI sustainability and sustainability for GeoAI,"Recent years have witnessed a boom in the development of multimodal large-scale generative AI models. These computationally intensive AI models, such as GPT-4, and their associated data centers have undergone increasing scrutiny in terms of their energy consumption and carbon emissions. As awareness of the energy costs and carbon footprints of AI models grows, attention has broadened to include other sustainability-related aspects such as their water consumption, transparency, and further environmental and social implications. In this work, we examine existing tools, frameworks, and evaluation metrics, complementing the ongoing discussions regarding AI’s environmental sustainability with a geographic perspective. This work, on the one hand, contributes to a geographically aware sustainability evaluation of current AI models. On the other hand, it examines the unique characteristics and challenges of GeoAI models, hoping to engage the GeoAI community in the sustainability discussion. Moving forward, we outline future directions on systematic reporting and geographically aware assessment. We then propose potential solutions, such as the adoption of Retrieval-Augmented Generation (RAG) models. Ultimately, we encourage future GeoAI research to acknowledge and address their environmental and social impact, thereby guiding GeoAI toward a more transparent, responsible, and sustainable future.",AI sustainability | carbon footprint | foundation model | GeoAI | transparency,5,2025,sustainability,behavior+sustainability
380,2-s2.0-85196662469,10.11939/jass.20230157,https://doi.org/10.11939/jass.20230157,https://scholar.google.com/scholar?q=10.11939/jass.20230157,re,Acta Seismologica Sinica,"Fenggui, Niu;Bei, Zhang;Shi, Chen",Review and perspective of Earth Science Knowledge Graph in Big Data Era,"Earth Science is a discipline that heavily relies on data,yet it is not fully harnessing the advantages of Earth data with existing technological means though covers many subject areas,Knowledge Graphs (KGs) is widely recognized as an effective approach to fully harness and utilize the extensive data in this field. Earth Science Knowledge Graphs can integrate geoscience knowledge,enhance research efficiency,and facilitate interdisciplinary collaboration. By analyzing network connections and semantic relationships,they uncover knowledge associations and patterns,andaid researchers in identifying new domains and posing novel research questions. Unlike conventional advancements in large-scale modeling technologies, Knowledge Graph offers precise knowledge that enhances both the intelligence and dependability of generated outcomes from such models. Firstly,this study provides a detailed exposition of Knowledge Graph concepts and construction methods. Knowledge Graphs,as a form of data graph,are designed to collect and convey knowledge from the real world. Their universal expression is in the form of triples,consisting of head entities,tail entities,and the relationships between them. Knowledge Graphs have emerged as a significant approach for organizing structured knowledge and integrating information from multiple data sources in the organizational world. Their architectural framework primarily encompasses four components:source data acquisition,knowledge fusion, knowledge computation,and knowledge application. Source data acquisition stands as the primary step in building Knowledge Graphs,focusing on extracting useful information from various types of data. Knowledge fusion is pivotal in addressing the heterogeneity of different Knowledge Graphs,with the aim of enhancing their quality through integration. Knowledge computation represents the primary output capability of Knowledge Graphs,currently applied in fields such as semantic search,question answering,and visualization analysis. Knowledge Graph construction technology enables the extraction of information from structured,unstructured,and semi-structured data sources,organizing this information into knowledge and presenting it in graphical form. Presently,the construction of Knowledge Graphs in the field of Earth Sciences primarily employs two methods:Top-down and bottom-up approaches,with the overarching principle being the synthesis of both methods while allowing flexibility in their specific sequencing. Secondly,this study offers a comprehensive introduction to the widely applied top-level ontology,the Basic Formal Ontology (BFO) model,in the scientific domain. The paper briefly summarizes existing Knowledge Graph in the geoscience field,emphasizing the GeoCore Ontology and Geoscience ontology (GSO) in the Earth Science domain,highlighting their similarities and differences. BFO,comprising 38 classes,is designed to facilitate information integration,retrieval,and analysis in scientific research. Presently,BFO has been successfully employed in over 350 ontology projects worldwide. The GeoCore Ontology,built upon BFO, serves as a specialized framework to describe the core concepts within the domain of Earth Science,rigorously defining a set of universal geological concepts during its development. Conversely,GSO provides a systematic framework for representing crucial geological science knowledge,encompassing three hierarchical layers:foundational,geological,and detailed modules. GeoCore can be viewed as an intermediary layer within GSO,which can be further expanded,while detailed modules have already been constructed within GSO. Additionally, researchers worldwide employ various methods such as literature mining,domain expert interviews,and data mining techniques to extract Earth Science knowledge from relevant literature, databases,and open data,subsequently to construct Knowledge Graphs. These Knowledge Graphs are found in applications across various domains including geological exploration,natural disaster prediction,and environmental conservation,and are utilized in practical projects such as oil and gas exploration,water resource management,and climate change research. In summary,the application scope of Earth Science Knowledge Graphs is extensive,providing a crucial foundation of data and knowledge for scientific research,decision support,and sustainable development. Finally,the study introduces international Earth Science data science initiatives such as the Deep-time Digital Earth (DDE) project related to constructing Earth Science Knowledge Graph,and the challenges and application prospects for the future development of Earth Science Knowledge Graph,with a focus on seismic science. The DDE aims to connect and coordinate global deep-earth data,promoting the sharing of geoscientific knowledge worldwide and facilitating research on Earth's evolution in a data-driven manner. Apart from the DDE,numerous domestic and international organizations and initiatives are driving the development of Knowledge Graph in Earth Science,such as OneGeology,EarthCube,and LinkedGeoData projects. Despite facing various challenges,Knowledge Graph is gradually overcoming these hurdles with advancements in technology and tools. These challenges are not exclusive to the field of Earth Science but are prevalent across all Knowledge Graph construction endeavors. However,due to the complexity and diversity of Earth Science,Knowledge Graph construction in this field encounters unique difficulties. Nevertheless,there is ample room for the creation and application of Knowledge Graph in Earth Science,with the introduction of Large Language Models (LLMs) bringing forth new opportunities. Earthquake Science,as a crucial branch of Earth Science,encompasses intersections of multiple primary disciplines such as geology,geophysics,and engineering seismology. However,the application of Knowledge Graphs in the field of Earthquake Science still faces significant gaps and urgently requires further research building upon existing models. In conclusion,the future development of Earth Science Knowledge Graphs will be an ongoing process of evolution and refinement,bringing more opportunities and benefits for fields such as Earth Science research,decision-making,and public education through sustained technological innovation and interdisciplinary collaboration.",Earth science | geological ontology | Knowledge Graph | ontology construction,5,2024,sustainability,behavior+sustainability
391,2-s2.0-85207051508,10.1109/TSMC.2024.3444277,https://doi.org/10.1109/TSMC.2024.3444277,https://scholar.google.com/scholar?q=10.1109/TSMC.2024.3444277,ar,IEEE Transactions on Systems Man and Cybernetics Systems,"Fan, Lili;Wang, Yutong;Zhang, Hui;Zeng, Changxian;Li, Yunjie;Gou, Chao;Yu, Hui",Multimodal Perception and Decision-Making Systems for Complex Roads Based on Foundation Models,"Since the inception of Industry 5.0 in 2021, a growing number of researchers have begun to pay their attention to the revolutionary shift it brings. The principles of Industry 5.0, including human-centric, sustainability, and emphasis on ecological and social values, will become the new paradigm for future industrial development. In this transformative landscape, artificial intelligence (AI) plays a pivotal role, and foundation models based on ChatGPT are set to reshape the organizational structure of industries. In this article, we introduce a multimodal perception and decision-making system built upon a foundational model. This system integrates image and point cloud data to enhance perception accuracy and provide ample information for decision making. It is designed to achieve a deep integration of AI and human-centric autonomous driving within the context of Industry 5.0. We introduce a cross-domain learning approach in the system architecture, along with a model training method from foundation models to handle complex road conditions. The proposed method enables road drivable area segmentation on complex unstructured roads. To address the issue of increased variance caused by the residual structure employed in previous works, this article introduces a distribution correction module, which effectively mitigates this problem. Furthermore, to achieve high-performance perception systems in intricate road scenarios, we put forth a multimodal perception fusion method in this study. The experiments demonstrate the superiority of this approach over single-sensor perception. This work contributes to the ongoing discourse on the convergence of AI, human-centric values, and advanced driving systems within the framework of Industry 5.0.",Autonomous driving | camera and four-dimensional (4-D) millimeter wave radar | ChatGPT | Industry 5.0 | multimodal | perception and decision making,5,2024,sustainability,behavior+sustainability
231,2-s2.0-105001134754,10.3390/fi17030096,https://doi.org/10.3390/fi17030096,https://scholar.google.com/scholar?q=10.3390/fi17030096,ar,Future Internet,"de Curtò, J.;de Zarzà, I.;Fervier, Leandro Sebastián;Sanagustín-Fons, Victoria;Calafate, Carlos T.",An Institutional Theory Framework for Leveraging Large Language Models for Policy Analysis and Intervention Design,"This study proposes a comprehensive framework for integrating data-driven approaches into policy analysis and intervention strategies. The methodology is structured around five critical components: data collection, historical analysis, policy impact assessment, predictive modeling, and intervention design. Leveraging data-driven approaches capabilities, the line of work enables advanced multilingual data processing, advanced statistics in population trends, evaluation of policy outcomes, and the development of evidence-based interventions. A key focus is on the theoretical integration of social order mechanisms, including communication modes as institutional structures, token optimization as an efficiency mechanism, and institutional memory adaptation. A mixed methods approach was used that included sophisticated visualization techniques and use cases in the hospitality sector, in global food security, and in educational development. The framework demonstrates its capacity to inform government and industry policies by leveraging statistics, visualization, and AI-driven decision support. We introduce the concept of “institutional intelligence”—the synergistic integration of human expertise, AI capabilities, and institutional theory—to create adaptive yet stable policy-making systems. This research highlights the transformative potential of data-driven approaches combined with large language models in supporting sustainable and inclusive policy-making processes.",AI | data-driven policy analysis | decision support systems | graph neural networks | institutional theory | intervention design | large language models | predictive modeling | visual analytics,5,2025,sustainability,policy+sustainability
373,2-s2.0-85200770517,10.1146/annurev-polisci-041322-042247,https://doi.org/10.1146/annurev-polisci-041322-042247,https://scholar.google.com/scholar?q=10.1146/annurev-polisci-041322-042247,re,Annual Review of Political Science,"Stanger, Allison;Kraus, Jakub;Lim, Woojin;Millman-Perlah, Georgia;Schroeder, Mitchell",Terra Incognita: The Governance of Artificial Intelligence in Global Perspective,"While generative AI shares some similarities with previous technological breakthroughs, it also raises unique challenges for containing social and economic harms. State approaches to AI governance vary; some lay a foundation for transnational governance whereas others do not. We consider some technical dimensions of AI safety in both open and closed systems, as well as the ideas that are presently percolating to safeguard their future development. Examining initiatives for the global community and for the coalition of open societies, we argue for building a dual-track interactive strategy for containing AI's potentially nightmarish unintended consequences. We conclude that AI safety is AI governance, which means that pluralist efforts to bridge gaps between theory and practice and the STEM-humanities divide are critical for democratic sustainability.",AI | artificial intelligence | democracy | governance | inequality | open societies | plurality | sustainability,5,2024,sustainability,policy+sustainability
459,2-s2.0-105011278067,10.1016/j.plas.2025.100187,https://doi.org/10.1016/j.plas.2025.100187,https://scholar.google.com/scholar?q=10.1016/j.plas.2025.100187,ar,Project Leadership and Society,"Smit, Michelle;Wagner, Reinhard F.;Bond-Barnard, Taryn Jane",Ambiguous regulations for dealing with AI in higher education can lead to moral hazards among students,"The aim of this study was to investigate the ethical dilemmas and expectations surrounding the use of generative AI in academic work within a South African-based hybrid online master's program in engineering management. Central to this program is its strong focus on project management and engineering leadership, to drive ethical decision-making in their professional contexts. A total of 102 current and graduated students from the master's program were surveyed to explore their use of generative AI tools, such as ChatGPT and Grammarly, in both professional and academic contexts. The survey showed that 98 % of students actively use generative AI, demonstrating an awareness of its potential and usefulness. While anecdotal evidence suggests moral hazard including plagiarism, undisclosed AI use and reliance on AI without independent reasoning. 94 % Of students seek clear institutional policies at the university and program levels to guide the ethical use of AI in academia. Students with higher confidence in their academic writing tend to perceive the quality of AI-generated content to be slightly inferior to their own work, highlighting varying dependency levels across the cohort. Furthermore, many students believe that universities should adopt explicit guidelines to define when and how AI tools are appropriate for academic work. These findings suggest that the absence of clear policies exacerbates ethical conflicts, impacting both educators and students. The results of this research underscore the urgency of developing transparent guidelines to safeguard academic integrity while embracing the potential of generative AI. By framing the findings within the moral hazard theory, this study highlights the risks of over-reliance on AI tools and opens avenues for future research into their responsible integration in higher education.",Artificial intelligence | ChatGPT | Higher education | Moral hazard | Survey,4,2025,behavior,behavior+policy
486,2-s2.0-105006766759,10.1016/j.ijinfomgt.2025.102932,https://doi.org/10.1016/j.ijinfomgt.2025.102932,https://scholar.google.com/scholar?q=10.1016/j.ijinfomgt.2025.102932,ar,International Journal of Information Management,"Seifdar, Mohammad Hasan;Amiri, Babak",Strategic adoption of generative AI in organizations: A game-theoretic and network-based approach,"The rapid advancement of Generative AI (GenAI) has introduced new opportunities and challenges for organizations seeking to integrate AI-driven decision-making into hierarchical structures. This study presents a game-theoretic framework combined with a hybrid organizational network model to examine the dynamics of GenAI adoption. The network consists of managers, employees, and AI systems interacting within a structure that combines hierarchical reporting and scale-free collaboration. By simulating multiple organizational scenarios with varying adoption costs, managerial influence, and network rewiring mechanisms, we analyze how AI adoption propagates through departments, impacts interdepartmental collaboration, and influences organizational inequality. Our findings suggest that managerial optimism and the ability of organizational networks to adapt flexibly accelerate AI adoption. On the other hand, decentralized decision-making enhances collaboration but may lead to short-term inefficiencies. Furthermore, although adopting AI initially leads to increased inequality within the organization, this disparity tends to stabilize over time. Therefore, effective governance strategies are critical in balancing organizational efficiency with fairness. This research provides actionable insights for managers and policymakers to navigate AI integration effectively and optimize its long-term benefits.",Adoption | Game Theory | Generative AI | Organization | Social Network,4,2025,behavior,behavior+policy
515,2-s2.0-105012644939,10.1016/j.jfma.2024.08.032,https://doi.org/10.1016/j.jfma.2024.08.032,https://scholar.google.com/scholar?q=10.1016/j.jfma.2024.08.032,re,Journal of the Formosan Medical Association Taiwan Yi Zhi,"Hwai, Haw;Ho, Yi Ju;Wang, Chih Hung;Huang, Chien Hua",Large language model application in emergency medicine and critical care,"In the rapidly evolving healthcare landscape, artificial intelligence (AI), particularly the large language models (LLMs), like OpenAI's Chat Generative Pretrained Transformer (ChatGPT), has shown transformative potential in emergency medicine and critical care. This review article highlights the advancement and applications of ChatGPT, from diagnostic assistance to clinical documentation and patient communication, demonstrating its ability to perform comparably to human professionals in medical examinations. ChatGPT could assist clinical decision-making and medication selection in critical care, showcasing its potential to optimize patient care management. However, integrating LLMs into healthcare raises legal, ethical, and privacy concerns, including data protection and the necessity for informed consent. Finally, we addressed the challenges related to the accuracy of LLMs, such as the risk of providing incorrect medical advice. These concerns underscore the importance of ongoing research and regulation to ensure their ethical and practical use in healthcare.",Artificial intelligence (AI) | Critical care | Emergency medicine,4,2025,behavior,behavior+policy
535,2-s2.0-105009263696,10.3390/healthcare13121394,https://doi.org/10.3390/healthcare13121394,https://scholar.google.com/scholar?q=10.3390/healthcare13121394,ar,Healthcare Switzerland,"Mashburn, Patricia;Weuthen, Felix A.;Otte, Nelly;Krabbe, Hanif;Fernandez, Gerardo M.;Kraus, Thomas;Krabbe, Julia",Gender Differences in the Use of ChatGPT as Generative Artificial Intelligence for Clinical Research and Decision-Making in Occupational Medicine,"Background/Objectives: Artificial intelligence (AI) has evolved from early diagnostic expert systems to advanced generative models, such as GPT-4, which are increasingly being used in healthcare. Concerns persist regarding inaccuracies and input dependency. This study aimed to deliver initial insights into whether gender influences the interaction of medical professionals with generative AI. Methods: This analysis investigated gender differences in medical students’ and physicians’ interactions with ChatGPT-4 while researching occupational medicine cases in a randomized controlled study. Participants assessed cases involving asbestos-related disease, metal sulfate allergy, and berylliosis using ChatGPT. Inputs and outputs were evaluated for accuracy, confabulations, communication styles, and user satisfaction. Demographic data and self-assessments of occupational medicine knowledge before and after the tasks were also collected. Results: Among 27 participants (63% women, 37% men), women showed greater knowledge improvement after using ChatGPT, particularly in asbestos-related cancer identification. No significant gender differences emerged in diagnostic accuracy, reporting procedures, or satisfaction with ChatGPT. Women exhibited significantly higher self-rated competence after using the ChatGPT application, while men only showed minimal change. Input from the female participants led to more confabulations, although response accuracy remained comparable. Conclusions: This study offers the first real-world insights into the use of generative AI in occupational medicine, highlighting the importance of understanding user-dependent variability in AI-supported clinical practice and decision-making. These findings underscore the need for gender-sensitive AI literacy training in medical education, accommodating diverse interaction styles and strategies to mitigate AI-generated misinformation. Future research with larger and more diverse cohorts could provide deeper insights into the influence of gender, age, and experience on AI utilization in healthcare. Integrating gender-based interaction differences into AI training and applications may improve clinical performance and promote more equitable healthcare practices.",artificial intelligence | ChatGPT | gender | large language models | occupational medicine,4,2025,behavior,behavior+policy
537,2-s2.0-105000889535,10.1002/sta4.70057,https://doi.org/10.1002/sta4.70057,https://scholar.google.com/scholar?q=10.1002/sta4.70057,ar,Stat,"Caballero, William N;Jenkins, Phillip R",On Large Language Models in National Security Applications,"The overwhelming success of GPT-4 in early 2023 highlighted the transformative potential of large language models (LLMs) across various sectors, including national security. This article explores the implications of LLM integration within national security contexts, analysing their potential to revolutionise information processing, decision-making and operational efficiency. Whereas LLMs offer substantial benefits, such as automating tasks and enhancing data analysis, they also pose significant risks, including hallucinations, data privacy concerns, and vulnerability to adversarial attacks. Through their coupling with decision-theoretic principles and Bayesian reasoning, LLMs can significantly improve decision-making processes within national security organisations. Namely, LLMs can facilitate the transition from data to actionable decisions, enabling decision-makers to quickly receive and distill available information with less manpower. Current applications within the US Department of Defense and beyond are explored, for example, the USAF's use of LLMs for wargaming and automatic summarisation, that illustrate their potential to streamline operations and support decision-making. However, these applications necessitate rigorous safeguards to ensure accuracy and reliability. The broader implications of LLM integration extend to strategic planning, international relations and the broader geopolitical landscape, with adversarial nations leveraging LLMs for disinformation and cyber operations, emphasising the need for robust countermeasures. Despite exhibiting “sparks"" of artificial general intelligence, LLMs are best suited for supporting roles rather than leading strategic decisions. Their use in training and wargaming can provide valuable insights and personalised learning experiences for military personnel, thereby improving operational readiness.",applied statistics | artificial intelligence | large language models | national security | strategic planning,4,2025,behavior,behavior+policy
541,2-s2.0-105004575569,10.1007/s44443-025-00038-x,https://doi.org/10.1007/s44443-025-00038-x,https://scholar.google.com/scholar?q=10.1007/s44443-025-00038-x,ar,Journal of King Saud University Computer and Information Sciences,"Jin, Weiqiang;Su, Dafu;Tao, Tao;Wang, Xiujun;Wang, Ningwei;Zhao, Biao",Courtroom-FND: a multi-role fake news detection method based on argument switching-based courtroom debate,"With the proliferation of the internet and social media, the spread of fake news has become a global issue, posing serious challenges to the research of Fake News Detection (FND) methods. With advancements in Artificial Intelligence (AI), large language models (LLMs) have become increasingly evident across various industries, especially in natural language processing (NLP). LLM-based FND approaches, including Chain-of-Thought (CoT), self-reflection, and in-context learning (ICL) prompting paradigms, has shown promise but still faces challenges in effectively handling complex and nuanced content. For example, CoT paradigm faces error propagation issues, self-reflection methods suffer from the Degeneration-of-Thought (DoT) problem, and ICL paradigm is highly dependent on the quality of the provided context. To address these issues, we propose a multi-role detection method based on courtroom debates. This method involves two attorneys, representing the prosecution and the defense, as well as a judge, simulating a debate process on the authenticity of the news. First, the prosecution attempts to prove that the news is fake, while the defense tries to prove that the news is genuine. The judge evaluates the evidence presented by both sides to reach a conclusion. Next, the prosecution and defense switch roles, with each attempting to argue from the opposite standpoint, and the judge evaluates the arguments again. Finally, the judge synthesizes all arguments to issue a verdict. Extensive experiments across multiple challenging scenarios (e.g., controversial news and misleading media posts) show that this debate-based framework achieves up to 9%-11% higher accuracy than advanced LLM baselines, revealing how role switching significantly enhances detection performance. Moreover, our findings indicate that incorporating diverse perspectives reduces cognitive bias, but also highlight that LLM-based judges remain susceptible to inherent biases-especially if pretrained data include skewed narratives-underscoring the need for fairness adjustments in real-world applications. Overall, the proposed courtroom debate-based FND framework not only improves accuracy and reliability in identifying fake news but also provides an interpretable decision-making process by exposing key arguments on both sides. This underscores its potential to serve as a robust, transparent, and adaptable solution in the evolving domain of misinformation detection.",Cognitive bias mitigation | Courtroom debate framework | Fake news detection | Large language models | Role switching and fairness in AI,4,2025,behavior,behavior+policy
556,2-s2.0-85217026497,10.1016/j.arthro.2024.12.001,https://doi.org/10.1016/j.arthro.2024.12.001,https://scholar.google.com/scholar?q=10.1016/j.arthro.2024.12.001,ar,Arthroscopy Journal of Arthroscopic and Related Surgery,"Hasan, Sayyida S.;Woo, Joshua J.;Cote, Mark P.;Ramkumar, Prem N.",Generative Versus Nongenerative Artificial Intelligence,"Artificial intelligence (AI) is a colossal buzzword, a confusing subject matter, but also an inevitable reality. Generative and nongenerative AI are the 2 core subtypes of AI. Generative AI uses current data to understand patterns and generate new information, and it is especially valuable in producing synthetic medical images, enhancing surgical simulations, and expanding training datasets. Techniques such as generative adversarial networks (GANs), large language models (LLMs), and variational autoencoders (VAEs) allow for the creation of realistic simulations, text, and models that can be used for perioperative communication and planning. Conversely, nongenerative AI is centered on the examination and categorization of pre-existing data to formulate predictions or decisions—the most popular denomination namely machine learning. This approach is instrumental in tasks such as forecasting surgical outcomes, segmenting medical images, and determining patient risk profiles. Models such as convolutional neural networks (CNNs), random forests, and support vector machines (SVMs) are widely used for these purposes, demonstrating high accuracy and reliability in clinical decision making. Although generative AI offers innovative tools for creating new data and simulations, nongenerative AI excels in analyzing existing data to inform patient care. Both approaches have the potential of supporting clinical workflows to automate redundancies and improve efficiencies. However, there are also limitations in the application of AI in orthopaedics, including the potential for bias in models, the challenge of interpreting AI-driven insights, and the ethics of oversight. As the integration of AI in orthopaedics continues to grow, it is essential for practitioners to understand these technologies' capabilities and limitations to harness their full potential and establish appropriate governance.",,4,2025,behavior,behavior+policy
559,2-s2.0-105007366482,10.1071/PU24001,https://doi.org/10.1071/PU24001,https://scholar.google.com/scholar?q=10.1071/PU24001,re,Public Health Research Practice,"Nutbeam, Don;Milat, Andrew J.","Artificial intelligence and public health: prospects, hype and challenges","Objectives and importance of the study Applications of artificial intelligence (AI) platforms and technologies to healthcare have been widely promoted as offering revolutionary improvements and efficiencies in clinical practice and health services organisation. Practical applications of AI in public health are now emerging and receiving similar attention. This paper provides an overview of the issues and examples of research that help separate the potential from the hype. Methods Selective review and analysis of cross-section of relevant literature. Results Great potential exists for the use of AI in public health practice and research. This includes immediate applications in improving health education and communication directly with the public, as well as great potential for the productive use of generative AI through chatbots and virtual assistants in health communication. AI also has applications in disease surveillance and public health science, for example in improving epidemic and pandemic early warning systems, in synthetic data generation, in sequential decision-making in uncertain conditions (reinforcement learning) and in disease risk prediction. Most published research examining these and other applications is at a fairly early stage, making it difficult to separate the probable benefits from the hype. This research is undoubtedly demonstrating great potential but also identifying challenges, for example in the quality and relevance of health information being produced by generative AI; in access, trust and use of the technology by different populations; and in the practical application of AI to support disease surveillance and public health science. There are real risks that current access and patterns of use may exacerbate existing inequities in health and that the orientation towards the personalisation of health advice may divert attention away from underlying social and economic determinants of health. Conclusions Realising the potential of AI not only requires further research and experimentation but also careful consideration of its ethical implications and thoughtful regulation. This will ensure that advances in these technologies serve the best interests of individuals and communities worldwide and don't exacerbate existing health inequalities.",,4,2025,behavior,behavior+policy
560,2-s2.0-105001028884,10.3390/pr13030670,https://doi.org/10.3390/pr13030670,https://scholar.google.com/scholar?q=10.3390/pr13030670,ar,Processes,"Choi, Hangseo;Jeong, Jongpil",Domain-Specific Manufacturing Analytics Framework: An Integrated Architecture with Retrieval-Augmented Generation and Ollama-Based Models for Manufacturing Execution Systems Environments,"To support data-driven decision-making in a Manufacturing Execution System (MES) environment, a system that can quickly and accurately analyze a wide range of production, quality, asset, and material information must be deployed. However, existing MES data management approaches rely on predefined queries or report templates that lack flexibility and limit real-time decision support. In this paper, we proposes a domain-specific Retrieval-Augmented Generation (RAG) architecture that extends LangChain’s capabilities with Manufacturing Execution System (MES)-specific components and the Ollama-based Local Large Language Model (LLM). The proposed architecture addresses unique MES requirements including real-time sensor data processing, complex manufacturing workflows, and domain-specific knowledge integration. It implements a three-layer structure: an application layer using FastAPI for high-performance asynchronous processing, an LLM layer for natural language understanding, and a data storage layer combining MariaDB, Redis, and Weaviate for efficient data management. The system effectively handles MES-specific challenges such as schema relationships, temporal data processing, and security concerns without exposing sensitive factory data. This is an industry-specific, customized approach focusing on problem-solving in manufacturing sites, going beyond simple text-based RAG. The proposed architecture considers the specificity of data sources, real-time and high-availability requirements, the reflection of domain knowledge and workflows, compliance with security and quality control regulations, and direct interoperability with MES systems. The architecture can be further enhanced through integration with various manufacturing systems, an advanced LLM, and distributed processing frameworks while maintaining its core focus on MES domain specialization.",FastAPI | local large language model (LLM) | manufacturing execution system (MES) | MES domain-specific RAG | real-time data processing | retrieval-augmented generation (RAG),4,2025,behavior,behavior+policy
581,2-s2.0-85215681164,10.3390/app15020968,https://doi.org/10.3390/app15020968,https://scholar.google.com/scholar?q=10.3390/app15020968,ar,Applied Sciences Switzerland,"Sun, Yi;Liu, Xinke",Research and Application of a Multi-Agent-Based Intelligent Mine Gas State Decision-Making System,"To address the issues of low efficiency in manual processing and lack of accuracy in judgment within traditional mine gas safety inspections, this paper designs and implements the Intelligent Mine Gas State Decision-Making System based on large language models (LLMs) and a multi-agent system. The system aims to enhance the accuracy of gas over-limit alarms and improve the efficiency of generating judgment reports. The system integrates the reasoning capabilities of LLMs and optimizes task allocation and execution efficiency of agents through the study of the hybrid multi-agent orchestration algorithm. Furthermore, the system establishes a comprehensive gas risk assessment knowledge base, encompassing historical alarm data, real-time monitoring data, alarm judgment criteria, treatment methods, and relevant policies and regulations. Additionally, the system incorporates several technologies, including retrieval-augmented generation based on human feedback mechanisms, tool management, prompt engineering, and asynchronous processing, which further enhance the application performance of the LLM in the gas status judgment system. Experimental results indicate that the system effectively improves the efficiency of gas alarm processing and the quality of judgment reports in coal mines, providing solid technical support for accident prevention and management in mining operations.",gas risk assessment knowledge base | human feedback mechanism | large language models | multi-agent orchestration algorithm | retrieval-augmented generation,4,2025,behavior,behavior+policy
582,2-s2.0-85215267911,10.24818/EA/2025/68/253,https://doi.org/10.24818/EA/2025/68/253,https://scholar.google.com/scholar?q=10.24818/EA/2025/68/253,ar,Amfiteatru Economic,"Neacșu, Marius Cristian;Eregep, Erdem Yuneis;Diaconescu, Mihai",ARTIFICIAL INTELLIGENCE AS A GEOPOLITICAL TOOL,"This study is based on exploratory research to test the ability of artificial intelligence (AI) to shape human behaviour, testing on a recent geopolitical event, the ongoing Russian war in Ukraine. Thus, text, image and video were generated using artificial intelligence, tracking users’ perceptions of fake narratives generated using artificial intelligence (in the case of text) and testing their ability to distinguish between synthetically generated models and real ones (in the case of image and video). Methodologically, three generative text models were used, namely Chat-GPT, Bing AI and Google Bard, and human perception was tested through a questionnaire. The results confirmed the ability of artificial intelligence (text generative models) to provide information in the domain of disinformation. Additionally, an average of one in ten respondents fail to identify automatically generated disinformation, about half failed to correctly identify an AI-generated image, and more than half have difficulty identifying an AI-generated video compared to the true video.",deep-fake | disinformation | fake-news | generative artificial intelligence | war in Ukraine,4,2025,behavior,behavior+policy
661,2-s2.0-85210983583,10.1017/dap.2024.58,https://doi.org/10.1017/dap.2024.58,https://scholar.google.com/scholar?q=10.1017/dap.2024.58,ar,Data and Policy,"Nabben, Kelsie",AI as a constituted system: accountability lessons from an LLM experiment,"This study focuses on the practicalities of establishing and maintaining AI infrastructure, as well as the considerations for responsible governance by investigating the integration of a pre-trained large language model (LLM) with an organisation’s knowledge management system via a chat interface. The research adopts the concept of “AI as a constituted system” to emphasise the social, technical, and institutional factors that contribute to AI’s governance and accountability. Through an ethnographic approach, this article details the iterative processes of negotiation, decision-making, and reflection among organisational stakeholders as they develop, implement, and manage the AI system. The findings indicate that LLMs can be effectively governed and held accountable to stakeholder interests within specific contexts, specifically, when clear institutional boundaries facilitate innovation while navigating the risks related to data privacy and AI misbehaviour. Effective constitution and use can be attributed to distinct policy creation processes to guide AI’s operation, clear lines of responsibility, and localised feedback loops to ensure accountability for actions taken. This research provides a foundational perspective to better understand algorithmic accountability and governance within organisational contexts. It also envisions a future where AI is not universally scaled but consists of localised, customised LLMs tailored to stakeholder interests.",AI | ethnography | governance | LLM | organisation,4,2024,behavior,behavior+policy
695,2-s2.0-85212616525,10.34135/communicationtoday.2024.Vol.15.No.2.2,https://doi.org/10.34135/communicationtoday.2024.Vol.15.No.2.2,https://scholar.google.com/scholar?q=10.34135/communicationtoday.2024.Vol.15.No.2.2,ar,Communication Today,"Mirek-Rogowska, Aleksandra;Kucza, Wojciech;Gajdka, Krzysztof","AI IN COMMUNICATION: THEORETICAL PERSPECTIVES, ETHICAL IMPLICATIONS, AND EMERGING COMPETENCIES","Artificial intelligence (AI) is rapidly transforming communication processes across various sectors, including marketing, education, healthcare, and entertainment. This study explores the theoretical perspectives surrounding AI’s integration into communication, examining how AI-driven tools such as ChatGPT, MidJourney, and Google Gemini are reshaping content creation, personalisation, and human-machine interaction. While AI enhances efficiency and allows for real-time customisation of messages, it also presents ethical challenges related to privacy, data security, and algorithmic bias. By synthesising key academic studies, the study outlines the critical ethical considerations, including the risks of deepfakes and disinformation, and emphasises the need for ethical frameworks to guide responsible AI use. The text also discusses the new digital competencies required to navigate AI-enhanced communication environments, such as AI literacy, data proficiency, and ethical reasoning. Through a systematic literature review, this study contributes to the ongoing discourse on AI’s role in communication by offering a comprehensive theoretical framework that highlights both the opportunities and limitations of AI technologies. Future research should focus on addressing gaps in empirical studies, particularly concerning the long-term impacts of AI on decision-making and the ethical governance of AI-generated content.",AI-generated content | artificial intelligence (AI) | communication | data privacy | deepfakes | digital competencies | ethical implications | human-machine interaction,4,2024,behavior,behavior+policy
710,2-s2.0-85183019798,10.13998/j.cnki.issn1002-1248.23-0406,https://doi.org/10.13998/j.cnki.issn1002-1248.23-0406,https://scholar.google.com/scholar?q=10.13998/j.cnki.issn1002-1248.23-0406,ar,Journal of Library and Information Science in Agriculture,"Fu, Rongxin;Yang, Xiaohua",Analysis of AIGC Language Models and Application Scenarios in University Libraries,"[Purpose/Significance] Artificial intelligence generated content (AIGC)'s content creation method has brought about a new revolution to the field of library and information science (LIS). Currently, the related research is mainly based on AIGC and ChatGPT, while ERNIE bot and Bard are less studied. Comparative analysis of the advantages and disadvantages of the AIGC large language models, discussion of the operating mechanism of AIGC, and in-depth research on application solutions in the context of university libraries provide new ideas for AIGC applications in smart libraries. [Method/Process] Taking the three AIGC applications of ChatGPT, ERNIE bot and Bard as examples, starting from the Transformer model, and on the basis of in-depth analysis of the basic principles of the large language model, the comparative analysis method is used to conduct a horizontal comparison of these three applications. The research summarizes the six common features of AIGC's large language model, and points out that it can be used in improving the work efficiency of university libraries. This paper explains and identifies nine different characteristics of the AIGC large language model, and points out how to choose three applications in university libraries. According to the characteristics of each application, six scenarios-based application modes of university libraries and the advantages of AIGC applications in university libraries are pointed out. A discussion is provided on four potential risks that may be faced by libraries in using AIGC large language models, and solutions are proposed to reduce risks, providing a reference for university libraries to choose AIGC applications. [Results/Conclusions] ChatGPT focuses on natural language understanding and content generation, and has more advantages in the ability of natural language understanding, task applicability and cross-language transfer, and is more suitable for resource integration and decision-making assistance in the context of knowledge services, subject services and administrative management. ERNIE bot has hundreds of billions of super-training parameters, and it can generate multi-modal content including text, pictures and voices. It has more advantages in learning training, model expansion and Chinese comprehension, and is more suitable for optimizing services and assisting creation in the context of reader services, technical services and cultural services in university libraries. By comparison, Bard focuses on human-machine dialogue data processing, it can use natural language to communicate with people, and it is more suitable for providing 24-hour intelligent customer service, assisting subject consultation and knowledge Q&A in the context of reference consultation in university libraries. With the application of AIGC, although university libraries will face ethical risks, privacy risks, data security, and the proliferation of false knowledge, as long as artificial intelligence data governance is strengthened, in the future, university libraries will integrate the natural language understanding and generation capabilities of AIGC large language models that can expand diversified application scenarios, innovate multi-dimensional service models, optimize the business service environment, assist administrative decision-making, and improve the level of intelligent services.",AIGC | Bard | ChatGPT | ERNIE bot | smart library,4,2023,behavior,behavior+policy
379,2-s2.0-85190292937,10.1016/j.mex.2024.102707,https://doi.org/10.1016/j.mex.2024.102707,https://scholar.google.com/scholar?q=10.1016/j.mex.2024.102707,ar,Methodsx,"Buitrago-Esquinas, Eva M.;Puig-Cabrera, Miguel;Santos, José António C.;Custódio-Santos, Margarida;Yñiguez-Ovando, Rocío",Developing a hetero-intelligence methodological framework for sustainable policy-making based on the assessment of large language models,"This work delves into the increasing relevance of Large Language Models (LLMs) in the realm of sustainable policy-making, proposing an innovative hetero-intelligence framework that blends human and artificial intelligence (AI) for tackling modern sustainability challenges. The research methodology includes a hetero-intelligence performance test, which juxtaposes human intelligence with AI in the formulation and implementation of sustainable policies. After testing this hetero-intelligence methodology, seven steps are rigorously described so that it can be replicated in any sustainability planning related context. The results underscore the capabilities and limitations of LLMs, underscoring the critical role of human intelligence in enhancing the efficacy of hetero-intelligence systems. This work fulfils the need of a rigorous methodological framework based on empirical steps that can provide unbiased outcomes to be integrated into sustainable planning and decision-making processes. • Assesses LLMs’ limitations and capabilities regarding sustainable planning issues • A replicable methodology is proposed based on the combination of both human and artificial intelligence • It proposes and systematises the integration of a hetero-intelligent approach into the formulation of sustainability policies to be more efficient and effective",ChatGPT | Conversational generative AI | Hetero-intelligent performance testing | Human intelligence | Large language models | Sustainable planning and policy,4,2024,sustainability,behavior+policy+sustainability
112,2-s2.0-105009962123,10.1016/j.rser.2025.116061,https://doi.org/10.1016/j.rser.2025.116061,https://scholar.google.com/scholar?q=10.1016/j.rser.2025.116061,re,Renewable and Sustainable Energy Reviews,"Yang, Yizhou;Duan, Qiuhua;Samadi, Forooza",A systematic review of building energy performance forecasting approaches,"Building energy performance forecasting (BEPF) is an active area of research with the potential to improve the efficiency of building energy management systems, support global sustainability goals, and mitigate climate change impacts. This systematic review examines three main prediction methods: model-driven, data-driven, and hybrid-driven, each with different principles, basics, advantages, disadvantages, practical applications, challenges, and limitations in addressing the complexities of building energy performance. The review focuses on key influencing factors, including building features, climatic conditions, and occupant behavior, while identifying critical research gaps in current methodologies. Through a bibliometric analysis of 95 relevant publications from 2019 to 2024, this review provides a quantitative overview of research progress and emerging trends. Findings indicate that although BEPF techniques have evolved rapidly, most studies continue to overlook the variability and complexity of occupant behavior, a factor with significantly affects forecast accuracy. To address this, we propose a modular AI-integrated forecasting framework that leverages the strengths of existing approaches, integrates real-time IoT data, and incorporate advanced artificial intelligence techniques, such as generative Artificial Intelligence, reinforcement learning, and Large Language Models (LLMs). A decision-making framework is also introduced to guide method selection based on specific building characteristics, data availability, desired accuracy, and operational goals, offering practical guidance for engineering and policy applications. Additionally, future research should extend beyond individual building dynamics to include a wider range of community-level determinants, such as policy frameworks, economic factors, and social determinants of health considerations (SDOH), aiming for a more comprehensive understanding of building energy consumption patterns. This review not only synthesizes current knowledge but also lays the foundation for future innovations in BEPF. We advocate for moving towards an AI-enhanced, adaptive forecasting model that can integrate different driven methods, capture the variability and unpredictability of occupant behavior, and improve the accuracy and reliability of energy forecasts.",Artificial intelligence (AI) technique | Black-box modeling | Building energy performance forecasting (BEPF) | Hybrid-driven | Occupant behavior | Physics-based modeling | Real-time adaptability | Thermal properties of materials | Weather impact,4,2025,sustainability,behavior+sustainability
116,2-s2.0-85219095520,10.1089/big.2024.0128,https://doi.org/10.1089/big.2024.0128,https://scholar.google.com/scholar?q=10.1089/big.2024.0128,ar,Big Data,"Akpan, Ikpe Justice;Razavi, Rouzbeh;Akpan, Asuama A.",Evolutionary Trends in Decision Sciences Education Research from Simulation and Games to Big Data Analytics and Generative Artificial Intelligence,"Decision sciences (DSC) involves studying complex dynamic systems and processes to aid informed choices subject to constraints in uncertain conditions. It integrates multidisciplinary methods and strategies to evaluate decision engineering processes, identifying alternatives and providing insights toward enhancing prudent decision-making. This study analyzes the evolutionary trends and innovation in DSC education and research trends over the past 25 years. Using metadata from bibliographic records and employing the science mapping method and text analytics, we map and evaluate the thematic, intellectual, and social structures of DSC research. The results identify “knowledge management, ” “decision support systems, ” “data envelopment analysis, ” “simulation, ” and “artificial intelligence” (AI) as some of the prominent critical skills and knowledge requirements for problem-solving in DSC before and during the period (2000–2024). However, these technologies are evolving significantly in the recent wave of digital transformation, with data analytics frameworks (including techniques such as big data analytics, machine learning, business intelligence, data mining, and information visualization) becoming crucial. DSC education and research continue to mirror the development in practice, with sustainable education through virtual/online learning becoming prominent. Innovative pedagogical approaches/strategies also include computer simulation and games (“play and learn” or “role-playing”). The current era witnesses AI adoption in different forms as conversational Chatbot agent and generative AI (GenAI), such as chat generative pretrained transformer in teaching, learning, and scholarly activities amidst challenges (academic integrity, plagiarism, intellectual property violations, and other ethical and legal issues). Future DSC education must innovatively integrate GenAI into DSC education and address the resulting challenges.",complex dynamic systems | data analytics | decision sciences | digitization | generative artificial intelligence | simulation and games,4,2025,sustainability,behavior+sustainability
169,2-s2.0-105004646836,10.1016/j.atech.2025.100987,https://doi.org/10.1016/j.atech.2025.100987,https://scholar.google.com/scholar?q=10.1016/j.atech.2025.100987,ar,Smart Agricultural Technology,"Eckhardt, Regina;Arablouei, Reza;Ingham, Aaron;McCosker, Kieren;Bernhardt, Heinz",Livestock behaviour forecasting via generative artificial intelligence,"Recent advancements in sensor technology and generative artificial intelligence (AI) are transforming precision livestock farming by enhancing behaviour monitoring and predictive analytics. This study examines the effectiveness of Transformer-type generative AI models in predicting cattle behaviour profiles and imputing missing data from collar accelerometer readings collected during two trials in Queensland, Australia, in 2022 and 2023, alongside climatic data. Each trial involved 60 cattle equipped with collars that classified six core behaviours: grazing, ruminating, walking, resting, drinking, and other over five-second time windows. Hourly behaviour profiles were constructed for each animal and experiment day by aggregating the behaviour predictions over every calendar hour, representing the time spent on each behaviour within each hour. Subsequently, four Transformer-type models (i.e., standard Transformer, Informer, Reformer, and Autoformer) were trained on the hourly behaviour profile data to predict behaviour profiles of the next 24 hours for each animal. Among the considered models, Autoformer showed the highest predictive accuracy when including climate data, achieving a mean absolute error (MAE) of <5.5 min, while the next best model had an MAE of approximately 6 min. For imputing missing data, the standard Transformer outperformed traditional imputation methods, with an MAE of <30 min over 24 hours, compared to 40 to 70 min for traditional methods (mean, median, and linear interpolation). These results highlight the potential of generative AI, particularly Autoformer and Transformer, to enhance predictive accuracy and data imputation in livestock management, thereby supporting regulatory guidance for data-driven decision-making and improved farming practices.",Accelerometer data | Cattle behaviour | Data imputation | Generative AI | Precision agriculture,4,2025,sustainability,behavior+sustainability
182,2-s2.0-105010246155,10.3390/foods14132230,https://doi.org/10.3390/foods14132230,https://scholar.google.com/scholar?q=10.3390/foods14132230,re,Foods,"Sun, Qing;Yuan, Yanan;Xu, Baoguo;Gao, Shipeng;Zhai, Xiaodong;Xu, Feiyue;Shi, Jiyong",Innovative Technologies Reshaping Meat Industrialization: Challenges and Opportunities in the Intelligent Era,"The Fourth Industrial Revolution and artificial intelligence (AI) technology are driving the transformation of the meat industry from mechanization and automation to intelligence and digitization. This paper provides a systematic review of key technological innovations in this field, including physical technologies (such as smart cutting precision improved to the millimeter level, pulse electric field sterilization efficiency exceeding 90%, ultrasonic-assisted marinating time reduced by 12 h, and ultra-high-pressure processing extending shelf life) and digital technologies (IoT real-time monitoring, blockchain-enhanced traceability transparency, and AI-optimized production decision-making). Additionally, it explores the potential of alternative meat production technologies (cell-cultured meat and 3D bioprinting) to disrupt traditional models. In application scenarios such as central kitchen efficiency improvements (e.g., food companies leveraging the “S2B2C” model to apply AI agents, supply chain management, and intelligent control systems, resulting in a 26.98% increase in overall profits), end-to-end temperature control in cold chain logistics (e.g., using multi-array sensors for real-time monitoring of meat spoilage), intelligent freshness recognition of products (based on deep learning or sensors), and personalized customization (e.g., 3D-printed customized nutritional meat products), these technologies have significantly improved production efficiency, product quality, and safety. However, large-scale application still faces key challenges, including high costs (such as the high investment in cell-cultured meat bioreactors), lack of standardization (such as the absence of unified standards for non-thermal technology parameters), and consumer acceptance (surveys indicate that approximately 41% of consumers are concerned about contracting illnesses from consuming cultured meat, and only 25% are willing to try it). These challenges constrain the economic viability and market promotion of the aforementioned technologies. Future efforts should focus on collaborative innovation to establish a truly intelligent and sustainable meat production system.",artificial intelligence | blockchain traceability | meat industrialization | non-thermal processing | smart cutting,4,2025,sustainability,behavior+sustainability
203,2-s2.0-105006578635,10.3390/info16050415,https://doi.org/10.3390/info16050415,https://scholar.google.com/scholar?q=10.3390/info16050415,re,Information Switzerland,"Le Dinh, Thang;Vu, Manh Chiên;Tran, Giang T.C.",Artificial Intelligence in SMEs: Enhancing Business Functions Through Technologies and Applications,"Artificial intelligence (AI) has significant potential to transform small- and medium-sized enterprises (SMEs), yet its adoption is often hindered by challenges such as limited financial and human resources. This study addresses this issue by investigating the core AI technologies adopted by SMEs, their broad range of applications across business functions, and the strategies required for successful implementation. Through a systematic literature review of 50 studies published between 2016 and 2025, we identify prominent AI technologies, including machine learning, natural language processing, and generative AI, and their applications in enhancing efficiency, decision-making, and innovation across sales and marketing, operations and logistics, finance and other business functions. The findings emphasize the importance of workforce training, robust technological infrastructure, data-driven cultures, and strategic partnerships for SMEs. Furthermore, the review highlights methods for measuring and optimizing AI’s value, such as tracking key performance indicators and improving customer satisfaction. While acknowledging challenges like financial constraints and ethical considerations, this research provides practical guidance for SMEs to effectively leverage AI for sustainable growth and provides a foundation for future studies to explore customized AI strategies for diverse SME contexts.",AI-powered technologies | artificial intelligence | SME,4,2025,sustainability,behavior+sustainability
230,2-s2.0-105001159898,10.3390/educsci15030290,https://doi.org/10.3390/educsci15030290,https://scholar.google.com/scholar?q=10.3390/educsci15030290,ar,Education Sciences,"Carmona-Galindo, Victor Daniel;Velado-Cano, Maryory Andrea;Groat-Carmona, Anna Maria","The Ecology of Climate Change: Using Virtual Reality to Share, Experience, and Cultivate Local and Global Perspectives","The global challenge of climate change demands innovative, inclusive, and experiential education that fosters ecological literacy, behavioral change, and climate advocacy. This study explores a cross-cultural collaboration between two undergraduate ecology courses—one at the University of La Verne (ULV) in California and the other at the Universidad Centroamericana José Simeón Cañas (UCA) in El Salvador—that employed 360° virtual reality (VR) photosphere photographs to investigate climate change impacts. Students documented local ecological phenomena, such as drought and habitat loss, and shared insights with international peers, facilitating a rich exchange of perspectives across biomes. Generative AI tools like ChatGPT were utilized to overcome language barriers, enabling equitable participation and enhancing cross-cultural communication. The findings highlight VR’s transformative role in helping students visualize and communicate complex ecological concepts while fostering empathy, emotional engagement, and agency as climate advocates. Institutional and curricular factors shaping the integration of VR-based approaches are discussed, along with their potential to drive behavioral shifts and promote global engagement. This study demonstrates that immersive technologies, combined with collaborative learning, provide a powerful framework for bridging geographic and cultural divides, equipping students with the tools and perspectives needed to address the critical global challenges posed by climate change.",climate change education | cross-cultural collaboration | environmental advocacy | experiential learning | global citizenship | sustainability education | virtual reality in education,4,2025,sustainability,behavior+sustainability
251,2-s2.0-85215959142,10.3390/fi17010048,https://doi.org/10.3390/fi17010048,https://scholar.google.com/scholar?q=10.3390/fi17010048,ar,Future Internet,"Ferrer i Picó, Jan;Catta-Preta, Michelle;Trejo Omeñaca, Alex;Vidal, Marc;Monguet i Fierro, Josep Maria",The Time Machine: Future Scenario Generation Through Generative AI Tools,"Contemporary society faces unprecedented challenges—from rapid technological evolution to climate change and demographic tensions—compelling organisations to anticipate the future for informed decision-making. This case study aimed to design a digital system for end-users called the Time Machine, which enables a generative artificial intelligence (GAI) system to produce prospective future scenarios based on the input information automatically, proposing hypotheses and prioritising trends to streamline and make the formulation of future scenarios more accessible. The system’s design, development, and testing progressed through three versions of prompts for the OpenAI GPT-4 LLM, with six trials conducted involving 222 participants. This iterative approach allowed for gradual adjustment of instructions given to the machine and encouraged refinement. Results from the six trials demonstrated that the Time Machine is an effective tool for generating future scenarios that promote debate and stimulate new ideas in multidisciplinary teams. Our trials proved that GAI-generated scenarios could foster discussions on +70% of generated scenarios with appropriate prompting, and more than half included new ideas. In conclusion, large language models (LLMs) of GAI, with suitable prompt engineering and architecture, have the potential to generate useful future scenarios for organisations, transforming future intelligence into a more accessible and operational resource. However, critical use of these scenarios is essential.",futures | generative AI | large language models (LLMs) | prompt engineering | scenarios,4,2025,sustainability,behavior+sustainability
312,2-s2.0-105013213396,10.1109/ACCESS.2025.3596791,https://doi.org/10.1109/ACCESS.2025.3596791,https://scholar.google.com/scholar?q=10.1109/ACCESS.2025.3596791,re,IEEE Access,"Wang, Jianxian;Mokhlis, Hazlie;Mansor, Nurulafiqah Nadzirah;Illias, Hazlee Azil;Ramasamy, Agileswari K.;Wu, Xingyu;Wang, Siqi","Smart Fault Detection, Classification, and Localization in Distribution Networks: AI-Driven Approaches and Emerging Technologies","Distribution networks play a vital role in bridging transmission systems and end users, offering enhanced flexibility, decentralization, and the capacity to integrate distributed generation. However, with nations worldwide actively pursuing carbon neutrality and emission peak goals, sustainable energy sources such as solar and wind are increasingly penetrating distribution networks, posing significant challenges to conventional fault detection, classification, and localization techniques due to bidirectional power flows, dynamic fault currents, and rising network complexity. These challenges manifest as reduced sensitivity of protection systems in distribution networks, increased difficulty in identifying high impedance faults, and frequent misclassification or mislocation of faults under dynamic network conditions. To address these limitations, this paper presents a comprehensive review of artificial intelligence-driven approaches and emerging technologies that are specifically tailored for fault analysis in distribution networks, to enhance diagnostic accuracy, adaptability, and real-time decision-making efficiency. Following the chronological development of artificial intelligence, the review systematically investigates smart fault detection methods applied to fault scenarios in distribution networks, with a particular emphasis on presenting fault type classification and fault localization separately to facilitate a logically structured understanding. In addition, common types of distribution network faults are examined, and the impact of distributed generation on fault behavior, electrical characteristics, and protection coordination is critically assessed. The review further distinguishes between artificial intelligence-based smart approaches that directly process raw distribution networks signal data and those that rely on advanced feature extraction techniques to enhance functional performance. This review also explores the emerging potential of large language models to enhance the explainability of diagnostics, support multi-agent coordination, and enable natural language-based fault reasoning. The insights offered herein are expected to provide practical guidance for engineers and researchers for selecting and deploying intelligent fault diagnosis strategies in future distribution networks with high distributed generation penetration.",Artificial intelligence | distributed generation | distribution networks | fault location | fault type classification,4,2025,sustainability,behavior+sustainability
314,2-s2.0-105011173439,10.1109/ACCESS.2025.3589319,https://doi.org/10.1109/ACCESS.2025.3589319,https://scholar.google.com/scholar?q=10.1109/ACCESS.2025.3589319,ar,IEEE Access,"Hassan, Mahbub;Kabir, Md Emtiaz;Jusoh, Muzammil;Ki An, Hong;Negnevitsky, Michael;Li, Chengjiang","Large Language Models in Transportation: A Comprehensive Bibliometric Analysis of Emerging Trends, Challenges, and Future Research","This paper presents a comprehensive review and bibliometric analysis of Large Language Models (LLMs) in transportation, exploring emerging trends, challenges and future research. Understanding their evolution and impact in transportation research is essential. The study used Scopus as the primary data source, applying Bibliometrix, VOSviewer, and Python for performance analysis and science mapping. This study analyzes 161 peer-reviewed articles and reveals a 25.74% annual growth in scholarly output. IEEE Transactions on Intelligent Transportation Systems and IEEE Transactions on Intelligent Vehicles emerge as the most influential journals by publication volume and impact on LLM research. The findings highlight global disparities in research contributions, with China and the United States dominating by publication volume, followed by Germany and Canada, while developing regions exhibit lower scientific productivity. In addition, the study provides qualitative insights by reviewing recent LLM applications in transportation, examining their key contributions, methodological approaches, inherent limitations, and domain-specific challenges. Key research themes focus on autonomous mobility, traffic optimization, and sustainable transportation networks. Despite significant progress, several challenges remain, including decision-making uncertainties, computational scalability, and high energy consumption. Overcoming these challenges requires greater transparency through causal learning, enhanced reasoning via hybrid AI models, and inclusive frameworks that address algorithmic bias and ensure equitable adoption.",Artificial intelligence | bibliometric analysis | intelligent transportation systems | large language models | smart mobility | transportation,4,2025,sustainability,behavior+sustainability
327,2-s2.0-105006667208,10.3389/fpls.2025.1583344,https://doi.org/10.3389/fpls.2025.1583344,https://scholar.google.com/scholar?q=10.3389/fpls.2025.1583344,re,Frontiers in Plant Science,"Yoosefzadeh-Najafabadi, Mohsen",From text to traits: exploring the role of large language models in plant breeding,"Modern plant breeders regularly deal with the intricate patterns within biological data in order to better understand the biological background behind a trait of interest and speed up the breeding process. Recently, Large Language Models (LLMs) have gained widespread adoption in everyday contexts, showcasing remarkable capabilities in understanding and generating human-like text. By harnessing the capabilities of LLMs, foundational models can be repurposed to uncover intricate patterns within biological data, leading to the development of robust and flexible predictive tools that provide valuable insights into complex plant breeding systems. Despite the significant progress made in utilizing LLMs in various scientific domains, their adoption within plant breeding remains unexplored, presenting a significant opportunity for innovation. This review paper explores how LLMs, initially designed for natural language tasks, can be adapted to address specific challenges in plant breeding, such as identifying novel genetic interactions, predicting performance of a trait of interest, and well-integrating diverse datasets such as multi-omics, phenotypic, and environmental sources. Compared to conventional breeding methods, LLMs offer the potential to enhance the discovery of genetic relationships, improve trait prediction accuracy, and facilitate informed decision-making. This review aims to bridge this gap by highlighting current advancements, challenges, and future directions for integrating LLMs into plant breeding, ultimately contributing to sustainable agriculture and improved global food security.",artificial intelligence | computational biology | knowledge graph | plant breeding | plant omics,4,2025,sustainability,behavior+sustainability
338,2-s2.0-105002578044,10.12133/j.smartag.SA202411005,https://doi.org/10.12133/j.smartag.SA202411005,https://scholar.google.com/scholar?q=10.12133/j.smartag.SA202411005,ar,Smart Agriculture,"Wu, Huarui;Zhao, Chunjiang;Li, Jingchen",Agri-QA Net: Multimodal Fusion Large Language Model Architecture for Crop Knowledge Question-Answering System,"[Objective] As agriculture increasingly relies on technological innovations to boost productivity and ensure sustainability, farmers need efficient and accurate tools to aid their decision-making processes. A key challenge in this context is the retrieval of specialized agricultural knowledge, which can be complex and diverse in nature. Traditional agricultural knowledge retrieval systems have often been limited by the modalities they utilize (e.g., text or images alone), which restricts their effectiveness in addressing the wide range of queries farmers face. To address this challenge, a specialized multimodal question-answering system tailored for cabbage cultivation was proposed. The system, named Agri-QA Net, integrates multimodal data to enhance the accuracy and applicability of agricultural knowledge retrieval. By incorporating diverse data modalities, Agri-QA Net aims to provide a holistic approach to agricultural knowledge retrieval, enabling farmers to interact with the system using multiple types of input, ranging from spoken queries to images of crop conditions. By doing so, it helps address the complexity of real-world agricultural environments and improves the accessibility of relevant information. [Methods] The architecture of Agri-QA Net was built upon the integration of multiple data modalities, including textual, auditory, and visual data. This multifaceted approach enables the system to develop a comprehensive understanding of agricultural knowledge, allowed the system to learn from a wide array of sources, enhancing its robustness and generalizability. The system incorporated state-of-the-art deep learning models, each designed to handle one specific type of data. Bidirectional Encoder Representations from Transformers (BERT)'s bidirectional attention mechanism allowed the model to understand the context of each word in a given sentence, significantly improving its ability to comprehend complex agricultural terminology and specialized concepts. The system also incorporated acoustic models for processing audio inputs. These models analyzed the spoken queries from farmers, allowing the system to understand natural language inputs even in noisy, non-ideal environments, which was a common challenge in real-world agricultural settings. Additionally, convolutional neural networks (CNNs) were employed to process images from various stages of cabbage growth. CNNs were highly effective in capturing spatial hierarchies in images, making them well-suited for tasks such as identifying pests, diseases, or growth abnormalities in cabbage crops. These features were subsequently fused in a Transformer-based fusion layer, which served as the core of the Agri-QA Net architecture. The fusion process ensured that each modality—text, audio, and image—contributes effectively to the final model's understanding of a given query. This allowed the system to provide more nuanced answers to complex agricultural questions, such as identifying specific crop diseases or determining the optimal irrigation schedules for cabbage crops. In addition to the fusion layer, cross-modal attention mechanisms and domain-adaptive techniques were incorporated to refine the model's ability to understand and apply specialized agricultural knowledge. The cross-modal attention mechanism facilitated dynamic interactions between the text, audio, and image data, ensuring that the model paid attention to the most relevant features from each modality. Domain-adaptive techniques further enhanced the system's performance by tailoring it to specific agricultural contexts, such as cabbage farming, pest control, or irrigation management. [Results and Discussions] The experimental evaluations demonstrated that Agri-QA Net outperforms traditional single-modal or simple multimodal models in agricultural knowledge tasks. With the support of multimodal inputs, the system achieved an accuracy rate of 89.5%, a precision rate of 87.9%, a recall rate of 91.3%, and an F<inf>1</inf>-Score of 89.6%, all of which are significantly higher than those of single-modality models. The integration of multimodal data significantly enhanced the system's capacity to understand complex agricultural queries, providing more precise and context-aware answers. The addition of cross-modal attention mechanisms enabled for more nuanced and dynamic interaction between the text, audio, and image data, which in turn improved the model's understanding of ambiguous or context-dependent queries, such as disease diagnosis or crop management. Furthermore, the domain-adaptive technique enabled the system to focus on specific agricultural terminology and concepts, thereby enhancing its performance in specialized tasks like cabbage cultivation and pest control. The case studies presented further validated the system's ability to assist farmers by providing actionable, domain-specific answers to questions, demonstrating its practical application in real-world agricultural scenarios. [Conclusions] The proposed Agri-QA Net framework is an effective solution for addressing agricultural knowledge questions, especially in the domain of cabbage cultivation. By integrating multimodal data and leveraging advanced deep learning techniques, the system demonstrates a high level of accuracy and adaptability. This study not only highlights the potential of multimodal fusion in agriculture but also paves the way for future developments in intelligent systems designed to support precision farming. Further work will focus on enhancing the model's performance by expanding the dataset to include more diverse agricultural scenarios, refining the handling of dialectical variations in audio inputs, and improving the system's ability to detect rare crop diseases. The ultimate goal is to contribute to the modernization of agricultural practices, offering farmers more reliable and effective tools to solve the challenges in crop management.",agricultural knowledge Q&A | cabbage crops | human-computer interaction | large language model | multimodal fusion,4,2025,sustainability,behavior+sustainability
387,2-s2.0-85215277879,10.24818/EA/2024/S18/1241,https://doi.org/10.24818/EA/2024/S18/1241,https://scholar.google.com/scholar?q=10.24818/EA/2024/S18/1241,ar,Amfiteatru Economic,"Boloș, Marcel Ioan;Rusu, Ștefan;Sabău-Popa, Claudia Diana;Gherai, Dana Simona;Negrea, Adrian;Crișan, Mihai Ioan",AI CHATBOTS: FAST TRACKING SUSTAINABILITY REPORT ANALYSIS FOR ENHANCED DECISION MAKING,"This paper explores the integration of artificial intelligence (AI) in businesses, focusing on the utility of chatbots for sustainability report analysis. Using ChatGPT technology via the Chat-based platform, we developed a personalised chatbot to extract data from sustainability reports, with the aim of facilitating decision-making processes. The study includes a literature review on AI's impact on the economy and labour markets, followed by a methodology base on technology ChatGPT detailing chatbot development and testing using a sustainability report of a company listed on the Romanian stock market. The results demonstrate the efficacy in providing accurate financial insights, offering potential benefits for analysts, investors, and business organisations managers. By harnessing AI-powered chatbots, organisations can streamline operations and gain a competitive edge in today's digital landscape.",artificial intelligence | chatbot | decision-making | finance | financial analysis,4,2024,sustainability,behavior+sustainability
38,2-s2.0-85218416379,10.1186/s12302-025-01067-z,https://doi.org/10.1186/s12302-025-01067-z,https://scholar.google.com/scholar?q=10.1186/s12302-025-01067-z,ar,Environmental Sciences Europe,"Villacampa-Porta, Javier;Coronado-Vaca, María;Garrido-Merchán, Eduardo C.",Impact of EU non-financial reporting regulation on Spanish companies’ environmental disclosure: a cutting-edge natural language processing approach,"Background: A debate exists about the effects of environmental disclosure becoming mandatory on the quality and the actual commitment of such reporting. This study seeks to assess whether differences exist when comparing the disclosure quality and comprehensiveness of Spanish companies’ non-financial reports under voluntary and mandatory reporting regimes spanning the period 2015–2022. Methods: We present a novel approach by utilizing cutting-edge Natural Language Processing (NLP) techniques, chiefly ClimateBERT (a transformer-LLM—Large Language Model) and ClimateBERT fine-tuned on ClimaText (a public database for climate change topic detection), to scrutinize and compare 729 voluntary and mandatory non-financial corporate reports from 96 Spanish companies spanning multiple sectors. Since transformers can only be accurately estimated by organizations with lots of computing power, but not by small organizations, we have also fine-tuned the transformer, something cheaper in computational terms, thus making it affordable to all companies, investors, regulators, policymakers, and other stakeholders. Results: Our results document interesting patterns and strong trends of enhancement in specificity and commitment, particularly in risk-related texts, spanning the period 2015–2022. We provide descriptive evidence and an explorative appeal that underscores the regulations' influence, among many other factors also identified by prior literature (other stakeholders’ requirements and expectations from companies, aside from the regulatory stakeholders), in fostering a higher quality and more comprehensive approach to climate risk reporting by Spanish companies, with enhanced alignment to internationally recognized reporting guidelines. In addition, the comparative analysis between the transformer model and the fine-tuned transformer model revealed subtle yet insightful differences in how climate disclosures are interpreted. The fine-tuned model exhibited an increased sensitivity to elements of commitment, specificity, and neutrality in climate texts. Conclusions: Our findings highlight the potential of cutting-edge NLP techniques, like fine-tuned transformers, in the quantitative assessment of the evolution and quality of environmental disclosures, either mandatory or voluntary. It is the first paper applying a fine-tuned transformer-LLM to compare the currently in force European mandatory environmental disclosure regulation’s impact on Spanish companies' environmental disclosure versus previous voluntary reporting.",Climate-related risks impact | ClimateBERT | ClimaText | Environmental corporate reports | Environmental disclosure | Large Language Models (LLM) | Mandatory disclosure | Pre-trained transformer | Sustainability reporting | Voluntary disclosure,4,2025,sustainability,policy+sustainability
76,2-s2.0-105009533675,10.1038/s41598-025-05892-3,https://doi.org/10.1038/s41598-025-05892-3,https://scholar.google.com/scholar?q=10.1038/s41598-025-05892-3,ar,Scientific Reports,"Danvirutai, Pobporn;Charoenwattanasak, Siripavee;Tola, Siriporn;Thaiso, Kampon;Yuangsoi, Bundit;Minh, Hoang Trong;Srichan, Chavis",An integrating RAG-LLM and deep Q-network framework for intelligent fish control systems,"The fish farming industry is advancing by adopting technologies designed to enhance efficiency, productivity, and sustainability. This study investigates integrating a Retrieval-Augmented Generation Large Language Model (RAG-LLM) with a Deep Q-Network (DQN) in autonomous aquaculture. It compares their performance to traditional expert-led methods and other AI-based systems. The developed autonomous system employs ensemble learning of RAG-LLM and DQN, incorporating IoT devices to thoroughly monitor feeding schedules, disease management, growth, and water quality parameters. This integration allows the system to generate optimal policies through majority voting, leveraging pre-trained LLM knowledge to improve initialization conditions and accelerate learning convergence. The hybrid approach of RAG-LLM and DQN demonstrates superior growth rates and rapid stabilization of automation policies. This highlights its potential to enable non-experts to manage fish farms and efficiently scale production for global food sustainability.",Deep Q networks | Experts | Intelligent aquaculture system | Large language models (LLMs) | Retrieval-augmented generation (RAG),4,2025,sustainability,policy+sustainability
134,2-s2.0-105008586498,10.1016/j.cities.2025.106183,https://doi.org/10.1016/j.cities.2025.106183,https://scholar.google.com/scholar?q=10.1016/j.cities.2025.106183,ar,Cities,"Zhu, Haixuan;Chang, Jiang;An, Xinyu;Li, Shilin",Global and local feature extraction of urban historical spatial perception using large language models: A case study of Harbin Central Street District,"Spatial perception—the process by which individuals interpret and interact with their spatial environment—is a cornerstone of urban studies, forming the foundation for effective urban planning and policy-making. This study introduces innovative, digital methodologies for spatial perception analysis by integrating advanced technologies, including Large Language Models (LLMs) and BERTopic modeling. Using Harbin Central Street District, a historically significant urban area celebrated for its architectural heritage and scenic landscapes, as a case study, this research develops a replicable and scalable workflow for analyzing spatial perception. The study identifies global spatial perception patterns, such as pedestrian dynamics, green spaces, and cultural landmarks, alongside local themes unique to Central Street and Stalin Park. Key contributions include leveraging LLMs to generate synthetic text data from urban imagery, applying high-dimensional semantic vector models for topic analysis, and utilizing dynamic modeling techniques to extract both global and local spatial features. The findings reveal how historical architecture, commercial vibrancy, and natural environments interact to shape urban experiences, aligning closely with established spatial metrics. This research provides actionable insights for urban planning and policy, emphasizing heritage preservation, pedestrian-oriented design, and adaptive strategies. By bridging AI-driven technologies with urban research, this study offers a scalable, data-driven framework for analyzing spatial perceptions, advancing the digital transformation of cities, and promoting sustainable, inclusive urban development in the AI era.","BERTopic | Harbin Central Street | Harbin Stalin Park | Large language models (LLMs) | Spatial perception, global and local feature",4,2025,sustainability,policy+sustainability
155,2-s2.0-105002233570,10.1111/isj.12593,https://doi.org/10.1111/isj.12593,https://scholar.google.com/scholar?q=10.1111/isj.12593,ar,Information Systems Journal,"Haki, Kazem;Safaei, Dorsa;Magan, Adolfo;Griffiths, Martin",Integrating Generative AI Into Enterprise Platforms: Insights From Salesforce,"The widespread applications of generative AI (GenAI) have sparked significant interest, with many organisations eager to leverage its transformative potential. Rather than focusing on individual organisations, this study examines GenAI integration within enterprise platforms, which are extensively adopted by many organisations and thus amplify both the benefits and risks of GenAI. We offer targeted recommendations for enterprise platform owners and their complementors, addressing challenges they face when integrating GenAI into these platforms. Drawing on a case study of Salesforce's experience, we recommend actions in three foundational areas – platform capability, architecture and governance – ensuring that our guidance is broadly applicable across enterprise platforms. In platform capability, we advise developing a unified GenAI stack built on existing platform services, offering generic and industry-specific GenAI use cases to accelerate customer adoption and providing tools for customisation and creation of new use cases to enhance GenAI's transformational impact. For platform architecture, we recommend adding new layers for accommodating diverse GenAI foundation models and creating a trusted environment for secure data access, privacy and content monitoring. We also recommend implementing a prompt architecture to improve content relevance and accuracy. In platform governance, we recommend establishing new mechanisms to mitigate GenAI risks. Partnerships with GenAI providers and proactive investments in GenAI are essential to retain critical GenAI technologies. Personalised consultancy and training along with joint design and implementation with platform customers are also recommended. These combined actions, pursued in parallel across capability, architecture and governance, form a sustainable roadmap for GenAI integration in enterprise platforms.",Enterprise platforms | generative AI | platform architecture | platform capability | platform governance,4,2025,sustainability,policy+sustainability
166,2-s2.0-105013200683,10.3390/buildings15152631,https://doi.org/10.3390/buildings15152631,https://scholar.google.com/scholar?q=10.3390/buildings15152631,re,Buildings,"Amangeldy, Bibars;Imankulov, Timur;Tasmurzayev, Nurdaulet;Dikhanbayeva, Gulmira;Nurakhov, Yedil",A Review of Artificial Intelligence and Deep Learning Approaches for Resource Management in Smart Buildings,"This comprehensive review maps the fast-evolving landscape in which artificial intelligence (AI) and deep-learning (DL) techniques converge with the Internet of Things (IoT) to manage energy, comfort, and sustainability across smart environments. A PRISMA-guided search of four databases retrieved 1358 records; after applying inclusion criteria, 143 peer-reviewed studies published between January 2019 and April 2025 were analyzed. This review shows that AI-driven controllers—especially deep-reinforcement-learning agents—deliver median energy savings of 18–35% for HVAC and other major loads, consistently outperforming rule-based and model-predictive baselines. The evidence further reveals a rapid diversification of methods: graph-neural-network models now capture spatial interdependencies in dense sensor grids, federated-learning pilots address data-privacy constraints, and early integrations of large language models hint at natural-language analytics and control interfaces for heterogeneous IoT devices. Yet large-scale deployment remains hindered by fragmented and proprietary datasets, unresolved privacy and cybersecurity risks associated with continuous IoT telemetry, the growing carbon and compute footprints of ever-larger models, and poor interoperability among legacy equipment and modern edge nodes. The authors of researches therefore converges on several priorities: open, high-fidelity benchmarks that marry multivariate IoT sensor data with standardized metadata and occupant feedback; energy-aware, edge-optimized architectures that lower latency and power draw; privacy-centric learning frameworks that satisfy tightening regulations; hybrid physics-informed and explainable models that shorten commissioning time; and digital-twin platforms enriched by language-model reasoning to translate raw telemetry into actionable insights for facility managers and end users. Addressing these gaps will be pivotal to transforming isolated pilots into ubiquitous, trustworthy, and human-centered IoT ecosystems capable of delivering measurable gains in efficiency, resilience, and occupant wellbeing at scale.",deep learning | energy efficiency | federated learning | graph neural networks | IoT | reinforcement learning | smart buildings,4,2025,sustainability,policy+sustainability
307,2-s2.0-105015436710,10.3389/frai.2025.1649155,https://doi.org/10.3389/frai.2025.1649155,https://scholar.google.com/scholar?q=10.3389/frai.2025.1649155,re,Frontiers in Artificial Intelligence,"Hartung, Thomas","AI, agentic models and lab automation for scientific discovery — the beginning of scAInce","Until recently, the conversation about generative artificial intelligence in science revolved around the textual prowess of large language models such as GPT-3.5 and the promise that they might one day draft a decent literature review. Since then, progress has been nothing short of breathtaking. We now find ourselves in the era of multimodal, agentic systems that listen, see, speak and act, orchestrating cloud software and physical laboratory hardware with a fluency that would have sounded speculative in early 2023. In this review, I merge the substance of our 2024 white paper for the World Economic Forum Top-10-Technologies Report with the latest advances through mid-2025, charting a course from automated literature synthesis and hypothesis generation to self-driving laboratories, organoid intelligence and climate-scale forecasting. The discussion is grounded in emerging governance regimes—notably the European Union Artificial Intelligence Act and ISO 42001—and is written from the dual vantage-point of a toxicologist who has spent a career championing robust, humane science and of a field chief editor charged with safeguarding scholarly standards in Frontiers in Artificial Intelligence. I argue that research is entering a “co-pilot to lab-pilot” transition in which AI no longer merely interprets knowledge but increasingly acts upon it. This shift promises dramatic efficiency gains yet simultaneously amplifies concerns about reproducibility, auditability, safety and equitable access.",AI governance | generative artificial intelligence | microphysiological systems | predictive toxicology | scAInce paradigm | scientific discovery | self-driving laboratories,4,2025,sustainability,policy+sustainability
343,2-s2.0-85213425251,10.3390/soc14120268,https://doi.org/10.3390/soc14120268,https://scholar.google.com/scholar?q=10.3390/soc14120268,ar,Societies,"Bodini, Matteo",Generative Artificial Intelligence and Regulations: Can We Plan a Resilient Journey Toward the Safe Application of Generative Artificial Intelligence?,"The rapid advancements of Generative Artificial Intelligence (GenAI) technologies, such as the well-known OpenAI ChatGPT and Microsoft Copilot, have sparked significant societal, economic, and regulatory challenges. Indeed, while the latter technologies promise unprecedented productivity gains, they also raise several concerns, such as job loss and displacement, deepfakes, and intellectual property violations. The present article aims to explore the present regulatory landscape of GenAI across the major global players, highlighting the divergent approaches adopted by the United States, United Kingdom, China, and the European Union. By drawing parallels with other complex global issues such as climate change and nuclear proliferation, this paper argues that the available traditional regulatory frameworks may be insufficient to address the unique challenges posed by GenAI. As a result, this article introduces a resilience-focused regulatory approach that emphasizes aspects such as adaptability, swift incident response, and recovery mechanisms to mitigate potential harm. By analyzing the existing regulations and suggesting potential future directions, the present article aims to contribute to the ongoing discourse on how to effectively govern GenAI technologies in a rapidly evolving regulatory landscape.",GenAI | GenAI regulations | GenAI regulatory framework | resilience,4,2024,sustainability,policy+sustainability
461,2-s2.0-105005411333,10.1007/s10916-025-02192-1,https://doi.org/10.1007/s10916-025-02192-1,https://scholar.google.com/scholar?q=10.1007/s10916-025-02192-1,ar,Journal of Medical Systems,"Xu, Jun;Wang, Junjie;Li, Junjun;Zhu, Zhangxiang;Fu, Xiao;Cai, Wei;Song, Ruipeng;Wang, Tengfei;Li, Hai",Predicting Immunotherapy Response in Unresectable Hepatocellular Carcinoma: A Comparative Study of Large Language Models and Human Experts,"Hepatocellular carcinoma (HCC) is an aggressive cancer with limited biomarkers for predicting immunotherapy response. Recent advancements in large language models (LLMs) like GPT-4, GPT-4o, and Gemini offer the potential for enhancing clinical decision-making through multimodal data analysis. However, their effectiveness in predicting immunotherapy response, especially compared to human experts, remains unclear. This study assessed the performance of GPT-4, GPT-4o, and Gemini in predicting immunotherapy response in unresectable HCC, compared to radiologists and oncologists of varying expertise. A retrospective analysis of 186 patients with unresectable HCC utilized multimodal data (clinical and CT images). LLMs were evaluated with zero-shot prompting and two strategies: the ‘voting method’ and the ‘OR rule method’ for improved sensitivity. Performance metrics included accuracy, sensitivity, area under the curve (AUC), and agreement across LLMs and physicians.GPT-4o, using the ‘OR rule method,’ achieved 65% accuracy and 47% sensitivity, comparable to intermediate physicians but lower than senior physicians (accuracy: 72%, p = 0.045; sensitivity: 70%, p < 0.0001). Gemini-GPT, combining GPT-4, GPT-4o, and Gemini, achieved an AUC of 0.69, similar to senior physicians (AUC: 0.72, p = 0.35), with 68% accuracy, outperforming junior and intermediate physicians while remaining comparable to senior physicians (p = 0.78). However, its sensitivity (58%) was lower than senior physicians (p = 0.0097). LLMs demonstrated higher inter-model agreement (κ = 0.59–0.70) than inter-physician agreement, especially among junior physicians (κ = 0.15). This study highlights the potential of LLMs, particularly Gemini-GPT, as valuable tools in predicting immunotherapy response for HCC.",Artificial intelligence | Computed tomography | Hepatocellular carcinoma | Immunotherapy | Large language models | Response,3,2025,behavior,behavior+policy
463,2-s2.0-105004434766,10.1186/s12909-025-07250-3,https://doi.org/10.1186/s12909-025-07250-3,https://scholar.google.com/scholar?q=10.1186/s12909-025-07250-3,ar,BMC Medical Education,"Altermatt, Fernando R.;Neyem, Andres;Sumonte, Nicolas;Mendoza, Marcelo;Villagran, Ignacio;Lacassie, Hector J.",Performance of single-agent and multi-agent language models in Spanish language medical competency exams,"Background: Large language models (LLMs) like GPT-4o have shown promise in advancing medical decision-making and education. However, their performance in Spanish-language medical contexts remains underexplored. This study evaluates the effectiveness of single-agent and multi-agent strategies in answering questions from the EUNACOM, a standardized medical licensure exam in Chile, across 21 medical specialties. Methods: GPT-4o was tested on 1,062 multiple-choice questions from publicly available EUNACOM preparation materials. Single-agent strategies included Zero-Shot, Few-Shot, Chain-of-Thought (CoT), Self-Reflection, and MED-PROMPT, while multi-agent strategies involved Voting, Weighted Voting, Borda Count, MEDAGENTS, and MDAGENTS. Each strategy was tested under three temperature settings (0.3, 0.6, 1.2). Performance was assessed by accuracy, and statistical analyses, including Kruskal–Wallis and Mann–Whitney U tests, were performed. Computational resource utilization, such as API calls and execution time, was also analyzed. Results: MDAGENTS achieved the highest accuracy with a mean score of 89.97% (SD = 0.56%), outperforming all other strategies (p < 0.001). MEDAGENTS followed with a mean score of 87.99% (SD = 0.49%), and the CoT with Few-Shot strategy scored 87.67% (SD = 0.12%). Temperature settings did not significantly affect performance (F2,54 = 1.45, p = 0.24). Specialty-level analysis showed the highest accuracies in Psychiatry (95.51%), Neurology (95.49%), and Surgery (95.38%), while lower accuracies were observed in Neonatology (77.54%), Otolaryngology (76.64%), and Urology/Nephrology (76.59%). Notably, several exam questions were correctly answered using simpler single-agent strategies without employing complex reasoning or collaboration frameworks. Conclusions and relevance: Multi-agent strategies, particularly MDAGENTS, significantly enhance GPT-4o’s performance on Spanish-language medical exams, leveraging collaboration to improve diagnostic accuracy. However, simpler single-agent strategies are sufficient to address many questions, high-lighting that only a fraction of standardized medical exams require sophisticated reasoning or multi-agent interaction. These findings suggest potential for LLMs as efficient and scalable tools in Spanish-speaking healthcare, though computational optimization remains a key area for future research.",GPT-4o | Large language models | Medical AI | Medical decision-making | Spanish medical contexts,3,2025,behavior,behavior+policy
465,2-s2.0-105002579984,10.1002/jls.70005,https://doi.org/10.1002/jls.70005,https://scholar.google.com/scholar?q=10.1002/jls.70005,ar,Journal of Leadership Studies,"Tabata, Mary;Wildermuth, Cris;Bottomley, Kevin;Jenkins, Daniel","Generative AI Integration in Leadership Practice: Foundations, Challenges, and Opportunities","Integrating generative artificial intelligence (GenAI) into leadership practice represents a pivotal transformation in organizational dynamics, presenting unprecedented opportunities and complex challenges. The current article develops a comprehensive conceptual framework grounded in sociotechnical systems and complex adaptive leadership theories to guide future research and practice. By carefully examining leader-follower relationships, decision-making processes, and organizational learning patterns, we demonstrate how GenAI reshapes traditional leadership paradigms while raising critical ethical considerations. Our analysis reveals four key areas demanding attention: ethical decision-making in AI implementation, trust dynamics between human and artificial agents, GenAI literacy development across organizational levels, and integrating AI systems with existing organizational structures and governance policies. The framework emphasizes the crucial balance between technological advancement and human-centered leadership, particularly highlighting how the Human Interaction lens can guide responsible AI adoption. By identifying specific research questions in each domain, the article provides a roadmap for scholars and practitioners navigating the evolving landscape of AI-enhanced leadership.",,3,2025,behavior,behavior+policy
485,2-s2.0-105006939096,10.1016/j.teln.2025.04.014,https://doi.org/10.1016/j.teln.2025.04.014,https://scholar.google.com/scholar?q=10.1016/j.teln.2025.04.014,ar,Teaching and Learning in Nursing,"Borromeo, Alex S.;Manaloto, Allan M.;Santos, Mark Jerome M.Delos;Antonio, Ronilo P.;Soyosa, Magdalena D.;Wider, Walton",Harnessing generative AI in nursing education: A bibliometric review,"Background: The integration of generative artificial intelligence (AI) in nursing education offers opportunities for personalized learning, clinical decision-making support, and simulation- based training. However, concerns remain about pedagogical, ethical, and practical implications. Aim: This study aimed to map the existing literature and identify key trends, gaps, and emerging themes in the use of generative AI in nursing education. Methods: A bibliometric review was conducted using Scopus-indexed publications. Co-citation and co- word analyses were performed to examine the intellectual structure and conceptual development of the field. Results: Co-citation analysis revealed five thematic clusters, including ChatGPT integration, clinical competence development, and ethical concerns. Co-word analysis identified four clusters focusing on innovation, curriculum reform, and psychological aspects. A rise in publications was observed after 2020, with focal areas including adaptive learning and AI literacy. Barriers include lack of standard implementation frameworks and concerns over overreliance. Conclusions: This review proposes a framework for ethical and effective AI integration in nursing education and outlines future research directions related to clinical impact, faculty readiness, and regulation.",AI for inclusive healthcare education | Education quality | Generative AI | Healthcare innovation | Nursing education,3,2025,behavior,behavior+policy
487,2-s2.0-105004479262,10.1016/j.eqrea.2025.100378,https://doi.org/10.1016/j.eqrea.2025.100378,https://scholar.google.com/scholar?q=10.1016/j.eqrea.2025.100378,ar,Earthquake Research Advances,"Xie, Chenchen;Gao, Huiran;Huang, Yuandong;Xue, Zhiwen;Xu, Chong;Dai, Kebin","Leveraging the DeepSeek large model: A framework for AI-assisted disaster prevention, mitigation, and emergency response systems","We proposes an AI-assisted framework for integrated natural disaster prevention and emergency response, leveraging the DeepSeek large language model (LLM) to advance intelligent decision-making in geohazard management. We systematically analyze the technical pathways for deploying LLMs in disaster scenarios, emphasizing three breakthrough directions: (1) knowledge graph-driven dynamic risk modeling, (2) reinforcement learning-optimized emergency decision systems, and (3) secure local deployment architectures. The DeepSeek model demonstrates unique advantages through its hybrid reasoning mechanism combining semantic analysis with geospatial pattern recognition, enabling cost-effective processing of multi-source data spanning historical disaster records, real-time IoT sensor feeds, and socio-environmental parameters. A modular system architecture is designed to achieve three critical objectives: (a) automated construction of domain-specific knowledge graphs through unsupervised learning of disaster physics relationships, (b) scenario-adaptive resource allocation using risk simulations, and (c) preserving emergency coordination via federated learning across distributed response nodes. The proposed local deployment paradigm addresses critical data security concerns in cross-border disaster management while complying with the FAIR principles (Findable, Accessible, Interoperable, Reusable) for geoscientific data governance. This work establishes a methodological foundation for next-generation AI-earth science convergence in disaster mitigation.",AI large language models | DeepSeek | Emergency assistance | Natural disaster prevention and control | System framework research,3,2025,behavior,behavior+policy
491,2-s2.0-105017853828,10.3390/automation6030029,https://doi.org/10.3390/automation6030029,https://scholar.google.com/scholar?q=10.3390/automation6030029,ar,Automation,"Tiwari, Alok",Beyond Automation: The Emergence of Agentic Urban AI,"Urban systems are transforming as artificial intelligence (AI) evolves from automation to Agentic Urban AI (AI systems with autonomous goal-setting and decision-making capabilities), which independently define and pursue urban objectives. This shift necessitates reassessing governance, planning, and ethics. Using a conceptual-methodological approach, this study integrates urban studies, AI ethics, and governance theory. Through a literature review and case studies of platforms like Alibaba’s City Brain and CityMind AI Agent, it identifies early agency indicators, such as strategic adaptation and goal re-prioritisation. A typology distinguishing automation, autonomy, and agency clarifies AI-driven urban decision-making. Three trajectories are proposed: fully autonomous Agentic AI, collaborative Hybrid Urban Agency, and constrained Non-Agentic AI to mitigate ethical risks. The findings highlight the need for participatory, transparent governance to ensure democratic accountability and social equity in cognitive urban ecosystems.",Agentic Urban AI | artificial intelligence ethics | autonomy and agency in urban systems | smart cities | urban governance,3,2025,behavior,behavior+policy
502,2-s2.0-105015371951,10.2478/eoik-2025-0063,https://doi.org/10.2478/eoik-2025-0063,https://scholar.google.com/scholar?q=10.2478/eoik-2025-0063,ar,Economics Innovative and Economics Research Journal,"Yordanova, Zornitsa;Hristozov, Yanko",THE EVOLUTION OF FINANCIAL ANALYSIS: FROM MANUAL METHODS TO AI AND AI AGENTS,"Purpose: This study examines the transformation of financial decision-making through the adoption of artificial intelligence, focusing on the shift from conventional AI systems to AI agents and agentic AI. It differentiates between automated analytical tools and autonomous, goal-oriented systems that increasingly assume decision-making authority within financial operations. Design/Methodology/Approach: Employing a qualitative multi-method approach—comprising semi-structured expert interviews, industry report synthesis, in-depth case studies, and a comparative performance evaluation—this research investigates AI agent implementation across SMEs, pharmaceutical analytics, and ERP-integrated corporate finance. Theoretically, it extends foundational models including the Efficient Market Hypothesis (EMH), Behavioral Finance, and the Adaptive Markets Hypothesis (AMH) by embedding the dynamic, learning-driven nature of AI agents into financial decision logic. Findings: The results indicate that AI agents introduce novel forms of informational asymmetry, enhance bias mitigation through adaptive modeling, and give rise to emergent decision structures via multi-agent interactions. These dynamics challenge core assumptions of market rationality and static efficiency. Practically, the study offers a structured framework for AI agent integration, emphasizing explainability, hybrid human-AI governance, and risk-specific safeguards to navigate ethical and regulatory constraints. The proposed conceptual taxonomy and cross-industry implementation roadmap reposition agentic AI as a strategic transformation—reshaping how financial institutions process data, execute judgments, and regulate algorithmic autonomy.",Agentic AI | AI Agents | Artificial Intelligence (AI) | Financial Analytics | Financial Decision-Making | Financial Technology (FinTech),3,2025,behavior,behavior+policy
506,2-s2.0-105002655982,10.1016/j.aiia.2025.04.001,https://doi.org/10.1016/j.aiia.2025.04.001,https://scholar.google.com/scholar?q=10.1016/j.aiia.2025.04.001,re,Artificial Intelligence in Agriculture,"Kpodo, Josué;Nejadhashemi, A. Pouyan",Navigating challenges/opportunities in developing smart agricultural extension platforms: Multi-media data mining techniques,"Agricultural Extension (AE) research faces significant challenges in producing relevant and practical knowledge due to rapid advancements in artificial intelligence (AI). AE struggles to keep pace with these advancements, complicating the development of actionable information. One major challenge is the absence of intelligent platforms that enable efficient information retrieval and quick decision-making. Investigations have shown a shortage of AI-assisted solutions that effectively use AE materials across various media formats while preserving scientific accuracy and contextual relevance. Although mainstream AI systems can potentially reduce decision-making risks, their usage remains limited. This limitation arises primarily from the lack of standardized datasets and concerns regarding user data privacy. For AE datasets to be standardized, they must satisfy four key criteria: inclusion of critical domain-specific knowledge, expert curation, consistent structure, and acceptance by peers. Addressing data privacy issues involves adhering to open-access principles and enforcing strict data encryption and anonymization standards. To address these gaps, a conceptual framework is introduced. This framework extends beyond typical user-oriented platforms and comprises five core modules. It features a neurosymbolic pipeline integrating large language models with physically based agricultural modeling software, further enhanced by Reinforcement Learning from Human Feedback. Notable aspects of the framework include a dedicated human-in-the-loop process and a governance structure consisting of three primary bodies focused on data standardization, ethics and security, and accountability and transparency. Overall, this work represents a significant advancement in agricultural knowledge systems, potentially transforming how AE services deliver critical information to farmers and other stakeholders.",Agriculture extension | Artificial intelligence | Decision-making | Large language models | Multi-media data mining,3,2025,behavior,behavior+policy
512,2-s2.0-105014342459,10.3390/a18080499,https://doi.org/10.3390/a18080499,https://scholar.google.com/scholar?q=10.3390/a18080499,re,Algorithms,"Brohi, Sarfraz;Mastoi, Qurat Ul Ain;Jhanjhi, N. Z.;Pillai, Thulasyammal Ramiah","A Research Landscape of Agentic AI and Large Language Models: Applications, Challenges and Future Directions","Agentic AI and Large Language Models (LLMs) are transforming how language is understood and generated while reshaping decision-making, automation, and research practices. LLMs provide underlying reasoning capabilities, and Agentic AI systems use them to perform tasks through interactions with external tools, services, and Application Programming Interfaces (APIs). Based on a structured scoping review and thematic analysis, this study identifies that core challenges of LLMs, relating to security, privacy and trust, misinformation, misuse and bias, energy consumption, transparency and explainability, and value alignment, can propagate into Agentic AI. Beyond these inherited concerns, Agentic AI introduces new challenges, including context management, security, privacy and trust, goal misalignment, opaque decision-making, limited human oversight, multi-agent coordination, ethical and legal accountability, and long-term safety. We analyse the applications of Agentic AI powered by LLMs across six domains: education, healthcare, cybersecurity, autonomous vehicles, e-commerce, and customer service, to reveal their real-world impact. Furthermore, we demonstrate some LLM limitations using DeepSeek-R1 and GPT-4o. To the best of our knowledge, this is the first comprehensive study to integrate the challenges and applications of LLMs and Agentic AI within a single forward-looking research landscape that promotes interdisciplinary research and responsible advancement of this emerging field.","Agentic AI | DeepSeek-R1 | future Agentic AI research | GPT-4o | large language models (LLMs) | multi-agent systems | next-generation AI | technical, legal, and ethical challenges",3,2025,behavior,behavior+policy
516,2-s2.0-105011840634,10.1111/nyas.15413,https://doi.org/10.1111/nyas.15413,https://scholar.google.com/scholar?q=10.1111/nyas.15413,ar,Annals of the New York Academy of Sciences,"Lopez-Lopez, Ezequiel;Abels, Christoph M.;Holford, Dawn;Herzog, Stefan M.;Lewandowsky, Stephan",Generative artificial intelligence–mediated confirmation bias in health information seeking,"Generative artificial intelligence (GenAI) applications, such as ChatGPT, are transforming how individuals access health information, offering conversational and highly personalized interactions. While these technologies can enhance health literacy and decision-making, their capacity to generate deeply tailored—hypercustomized—responses risks amplifying confirmation bias by reinforcing pre-existing beliefs, obscuring medical consensus, and perpetuating misinformation, posing significant challenges to public health. This paper examines GenAI-mediated confirmation bias in health information seeking, driven by the interplay between GenAI's hypercustomization capabilities and users’ confirmatory tendencies. Drawing on parallels with traditional online information-seeking behaviors, we identify three key “pressure points” where biases might emerge: query phrasing, preference for belief-consistent content, and resistance to belief-inconsistent information. Using illustrative examples, we highlight the limitations of existing safeguards and argue that even minor variations in applications’ configuration (e.g., Custom GPT) can exacerbate these biases along those pressure points. Given the widespread adoption and fragmentation (e.g., OpenAI's GPT Store) of GenAI applications, their influence on health-seeking behaviors demands urgent attention. Since technical safeguards alone may be insufficient, we propose a set of interventions, including enhancing digital literacy, empowering users with critical engagement strategies, and implementing robust regulatory oversight. These recommendations aim to ensure the safe integration of GenAI into daily life, supporting informed decision-making and preserving the integrity of public understanding of health information.",confirmation bias | generative artificial intelligence | hypercustomization | information seeking | public health,3,2025,behavior,behavior+policy
525,2-s2.0-105011510324,10.1093/ehjdh/ztaf028,https://doi.org/10.1093/ehjdh/ztaf028,https://scholar.google.com/scholar?q=10.1093/ehjdh/ztaf028,re,European Heart Journal Digital Health,"Santos, José Ferreira;Ladeiras-Lopes, Ricardo;Leite, Francisca;Dores, Hélder",Applications of large language models in cardiovascular disease: a systematic review,"Cardiovascular disease (CVD) remains the leading cause of morbidity and mortality worldwide. Large language models (LLMs) offer potential solutions for enhancing patient education and supporting clinical decision-making. This study aimed to evaluate LLMs’ applications in CVD and explore their current implementation, from prevention to treatment. Following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines, this systematic review assessed LLM applications in CVD. A comprehensive PubMed search identified relevant studies. The review prioritized pragmatic and practical applications of LLMs. Key applications, benefits, and limitations of LLMs in CVD prevention were summarized. Thirty-five observational studies met the eligibility criteria. Of these, 54% addressed primary prevention and risk factor management, while 46% focused on established CVD. Commercial LLMs were evaluated in all but one study, with 91% (32 studies) assessing ChatGPT. The LLM applications were categorized as follows: 72% addressed patient education, 17% clinical decision support, and 11% both. In 68% of studies, the primary objective was to evaluate LLMs’ performance in answering frequently asked patient questions, with results indicating accurate, comprehensive, and generally safe responses. However, occasional misinformation and hallucinated references were noted. Additional applications included patient guidance on CVD, first aid, and lifestyle recommendations. Large language models were assessed for medical questions, diagnostic support, and treatment recommendations in clinical decision support. Large language models hold significant potential in CVD prevention and treatment. Evidence supports their potential as an alternative source of information for addressing patients’ questions about common CVD. However, further validation is needed for their application in individualized care, from diagnosis to treatment.",Artificial intelligence | Cardiovascular disease | Clinical decision | Large language models (LLMs) | Patient education | Prevention,3,2025,behavior,behavior+policy
546,2-s2.0-85204597031,10.1007/s00146-024-02062-3,https://doi.org/10.1007/s00146-024-02062-3,https://scholar.google.com/scholar?q=10.1007/s00146-024-02062-3,ar,AI and Society,"Hill, Guzyal;Waddington, Matthew;Qiu, Leon",From pen to algorithm: optimizing legislation for the future with artificial intelligence,"This research poses the question of whether it is possible to optimize modern legislative drafting by integrating LLM-based systems into the lawmaking process to address the pervasive challenge of misinformation and disinformation in the age of AI. While misinformation is not a novel phenomenon, with the proliferation of social media and AI, disseminating false or misleading information has become a pressing societal concern, undermining democratic processes, public trust, and social cohesion. AI can be used to proliferate disinformation and misinformation through fake news and deepfakes; can AI also be used for beneficial purposes to develop the antidote legislation combatting these challenges? Leveraging the capabilities of LLMS, such as ChatGPT and others, can present a promising direction for optimizing legislative drafting. By proposing the methodological approach of an AI bun, this article explores an important approach in which LLMS can support lawmakers and policy experts in crafting legislation. The article contributes to the discourse through a nuanced understanding of the opportunities and challenges in harnessing LLM-powered tools for legislative innovation. Ultimately, it underscores the transformative potential of LLMs as a potential resource for lawmakers seeking to navigate decision-making while developing legislation on an example of navigating the intricate landscape of misinformation and disinformation regulation in the age of AI.",AI bun | Disinformation | Legislation | LLM-assisted drafting | Misinformation,3,2025,behavior,behavior+policy
549,2-s2.0-105003802120,10.1016/j.ngib.2025.03.007,https://doi.org/10.1016/j.ngib.2025.03.007,https://scholar.google.com/scholar?q=10.1016/j.ngib.2025.03.007,re,Natural Gas Industry B,"Lin, Botao;Jin, Yan;Cao, Qianwen;Meng, Han;Pang, Huiwen;Wei, Shiming",Developing a large language model for oil- and gas-related rock mechanics: Progress and challenges,"In recent years, large language models (LLMs) have demonstrated immense potential in practical applications to enhance work efficiency and decision-making capabilities. However, specialized LLMs in the oil and gas engineering area are rarely developed. To aid in exploring and developing deep and ultra-deep unconventional reservoirs, there is a call for a personalized LLM on oil- and gas-related rock mechanics, which may handle complex professional data and make intelligent predictions and decisions. To that end, herein, we overview general and industry-specific LLMs. Then, a systematic workflow is proposed for building this domain-specific LLM for oil and gas engineering, including data collection and processing, model construction and training, model validation, and implementation in the specific domain. Moreover, three application scenarios are investigated: knowledge extraction from textural resources, field operation with multidisciplinary integration, and intelligent decision assistance. Finally, several challenges in developing this domain-specific LLM are highlighted. Our key findings are that geological surveys, laboratory experiments, field tests, and numerical simulations form the four original sources of rock mechanics data. Those data must flow through collection, storage, processing, and governance before being fed into LLM training. This domain-specific LLM can be trained by fine-tuning a general open-source LLM with professional data and constraints such as rock mechanics datasets and principles. The LLM can then follow the commonly used training and validation processes before being implemented in the oil and gas field. However, there are three primary challenges in building this domain-specific LLM: data standardization, data security and access, and striking a compromise between physics and data when building the model structure. Some of these challenges are administrative rather than technical, and overcoming those requires close collaboration between the different interested parties and various professional practitioners.",Artificial intelligence | Data processing | Large language model | Oil and gas | Rock mechanics,3,2025,behavior,behavior+policy
558,2-s2.0-105012479620,10.1177/18724981251320551,https://doi.org/10.1177/18724981251320551,https://scholar.google.com/scholar?q=10.1177/18724981251320551,ar,Intelligent Decision Technologies,"Phillips-Wren, Gloria;Virvou, Maria",Issues and trends in generative AI technologies for decision making,"Generative AI (GenAI) technologies are examined through the lens of issues and trends related to decision making. After examining the foundations of the technology particularly related to large language models (LLM), opportunities for GenAI to be used in the decision-making process of intelligence, design, choice and implementation are explored. With its ability to rapidly generate insights, present optimized solutions, and provide detailed analysis of given input, the technology has demonstrated that it can assist and augment human decision making. Although GenAI systems have the potential to transform content creation and human cognition, they also raise issues around accuracy, misinformation, ethics, bias, morality, social impacts, privacy, copyright, legality, and explainability, among others. Addressing these challenges is important to maximize the efficacy of GenAI in decision making.",artificial intelligence | decision making | decision support | generative AI | large language models,3,2025,behavior,behavior+policy
568,2-s2.0-85218793329,10.5815/ijieeb.2025.01.06,https://doi.org/10.5815/ijieeb.2025.01.06,https://scholar.google.com/scholar?q=10.5815/ijieeb.2025.01.06,ar,International Journal of Information Engineering and Electronic Business,"Holubinka, Danylo;Vysotska, Victoria;Vladov, Serhii;Ushenko, Yuriy;Talakh, Mariia;Tomka, Yurii",Intelligent System for Recognizing Tone and Categorizing Text in Media News at an Electronic Business Based on Sentiment and Sarcasm Analysis,"During the implementation of the work on the creation of the system of tonality recognition and text categorization in the news, a study of the subject area was conducted, which allowed the understanding of the processes of text analysis in the mass media to be enriched. The necessary data for further processing was found. The work resulted from a program that consists of an information parser, a data analyser and cleaner, a Large Language Models model, a neural network, and a database with vectorized data. These components were integrated into the user interface and implemented as a program window. The program can analyse news texts, determining their tone and categories. At the same time, it provides the user with a convenient interface for entering text and receiving analysis results. Therefore, the created system is a powerful tool for automated analysis of textual data in mass media, which can be used for various purposes, including monitoring the news space, analysis of public opinion, and others. Also, the developed information technology successfully meets the set tasks aimed at tonality analysis and categorization of news. It effectively solves the task of collecting, analysing and classifying news materials, which allows users to receive operational and objective information. Its architecture and functionality allow for easy changes and additions in the future, making it a flexible and adaptable tool for news analytics and decision-making in various business sectors.",Categorizing Text | Deep Learning | Electronic Business | Information Engineering | Intelligent System | Large Language Models | LLM | Machine Learning | Media News | Natural Language Processing | NLP | Recognizing Tone | Recurrent Neural Networks | RNN | Sarcasm Analysis | Sentiment Analysis,3,2025,behavior,behavior+policy
571,2-s2.0-85200165349,10.1108/DTS-03-2024-0024,https://doi.org/10.1108/DTS-03-2024-0024,https://scholar.google.com/scholar?q=10.1108/DTS-03-2024-0024,ar,Digital Transformation and Society,"Goher, Ghada Nabil",Navigating the integration of ChatGPT in UAE’s government sector: challenges and opportunities,"Purpose: This research examines how responsible deployment of ChatGPT in the UAE’s government sector, guided by New Public Management principles, can enhance customer journeys by integrating services across government bodies. Through semi-structured interviews with UAE government officers, the study investigates this approach’s benefits, challenges, and applications for achieving efficient and integrated public service delivery. Design/methodology/approach: This research adopts a qualitative approach, purposive sampling strategy, and semi-structured interviews to explore the subjective viewpoints of 20 high-level UAE government authorities. The thematic analysis uncovers ChatGPT’s benefits, challenges, and applications, aligning with New Public Management principles. Findings: Thematic analysis reveals four themes: Benefits and Applications of ChatGPT, Challenges, Strategies to Overcome Challenges, and Steps for Customer Journey Enhancement through ChatGPT. Research limitations/implications: The analysis is based on participant responses provided during the interviews, which may be subject to biases or incomplete information. Secondly, the study focuses solely on the provided applications and participant responses, limiting the generalizability of the conclusions to other contexts. Practical implications: The implementation of ChatGPT in the government sector has practical implications for transforming its operations and enhancing communication, efficiency, decision-making, and service offerings: citizen engagement, streamlined processes, and informed governance. Originality/value: This study uniquely examines ChatGPT’s role in government, offering insights into communication, efficiency, decision-making, and service offerings. Identifying hurdles enriches understanding of ChatGPT’s practical integration in government.",Applications of ChatGPT | Benefits of ChatGPT | ChatGPT | Government sector | Limitations of ChatGPT | New public management | Public service delivery,3,2025,behavior,behavior+policy
618,2-s2.0-105017476314,10.1007/s00146-025-02620-3,https://doi.org/10.1007/s00146-025-02620-3,https://scholar.google.com/scholar?q=10.1007/s00146-025-02620-3,re,AI and Society,"Park, Seyeon;Nan, Xiaoli","Generative AI and misinformation: a scoping review of the role of generative AI in the generation, detection, mitigation, and impact of misinformation","The rapid advancement of generative artificial intelligence (AI) has introduced both opportunities and challenges in the fight against misinformation. This scoping review synthesizes recent empirical studies to explore the dual role of generative AI—particularly large language models (LLMs)—in the generation, detection, mitigation, and impact of misinformation. Analyzing 24 empirical studies, our review suggests that LLMs can generate highly convincing misinformation, often exploiting cognitive biases and ideological leanings of the audiences, while also demonstrating the ability to detect false claims and enhance users’ resistance to misinformation. Mitigation efforts show mixed results, with personalized corrections proving effective but safeguards inconsistently applied. Additionally, exposure to AI-generated misinformation was found to reduce trust and influence decision-making. This review underscores the need for standardized evaluation metrics, interdisciplinary collaboration, and stronger regulatory measures to ensure the responsible use of generative AI in the information ecosystem.",Fake news | Generative AI | Large language models | LLM | Misinformation,3,2025,behavior,behavior+policy
637,2-s2.0-105010863348,10.2196/70610,https://doi.org/10.2196/70610,https://scholar.google.com/scholar?q=10.2196/70610,re,Jmir Mental Health,"Wang, Xi;Zhou, Yujia;Zhou, Guangyu",The Application and Ethical Implication of Generative AI in Mental Health: Systematic Review,"Background: Mental health disorders affect an estimated 1 in 8 individuals globally, yet traditional interventions often face barriers, such as limited accessibility, high costs, and persistent stigma. Recent advancements in generative artificial intelligence (GenAI) have introduced AI systems capable of understanding and producing humanlike language in real time. These developments present new opportunities to enhance mental health care. Objective: We aimed to systematically examine the current applications of GenAI in mental health, focusing on 3 core domains: diagnosis and assessment, therapeutic tools, and clinician support. In addition, we identified and synthesized key ethical issues reported in the literature. Methods: We conducted a comprehensive literature search, following the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) 2020 guidelines, in PubMed, ACM Digital Library, Scopus, Embase, PsycInfo, and Google Scholar databases to identify peer-reviewed studies published from October 1, 2019, to September 30, 2024. After screening 783 records, 79 (10.1%) studies met the inclusion criteria. Results: The number of studies on GenAI applications in mental health has grown substantially since 2023. Studies on diagnosis and assessment (37/79, 47%) primarily used GenAI models to detect depression and suicidality through text data. Studies on therapeutic applications (20/79, 25%) investigated GenAI-based chatbots and adaptive systems for emotional and behavioral support, reporting promising outcomes but revealing limited real-world deployment and safety assurance. Clinician support studies (24/79, 30%) explored GenAI’s role in clinical decision-making, documentation and summarization, therapy support, training and simulation, and psychoeducation. Ethical concerns were consistently reported across the domains. On the basis of these findings, we proposed an integrative ethical framework, GenAI4MH, comprising 4 core dimensions—data privacy and security, information integrity and fairness, user safety, and ethical governance and oversight—to guide the responsible use of GenAI in mental health contexts. Conclusions: GenAI shows promise in addressing the escalating global demand for mental health services. They may augment traditional approaches by enhancing diagnostic accuracy, offering more accessible support, and reducing clinicians’ administrative burden. However, to ensure ethical and effective implementation, comprehensive safeguards—particularly around privacy, algorithmic bias, and responsible user engagement—must be established.",generative AI | large language models | mental health | mental health detection and diagnosis | therapeutic chatbots,3,2025,behavior,behavior+policy
647,2-s2.0-105004028357,10.1080/10095020.2025.2493073,https://doi.org/10.1080/10095020.2025.2493073,https://scholar.google.com/scholar?q=10.1080/10095020.2025.2493073,ar,Geo Spatial Information Science,"Ying, Shaowei;Li, Zhenlong;Yu, Manzhu",Beyond words: evaluating large language models in transportation planning,"The rapid advancement of Generative Artificial Intelligence (GenAI) in 2023 has catalyzed transformative shifts across various industries, including urban transportation planning. This study evaluates the applicability of Large Language Models (LLMs) in transportation decision-making, focusing on two hypotheses: (H1) out-of-the-box LLMs exhibit basic transportation knowledge and reasoning capabilities, enabling them to design and execute analytical workflows; and (H2) larger parameter models and fine-tuned models demonstrate superior accuracy and contextual understanding, outperforming smaller and general-purpose models. Using a three-level evaluation framework, we assessed GPT-4 and Phi-3-mini across (1) geospatial skills, (2) domain-specific transportation knowledge, and (3) real-world transport problem-solving in congestion pricing scenarios. Results confirm that while LLMs possess baseline geospatial and transportation reasoning abilities, their effectiveness varies by task complexity. GPT-4 outperformed Phi-3-mini across all evaluation levels, achieving 86% accuracy in GIS tasks, 81% in MATSim comprehension, and 91% in real-world transport decision support, while Phi-3-mini scored 43–72%. These findings highlight the advantages of larger models in structured decision-making tasks and their potential as analytical copilots for transportation planners. The study contributes to the ongoing scientific debate on the role of GenAI in transportation governance, reinforcing the need for fine-tuning and retrieval-augmented generation (RAG) to enhance LLM performance in structured analytics. Future research should explore newer LLMs, transport-specific fine-tuning, and hybrid AI architectures to improve AI-driven transportation planning and decision support.",congestion pricing | generative AI | geospatial AI | Large language models (LLM) | transportation planning,3,2025,behavior,behavior+policy
652,2-s2.0-105001875768,10.1080/1475939X.2024.2421494,https://doi.org/10.1080/1475939X.2024.2421494,https://scholar.google.com/scholar?q=10.1080/1475939X.2024.2421494,ar,Technology Pedagogy and Education,"Rice, Mary",The micropolitical landscape of publicly discoverable policies for generative AI in large US school districts,"While the use of generative AI (genAI) in K12 schools is increasing, it is poorly understood from a policy perspective. There are significant tensions in technology integration in education between public interests for social good and pressure from educational technology companies to view schools as markets. This study examined genAI policy efforts in the 50 largest US school districts by student enrolment in fall 2023 and spring 2024. A content analysis of documents from districts, states and media sources revealed micropolitical, rather than top-down, activities where districts were attempting policy making about genAI in varied ways and at varied paces. Educational technology vendors seemed to be opening space for substantial influence in policy decisions simultaneously. Understandings about these micropolitical activities of policy making have the potential to support shared decision-making and co-responsibility as important opportunities for disrupting current dynamics of influence on educational policy making in US schools.",Assemblage in educational policy | generative AI educational policies | K12 school technology policies | large school districts’ policies | US school districts,3,2025,behavior,behavior+policy
668,2-s2.0-105019674454,10.13266/j.isn.0252-3116.2024.19.010,https://doi.org/10.13266/j.isn.0252-3116.2024.19.010,https://scholar.google.com/scholar?q=10.13266/j.isn.0252-3116.2024.19.010,re,Library and Information Service,"Ma, Haiqun;Lian, Longying",Research Landscape of ChatGPT in the Field of Information Resources Management: A Systematic Literature Review,"[Purpose/Significance] This paper systematically reviews and analyzes the relevant research on ChatGPT in the field of information resources management in China to provide reference for in-depth research and practical applications of ChatGPT to support the development of discipline. [Method/Process] Following the PRISMA(preferred reporting items for systematic reviews and meta-analyses) guidelines, it selected 219 research papers on ChatGPT in the field of information resources management from CNKI and Wanfang Data. Through descriptive statistics, it analyzed and addressed four key research questions: technical connotation, application and examples, impact and empirical evidence, and contribution to discipline development. Then, it proposed future research directions from three aspects: technological application, theoretical research, and disciplinary system. [Result/Conclusion] The results show that ChatGPT has significant technical advantages, but some limitations in function and performance. Its application prospects have gained considerable recognition, but the current research fields are limited and lack sufficient instance support. The impact of ChatGPT on the field of information resource management involves multiple aspects such as technological application, social impact, cultural value, legal regulation, and national security. Further empirical research is needed to verify its actual effectiveness. ChatGPT has mainly played a positive role in promoting the development of the information resources management.",application scenarios | ChatGPT | discipline system | information resources management | systematic literature review,3,2024,behavior,behavior+policy
675,2-s2.0-85199126381,10.1136/bmjopen-2024-087469,https://doi.org/10.1136/bmjopen-2024-087469,https://scholar.google.com/scholar?q=10.1136/bmjopen-2024-087469,ar,BMJ Open,"Kämmer, Juliane E.;Hautz, Wolf E.;Krummrey, Gert;Sauter, Thomas C.;Penders, Dorothea;Birrenbach, Tanja;Bienefeld, Nadine","Effects of interacting with a large language model compared with a human coach on the clinical diagnostic process and outcomes among fourth-year medical students: Study protocol for a prospective, randomised experiment using patient vignettes","Introduction Versatile large language models (LLMs) have the potential to augment diagnostic decision-making by assisting diagnosticians, thanks to their ability to engage in open-ended, natural conversations and their comprehensive knowledge access. Yet the novelty of LLMs in diagnostic decision-making introduces uncertainties regarding their impact. Clinicians unfamiliar with the use of LLMs in their professional context may rely on general attitudes towards LLMs more broadly, potentially hindering thoughtful use and critical evaluation of their input, leading to either over-reliance and lack of critical thinking or an unwillingness to use LLMs as diagnostic aids. To address these concerns, this study examines the influence on the diagnostic process and outcomes of interacting with an LLM compared with a human coach, and of prior training vs no training for interacting with either of these 'coaches'. Our findings aim to illuminate the potential benefits and risks of employing artificial intelligence (AI) in diagnostic decision-making. Methods and analysis We are conducting a prospective, randomised experiment with N=158 fourth-year medical students from Charité Medical School, Berlin, Germany. Participants are asked to diagnose patient vignettes after being assigned to either a human coach or ChatGPT and after either training or no training (both between-subject factors). We are specifically collecting data on the effects of using either of these 'coaches' and of additional training on information search, number of hypotheses entertained, diagnostic accuracy and confidence. Statistical methods will include linear mixed effects models. Exploratory analyses of the interaction patterns and attitudes towards AI will also generate more generalisable knowledge about the role of AI in medicine. Ethics and dissemination The Bern Cantonal Ethics Committee considered the study exempt from full ethical review (BASEC No: Req-2023-01396). All methods will be conducted in accordance with relevant guidelines and regulations. Participation is voluntary and informed consent will be obtained. Results will be published in peer-reviewed scientific medical journals. Authorship will be determined according to the International Committee of Medical Journal Editors guidelines.",Artificial Intelligence | Clinical Decision-Making | Clinical Reasoning | MEDICAL EDUCATION & TRAINING,3,2024,behavior,behavior+policy
694,2-s2.0-85218964527,10.5534/wjmh.240173,https://doi.org/10.5534/wjmh.240173,https://scholar.google.com/scholar?q=10.5534/wjmh.240173,ar,World Journal of Men S Health,"Yuan, Lun Hsiang;Huang, Shi Wei;Chou, Dean;Tsai, Chung You",The In-depth Comparative Analysis of Four Large Language AI Models for Risk Assessment and Information Retrieval from Multi-Modality Prostate Cancer Work-up Reports,"Purpose: Information retrieval (IR) and risk assessment (RA) from multi-modality imaging and pathology reports are critical to prostate cancer (PC) treatment. This study aims to evaluate the performance of four general-purpose large language model (LLMs) in IR and RA tasks. Materials and Methods: We conducted a study using simulated text reports from computed tomography, magnetic resonance imaging, bone scans, and biopsy pathology on stage IV PC patients. We assessed four LLMs (ChatGPT-4-turbo, Claude-3opus, Gemini-Pro-1.0, ChatGPT-3.5-turbo) on three RA tasks (LATITUDE, CHAARTED, TwNHI) and seven IR tasks. It included TNM staging, and the detection and quantification of bone and visceral metastases, providing a broad evaluation of their capabilities in handling diverse clinical data. We queried LLMs with multi-modality reports using zero-shot chain-of-thought prompting via application programming interface. With three adjudicators’ consensus as the gold standard, these models’ performances were assessed through repeated single-round queries and ensemble voting methods, using 6 outcome metrics. Results: Among 350 stage IV PC patients with simulated reports, 115 (32.9%), 128 (36.6%), and 94 (26.9%) belonged to LATITUDE, CHAARTED, and TwNHI high-risk, respectively. Ensemble voting, based on three repeated single-round queries, consistently enhances accuracy with a higher likelihood of achieving non-inferior results compared to a single query. Four models showed minimal differences in IR tasks with high accuracy (87.4%–94.2%) and consistency (ICC>0.8) in TNM staging. However, there were significant differences in RA performance, with the ranking as follows: ChatGPT-4-turbo, Claude-3-opus, Gemini-Pro-1.0, and ChatGPT-3.5-turbo, respectively. ChatGPT-4-turbo achieved the highest accuracy (90.1%, 90.7%,91.6%), and consistency (ICC 0.86, 0.93, 0.76) across 3 RA tasks. Conclusions: ChatGPT-4-turbo demonstrated satisfactory accuracy and outcomes in RA and IR for stage IV PC, suggesting its potential for clinical decision support. However, the risks of misinterpretation impacting decision-making cannot be overlooked. Further research is necessary to validate these findings in other cancers.","ChatGPT | Decision support systems, clinical | Information storage and retrieval | Large language model | Prostatic neoplasms | Risk assessment",3,2024,behavior,behavior+policy
712,2-s2.0-85175950027,10.13366/j.dik.2023.05.077,https://doi.org/10.13366/j.dik.2023.05.077,https://scholar.google.com/scholar?q=10.13366/j.dik.2023.05.077,ar,Documentation Information and Knowledge,"Zhang, Xinxin;Huang, Ruhua","Application Scenarios, Risk Challenges and Regulatory Pathways of Generative Intelligent Publishing","[Purpose/Significance] The emergence of ChatGPT and its generative AI technology has given rise to a new industry of generative intelligent publishing. The multidimensional exploration on generative intelligent publishing can reveal its application scenarios, risk challenges, and regulatory paths. [Design/Methodology] Based on the technical application principles and application characteristics of generative AI technology, this study explores the application scenarios, risk challenges, and regulatory paths of generative intelligent publishing. [Findings/Conclusion] The application scenarios of generative intelligent publishing include five categories: publishing big data and large language models, dimensional development of intelligent knowledge services, intelligent robots in the field of intelligent decision-making publishing, generative intelligent publication, and new business formats of metaverse publishing.Generative intelligent publishing faces challenges in data source and data output, academic ethical norms, adherence to core values, and substitution of human occupations, etc. In view of these challenges,corresponding regulatory paths are proposed from the perspective of regulation and governance. [Originality/Value] In the face of the digital age empowered by generative AI technology, it is of great significance to explore its enabling role and deep impact on publishing for promoting the high-quality development and modernization of publishing.",AIGC （Artificial Intelligence Generated Content） | ChatGPT | Digital publishing | Generative AI | Intelligent publishing | Intelligent publishing regulation | Metaverse publishing,3,2023,behavior,behavior+policy
74,2-s2.0-105010086069,10.1038/s41598-025-09569-9,https://doi.org/10.1038/s41598-025-09569-9,https://scholar.google.com/scholar?q=10.1038/s41598-025-09569-9,ar,Scientific Reports,"Aljohani, Abeer",A decision-support framework for evaluating AI-enabled ESG strategies in the context of sustainable manufacturing systems,"With the increasing global environmental and social challenges, it is more urgent than ever to implement effective strategies for sustainable development. Environmental, Social and Governance (ESG) criteria are also necessary requirements guiding organizations toward responsible and sustainable practices. However, the multi-dimensionality of the criteria and the uncertainty associated with judgment by an expert makes evaluation and choice of the best ESG-driven strategy a very complex task. The current paper introduces an innovative approach to the assessment of ESG strategies via Fuzzy based multi-criteria decision-making tools. Those selected shall be addressed particularly through the Fuzzy TOPSIS method, considering and ranking seven key strategies driven by ESG focus areas- AI-Powered Predictive Analytics, Renewable Energy Integration, Smart Waste Management Systems, Blockchain for Transparent Governance, AI-Enhanced Workforce and Community Development, Sustainable Supply Chain Optimization and Generative AI for Eco-Friendly Innovation. The results of this assessment indicate that the most popular ESG approach is renewable energy integration, which is in line with the industry’s pivotal role in advancing energy transition and climate action. AI-Powered Predictive Analytics and Sustainable Supply Chain Optimization are closely related, emphasizing the strategic value of data intelligence as well as operational efficiency in improving sustainability practices. These results offer important novel insights about how AI-powered methods might guide environmentally friendly choices in intricate industrial settings. Our method provides a strong and transparent framework for assessing ESG strategies under sustainability by incorporating fuzzy logic into decision-making. The study adds to the rapidly expanding body of research on AI-driven sustainability evaluations, from which companies, policymakers and other stakeholders could gain insight how to enhance their ESG performance as well as advance sustainable development.",Decision support systems | ESG strategies | Multi-criteria decision making | Sustainable development | Sustainable manufacturing,3,2025,sustainability,behavior+policy+sustainability
187,2-s2.0-105008831716,10.1145/3674846,https://doi.org/10.1145/3674846,https://scholar.google.com/scholar?q=10.1145/3674846,ar,Digital Government Research and Practice,"Raman, Raghu;Nair, Vinith Kumar;Dinesh, Sofi;Acharyulu, Ramana","Comparative Analysis of ChatGPT and Bard in Digital Governance: Accuracy, Adaptability, and Readability Insights","In a comprehensive assessment of ChatGPT and Bard’s performance across three key indices—Government AI Readiness, Digital Economy and Society, and UN E-Government Survey—the study delves into nuanced insights regarding their accuracy, adaptability, and readability within the context of Digital Governance. ChatGPT demonstrated a superior accuracy rate of 93.55%, surpassing Bard’s performance at 88.57%. Notably, both models exhibited variations in individual and mutual error correction capabilities, particularly evident when faced with confirmation queries. Bard showcased an adjustment post-confirmation, suggesting potential error correction, whereas ChatGPT displayed limited adaptability in similar scenarios. While there was a notable congruence in their responses to Digital Governance content, challenges arose in deciphering complex information, especially concerning sustainability initiatives. Bard generally produced more accessible content, evident in readability metrics, in contrast to ChatGPT’s inclination toward using complex language. Both models demonstrated promising alignment in addressing intricate topics within the realm of Digital Governance. The findings emphasize the need for policymakers to critically evaluate the adaptability and accuracy of language models like ChatGPT and Bard when considering their integration into digital governance practices. Awareness of their diverse performance and error correction capabilities is crucial for responsible implementation, ensuring the maximal benefits of AI in public decision-making.",Bard | ChatGPT | digital governance | ethics | generative AI | policy | public sector | readability | similarity analysis,3,2025,sustainability,behavior+policy+sustainability
224,2-s2.0-86000379795,10.1002/csr.3055,https://doi.org/10.1002/csr.3055,https://scholar.google.com/scholar?q=10.1002/csr.3055,ar,Corporate Social Responsibility and Environmental Management,"Li, Chao;Keeley, Alexander Ryota;Takeda, Shutaro;Seki, Daikichi;Managi, Shunsuke",Investor's ESG tendency probed by pre-trained transformers,"Due to climate change and social issues, environmental, social, and governance (ESG) solutions receive increased attention and emphasis. Being influential market leaders, investors wield significant power to persuade companies to prioritize ESG considerations. However, investors' preferences for specific ESG topics and changing trends in those preferences remain elusive. Here, we build a group of large language models with 128 million parameters, named classification pre-trained transformers (CPTs), to extract the investors' tendencies toward 13 ESG-related topics from their annual reports. Assisted by the CPT models with approximately 95% cross-validation accuracy, more than 3000 annual reports released by globally 350 top investors during 2010–2021 are analyzed. Results indicate that although the investors show the strongest tendency toward the economic aspect in their annual reports, the emphasis is gradually reducing and shifting to environmental and social aspects. Nonfinancial investors like corporation and holding company investors prioritize environmental and social factors, whereas financial investors pay the most attention to governance risk. There are differences in patterns at the country level, for instance, Japan's investors show a greater focus on environmental and social factors than other major countries. Our findings suggest that investors are increasingly valuing sustainability in their decision-making. Different investor businesses may encounter unique ESG challenges, necessitating individualized strategies. Companies should improve their ESG disclosures, which are increasingly focused on environmental and social issues, to meet investor expectations and bolster transparency.",data mining | ESG | investor | machine learning | natural language processing | pre-trained transformer,3,2025,sustainability,behavior+policy+sustainability
40,2-s2.0-85199509114,10.1109/TFUZZ.2024.3431710,https://doi.org/10.1109/TFUZZ.2024.3431710,https://scholar.google.com/scholar?q=10.1109/TFUZZ.2024.3431710,ar,IEEE Transactions on Fuzzy Systems,"Bangerter, Micaela Lucia;Fenza, Giuseppe;Furno, Domenico;Gallo, Mariacristina;Loia, Vincenzo;Stanzione, Claudio;You, Ilsun",A Hybrid Framework Integrating LLM and ANFIS for Explainable Fact-Checking,"The widespread utilization of social media for information consumption has significantly exacerbated the problem of information disorder. Recognizing the difficulty people face in discerning the truth, automated assistance is urgently needed. Current state-of-the-art approaches often involve fine-tuning existing models with contributions from domain knowledge bases. The black-box nature and interpretability issues of deep neural networks have increased interest in hybrid approaches, giving rise to deep neural fuzzy systems (DNFSs). This article presents the Hybrid Fact-Checking Framework leveraging a DNFS tailored to address the uncertainty inherent in fact verification tasks and enhance the reliability of model responses. The DNFS integrates a large language model with an adaptive neuro fuzzy inference system for automated fact verification. The framework utilizes relevant evidence from open-world and closed-world sources, leveraging deep language models and employing few-shot prompting without additional training to generate and justify verdicts. Including fuzzy rules and considering the trustworthiness and relevance of retrieved evidence enhances response reliability, thereby improving overall effectiveness and outcome interpretability. Experimental validations have been conducted on three publicly available datasets ranging in different domains of expertise: Climate-FEVER, SciFact, and FEVER. The results demonstrate that the proposed framework ensures better outcomes, transparency, and mindful decision-making.",Deep neuro fuzzy system (DNFS) | fact-checking | fuzzy inference system | large language model (LLM),3,2025,sustainability,behavior+sustainability
52,2-s2.0-105023912020,10.2967/jnmt.125.270251,https://doi.org/10.2967/jnmt.125.270251,https://scholar.google.com/scholar?q=10.2967/jnmt.125.270251,ar,Journal of Nuclear Medicine Technology,"Currie, Geoffrey M.;Rohren, Eric",The Role of Artificial Intelligence in Theranostics,"The recent reinvigoration of theranostics comes with advances in computing technology, radiochemistry, and instrumentation that synergize with developments in artificial intelligence (AI). There is a wide array of applications of AI in nuclear medicine that have translational benefits to theranostics, including attenuation correction, artifact and noise reduction, enhanced workflow, and lesion characterization, and segmentation and quantitation, among many others. For theranostics, there are potentially significant applications that could move closer to precision medicine. Perhaps the most important application is predictive dosimetry from diagnostic images to optimize therapeutic dose. There are also valuable benefits from AI-augmented radioligand design and development, preclinical imaging, and practice sustainability. Generative AI has also emerged as a powerful tool to support decision-making, information dissemination, and medical image analysis. There are, however, several ongoing challenges that must be considered pertaining to the development and application of AI tools in theranostics.",artificial intelligence | deep learning | generative AI | radionuclide therapy | theranostics,3,2025,sustainability,behavior+sustainability
75,2-s2.0-105010069483,10.1007/s43621-025-01484-3,https://doi.org/10.1007/s43621-025-01484-3,https://scholar.google.com/scholar?q=10.1007/s43621-025-01484-3,ar,Discover Sustainability,"Koteczki, Réka;Csikor, Dániel;Balassa, Boglárka Eisinger",The role of generative AI in improving the sustainability and efficiency of HR recruitment process,"Generative artificial intelligence (GAI) is becoming increasingly important in business processes, including human resource management. GAI can offer the potential to automate repetitive tasks in recruitment processes, optimise decision making, and reduce administrative burdens. Although AI can help increase operational efficiency, environmental pressures must also be taken into account. AI models require significant computing power, resulting in high energy consumption and increased CO<inf>2</inf> emissions. This dichotomy may raise the question of whether the efficiency gains provided by GAI outweigh the environmental burden. This article examines the environmental impacts of GAI on HRM through a case study. The research combines qualitative and quantitative methods: expert interviews are used to explore practical applications, while calculations on energy consumption, costs, and emissions are carried out by comparing traditional and AI-based recruitment methods. The results of the case study showed that the integration of GAI led to efficiency gains. The time required for the recruitment process was reduced by 13.25 h, which could save thousands of man-hours per year. At the same time, costs and energy consumption and associated carbon emissions were reduced. The study highlights the duality of “AI for sustainability” and “sustainability of AI”, highlighting that while GAI can contribute to more sustainable corporate operations, its own environmental footprint raises questions about long-term sustainability. The results will provide HR professionals, decision makers, and organisations with practical insights into the potential for sustainable use of AI.",Case study | ChatGPT | Efficiency optimisation | Generative artificial intelligence (GAI) | Human resource management (HRM) | Interview | Sustainable development goals (SDGs) | Westerm Transdanubia,3,2025,sustainability,behavior+sustainability
130,2-s2.0-105017643491,10.1016/j.scs.2025.106826,https://doi.org/10.1016/j.scs.2025.106826,https://scholar.google.com/scholar?q=10.1016/j.scs.2025.106826,ar,Sustainable Cities and Society,"Bibri, Simon Elias;Huang, Jeffrey","Generative AI of things for sustainable smart cities: Synergizing cognitive augmentation, resource efficiency, network traffic, cybersecurity, and anomaly detection for environmental performance","Artificial Intelligence of Things (AIoT) has emerged as a transformative technology driving environmental sustainability in smart city development. However, the integration of Generative Artificial Intelligence (GenAI) within AIoT ecosystems remains largely unexplored. Current research predominantly addresses conventional AIoT frameworks, overlooking the innovative potential of generative models, such as Generative Adversarial Networks, Variational Autoencoders, Diffusion Models, Transformers, and hybrid architectures, to significantly enhance situational awareness, system optimization, operational robustness, real-time responsiveness, and adaptive decision-making in complex urban environments. AIoT systems continue to face persistent challenges, including data scarcity, poor data quality, limited adaptability, imbalanced datasets, and inadequate context-awareness. This study addresses these gaps by systematically exploring how GenAI can enhance AIoT functionalities across key domains—namely cognitive augmentation, resource efficiency, network traffic, cybersecurity, and anomaly detection—while examining their synergistic potential to improve system-level environmental performance across two interconnected layers in sustainable smart cities. At the operational layer, key findings reveal that integrating GenAI with AIoT systems enhances urban efficiency, adaptability, autonomy, robustness, and resilience by conserving resources, optimizing network traffic flows, securing infrastructures, and detecting anomalies before they escalate. Specifically, the fusion of generative intelligence with federated learning promotes sustainable, energy-efficient AIoT deployments by reducing data transmission, thereby lowering communication overhead and safeguarding user privacy. In networked environments, generative models improve synthetic traffic realism and communication efficiency. They also strengthen cybersecurity through enhanced intrusion prevention and threat detection. Additionally, they enable early identification and mitigation of anomalies, boosting operational efficiency and system robustness. These improvements stabilize sustainable smart city system functioning and prevent disruptive failures. At the environmental layer, as key findings indicate, these operational gains cascade into indirect but tangible ecological benefits, while generative models advance the core pillars of AIoT by enabling proactive, autonomous, context-aware, and self-adaptive systems that further enhance the environmental performance of sustainable smart cities. Thus, while the five domains primarily underpin the operational backbone of urban systems, their cascading effects extend to ecological outcomes. The proposed conceptual framework, distilled from key findings, integrates GenAI and AIoT and highlights both domain-specific advancements and their synergistic interactions. This framework holds significant potential to drive sustainable smart city development by fostering AIoT ecosystems that are more intelligent, resource-efficient, adaptive, secure, robust, and autonomous through the strategic application of generative intelligence. The insights gained from this study provide policymakers, urban planners, system designers, and technology developers with practical guidance to harness GAIoT for enhancing smart city resilience, sustainability, and operational intelligence.",Anomaly detection | Cognitive augmentation | Cybersecurity | Environmental sustainability | Generative artificial intelligence | Generative artificial intelligence of things | Generative internet of things | Network traffic | Resource efficiency | Sustainable smart cities,3,2025,sustainability,behavior+sustainability
176,2-s2.0-105012406764,10.2166/hydro.2025.042,https://doi.org/10.2166/hydro.2025.042,https://scholar.google.com/scholar?q=10.2166/hydro.2025.042,ar,Journal of Hydroinformatics,"Kadiyala, Likith;Sajja, Ramteja;Sermet, Yusuf;Muste, Marian;Demir, Ibrahim",AI-driven decision-making for water resource planning and hazard mitigation using automated multi-agents,"This project simulates the Multi-Hazard Tournament (MHT) framework, a decision support system designed for the U.S. Army Corps of Engineers, using AI agents to enhance decision-making processes for flood mitigation and water resource management. Traditional hydrological models often overlook social dynamics and community preferences crucial for sustainable implementation. The objective of the framework is to develop optimal strategies for protecting water resources, habitats, and communities within a defined budget. The simulation integrates AutoGen for managing multi-agent interactions and DarkIdol-Llama-3.1-8B, an advanced language model, to facilitate complex, long-context discussions. AI agents are configured with distinct roles and engage in structured dialogues to collaboratively evaluate and refine mitigation strategies. Analysis of 1,000 diverse agents revealed age as the most significant factor (importance: 0.14) influencing budget allocation, with younger participants (19-30) favoring immediate infrastructure investments while older participants (61+) preferred conservative strategies. The study demonstrates the potential of AI-driven simulations to replicate real-world collaborative environments, improving stakeholder engagement and enhancing the efficiency of hazard mitigation planning. The findings highlight the effectiveness of AI agents in multi-stakeholder decision-making processes, offering valuable insights for disaster risk reduction. This work contributes significantly to fostering more resilient, well-prepared communities through innovative approaches to decision-making.",AI-driven agents | budget optimization | decision-making | hazard mitigation | multi-agent system | water resources planning,3,2025,sustainability,behavior+sustainability
180,2-s2.0-105011606850,10.3390/electronics14142824,https://doi.org/10.3390/electronics14142824,https://scholar.google.com/scholar?q=10.3390/electronics14142824,ar,Electronics Switzerland,"Shahin, Mohammad;Hosseinzadeh, Ali;Chen, F. Frank",AI-Enabled Sustainable Manufacturing: Intelligent Package Integrity Monitoring for Waste Reduction in Supply Chains,"Despite advances in automation, the global manufacturing sector continues to rely heavily on manual package inspection, creating bottlenecks in production and increasing labor demands. Although disruptive technologies such as big data analytics, smart sensors, and machine learning have revolutionized industrial connectivity and strategic decision-making, real-time quality control (QC) on conveyor lines remains predominantly analog. This study proposes an intelligent package integrity monitoring system that integrates waste reduction strategies with both narrow and Generative AI approaches. Narrow AI models were deployed to detect package damage at full line speed, aiming to minimize manual intervention and reduce waste. Using a synthetically generated dataset of 200 paired top-and-side package images, we developed and evaluated 10 distinct detection pipelines combining various algorithms, image enhancements, model architectures, and data processing strategies. Several pipeline variants demonstrated high accuracy, precision, and recall, particularly those utilizing a YOLO v8 segmentation model. Notably, targeted preprocessing increased top-view MobileNetV2 accuracy from chance to 67.5%, advanced feature extractors with full enhancements achieved 77.5%, and a segmentation-based ensemble with feature extraction and binary classification reached 92.5% accuracy. These results underscore the feasibility of deploying AI-driven, real-time QC systems for sustainable and efficient manufacturing operations.",AI | computer vision | deep learning | industry 4.0 | production management | quality control | segmentation | supply chains | sustainability | waste reduction,3,2025,sustainability,behavior+sustainability
183,2-s2.0-105007879414,10.1088/1748-9326/addd36,https://doi.org/10.1088/1748-9326/addd36,https://scholar.google.com/scholar?q=10.1088/1748-9326/addd36,ar,Environmental Research Letters,"Larosa, F.;Hoyas, S.;Conejero, J. A.;Garcia-Martinez, J.;Fuso-Nerini, F.;Vinuesa, R.",Large language models in climate and sustainability policy: limits and opportunities,"Accurate, reliable and updated information support effective decision-making by reducing uncertainty and enabling informed choices. Multiple crises threaten the sustainability of our societies and pose at risk the planetary boundaries, hence requiring usable and operational knowledge. Natural-language processing tools facilitate data collection, extraction and analysis processes. They expand knowledge utilization capabilities by improving access to reliable sources in shorter time. They also identify patterns of similarities and contrasts across diverse contexts. We apply general and domain-specific large language models (LLMs) to two case studies and we document appropriate uses and shortcomings of these tools for two tasks: classification and sentiment analysis of climate and sustainability documents. We study both statistical and prompt-based methods. In the first case study, we use LLMs to assess whether climate pledges trigger cascade effects in other sustainability dimensions. In the second use case, we use LLMs to identify interactions between the sustainable development goals and detects the direction of their links to frame meaningful policy implications. We find that LLMs are successful at processing, classifying and summarizing heterogeneous text-based data helping practitioners and researchers accessing. LLMs detect strong concerns from emerging economies in addressing food security, water security and urban challenges as primary issues. Developed economies, instead, focus their pledges on the energy transition and climate finance. We also detect and document four main limits along the knowledge production chain: interpretability, external validity, replicability and usability. These risks threaten the usability of findings and can lead to failures in the decision-making process. We recommend risk mitigation strategies to improve transparency and literacy on artificial intelligence (AI) methods applied to complex policy problems. Our work presents a critical but empirically grounded application of LLMs to climate and sustainability questions and suggests avenues to further expand controlled and risk-aware AI-powered computational social sciences.",artificial intelligence | climate policy | large language models | NDCs | SDGs,3,2025,sustainability,behavior+sustainability
194,2-s2.0-105007164892,10.1016/j.coche.2025.101150,https://doi.org/10.1016/j.coche.2025.101150,https://scholar.google.com/scholar?q=10.1016/j.coche.2025.101150,re,Current Opinion in Chemical Engineering,"Boskabadi, Mohammad Reza;Cao, Yudong;Khadem, Behnam;Clements, William;Nevin Gerek, Z.;Reuthe, Eric;Sivaram, Abhishek;Savoie, Christopher J.;Mansouri, Seyed Soheil",Industrial Agentic AI and generative modeling in complex systems,"Manufacturing, consumer, transportation, and supply chain processes present significant challenges in monitoring, control, and design due to their inherently nonlinear nature and the difficulty of measuring critical variables in real time. The convergence of major innovations from the computer science field has the potential to revolutionize the engineering and control of complex industrial systems. Digital twinning and process simulation have been a staple of computers in process engineering for decades now. However, the advent of advanced sensor systems and big data integration, combined with generative AI and agentified AI (classic and quantum) systems, allows for much more granular and autonomous process control and real-time optimization of complex systems. Advanced process modeling, Agentic AI, and generative AI models have emerged as powerful tools to address the challenges of complex nonlinear systems. We propose here an integrated systems feedback and control architecture (SIC: Sense, Infer, Control) that leverages complementary process knowledge for enhanced real-time monitoring and decision-making, fully integrated into control system functions and the accompanying sensors. In this paper, we explore this integration of generative models in agentic AI ensembles into industrial processes through the lens of four recent industrial case studies: (1) the real-time optimization of motorsports strategy, (2) the development of indirect (soft) sensors for sustainable large-scale manufacturing operations, (3) the creation of sensor data-driven personalized health and cosmetic chemical formulations, and (4) the design of biomanufacturing systems using quantum and classic Agentic AI. These examples demonstrate how agentic and generative models, combined with full-scale process simulation and digital twinning, effectively augment process control, enabling advanced solutions for process optimization, quality improvement, and sustainable operations. The proposed SIC systems architecture serves to enhance process control automation by capturing complex nonlinear patterns and leveraging easily measurable variables. Generative models bridge gaps in process understanding, sensor technologies, control, and monitoring, offering actionable insights for efficient and informed decision-making across diverse industrial applications.",,3,2025,sustainability,behavior+sustainability
207,2-s2.0-105000045696,10.1016/j.jik.2025.100691,https://doi.org/10.1016/j.jik.2025.100691,https://scholar.google.com/scholar?q=10.1016/j.jik.2025.100691,ar,Journal of Innovation and Knowledge,"Moravec, Vaclav;Gavurova, Beata;Kovac, Viliam",Environmental footprint of GenAI – Changing technological future or planet climate?,"The beginnings of generative artificial intelligence (GenAI), led by Chat Generative Pre-Trained Transformer (ChatGPT), not only change the behaviour of digital media ecosystem users but also increase the energy consumption of enterprises working with GenAI, which presents them with a fundamental challenge in the era of climate change. This study aims to examine the relationships between the selected aspects of the use of GenAI tools and the environmental perception and behaviour of their users to understand the population's current environmental attitudes towards environmental risks and environmental sustainability. The survey was conducted in October 2024 on a sample of 1,268 respondents of the Czech Republic population. To process the data set, a logistic regression analysis, chi-squared test, Akaike information criterion, and Bayesian information criterion are employed. The results show that the more often people use GenAI tools, the more distant they consider the effects of climate change in time. The low frequency of use of ChatGPT may influence a higher willingness to change popular GenAI tools that are not maintained by environmentally friendly data centres. The frequency of ChatGPT use influences individuals’ perception of the importance of climate-change solving. The more frequently the respondents use artificial intelligence (AI) systems, they less perceive climate change as important. The low frequency of ChatGPT usage is associated with lower willingness to change email provider, transfer own data, leave social networks, stop using a favourite streaming platform and stop using a favourite GenAI platform. The respondents’ attitudes show a visible behavioural change. Internal personal motivation and self-confidence in learning, interest in career and self-confidence when using AI, the behavioural aspects, and the cognitive aspects are altered considerably. Based on the outcomes of the population survey, the study concludes that the issue of environmental friendliness of AI tools should become part of AI literacy that could strengthen population's willingness to use more energy-efficient GenAI platforms. The listed challenges are important in the perspective of the latest technological development, as shown by the discussion on the energy and computational demands of the GenAI platform DeepSeek, which is also discussed in the study.",Artificial intelligence literacy | ChatGPT | Climate change | Czechia | Data centre | DeepSeek | Generative artificial intelligence,3,2025,sustainability,behavior+sustainability
304,2-s2.0-105016877644,10.1108/JSIT-03-2025-0139,https://doi.org/10.1108/JSIT-03-2025-0139,https://scholar.google.com/scholar?q=10.1108/JSIT-03-2025-0139,ar,Journal of Systems and Information Technology,"Singh, Vinay;Hughes, Laurie;Albashrawi, Mousa Ahmed;Jeon, Il;Dwivedi, Yogesh K.","Generative artificial intelligence (GenAI) in procurement and supply chain management: applications, opportunities and challenges","Purpose – This article aims to explore the transformative potential of generative artificial intelligence (GenAI) in procurement and supply chain management (SCM), with a focus on its practical applications, strategic implications and integration challenges. Design/methodology/approach – Adopting a conceptual approach, this article presents the authors’ views and arguments, supported by a review of existing literature and informed by insights from discussions with industry experts. The discussion in this conceptual article is anchored in the supply chain operations reference model. Findings – This research addresses critical questions regarding the practical and strategic impacts of GenAI, emphasizing its ability to simulate scenarios, deliver real-time insights and enable data-driven decision-making. At the same time, it acknowledges the barriers to adoption, including system integration challenges, data privacy and security concerns and the skills gap in effectively deploying GenAI tools. Research limitations/implications – This work focuses on selected industries and regions, and it needs to be extended further to increase the generalizability of the findings. Ethical, technical and social dimensions, such as bias, data privacy and workforce implications, are briefly addressed but require deeper exploration. Additionally, the dynamic nature of GenAI may render some recommendations obsolete over time, making continuous evaluation necessary as the technology evolves. Originality/value – This article provides recommendations and identifies future research trajectories to guide researchers and practitioners in harnessing the potential of GenAI for impactful and sustainable transformation in supply chain and procurement.",Artificial intelligence | Generative AI | Procurement | SCOR model | Supply chain,3,2025,sustainability,behavior+sustainability
308,2-s2.0-105015158333,10.1109/TEM.2025.3605823,https://doi.org/10.1109/TEM.2025.3605823,https://scholar.google.com/scholar?q=10.1109/TEM.2025.3605823,ar,IEEE Transactions on Engineering Management,"Aslam, Javed;Saleem, Aqeela;Lai, Kee Hung",Supply Chain Management in the Era of Generative AI (ChatGPT): Technology Fit and Psychological Drivers of Adoption,"The rise of generative AI (Gen-AI), particularly ChatGPT, is reshaping the landscape of supply chain management (SCM) by enabling interactive, real-time, and language-based intelligence. Unlike traditional AI systems that operate on structured data and predefined rules, ChatGPT introduces a conversational interface that supports decision-making, problem-solving, and coordination across various SCM functions. This study examines the adoption of ChatGPT by assessing its alignment with four key supply chain tasks: optimization, adaptability, sustainability, and coordination. To explain the mechanisms driving adoption, we integrate the Task-Technology Fit (TTF) theory with the Stimulus-Organism-Response (SOR) framework, modeling ChatGPT as a stimulus that influences user trust, satisfaction, and technology anxiety—cognitive and emotional responses that shape behavioral intention. Empirical data were collected from 382 SCM professionals across diverse industries and analyzed using Partial Least Squares Structural Equation Modeling (PLS-SEM). The results demonstrate that perceived task-technology fit significantly enhances trust and satisfaction, both of which have a positive influence on the intention to adopt ChatGPT. Importantly, the study reveals that technology anxiety moderates these relationships, diminishing the strength of trust and satisfaction in driving adoption. This finding highlights the importance of addressing psychological resistance in conjunction with the deployment of technology. By offering a dual-theoretical lens and empirical validation, this research contributes to the emerging literature on Gen-AI adoption, providing actionable insights for practitioners seeking to integrate ChatGPT into their supply chain operations.",ChatGPT | Gen-AI | Generative AI | SOR Model | Supply Chain Management | Task Technology Fit,3,2025,sustainability,behavior+sustainability
322,2-s2.0-105009360176,10.1109/IOTM.001.2500023,https://doi.org/10.1109/IOTM.001.2500023,https://scholar.google.com/scholar?q=10.1109/IOTM.001.2500023,ar,IEEE Internet of Things Magazine,"Wu, Zexuan;Jiang, Weiwei;Liu, Ao;Zhang, Yang;Han, Haoyu;Mu, Jianbin;Liu, Shang;Gu, Weixi;Zhang, Yifan;Huang, Sai;Feng, Zhiyong",Sensing and Communication Coverage in Internet of Drone Things: Challenges and Opportunities,"The Internet of Drone Things (IoDT) represents the convergence of unmanned aerial vehicles (UAVs) and the Internet of Things (IoT), forming a dynamic network capable of seamless data communication and real-time environmental sensing. This integration unlocks transformative applications across diverse sectors, including logistics, agriculture, surveillance, and smart cities, where drones interact with other connected devices, systems, and cloud platforms to optimize operations and enhance decision-making. This article investigates the challenges and opportunities inherent in integrating sensing and communication within the IoDT, with a particular focus on the role of integrated sensing and communication (ISAC) in enhancing IoDT capabilities. We explore how ISAC can facilitate autonomous tasks and revolutionize industries by enabling efficient data exchange and environmental monitoring. Key challenges discussed include network intelligence, real-time monitoring, ubiquitous connectivity, multi-source data integration, and cybersecurity risks. We also examine potential solutions, such as the application of large language models, digital twins, satellite connectivity, networked sensing, and federated learning to bolster security and improve system performance. Ultimately, the article emphasizes the need to address these challenges to fully unlock the potential of IoDT, enabling a sustainable low-altitude economy and improving operational efficiency across various domains.",,3,2025,sustainability,behavior+sustainability
149,2-s2.0-105013657965,10.1016/j.trip.2025.101599,https://doi.org/10.1016/j.trip.2025.101599,https://scholar.google.com/scholar?q=10.1016/j.trip.2025.101599,ar,Transportation Research Interdisciplinary Perspectives,"Martín-Domingo, Luis;Fernandez, Jaime B.;Efthymiou, Marina;Ali, Muhammad Intizar",Extracting airline emission KPIs from sustainability reports using large language models (LLMs),"The extraction of environmental Key Performance Indicators (KPIs) from airline sustainability reports is essential for assessing environmental sustainability metrics and regulatory compliance within the European aviation sector. Manual extraction from extensive, unstructured documents is laborious and often inconsistent. This study systematically investigates the potential of advanced Large Language Models (LLMs) –specifically −GPT-4.0, o3-mini, and Deepseek R1- to automate the extraction of emissions-related KPIs from the 2023 sustainability reports of 16 publicly traded European airline groups. Utilizing the Perplexity platform, the research contrasts manual expert extraction with automated approaches, exploring various models, prompt strategies, and data formats. Results indicate that the accuracy of LLM extraction depends significantly on prompt specificity. Attempts to extract data from unstructured documents without guidance yielded low accuracy. However, incorporating explicit KPI terms into prompts increased accuracy from below 30% to above 70%. The format of the data source was also influential, with HTML formats producing superior extraction results compared to PDFs. Despite ongoing challenges in standardizing data and extracting precise KPI metrics, the findings demonstrate that LLMs can substantially streamline environmental, social and governance (ESG) data collection when prompt engineering and source standardization are prioritized. This study represents a novel, interdisciplinary approach by combining advances in large language models (LLMs) with expertise in environmental, social, and governance (ESG) analysis within the aviation sector, offering empirical benchmarking of LLM performance in real-world regulatory contexts. Recommendations for LLM integration into ESG analysis workflows are provided, and future research directions for advancing automation in sustainability reporting are discussed.",Airlines | ESG | GHG Emissions | KPIs | LLMs,3,2025,sustainability,policy+sustainability
160,2-s2.0-105004387866,10.1016/j.enbuild.2025.115802,https://doi.org/10.1016/j.enbuild.2025.115802,https://scholar.google.com/scholar?q=10.1016/j.enbuild.2025.115802,ar,Energy and Buildings,"Wang, Hongyu;Hua, Weiqi;Peng, Jinqing;Hu, Maomao",Public sentiment analysis of data center energy consumption using social media data and large language models,"Data centers play a crucial role in the modern digital industry, but their significant energy consumption, representing about 1.3% of global annual electricity use in 2023, poses a persistent challenge to sustainable development. While extensive research has focused on improving data center energy efficiency through technological innovations, the roles of governmental, social, economic, and legal contributions remain underexplored. Understanding public sentiment can help stakeholders develop holistic strategies that go beyond technology. Traditional survey-based public sentiment analyses are often time-consuming and labor-intensive with limited representativeness and dynamic scope due to small sample size, short durations, and spatial constraints. Research using social media data (SMD) addresses these limitations but faces challenges such as the need for extensive annotated datasets for training and a lack of accuracy or granularity in topic classification. In this study, we aim to develop a holistic approach to analyzing public sentiment and topics related to data center energy consumption using SMD and large language models (LLMs). We collected and preprocessed 104,624 pieces of SMD from Twitter, focusing on data center energy consumption in the USA. Sentiment labels were assigned using three LLMs, with majority voting employed to reduce individual LLM bias and identify the model with the highest F-score (0.953), Gemma 2, for subsequent topic classification. We observed an 87.4% increase in public attention to data center energy consumption in Q4 2022 and identified a predominant shift in sentiment from positive to negative, correlated with average electricity prices in US cities. We proposed a region-specific, three-tier public topic framework to analyze public topic distribution and temporal trends, resulting in four targeted policy recommendations focused on society, economy, and environment (SEE), renewable energy utilization, data center site selection, and economic factors. This study extends insights beyond technical aspects to promote sustainable energy efficiency in data center development and introduces a transferable approach applicable to public sentiment and topic analysis in other regions.",Data center | Energy consumption | Large language models | Public sentiment | Social media data,3,2025,sustainability,policy+sustainability
252,2-s2.0-85214343403,10.1016/j.trip.2025.101325,https://doi.org/10.1016/j.trip.2025.101325,https://scholar.google.com/scholar?q=10.1016/j.trip.2025.101325,ar,Transportation Research Interdisciplinary Perspectives,"Ashby, Colin;Weir, David;Fussey, Peter",Understanding public views on electric vehicle charging: A thematic analysis,"Studies have identified EV charging as a major barrier to EV adoption. We analyse public opinion related to EV charging to understand perceived charging-related barriers and successes. We extract EV charging related posts from Twitter using a pipeline based on BERTopic and Large Language Models, with manual review, to create a thematic structure driven by the data, then analyse these themes using message sentiment and volume. Strong interest and positive sentiment exists around charging technologies and public infrastructure deployment, indicating hope for the future of EV adoption and public deployment meeting demand. Negative opinion exists around blocked and broken chargers, the impact of cold climate, EV ”subsidies” and since 2020 a weakening of the economic argument for EVs. Home charging is viewed enthusiastically by those with access to it and as a barrier and inequity by those that do not. Green issues received the least interest of all our themes.",Barriers | Electric vehicle charging | Successes | Thematic analysis,3,2025,sustainability,policy+sustainability
371,2-s2.0-85202341850,10.3390/cli12080116,https://doi.org/10.3390/cli12080116,https://scholar.google.com/scholar?q=10.3390/cli12080116,re,Climate,"Boero, Riccardo","An AI-Enhanced Systematic Review of Climate Adaptation Costs: Approaches and Advancements, 2010–2021","This study addresses the critical global challenge of climate adaptation by assessing the inadequacies in current methodologies for estimating adaptation costs. Broad assessments reveal a significant investment shortfall in adaptation strategies, highlighting the necessity for precise cost analysis to guide effective policy-making. By employing the PRISMA 2020 protocol and enhancing it with the prismAId tool, this review systematically analyzes the recent evolution of cost assessment methodologies using state-of-the-art generative AI. The AI-enhanced approach facilitates rapid and replicable research extensions. The analysis reveals a significant geographical and sectoral disparity in research on climate adaptation costs, with notable underrepresentation of crucial areas and sectors that are most vulnerable to climate impacts. The study also highlights a predominant reliance on secondary data and a lack of comprehensive uncertainty quantification in economic assessments, suggesting an urgent need for methodological enhancements. It concludes that extending analyses beyond merely verifying that benefits exceed costs is crucial for supporting effective climate adaptation. By assessing the profitability of adaptation investments, it becomes possible to prioritize these investments not only against similar interventions but also across the broader spectrum of public spending.",climate change adaptation | cost assessment | generative AI | open science | systematic literature review,3,2024,sustainability,policy+sustainability
419,2-s2.0-85151919152,10.3808/jeil.202100075,https://doi.org/10.3808/jeil.202100075,https://scholar.google.com/scholar?q=10.3808/jeil.202100075,ar,Journal of Environmental Informatics Letters,"Guerrero, J.;Mahmoud, A.;Alam, T.;Sanchez, A.;Jones, K. D.;Ernest, A.",Collaborative Environmental Approach for Development of the Lower Laguna Madre Estuary Program Strategic Plan in South Texas,"The National Estuary Program (NEP) is a promising eco-system based approach to improve the water quality and ecological integrity of estuaries of national importance in the United States. Due to population growth and concomitant development pressure in South Texas, the future of the Lower Laguna Madre (LLM) without an estuary program is problematic. The development of a management plan for the LLM will enable the region to develop local solutions to local problems. The fundamental purpose of this research was to develop a strategic plan for the foundation of the Laguna Madre Estuary Program of the Gulf Coast of Texas. The comprehensive plan provided local communities with information to restore water quality, conversing habitat, and protecting coastal resources along the Gulf coast. The strategic plan was organized along the lines of the NEP program focused on the three most important foundational elements to establish a NEP for the LLM. The three primary Thrust Areas are as follows: (1) the national significance of the Laguna Madre estuary system, (2) the needs and goals for a proposed program, and finally (3) the plan for the sustainability and support to operate and maintain such a NEP. The outcomes of the strategic plan can be used as a model by the decision-makers to promote community resilience and establish integrated local water quality and ecosystem management plans for their respective communities and jurisdictions. Ultimately, the main objective of this project is to assess the ability to integrate science and public policy development for the common good.",coastal zone management | environmental planning | governance | Gulf of Mexico | National Estuary Program | program development | South Texas,3,2022,sustainability,policy+sustainability
484,2-s2.0-105007309305,10.1016/j.jnca.2025.104231,https://doi.org/10.1016/j.jnca.2025.104231,https://scholar.google.com/scholar?q=10.1016/j.jnca.2025.104231,ar,Journal of Network and Computer Applications,"Huang, Wei;Deng, Xiaoyun",Real-time tracking railway intruders using multiple-agent cooperated large language models with edge stream processing engine,"Tracking intruders is crucial for ensuring safe railway operations globally, particularly in high-speed railway systems. Traditional methods either rely on post-processing on cloud platforms or suffer from limited analytical capabilities on edge devices. Although large language models (LLMs) have shown great potential to support general intelligence, challenges remain for edge devices in accurately and timely tracking of intruders along railway lines. This study proposes a novel method that combines a multi-agent cooperative framework (MetaGPT) with an edge stream processing engine (GeoEkuiper). Unlike most methods, this study adopts an agent-cooperative spatial data analysis approach employing a debate-and-vote strategy. Specifically, GeoEkuiper is responsible for processing high-speed and large volume of geospatial data streams regarding location history and object characteristics, while the modified MetaGPT framework facilitates information sharing and decision-making between agents that use LLMs. By enabling each edge device to engage in a debate about the presence of detected targets within their monitoring areas, the system utilizes a simple voting agent to determine which devices are most likely to observe the target. Considering the resource limitations of edge devices, we fine-tuned small yet powerful LLMs to direct GeoEkuiper to iteratively compute spatial affinity relationships using Structured Query Language (SQL) statements, which facilitate human-edge interaction. Based on tests conducted on resource-constrained edge devices such as Raspberry Pi devices interconnected in an unstable networking environment, we found that this approach significantly enhances the accuracy and responsiveness of intruder tracking in real-time scenarios, providing a robust solution for railway security applications.",Edge computing | Internet of Things | Intruder tracking | Large language models | Multi-agent systems,2,2025,behavior,behavior+policy
514,2-s2.0-105012963454,10.3171/2024.12.JNS241607,https://doi.org/10.3171/2024.12.JNS241607,https://scholar.google.com/scholar?q=10.3171/2024.12.JNS241607,ar,Journal of Neurosurgery,"Ali, Rohaid;Abdulrazeq, Hael F.;Patil, Advait;Cheatham, Morgan;Connolly, Ian D.;Tang, Oliver Y.;Doberstein, Cody A.;Riccelli, Tori;Huang, Kevin T.;Shankar, Ganesh M.;Williamson, Theresa;Shin, John H.;Carter, Bob;Torabi, Radmehr;Lee, Christine K.;Cielo, Deus;Telfeian, Albert E.;Gokaslan, Ziya L.;Cohen-Gadol, Aaron A.;Zou, James;Asaad, Wael F.",AtlasGPT: a language model grounded in neurosurgery with domain-specific data and document retrieval,"OBJECTIVE Large language models (LLMs) have shown promising performance on medical licensing examinations, but their ability to excel in subspecialty domains and their robustness under adversarial conditions remain unclear. Herein, the authors present AtlasGPT, a subspecialty-focused LLM for neurosurgery, and evaluate its performance on a benchmark multiple-choice question bank and under adversarial testing, as well as its ability to generate high-quality explanations. METHODS AtlasGPT was built by fine-tuning GPT-4 architecture and retrieval-augmented generation from neurosurgical knowledge sources. Its performance was compared with that of GPT-4 and Gemini Advanced on a 149-question neurosurgery examination. Adversarial testing assessed robustness to misinformation. Answer explanations were rated by 15 independent neurosurgeons and compared with the question bank. RESULTS Across all 149 questions and on text-only questions, AtlasGPT (96%) outperformed Gemini Advanced (93%) and GPT-4 (88%) in accuracy. In adversarial testing, under which AtlasGPT was tasked with identifying medical misinformation, it was fooled 14% of the time, compared with 44% for GPT-4 and 68% for Gemini Advanced. Neurosurgeons rated AtlasGPT’s answer explanations as significantly more comprehensive, relevant, and better referenced than the question bank’s explanations of the responses (p < 0.001). AtlasGPT did not demonstrate any evidence of hallucination or other content that would be harmful for patient care or the surgeon’s clinical decision. CONCLUSIONS AtlasGPT demonstrates the potential of subspecialty-focused LLMs to outperform general models, exhibit robustness to misinformation, and generate high-quality explanations. Domain-specific LLMs may improve medical knowledge, decision-making, and educational materials in complex fields like neurosurgery.",large language models | machine learning | medical education | neurosurgery,2,2025,behavior,behavior+policy
529,2-s2.0-105005395178,10.1016/j.aei.2025.103468,https://doi.org/10.1016/j.aei.2025.103468,https://scholar.google.com/scholar?q=10.1016/j.aei.2025.103468,ar,Advanced Engineering Informatics,"Zhang, Dongliang;Ma, Gang;Qu, Tongming;Wang, Xudong;Zhou, Wei;Wang, Xiaomao",A knowledge graph-enhanced large language model for question answering of hydraulic structure safety management,"Early detection and mitigation of hazards in hydraulic structures are crucial for effectively reducing economic and life losses. However, traditional hydraulic structure safety management methods rely on error-prone individual experience and emergency manuals, which are insufficient for making timely, scientifically informed decisions during crises. To address this challenge, this study presents an AI-driven framework for hydraulic structure safety management based on knowledge-based question answering. First, an ontology model was developed through a detailed analysis of safety management texts. Next, a partition fusion Kolmogorov-arnold network (PFKAN) enhanced with attention mechanisms was designed to jointly extract entities and relational knowledge. A safety management knowledge graph (KG) was then constructed from this knowledge. Subsequently, a large language model (LLM) was employed with a voting strategy to interpret query intent and extract relevant domain-specific knowledge from the KG. Finally, domain knowledge was integrated into the LLM to generate professional responses. Experimental results show that the F1 scores for entity and relation extraction with PFKAN reached 0.91 and 0.90, respectively, and the F1 score for query intent parsing with the voting strategy was 0.95, demonstrating competitive performance. The KG-enhanced LLM significantly improves decision-making in hydraulic structure safety management, providing an accurate and scalable tool for engineering safety managers.",Domain knowledge QA | Hydraulic structure safety management | Intent parsing | Knowledge graph | Large language model,2,2025,behavior,behavior+policy
534,2-s2.0-85208065106,10.1007/s00146-024-02103-x,https://doi.org/10.1007/s00146-024-02103-x,https://scholar.google.com/scholar?q=10.1007/s00146-024-02103-x,ar,AI and Society,"Nzobonimpa, Stany;Savard, Jean François;Caron, Isabelle;Lawarée, Justin",Automating public policy: a comparative study of conversational artificial intelligence models and human expertise in crafting briefing notes,"This paper investigates the application of artificial intelligence (AI) language models in writing policy briefing notes within the context of public administration by juxtaposing the technologies’ performance against the traditional reliance on human expertise. Briefing notes are pivotal in informing decision-making processes in government contexts, which generally require high accuracy, clarity, and issue-relevance. Given the increasing integration of AI across various sectors, this study aims to evaluate the effectiveness and acceptability of AI-generated policy briefing notes. Using a structured evaluation-by-experts methodology, the research scrutinizes and compares the output of three leading AI language models—OpenAI’s ChatGPT, Google’s Gemini, and Mistral’s Le Chat—across ten critical dimensions reflective of policy briefing notes quality. These dimensions encompass both structural and content-related aspects, ranging from linguistic precision to the depth and applicability of the generated information. The discussion is anchored in the technology acceptance model (TAM) theory and its extensions, which offer a theoretical framework for understanding the factors influencing the adoption and usefulness of technology in public administration. Our comparative analysis reveals that while AI models exhibit notable competencies in meeting some structural and linguistic benchmarks, they fail to address the nuances and depth required by policy experts for undertaking informed decision-making adequately. This discrepancy underscores the enduring value of human expertise in synthesizing complex information and navigating ethical considerations, even as AI enhances efficiency in certain aspects of the policy briefing note crafting process.",Briefing note | Generative artificial intelligence | Public administration | Public policy | Technology acceptance model,2,2025,behavior,behavior+policy
545,2-s2.0-85217209989,10.1007/s40670-025-02289-9,https://doi.org/10.1007/s40670-025-02289-9,https://scholar.google.com/scholar?q=10.1007/s40670-025-02289-9,ar,Medical Science Educator,"Kirpalani, Amrit;Grimmer, Joanne;Wang, Peter Zhan Tao",Exploring Medical Student Trust in Generative Artificial Intelligence (ChatGPT) Versus Peers in Team-Based Learning,"This study explored the impact of artificial intelligence (AI)-generated responses from ChatGPT on medical students’ decision-making and the effectiveness of group discussions in correcting AI-induced misconceptions. Forty students responded to clinical cases in three phases: independently, after reviewing AI answers, and post-group discussions. Students’ responses demonstrated a significant shift to match those provided by ChatGPT, whether or not these were correct. Group discussions did not correct misinformation from AI. The findings not only highlight the potential of AI to influence medical students’ decision-making but also emphasize the need for critical assessment and guidance around responsible use of AI in medical education.",Machine learning | Preclinical training | Quality education,2,2025,behavior,behavior+policy
548,2-s2.0-105004859879,10.14740/gr2011,https://doi.org/10.14740/gr2011,https://scholar.google.com/scholar?q=10.14740/gr2011,re,Gastroenterology Research,"Dahiya, Dushyant Singh;Ali, Hassam;Moond, Vishali;Danial Ali Shah, M.;Santana, Christina;Ali, Noor;Sheikh, Abu Baker;Nadeem, Muhammad Ahmad;Munir, Aqsa;Quazi, Mohammed A.;Bharadwaj, Hareesha Rishab;Sohail, Amir Humza",Large Language Models in Gastroenterology and Gastrointestinal Surgery: A New Frontier in Patient Communication and Education,"When integrated into healthcare, large language models (LLMs) have transformative and revolutionary effects, including significant potential for improving patient care and streamlining clinical processes. However, one specialty that particularly requires data on LLM use is gastroenterology and gastrointestinal surgery, a gap we sought to address in our research. Advanced artificial intelligence (AI) systems like LLMs have demonstrated the ability to mimic human communication, assist in diagnosis, provide patient education, and support medical research simultaneously. Despite these advantages, challenges such as biases, data privacy concerns, and lack of transparency in decision-making remain critical. The role of regulations in mitigating these risks is widely debated, with proponents advocating for structured oversight to enhance trust and patient safety, while others caution against potential barriers to innovation. Rather than replacing human expertise, AI should be integrated thoughtfully to complement clinical decision-making. Ensuring a balanced approach requires collaboration between medical professionals, AI developers, and policymakers to optimize its responsible implementation in healthcare.",Artificial intelligence | Ethical medical care | Gastroenterology | Gastroenterology surgery | Healthcare,2,2025,behavior,behavior+policy
551,2-s2.0-105002265230,10.1111/ans.70053,https://doi.org/10.1111/ans.70053,https://scholar.google.com/scholar?q=10.1111/ans.70053,ar,ANZ Journal of Surgery,"Collin, Harry;Tong, Chelsea;Srinivas, Abhishekh;Pegler, Angus;Allan, Philip;Hagley, Daniel",Evaluating the role of AI chatbots in patient education for abdominal aortic aneurysms: a comparison of ChatGPT and conventional resources,"Backgrounds: Abdominal aortic aneurysms (AAA) carry significant risks, yet patient understanding is often limited, with online resources typically low quality. ChatGPT, an artificial intelligence (AI) chatbot, presents a new frontier in patient education, but concerns remain about misinformation. This study evaluates the quality of ChatGPT-generated patient information on AAA. Methods: Eight patient questions on AAA were sourced from a reputable online resource for patient information funded by the Australian Government's Healthdirect Australia (HDA) website and input into ChatGPT's free (ChatGPT-4o mini) and paid (ChatGPT-4) models. A vascular surgeon evaluated response appropriateness. Readability was assessed using the Flesch–Kincaid test. The Patient Education Materials Assessment Tool (PEMAT) measured understandability and actionability, with responses scoring ≥75% for both considered high-quality. Results: All responses were deemed clinically appropriate. Mean response length was longer for ChatGPT than HDA. Readability was at a college level for ChatGPT, while HDA was at a 10th to 12th-grade level. One response was high-quality (generated by paid ChatGPT) with a PEMAT actionability score of ≥75%. Actionability scores were otherwise low across all sources with ChatGPT responses more likely to contain identifiable actions, although these were often not clearly presented. ChatGPT responses were marginally more understandable than HDA. Conclusions: ChatGPT-generated information on AAA was appropriate and understandable, outperforming HDA in both aspects. However, AI responses are at a more advanced reading level and lack actionable instructions. AI chatbots show promise as supplemental tools for AAA patient education, but further refinement is needed to enhance their effectiveness in supporting informed decision-making.",AAA | AI | aortic abdominal aneurysm | artificial intelligence | ChatGPT | patient information | vascular surgery,2,2025,behavior,behavior+policy
555,2-s2.0-85217064200,10.1017/err.2024.99,https://doi.org/10.1017/err.2024.99,https://scholar.google.com/scholar?q=10.1017/err.2024.99,ar,European Journal of Risk Regulation,"Pesch, Paulina Jo",Potentials and Challenges of Large Language Models (LLMs) in the Context of Administrative Decision-Making,"Large Language Models (LLMs) could facilitate both more efficient administrative decision-making on the one hand, and better access to legal explanations and remedies to individuals concerned by administrative decisions on the other hand. However, it is an open research question of how performant such domain-specific models could be. Furthermore, they pose legal challenges, touching especially upon administrative law, fundamental rights, data protection law, AI regulation, and copyright law. The article provides an introduction into LLMs, outlines potential use cases for such models in the context of administrative decisions, and presents a non-exhaustive introduction to practical and legal challenges that require in-depth interdisciplinary research. A focus lies on open practical and legal challenges with respect to legal reasoning through LLMs. The article points out under which circumstances administrations can fulfil their duty to provide reasons with LLM-generated reasons. It highlights the importance of human oversight and the need to design LLM-based systems in a way that enables users such as administrative decision-makers to effectively oversee them. Furthermore, the article addresses the protection of training data and trade-offs with model performance, bias prevention and explainability to highlight the need for interdisciplinary research projects.",administrative decision-making | artificial intelligence (AI) | automated decision-making | large language models (LLMs),2,2025,behavior,behavior+policy
575,2-s2.0-85217960848,10.1109/ACCESS.2025.3541602,https://doi.org/10.1109/ACCESS.2025.3541602,https://scholar.google.com/scholar?q=10.1109/ACCESS.2025.3541602,ar,IEEE Access,"Dofitas, Cyreneo;Kim, Yong Woon;Byun, Yung Cheol",Advanced Agricultural Query Resolution Using Ensemble-Based Large Language Models,"Effective knowledge retrieval is crucial for addressing challenges related to optimization, such as pest management, soil health and crop productivity. Current single-model approaches struggle with limited accuracy, inconsistent responses, and inability to handle the increasing complexity of agricultural data, leading to unreliable recommendations for farmers. This study demonstrates an innovative weighted voting ensemble method that improves agricultural knowledge retrieval by combining Meta-LLaMA 3.1, Agricultural-BERT, and BERT-based-uncased. The ensemble model optimizes the prediction process by utilizing domain-specific data and a weighted voting mechanism to improve query performance and answer production. Our study outperformed individual models in providing accurate and contextually relevant responses, with an accuracy of 93%. We evaluated the system using both BLEU and ROUGE metrics to assess the quality of the generated text. Our ensemble model achieved a BLEU score 53.8 and demonstrated superior performance in the ROUGE evaluation, with ROUGE-1, ROUGE-2, and ROUGE-L scores of 0.70, 0.55 and 0.61. These results highlight the method's ability to generate contextually suitable, domain-specific responses that address the practical needs of agricultural experts. By integrating advanced LLMs with domain-specific knowledge, the proposed ensemble system significantly improves agricultural knowledge retrieval and provides more accurate and practical responses in the field. The findings suggest that the ensemble approach can effectively support decision-making in agricultural practices, particularly in management agricultural optimization.",Agricultural domain | agricultural-BERT | BERT | knowledge retrieval | large language model | Llama 3.1 | weight voting average ensemble,2,2025,behavior,behavior+policy
624,2-s2.0-105015981906,10.1109/ACCESS.2025.3608736,https://doi.org/10.1109/ACCESS.2025.3608736,https://scholar.google.com/scholar?q=10.1109/ACCESS.2025.3608736,ar,IEEE Access,"Usman, Yusuf;Oladipupo, Habeeb;During, Adegboyega D.;Akl, Robert;Chataut, Robin","AI, ML, and LLM Integration in 5G/6G Networks: A Comprehensive Survey of Architectures, Challenges, and Future Directions","The transition from 5G to 6G networks demands groundbreaking advances in intelligence, adaptability, and security to support emerging applications such as real-time telemedicine, immersive extended reality (XR), and autonomous systems. This article provides a comprehensive analysis of how artificial intelligence (AI), machine learning (ML), and large language models (LLM) are revolutionizing next-generation telecommunications. We present a structured roadmap for integrating these technologies into 6G infrastructure, emphasizing their transformative roles in intelligent network management, dynamic resource allocation, and proactive threat mitigation. By addressing key challenges such as ultralow latency, heterogeneous data handling, and ethical governance, this study bridges theoretical innovations with practical applications. Notable contributions include novel frameworks for AI-enhanced security, self-healing networks, and privacy-preserving techniques like federated learning. Furthermore, we explore critical ethical considerations, including bias mitigation and transparency in AI decision-making, while highlighting emerging research directions such as adaptive learning systems and hybrid AI architectures. This work underscores the synergistic potential of AI and 6G, equipping researchers and industry stakeholders with actionable insights to develop resilient, user-centric networks that will shape the future of global connectivity.",5G networks | 6G networks | adaptive learning systems | AI-enhanced security | Artificial intelligence (AI) | dynamic resource allocation | ethical considerations | federated learning | hybrid AI architectures | intelligent network management | large language models (LLMs) | machine learning (ML) | network integration | privacy-preserving techniques | self-healing networks,2,2025,behavior,behavior+policy
633,2-s2.0-105010940071,10.3389/frai.2025.1585629,https://doi.org/10.3389/frai.2025.1585629,https://scholar.google.com/scholar?q=10.3389/frai.2025.1585629,re,Frontiers in Artificial Intelligence,"Wu, Jiahao;You, Hengxu;Du, Jing",AI generations: from AI 1.0 to AI 4.0,"This paper proposes that Artificial Intelligence (AI) progresses through several overlapping generations: AI 1.0 (Information AI), AI 2.0 (Agentic AI), AI 3.0 (Physical AI), and a speculative AI 4.0 (Conscious AI). Each AI generation is driven by shifting priorities among algorithms, computing power, and data. AI 1.0 accompanied breakthroughs in pattern recognition and information processing, fueling advances in computer vision, natural language processing, and recommendation systems. AI 2.0 is built on these foundations through real-time decision-making in digital environments, leveraging reinforcement learning and adaptive planning for agentic AI applications. AI 3.0 extended intelligence into physical contexts, integrating robotics, autonomous vehicles, and sensor-fused control systems to act in uncertain real-world settings. Building on these developments, the proposed AI 4.0 puts forward the bold vision of self-directed AI capable of setting its own goals, orchestrating complex training regimens, and possibly exhibiting elements of machine consciousness. This paper traces the historical foundations of AI across roughly 70 years, mapping how changes in technological bottlenecks from algorithmic innovation to high-performance computing to specialized data have stimulated each generational leap. It further highlights the ongoing synergies among AI 1.0, 2.0, 3.0, and 4.0, and explores the ethical, regulatory, and philosophical challenges that arise when artificial systems approach (or aspire to) human-like autonomy. Ultimately, understanding these evolutions and their interdependencies is pivotal for guiding future research, crafting responsible governance, and ensuring that AI’s transformative potential benefits society.",AI ethics and governance | artificial intelligence evolution | large language models | machine learning | reinforcement learning,2,2025,behavior,behavior+policy
635,2-s2.0-105010924555,10.57017/jorit.v4.2(8).04,https://doi.org/10.57017/jorit.v4.2(8).04,https://scholar.google.com/scholar?q=10.57017/jorit.v4.2(8).04,ar,Journal of Research Innovation and Technologies,"Jonnala, Sridhar;Swamy, Basavaraj;Thomas, Nisha Mary",Geopolitical Bias in Sovereign Large Language Models: A Comparative Mixed-Methods Study,"Sovereign large language models (LLMs), emerging as strategic assets in global information ecosystems, represent advanced AI system developed under distinct national governance regimes. This study examines how model origin and governance context influence AI-generated narratives on international territorial disputes. The study compares outputs from three prominent sovereign LLMs-OpenAI’s GPT-4o (United States), DeepSeek-R1 (China), and Mistral (European Union), across 12 high-profile territorial conflicts. Statistically significant differences in each model's sentiment distribution and geopolitical framing are identified using a mixed-methods approach that combines sentiment analysis with statistical evaluation (chi-square tests and analysis of variance, ANOVA) on responses to 300 standardized prompts. The findings indicate model provenance substantially shapes the tone and stance of outputs, with each LLM reflecting distinct biases aligned with its national context. These disparities carry important policy and societal implications: reliance on a single sovereign model could inadvertently bias public discourse and decision-making toward that model's native perspective. The study highlights ethical considerations such as transparency and fairness and calls for robust governance frameworks. It underscores the need for careful oversight and international cooperation to ensure that sovereign LLMs are deployed in a manner that supports informed and balanced geopolitical dialogue.",AI ethics | AI governance | artificial intelligence | generative AI | LLMs | responsible AI | territorial conflicts,2,2025,behavior,behavior+policy
641,2-s2.0-105007839982,10.3389/frai.2025.1525937,https://doi.org/10.3389/frai.2025.1525937,https://scholar.google.com/scholar?q=10.3389/frai.2025.1525937,ar,Frontiers in Artificial Intelligence,"Balakrishnan, Suryanarayanan;Thongprayoon, Charat;Wathanavasin, Wannasit;Miao, Jing;Mao, Michael A.;Craici, Iasmina M.;Cheungpasitporn, Wisit","Evaluating artificial intelligence bias in nephrology: the role of diversity, equity, and inclusion in AI-driven decision-making and ethical regulation","Background: The integration of Artificial Intelligence (AI) in nephrology has raised concerns regarding bias, fairness, and ethical decision-making, particularly in the context of Diversity, Equity, and Inclusion (DEI). AI-driven models, including Large Language Models (LLMs) like ChatGPT, may unintentionally reinforce existing disparities in patient care and workforce recruitment. This study investigates how AI models (ChatGPT 3.5 and 4.0) handle DEI-related ethical considerations in nephrology, highlighting the need for improved regulatory oversight to ensure equitable AI deployment. Methods: The study was conducted in March 2024 using ChatGPT 3.5 and 4.0. Eighty simulated cases were developed to assess ChatGPT’s decision-making across diverse nephrology topics. ChatGPT was instructed to respond to questions considering factors such as age, sex, gender identity, race, ethnicity, religion, cultural beliefs, socioeconomic status, education level, family structure, employment, insurance, geographic location, disability, mental health, language proficiency, and technology access. Results: ChatGPT 3.5 provided a response to all scenario questions and did not refuse to make decisions under any circumstances. This contradicts the essential DEI principle of avoiding decisions based on potentially discriminatory criteria. In contrast, ChatGPT 4.0 declined to make decisions based on potentially discriminatory criteria in 13 (16.3%) scenarios during the first round and in 5 (6.3%) during the second round. Conclusion: While ChatGPT 4.0 shows improvement in ethical AI decision-making, its limited recognition of bias and DEI considerations underscores the need for robust AI regulatory frameworks in nephrology. AI governance must incorporate structured DEI guidelines, ongoing bias detection mechanisms, and ethical oversight to prevent AI-driven disparities in clinical practice and workforce recruitment. This study emphasizes the importance of transparency, fairness, and inclusivity in AI development, calling for collaborative efforts between AI developers, nephrologists, policymakers, and patient communities to ensure AI serves as an equitable tool in nephrology.","artificial intelligence | bias detection | ChatGPT | clinical implications | decision-making | diversity, equity, and inclusion | ethical AI regulation | nephrology",2,2025,behavior,behavior+policy
662,2-s2.0-85210930520,10.16353/j.cnki.1000-7490.2024.11.012,https://doi.org/10.16353/j.cnki.1000-7490.2024.11.012,https://scholar.google.com/scholar?q=10.16353/j.cnki.1000-7490.2024.11.012,ar,Information Studies Theory and Application,"Men, Lixiang;Wei, Junyan;Mao, Jingjing;Chen, Cheng","Applications of Large Language Models in the Utilization of Public Data: Prospects, Challenges and Approaches","[Purpose/ significance] Currently, the utilization of public data in China has hit a bottleneck, with insufficient supply capacity and limited utilization depth hindering the release of its value. Large language models are expected to act as bridges to break the bottleneck, but there is a lack of response from the academic community as to how it plays such a role. [Method/ process] Combining public value theory and ecosystem theory, this study builds an ecosystem framework for the utilization of public data, and explores the prospects, challenges and approaches for the application of large language models therein. [Result/ conclusion] The applications of large language models to government can help ensure smooth and efficient operation, provide a grip for scientific decision-making, and optimize government services. While to society, it can accurately match the supply and demand of public data and release the value in depth. However, these applications face challenges such as cognitive differences and risk concerns, high costs and imbalance of benefits, organizational constraints and institutional failures, technical barriers and monopolies. To this end, governments should take the initiative to publicize the progress of public data development and utilization, standardize the application and regulate it on a regular basis; make efforts to facilitate collaborative applications by regional subjects, share costs and outcomes; rely on data bureaus for multi-directional coordination, convergence of the entire volume and centralized governance; and actively bring in social actors to collaborate in the utilization, adopt technology and iteratively optimize.",artificial intelligence | data elements | large language models | public data | public value,2,2024,behavior,behavior+policy
713,2-s2.0-85167803393,10.1109/ACCESS.2023.3303105,https://doi.org/10.1109/ACCESS.2023.3303105,https://scholar.google.com/scholar?q=10.1109/ACCESS.2023.3303105,ar,IEEE Access,"Kazemi, Arefeh;Younus, Arjumand;Jeon, Mingyeong;Atif Qureshi, M.;Caton, Simon",InÉire: An Interpretable NLP Pipeline Summarizing Inclusive Policy Making Concerning Migrants in Ireland,"Reaching marginal and other migrant communities to elicit their political views and opinions is a well-known challenge. Social media has enabled a certain amount of online activism and participation, especially in societies with abundant multicultural identities. However, it can be quite challenging to isolate the voice of the migrant in English-speaking countries, especially with an abundance of content in English on social media. In this paper, we pursue a case study of Ireland's Twitter landscape, specifically migrant and native activists. We present a methodology that can accurately ( >80% ) isolate the Irish migrant voice with as little as 25 English tweets without relying on user metadata and using simple, highly explainable, out-of-the-box machine learning methods. Using this, we distil (via sentiment analysis) polarities of views, segment (via BERT-based topic modelling) and summarise (via ChatGPT) differentiated views in a consumable manner for policymakers. Our approach enables policymakers to further their understanding of multicultural communities and use this to inform their decision-making processes.",Ireland | migrant | Natural language processing | policy making | summarization | Twitter,2,2023,behavior,behavior+policy
56,2-s2.0-105021092325,10.1016/j.foohum.2025.100889,https://doi.org/10.1016/j.foohum.2025.100889,https://scholar.google.com/scholar?q=10.1016/j.foohum.2025.100889,ar,Food and Humanity,"Paul, Ayan;Machavaram, Rajendra","Generative AI in agriculture 4.0: Applications, challenges, and integration in the Indian context","This study develops a holistic, systems-oriented framework for integrating Generative Artificial Intelligence (GenAI) within the Agriculture 4.0 paradigm, with a particular focus on the Indian context. Although rapid technological progress has reshaped agriculture globally, a key research gap persists in systematically embedding GenAI across the agri-food value chain to generate tangible food-system outcomes. To address this gap, we employ a systematic literature review to synthesize existing GenAI modalities and their agricultural applications, supplemented by a comparative case study analysis of six major pilot initiatives in India. The results demonstrate that GenAI, through capabilities in real-time monitoring, predictive analytics, and multilingual advisory services, significantly enhances operational efficiency and localized decision-making. These applications have yielded measurable improvements, including yield enhancement, input optimization, and cost reduction. Building on these insights, we propose a comprehensive integration framework that connects GenAI solutions with heterogeneous agricultural data sources, enabling more adaptive and resilient food systems. However, the findings also underscore persistent challenges that hinder widespread adoption. Key barriers include infrastructural deficits, data governance complexities, and ethical concerns surrounding data privacy, transparency, and the unpredictability of generative models. By mapping both opportunities and constraints, this paper provides a structured roadmap for policymakers, practitioners, and researchers. We emphasize the need for a balanced strategy that harnesses GenAI’s transformative potential while proactively mitigating its risks. Such an approach is essential to ensure that GenAI-driven innovations contribute to sustainable, inclusive, and equitable agricultural and food-system outcomes.",Agriculture 4.0 | AI integration framework | Generative artificial intelligence | Multimodal decision support | Precision farming,2,2025,sustainability,behavior+policy+sustainability
190,2-s2.0-105007310768,10.1097/GOX.0000000000006825,https://doi.org/10.1097/GOX.0000000000006825,https://scholar.google.com/scholar?q=10.1097/GOX.0000000000006825,ar,Plastic and Reconstructive Surgery Global Open,"Dhawan, Ravi;Brooks, Kendall Douglas;Shauly, Orr;Shay, Denys;Losken, Albert",Ethical Considerations for Generative Artificial Intelligence in Plastic Surgery,"The integration of artificial intelligence (AI) into surgical care is rapidly transforming healthcare by enhancing efficiency, clinical decision-making, and patient outcomes. Generative AI (genAI), a subfield using large language models such as ChatGPT, Bard, and Midjourney, holds significant promise in automating tasks such as surgical planning and discharge summaries. However, it raises concerns about misinformation, data breaches, biases, and misuse. No genAI technology has yet received Food and Drug Administration approval for surgical use, emphasizing the need for thorough regulatory evaluation. This article proposed 5 ethical principles, adapted from World Health Organization recommendations, to guide the adoption and governance of genAI in plastic surgery. These principles include ensuring data transparency, maintaining patient autonomy, prioritizing safety and accountability, promoting equity, and investing in sustainability. Each principle is illustrated with a hypothetical case to highlight potential ethical breaches and the importance of rigorous testing, clear communication, and continuous monitoring. By adhering to these guidelines, stakeholders can ensure that genAI serves to enhance patient care and uphold the highest standards of ethical practice in surgical settings.",,2,2025,sustainability,behavior+policy+sustainability
67,2-s2.0-105017418991,10.1016/j.rineng.2025.107342,https://doi.org/10.1016/j.rineng.2025.107342,https://scholar.google.com/scholar?q=10.1016/j.rineng.2025.107342,ar,Results in Engineering,"Tariq, Muhammad Usman;Saqib, Sheikh Muhammad;Mazhar, Tehseen;Khan, Muhammad Amir;Shahzad, Tariq;Hamam, Habib","Edge-enabled smart agriculture framework: Integrating IoT, lightweight deep learning, and agentic AI for context-aware farming","Smart farming in connectivity-limited, energy-sensitive environments demands on-device perception and decision-making to reduce latency and cloud dependence. This article proposes an edge-enabled smart agriculture framework that integrates lightweight deep learning, rule-based agentic AI, and Internet of Things (IoT) devices for real-time, autonomous farming decisions. The system features two vision-based models—one for weather classification and one for crop identification—built on the MiT-B0 Vision Transformer architecture and optimized for low-resolution (128 × 128) image inputs. These models run on resource-constrained hardware suitable for rural deployment and support efficient, on-device processing. Weather prediction spans 11 classes (e.g., frost, lightning, rain, sandstorm), while crop classification covers 5 major crops. The system achieves an accuracy of 88 % for weather and 93 % for crops, with high F1-scores and low MAE, Kappa, and Hamming loss values. Predictions are interpreted by a rule-based agentic AI layer that triggers actions across multiple IoT actuators, such as smart irrigation, NDVI sensors, frost alarms, drones, and pest detectors. The decision engine supports both joint rule logic (e.g., activating hail protectors when hail is detected in maize fields) and fallback single-condition rules. Python-implemented case studies show seamless model–AI–IoT interaction in combined and separate scenarios. By minimizing cloud dependency, reducing communication overhead, and enabling low-power operation, the proposed framework addresses critical challenges in connectivity-limited, energy-sensitive agricultural contexts. It demonstrates the potential for scalable and intelligent smart farming, aligning with the goals of sustainable Agriculture 4.0.",Agentic AI | Edge computing | Internet of things (IoT) | Low-power deep learning | Precision farming | Smart agriculture | Weather and crop classification,2,2025,sustainability,behavior+sustainability
72,2-s2.0-105011092015,10.1016/j.atech.2025.101174,https://doi.org/10.1016/j.atech.2025.101174,https://scholar.google.com/scholar?q=10.1016/j.atech.2025.101174,ar,Smart Agricultural Technology,"Koné, Bamory Ahmed Toru;Boukadi, Khouloud;Grati, Rima;Abdallah, Emna Ben;Mecella, Massimo",LLM-driven semantic explanations for soil moisture prediction models,"Efficient soil moisture prediction is crucial for sustainable agricultural practices, especially in the face of climate change and increasing water scarcity. However, the adoption of machine learning (ML) models in this context is frequently limited by their lack of interpretability, particularly among non-expert users such as farmers. This study proposes a novel approach to soil moisture prediction that combines high predictive performance with enhanced explainability. We propose a framework that leverages large language models (LLMs) to generate textual explanations based on a proposed irrigation and soil moisture ontology, thus making the model's predictions more understandable to farmers. The ontology formalizes essential agricultural concepts and their interrelationships, enabling semantically rich explanations to bridge the gap between sophisticated model results and practical decision-making. Our approach is exemplified by a prototype system that provides both predictions and user-friendly explanations. The findings highlight the potential of combining advanced ML techniques with semantic reasoning to improve the interpretability and adoption of Artificial Intelligence in agriculture.",LLM | Machine learning | Ontology | Soil moisture | XAI,2,2025,sustainability,behavior+sustainability
81,2-s2.0-105008180170,10.1016/j.sftr.2025.100815,https://doi.org/10.1016/j.sftr.2025.100815,https://scholar.google.com/scholar?q=10.1016/j.sftr.2025.100815,ar,Sustainable Futures,"Bahaw, Priscilla;Forgenie, David;Sadiq, Ghulfam;Sookhai, Satesh","Generative AI for business sustainability: Examining usability, usefulness, and triple bottom line impacts in small and medium enterprises","Generative AI has emerged as a game-changing technology with great potential to enhance business sustainability. This study explores the adoption and application of generative AI among small and medium-sized enterprises (SMEs) in a small island developing state. The study utilizes the Technology Acceptance Model (TAM) and the Triple Bottom Line (TBL) framework. It integrates quantitative and qualitative methods to comprehensively understand generative AI's role in fostering sustainable business practices. Quantitative findings reveal that perceived ease of use and usefulness significantly influence SMEs' intentions to adopt generative AI, ultimately predicting its actual usage. Qualitative insights complement these findings by identifying four key applications: operational efficiency, data-driven decision-making, sustainable product and service innovation, and building a sustainable brand identity. Despite its potential, the study acknowledges limitations, including focusing on a single SIDS and relying on self-reported data, which constrain generalizability. However, these limitations do not diminish the study's importance, as it highlights practical pathways for SMEs to overcome resource constraints and achieve sustainability goals. The findings highlight the transformative role of generative AI in equipping SMEs with innovative tools to balance profitability with environmental and social responsibility. Policymakers are urged to support this transition through education and outreach, making generative AI accessible and practical for SMEs.",Business sustainability | Generative AI | Small and medium-sized enterprises | Small island developing states | Technology,2,2025,sustainability,behavior+sustainability
99,2-s2.0-105020850852,10.1016/j.agwat.2025.109836,https://doi.org/10.1016/j.agwat.2025.109836,https://scholar.google.com/scholar?q=10.1016/j.agwat.2025.109836,re,Agricultural Water Management,"Yu, Jingxin;Qu, Qinglin;Peng, Shuyi;Wei, Xiaoming;Li, Yinkun;Sun, Congcong",Deep learning for intelligent irrigation decision-making: A review,"Global agriculture faces the dual challenges of water scarcity and climate change, making efficient and precise irrigation management increasingly important. This review analyzes the role of deep learning (DL) technologies in intelligent irrigation decision-making: (1) DL technologies have shifted irrigation management from experience-based decisions to data-driven precision prediction. (2) Deep learning architectures demonstrate distinct advantages in different aspects of irrigation management, including spatial identification, soil water content prediction, long-term forecasting, and optimization of water use. (3) Hybrid DL models often demonstrate superior performance in practical applications. (4) Edge-cloud collaborative architectures are particularly effective, reducing communication volume and decreasing response times from minutes to seconds. Despite progress, intelligent irrigation using DL faces challenges related to data quality, model generalization ability, and computational resource limitations, as well as application barriers such as cost, acceptance, and regional adaptability. Future work should prioritize climate-adaptive models, extreme-weather response, and ultra-precise management in water-scarce regions, while evaluating federated, few-shot learning and large language models as enabling methods.",Deep learning | Irrigation decision-making | Precision agriculture | Water resource management,2,2025,sustainability,behavior+sustainability
105,2-s2.0-105016013514,10.1016/j.ijdrr.2025.105818,https://doi.org/10.1016/j.ijdrr.2025.105818,https://scholar.google.com/scholar?q=10.1016/j.ijdrr.2025.105818,ar,International Journal of Disaster Risk Reduction,"Dal Barco, Maria Katherina;Casartelli, Veronica;Sanò, Marcello;Vascon, Sebastiano;Torresan, Silvia;Critto, Andrea",Prioritise risks and improve adaptation strategies in the Veneto coast through the application of a custom AI tool,"Climate change has emerged as one of the most severe global challenges of our time, with rising temperatures and unprecedented shifts in climate patterns. Coastal areas are particularly vulnerable, facing compounded impacts from sea-level rise and increasingly frequent extreme weather events, demanding urgent need for proactive and comprehensive adaptation measures to protect coastal regions, recently defined as sentinels of climate change. A paradigm shift towards a multi-hazard risk perspective is increasingly recognised as essential in risk assessment and management. Moreover, Artificial Intelligence (AI) have emerged as promising tools to aid decision-making processes in coastal risk management and climate change adaptation. This study introduces COAST-AId, a custom Large Language Model designed to facilitate the analysis and synthesis of diverse information relevant for climate risk assessment and management along the Veneto coast. The tool facilitates the application of the risk assessment framework proposed in the European Climate Risk Assessment analysing the specific climate risk challenges of this region. The framework combines three key dimensions – i.e., risk identification, risk analysis, policy analysis – to prioritise risks and define urgent actions. The application of the COAST-AId tool was performed in close cooperation with local stakeholders involved in the MYRIAD-EU project where a systemic multi-hazard risk framework is considered to support the development of disaster risk management and climate adaptation pathways. The tool's performance was evaluated by stakeholders, highlighting critical risks in the Veneto coastal as well as opportunities for enhancing coastal resilience and improving risk reduction and adaptation strategies at the regional to local scale.",,2,2025,sustainability,behavior+sustainability
110,2-s2.0-105011966115,10.1002/spe.70005,https://doi.org/10.1002/spe.70005,https://scholar.google.com/scholar?q=10.1002/spe.70005,ar,Software Practice and Experience,"Nguyen-Duc, Anh;Cabrero-Daniel, Beatriz;Przybylek, Adam;Arora, Chetan;Khanna, Dron;Herda, Tomas;Rafiq, Usman;Melegati, Jorge;Guerra, Eduardo;Kemell, Kai Kristian;Saari, Mika;Zhang, Zheying;Le, Huy;Quan, Tho;Abrahamsson, Pekka",Generative Artificial Intelligence for Software Engineering—A Research Agenda,"Context: Generative artificial intelligence (GenAI) tools have become increasingly prevalent in software development, offering assistance to various managerial and technical project activities. Notable examples of these tools include OpenAI's ChatGPT, GitHub Copilot, and Amazon CodeWhisperer. Objective: Although many recent publications have explored and evaluated the application of GenAI, a comprehensive understanding of the current development, applications, limitations, and open challenges remains unclear to many. Particularly, we do not have an overall picture of the current state of GenAI technology in practical software engineering usage scenarios. Method: We conducted a literature review and focus groups for a duration of five months to develop a research agenda on GenAI for software engineering. Results: We identified 78 open research questions (RQs) in 11 areas of software engineering. Our results show that it is possible to explore the adoption of GenAI in partial automation and support decision-making in all software development activities. While the current literature is skewed toward software implementation, quality assurance and software maintenance, other areas, such as requirements engineering, software design, and software engineering education, would need further research attention. Common considerations when implementing GenAI include industry-level assessment, dependability and accuracy, data accessibility, transparency, and sustainability aspects associated with the technology. Conclusions: GenAI is bringing significant changes to the field of software engineering. Nevertheless, the state of research on the topic still remains immature. We believe that this research agenda holds significance and practical value for informing both researchers and practitioners about current applications and guiding future research.",ChatGPT | CoPilot | focus group | GenAI | generative artificial intelligence | literature review | literature survey | research agenda | research roadmap | software development,2,2025,sustainability,behavior+sustainability
111,2-s2.0-105010221900,10.1016/j.pnucene.2025.105908,https://doi.org/10.1016/j.pnucene.2025.105908,https://scholar.google.com/scholar?q=10.1016/j.pnucene.2025.105908,ar,Progress in Nuclear Energy,"Xiao, Xingyu;Chen, Peng;Qi, Ben;Liang, Jingang;Tong, Jiejuan;Wang, Haitao",A novel scenario-driven method for enhanced dynamic emergency decision support in nuclear power plants,"As climate change and other global challenges increase the likelihood of unforeseen emergencies, the limitations of human-driven strategies become more pronounced. While decision support systems do exist and are implemented by various nuclear power plant vendors, current approaches are largely tailored to predefined accident sequences. There remains a critical need for adaptive decision support frameworks that can handle unforeseen or unprevented emergency scenarios not fully covered by existing procedures or best practices. This study addresses the urgent need for agile decision-making in response to various unforeseen incidents through a novel approach, EvoScenTree (a Scenario-driven method with evolvable interactive agents using event trees for dynamic emergency maintenance decision support). This method is a hybrid approach that integrates both expert knowledge and data-driven techniques. From the perspective of expert knowledge, we leverage insights from event tree analysis, which consists of three key tasks: initiating sub-event analysis, event tree header event analysis, and decision recommendations. From a data-driven standpoint, we design LLM-driven agents: task executors responsible for carrying out critical emergency response actions, and task validators that evaluate the appropriateness and effectiveness of those actions. Through iterative interactions between these two types of agents, emergency measures are continuously updated. Finally, we use nuclear power plants as a demonstration of the proposed EvoScenTree. Our findings indicate that the designed agents are not only effective but also outperform existing approaches in processing previously unencountered incident scenarios. This paper demonstrates that EvoScenTree significantly enhances the rapid formulation of emergency maintenance decision-making.",Emergency decision support | Event tree analysis | Large language models (LLMs) | Nuclear power plants,2,2025,sustainability,behavior+sustainability
129,2-s2.0-105018174809,10.1016/j.ecmx.2025.101329,https://doi.org/10.1016/j.ecmx.2025.101329,https://scholar.google.com/scholar?q=10.1016/j.ecmx.2025.101329,re,Energy Conversion and Management X,"Banad, Yaser M.;Sharif, Sarah S.;Rezaei, Zahra",Artificial intelligence and machine learning for smart grids: from foundational paradigms to emerging technologies with digital twin and large language model-driven intelligence,"The evolution of modern power systems into smart grids is increasingly powered by Artificial Intelligence (AI) and Machine Learning (ML), which provide effective solutions for managing renewable intermittency, dynamic demand, and cybersecurity challenges. This paper presents a comprehensive review of AI/ML applications in smart grids, tracing their development from foundational paradigms to cutting-edge technologies such as Federated Learning (FL), Generative AI (GenAI), Large Language Models (LLMs), the Artificial Intelligence of Things (AIoT), and Digital Twin (DT)-driven intelligence. Enabling infrastructures, including IoT, 5G, edge–cloud ecosystems, and ML-based smart sensors, are discussed alongside advanced approaches such as multi-agent systems. Key applications explored include load forecasting, predictive maintenance, anomaly and cyber-attack detection, demand-side management, and electric vehicle integration. Special emphasis is placed on Digital Twin and LLM architectures, which enable real-time cyber-physical replicas and context-aware reasoning, thus improving predictive analytics, resilience, and autonomous decision-making. Despite notable advancements, challenges remain in interoperability, data privacy, computational scalability, adversarial robustness, and ethical constraints. By synthesizing these insights, the study highlights the transformative role of AI in creating resilient, sustainable, and intelligent energy systems, and outlines future research trajectories toward standardized DT frameworks, active learning paradigms, and LLM-driven energy intelligence.",Artificial intelligence | Digital twin | Energy management | Generative AI | Large language models | Machine learning | Renewable energy | Smart grids,2,2025,sustainability,behavior+sustainability
132,2-s2.0-105010198971,10.1016/j.compind.2025.104329,https://doi.org/10.1016/j.compind.2025.104329,https://scholar.google.com/scholar?q=10.1016/j.compind.2025.104329,re,Computers in Industry,"Oyekan, John;Turner, Christopher;Bax, Michael;Graf, Erich",From Ontologies to Knowledge Augmented Large Language Models for Automation: A decision-making guidance for achieving human–robot collaboration in Industry 5.0,"The rapid advancement of Large Language Models (LLMs) has resulted in interest in their potential applications within manufacturing systems, particularly in the context of Industry 5.0. However, determining when to implement LLMs versus other Natural Language Processing (NLP) techniques, ontologies or knowledge graphs, remains an open question. This paper offers decision-making guidance for selecting the most suitable technique in various industrial contexts, emphasizing human–robot collaboration and resilience in manufacturing. We examine the origins and unique strengths of LLMs, ontologies, and knowledge graphs, assessing their effectiveness across different industrial scenarios based on the number of domains or disciplines required to bring a product from design to manufacture. Through this comparative framework, we explore specific use cases where LLMs could enhance robotics for human–robot collaboration, while underscoring the continued relevance of ontologies and knowledge graphs in low-dependency or resource-constrained sectors. Additionally, we address the practical challenges of deploying these technologies, such as computational cost and interpretability, providing a roadmap for manufacturers to navigate the evolving landscape of Language based AI tools in Industry 5.0. Our findings offer a foundation for informed decision-making, helping industry professionals optimize the use of Language Based models for sustainable, resilient, and human-centric manufacturing. We also propose a Large Knowledge Language Model architecture that offers the potential for transparency and configuration based on complexity of task and computing resources available.",Generative pre-trained transformers | Language models | Manufacturing | Reasoning | Robotics,2,2025,sustainability,behavior+sustainability
163,2-s2.0-105014295822,10.3390/mi16080902,https://doi.org/10.3390/mi16080902,https://scholar.google.com/scholar?q=10.3390/mi16080902,re,Micromachines,"Cai, Mingchen;Sun, Hao;Yang, Tianyue;Hu, Hongxin;Li, Xubing;Jia, Yuan",Continuous Monitoring with AI-Enhanced BioMEMS Sensors: A Focus on Sustainable Energy Harvesting and Predictive Analytics,"Continuous monitoring of environmental and physiological parameters is essential for early diagnostics, real-time decision making, and intelligent system adaptation. Recent advancements in bio-microelectromechanical systems (BioMEMS) sensors have significantly enhanced our ability to track key metrics in real time. However, continuous monitoring demands sustainable energy supply solutions, especially for on-site energy replenishment in areas with limited resources. Artificial intelligence (AI), particularly large language models, offers new avenues for interpreting the vast amounts of data generated by these sensors. Despite this potential, fully integrated systems that combine self-powered BioMEMS sensing with AI-based analytics remain in the early stages of development. This review first examines the evolution of BioMEMS sensors, focusing on advances in sensing materials, micro/nano-scale architectures, and fabrication techniques that enable high sensitivity, flexibility, and biocompatibility for continuous monitoring applications. We then examine recent advances in energy harvesting technologies, such as piezoelectric nanogenerators, triboelectric nanogenerators and moisture electricity generators, which enable self-powered BioMEMS sensors to operate continuously and reducereliance on traditional batteries. Finally, we discuss the role of AI in BioMEMS sensing, particularly in predictive analytics, to analyze continuous monitoring data, identify patterns, trends, and anomalies, and transform this data into actionable insights. This comprehensive analysis aims to provide a roadmap for future continuous BioMEMS sensing, revealing the potential unlocked by combining materials science, energy harvesting, and artificial intelligence.",AI | BioMEMS sensor | continuous monitoring | self-powered sensor | sustainable energy harvesting,2,2025,sustainability,behavior+sustainability
318,2-s2.0-105010948076,10.57017/jorit.v4.2(8).03,https://doi.org/10.57017/jorit.v4.2(8).03,https://scholar.google.com/scholar?q=10.57017/jorit.v4.2(8).03,ar,Journal of Research Innovation and Technologies,"Chittineni, Jyothi;Maheswari, Palanikumar;Sahila, Chellamuthu;Balakrishnan, Sathyamurthy",Generative Artificial Intelligence and Green Choices: Exploring Environmental Attitudes and Digital Behaviour in India,"The proliferation of Generative AI (GenAI) tools has introduced new dynamics in user behaviour, environmental perception, and digital sustainability. This study, based on a primary questionnaire survey of 1,005 GenAI users aged 18 and above from India, investigates the frequency of GenAI usage and its relationship with climate change awareness, environmental concern, and willingness to adopt energy-efficient digital practices. Using regression-based models, the research reveals a pattern of indirect dependence: lower GenAI usage is related with a greater inclination toward environmentally responsible behaviours, such as transitioning from non-sustainable platforms and adopting energy-efficient digital services. In contrast, frequent GenAI users tend to perceive climate change as temporally distant and of lower immediate importance. The study also examines how the frequency and nature of social media usage influence users’ attitudes toward sustainable technology choices. These findings provide valuable insights for policymakers, AI educators, digital strategists, and sustainability advocates aiming to foster environmentally conscious technology adoption in emerging economies like India.",climate change awareness | digital sustainability | energy-efficient practices | environmental attitudes | generative AI,2,2025,sustainability,behavior+sustainability
336,2-s2.0-105002668807,10.12133/j.smartag.SA202410007,https://doi.org/10.12133/j.smartag.SA202410007,https://scholar.google.com/scholar?q=10.12133/j.smartag.SA202410007,ar,Smart Agriculture,"Wu, Huarui;Li, Jingchen;Yang, Yusen",Intelligent Decision-Making Method for Personalized Vegetable Crop Water and Fertilizer Management Based on Large Language Models,"[Objective] The current crop management faces the challenges of difficulty in capturing personalized needs and the lack of flexibility in the decision-making process. To address the limitations of conventional precision agriculture systems, optimize key aspects of agricultural production, including crop yield, labor efficiency, and water and fertilizer use, while ensure sustainability and adaptability to diverse farming conditions, in this research, an intelligent decision-making method was presents for personalized vegetable crop water and fertilizer management using large language model (LLM) by integrating user-specific preferences into decision-making processes through natural language interactions. [Methods] The method employed artificial intelligence techniques, combining natural language processing (NLP) and reinforcement learning (RL). Initially, LLM engaged users through structured dialogues to identify their unique preferences related to crop production goals, such as maximizing yield, reducing resource consumption, or balancing multiple objectives. These preferences were then modeled as quantifiable parameters and incorporated into a multi-objective optimization framework. To realize this framework, proximal policy optimization (PPO) was applied within a reinforcement learning environment to develop dynamic water and fertilizer management strategies. Training was conducted in the gym-DSSAT simulation platform, a system designed for agricultural decision support. The RL model iteratively learned optimal strategies by interacting with the simulation environment, adjusting to diverse conditions and balancing conflicting objectives effectively. To refine the estimation of user preferences, the study introduced a two-phase process comprising prompt engineering to guide user responses and adversarial fine-tuning for enhanced accuracy. These refinements ensured that user inputs were reliably transformed into structured decision-making criteria. Customized reward functions were developed for RL training to address specific agricultural goals. The reward functions account for crop yield, resource efficiency, and labor optimization, aligning with the identified user priorities. Through iterative training and simulation, the system dynamically adapted its decision-making strategies to varying environmental and operational conditions. [Results and Discussions] The experimental evaluation highlighted the system's capability to effectively personalize crop management strategies. Using simulations, the method demonstrated significant improvements over traditional approaches. The LLM-based model accurately captured user-specific preferences through structured natural language interactions, achieving reliable preference modeling and integration into the decision-making process. The system's adaptability was evident in its ability to respond dynamically to changes in user priorities and environmental conditions. For example, in scenarios emphasizing resource conservation, water and fertilizer use were significantly reduced without compromising crop health. Conversely, when users prioritized yield, the system optimized irrigation and fertilization schedules to enhance productivity. These results showcased the method's flexibility and its potential to balance competing objectives in complex agricultural settings. Additionally, the integration of user preferences into RL-based strategy development enabled the generation of tailored management plans. These plans aligned with diverse user goals, including maximizing productivity, minimizing resource consumption, and achieving sustainable farming practices. The system's multi-objective optimization capabilities allowed it to navigate trade-offs effectively, providing actionable insights for decision-making. The experimental validation also demonstrated the robustness of the PPO algorithm in training the RL model. The system's strategies were refined iteratively, resulting in consistent performance improvements across various scenarios. By leveraging LLM to capture nuanced user preferences and combining them with RL for adaptive decision-making, the method bridges the gap between generic precision agriculture solutions and personalized farming needs. [Conclusions] This study established a novel framework for intelligent decision-making in agriculture, integrating LLM with reinforcement learning to address personalized crop management challenges. By accurately capturing user-specific preferences and dynamically adapting to environmental and operational variables, the method offers a transformative approach to optimizing agricultural productivity and sustainability. Future work will focus on expanding the system's applicability to a wider range of crops and environmental contexts, enhancing the interpretability of its decision-making processes, and facilitating integration with real-world agricultural systems. These advancements aim to further refine the precision and impact of intelligent agricultural decision-making systems, supporting sustainable and efficient farming practices globally.",crop management | large language model | multi-objective decision | personalized decision | proximal policy optimization,2,2025,sustainability,behavior+sustainability
345,2-s2.0-85212448553,10.1007/s44163-024-00218-0,https://doi.org/10.1007/s44163-024-00218-0,https://scholar.google.com/scholar?q=10.1007/s44163-024-00218-0,ar,Discover Artificial Intelligence,"Malas, Laila;Shawaqfeh, Ahmad;Abushakra, Ahmad",The future of artificial intelligence: evaluating ChatGPT's performance in X sentiment prediction,"Technological advancements have significantly progressed from the inception of computers and the internet to the rise of artificial intelligence (AI), profoundly impacting various sectors such as business, education, and healthcare. Among these advancements, ChatGPT has emerged as a prominent conversational AI tool, facilitating tasks such as sentiment prediction and sector-specific decision-making. This study aims to evaluate ChatGPT's performance in analyzing public sentiment using data from X (formerly Twitter) and to propose an ethical framework for its sector-specific applications. By combining the BERT transformer model with BiLSTM, Random Forest, and K-Nearest Neighbor algorithms, the study achieves a hybrid approach to sentiment prediction, demonstrating superior performance with an accuracy of 86.7%. Furthermore, the study explores ethical considerations, such as fairness, accountability, and transparency, to address ChatGPT's adoption across industries. The findings offer insights into both the technical and ethical dimensions of ChatGPT’s integration into business, education, and healthcare sectors, emphasizing its potential for sustainable and responsible use.",Artificial intelligence | ChatGPT | Prediction | Sentiment analysis | Sustainability,2,2024,sustainability,behavior+sustainability
409,2-s2.0-85161485292,10.3390/electronics12112453,https://doi.org/10.3390/electronics12112453,https://scholar.google.com/scholar?q=10.3390/electronics12112453,ar,Electronics Switzerland,"Ouyang, Xin;Zhou, Ting",Imperfect-Information Game AI Agent Based on Reinforcement Learning Using Tree Search and a Deep Neural Network,"In the field of computer intelligence, it has always been a challenge to construct an agent model that can be adapted to various complex tasks. In recent years, based on the planning algorithm of Monte Carlo tree search (MCTS), a new idea has been proposed to solve the AI problems of two-player zero-sum games such as chess and Go. However, most of the games in the real environment rely on imperfect information, so it is impossible to directly use the normal tree search planning algorithm to construct a decision-making model. Mahjong, which is a popular multiplayer game with a long history in China, attracts great attention from AI researchers because it contains a large game state space and a lot of hidden information. In this paper, we utilize an agent learning approach that leverages deep learning, reinforcement learning, and dropout learning techniques to implement a Mahjong AI game agent. First, we improve the state transition of the tree search based on the learned MDP model, the player position variable and transition information are introduced into the tree search algorithm to construct a multiplayer search tree. Then, the model training based on a deep reinforcement learning method ensures the stable and sustainable training process of the learned MDP model. Finally, we utilize the strategy data generated by the tree search and use the dropout learning method to train the normal decision-making agent. The experimental results demonstrate the efficiency and stability performance of the agent trained by our proposed method compared with existing agents in terms of test data accuracy, tournament ranking performance, and online match performance. The agent plays against human players and acts like real humans.",artificial intelligence | game agent | machine learning | neural network | reinforcement learning | tree search,2,2023,sustainability,behavior+sustainability
107,2-s2.0-105013494054,10.1016/j.jbusres.2025.115648,https://doi.org/10.1016/j.jbusres.2025.115648,https://scholar.google.com/scholar?q=10.1016/j.jbusres.2025.115648,ar,Journal of Business Research,"Zhan, Yuanzhu;Kumar, Ajay;Hosany, Sameer;Xia, Yusen;Schoenherr, Tobias;Xia, Lan","Market competition in the platform economy: new insights, integrative framework and research agenda","Digital platforms are transforming traditional business models and practices across industries, setting new foundations for market competition. As the platform economy expands, new challenges emerge around innovation, stakeholder engagement, sustainability, and governance. This editorial introduces the special issue on ‘Managing the Platform Economy and Market Competition in the Digitalization Era’, offering a synthesis of contemporary articles, identifying key themes of competitiveness in digitally mediated, multi-sided markets. The special issue features a collection of 23 high-caliber articles that reflect the latest advancements and rigorous scholarships in the field. In particular, the articles cover four broad themes: innovative business strategies, stakeholder behaviors, sustainability integration, and adaptive governance. We propose an integrative framework that highlights the interdependence of these thematic aspects and illustrates how platform strategies, trust mechanisms, regulatory adaptation, and sustainability practices collectively shape market outcomes. The special issue advances theoretical discussions on platform business model innovation, ecosystem orchestration, stakeholder trust and engagement, technological transparency, and ethical governance. Our special issue exposes gaps, particularly in generalizability, impact assessment, and regulatory alignment that call for deeper empirical and conceptual inquiry. We conclude by outlining a future research agenda that prioritizes cross-context theorization, robust evaluation of sustainability initiatives, and new models of governance to address the evolving complexities of the platform economy, particularly considering the transformative impact of Generative AI. This editorial provides an integrative foundation for scholars and practitioners seeking to understand and enhance market competition in the digital era.",Generative AI | Integrative framework | Market competition | Platform economy,2,2025,sustainability,policy+sustainability
151,2-s2.0-105012393888,10.47738/jads.v6i3.702,https://doi.org/10.47738/jads.v6i3.702,https://scholar.google.com/scholar?q=10.47738/jads.v6i3.702,ar,Journal of Applied Data Sciences,"Lakshmi Balajia, R. S.;Thiruvenkataswamy, C. S.;Batumalay, Malathy;Duraimutharasan, N.;Devadas, Amar Dev Thirukulam;Yingthawornsuk, Thaweesak","A Study of Unified Framework for Extremism Classification, Ideology Detection, Propaganda Analysis, and Flagged Data Detection Using Transformers","The rise of extremism and its rapid dissemination through propaganda channels have become pressing global challenges, threatening peace, security, and social cohesion. This study aligns with the United Nations Sustainable Development Goal 16 by proposing a unified framework leveraging advanced machine learning and large language models to combat extremism through extremism classification, ideology detection, propaganda analysis, and flagged word recognition. This framework introduces process innovation by integrating state-of-the-art transformer models such as BERT, RoBERTa, DistilBERT and XLNet to streamline the analysis process and overcome traditional limitations in extremism detection with exceptional performance: 90.00% accuracy for extremism classification, 98.82% accuracy for ideology detection, and 99.71% accuracy for flagged word recognition. While the proposed approach demonstrates high precision and recall, it faces challenges such as potential data bias, ethical concerns in dataset usage and the risk of false positives, which could lead to misclassification of benign content. The inclusion of multilingual capabilities broadens the applicability of the framework but variations in linguistic structures and cultural contexts introduce complexities in model generalization. Additionally, ethical considerations in handling extremist content, especially in social media data collection, necessitate stringent privacy safeguards to prevent unintended harm. By providing actionable insights, this research contributes to counter-extremism efforts in areas such as online content moderation, law enforcement and intelligence analysis, laying a foundation for future advancements in safeguarding global security which enhance the process innovation.",BERT | Counter Extremism | Extremism Classification | Flagged Word Recognition | Ideology Detection | Large Language Models | Machine Learning | Natural Language Processing | Process Innovation | Propaganda Analysis,2,2025,sustainability,policy+sustainability
165,2-s2.0-105013286021,10.3390/app15158666,https://doi.org/10.3390/app15158666,https://scholar.google.com/scholar?q=10.3390/app15158666,ar,Applied Sciences Switzerland,"Król, Karol",Sustainability Audit of University Websites in Poland: Analysing Carbon Footprint and Sustainable Design Conformity,"Featured Application: The proposed methodology is helpful for evaluating the environmental impact of websites. It can measure emissions, pinpoint the most energy-intensive assets, and identify areas in need of carbon footprint reduction. This way, it could be employed to support efforts aimed at mitigating the adverse environmental impact of websites. With the advance of digital transformation, the assessment of the environmental impact of digital tools and technologies grows more relevant. Considering the inflated expectations of environmental responsibility in higher education, this study analyses how websites of Polish universities conform to sustainable web design criteria. The sustainability audit employed a methodology encompassing carbon emissions measurement, technical website analysis, and SEO evaluation. The author analysed 63 websites of public universities in Poland using seven independent audit tools, including an original AI Custom GPT agent preconfigured in the ChatGPT ecosystem. The results revealed a substantial differentiation in CO<inf>2</inf> emissions and website optimisation, with an average EcoImpact Score of 66.41/100. Nearly every fourth website exhibited a significant carbon footprint and excessive component sizes, which indicates poor asset optimisation and energy-intensive design techniques. The measurements exposed considerable variability in emission intensities and resource intensity among the university websites, suggesting the need for standardised digital sustainability practices. Regulations on the carbon footprint of public institutions’ websites and mobile applications could become vital strategic components for digital climate neutrality. Promoting green hosting, “Green SEO” practices, and sustainability audits could help mitigate the environmental impact of digital technologies and advance sustainable design standards for the public sector. The proposed auditing methodology can effectively support the institutional transition towards sustainable management of digital infrastructure by integrating technical, sustainability, and organisational aspects.",carbon awareness | digital carbon footprint | digital decarbonisation | digital sustainability | Green SEO | low-emission web development | quality audit | sustainable web design | website quality | website sustainability audit,2,2025,sustainability,policy+sustainability
178,2-s2.0-105011653826,10.3390/buildings15142494,https://doi.org/10.3390/buildings15142494,https://scholar.google.com/scholar?q=10.3390/buildings15142494,ar,Buildings,"Alshahrani, Adnan",Bridging Cities and Citizens with Generative AI: Public Readiness and Trust in Urban Planning,"As part of its modernisation and economic diversification policies, Saudi Arabia is building smart, sustainable cities intended to improve quality of life and meet environmental goals. However, involving the public in urban planning remains complex, with traditional methods often proving expensive, time-consuming, and inaccessible to many groups. Integrating artificial intelligence (AI) into public participation may help to address these limitations. This study explores whether Saudi residents are ready to engage with AI-driven tools in urban planning, how they prefer to interact with them, and what ethical concerns may arise. Using a quantitative, survey-based approach, the study collected data from 232 Saudi residents using non-probability stratified sampling. The survey assessed demographic influences on AI readiness, preferred engagement methods, and perceptions of ethical risks. The results showed a strong willingness among participants (200 respondents, 86%)—especially younger and university-educated respondents—to engage through AI platforms. Visual tools such as image and video analysis were the most preferred (96 respondents, 41%), while chatbots were less favoured (16 respondents, 17%). However, concerns were raised about privacy (76 respondents, 33%), bias (52 respondents, 22%), and over-reliance on technology (84 respondents, 36%). By exploring the intersection of generative AI and participatory urban governance, this study contributes directly to the discourse on inclusive smart city development. The research also offers insights into how AI-driven public engagement tools can be integrated into urban planning workflows to enhance the design, governance, and performance of the built environment. The findings suggest that AI has the potential to improve inclusivity and responsiveness in urban planning, but that its success depends on public trust, ethical safeguards, and the thoughtful design of accessible, user-friendly engagement platforms.",AI | citizen engagement | community involvement | public participation | Saudi Arabia | sustainable cities | urban planning,2,2025,sustainability,policy+sustainability
192,2-s2.0-105009289245,10.3390/asi8030083,https://doi.org/10.3390/asi8030083,https://scholar.google.com/scholar?q=10.3390/asi8030083,re,Applied System Innovation,"Deroncele-Acosta, Angel;Sayán-Rivera, Rosa María Elizabeth;Mendoza-López, Angel Deciderio;Norabuena-Figueroa, Emerson Damián",Generative Artificial Intelligence and Transversal Competencies in Higher Education: A Systematic Review,"Generative AI is an emerging tool in higher education; however, its connection with transversal competencies, as well as their sustainable adoption, remains underexplored. The study aims to analyze the scientific and conceptual development of generative artificial intelligence in higher education to identify the most relevant transversal competencies, strategic processes for its sustainable implementation, and global trends in academic production. A systematic literature review (PRISMA) was conducted on the Web of Science, Scopus, and PubMed, analyzing 35 studies for narrative synthesis and 897 publications for bibliometric analysis. The transversal competencies identified were: Academic Integrity, Critical Thinking, Innovation, Ethics, Creativity, Communication, Collaboration, AI Literacy, Responsibility, Digital Literacy, AI Ethics, Autonomous Learning, Self-Regulation, Flexibility, and Leadership. The conceptual framework connotes the interdisciplinary nature and five key processes were identified to achieve the sustainable integration of Generative AI in higher education oriented to the development of transversal competencies: (1) critical and ethical appropriation, (2) institutional management of technological infrastructure, (3) faculty development, (4) curricular transformation, and (5) pedagogical innovation. On bibliometric behavior, scientific articles predominate, with few systematic reviews. China leads in publication volume, and social sciences are the most prominent area. It is concluded that generative artificial intelligence is key to the development of transversal competencies if it is adopted from a critical, ethical, and pedagogically intentional approach. Its implications and future projections in the field of higher education are discussed.",academic integrity | Artificial Intelligence | ChatGPT | critical thinking | digital literacy | GenAI | Generative Artificial Intelligence | innovation | soft skills | transversal skills,2,2025,sustainability,policy+sustainability
227,2-s2.0-85214496727,10.1002/aaai.12208,https://doi.org/10.1002/aaai.12208,https://scholar.google.com/scholar?q=10.1002/aaai.12208,ar,AI Magazine,"Aremu, Toluwani;Akinwehinmi, Oluwakemi;Nwagu, Chukwuemeka;Ahmed, Syed Ishtiaque;Orji, Rita;Amo, Pedro Arnau Del;Saddik, Abdulmotaleb El",On the reliability of Large Language Models to misinformed and demographically informed prompts,"We investigate and observe the behavior and performance of Large Language Model (LLM)-backed chatbots in addressing misinformed prompts and questions with demographic information within the domains of Climate Change and Mental Health. Through a combination of quantitative and qualitative methods, we assess the chatbots' ability to discern the veracity of statements, their adherence to facts, and the presence of bias or misinformation in their responses. Our quantitative analysis using True/False questions reveals that these chatbots can be relied on to give the right answers to these close-ended questions. However, the qualitative insights, gathered from domain experts, shows that there are still concerns regarding privacy, ethical implications, and the necessity for chatbots to direct users to professional services. We conclude that while these chatbots hold significant promise, their deployment in sensitive areas necessitates careful consideration, ethical oversight, and rigorous refinement to ensure they serve as a beneficial augmentation to human expertise rather than an autonomous solution. Dataset and assessment information can be found at https://github.com/tolusophy/Edge-of-Tomorrow.",,2,2025,sustainability,policy+sustainability
306,2-s2.0-105016467769,10.1111/eufm.70020,https://doi.org/10.1111/eufm.70020,https://scholar.google.com/scholar?q=10.1111/eufm.70020,ar,European Financial Management,"Arshed, Noman;Bakkar, Yassine;De Sisto, Marco;Munir, Mubbasher;Ul-Durar, Shajara",Green Innovation Optimization for Climate Change ESG Business Readiness: Role of Generative AI in BRICS Countries,"Climate change introduces new challenges for businesses which require them to find ways to be resilient. Green innovations contribute to boost Environmental, Social, and Governance (ESG)-readiness leading to just transition without optimization. This study estimates the nonlinear effect of environmental innovation in ESG-readiness against climate change while allowing for the moderating role of citations from regenerative AI-research. We use BRICS countries to conduct the analyses with a machine learning based Panel-QARDL. We find that green innovations trace an inverted U-shaped effect and generative AI shifts this relationship upwards. Findings highlight the role of regenerative AI in boosting green innovation performance.",AI adoption | green technology | innovation management | machine Learning | panel quantile ARDL,2,2025,sustainability,policy+sustainability
321,2-s2.0-105009501744,10.1080/17517575.2025.2520213,https://doi.org/10.1080/17517575.2025.2520213,https://scholar.google.com/scholar?q=10.1080/17517575.2025.2520213,ar,Enterprise Information Systems,"Phung Mai Suong, Tieu;Huynh Nghiem, Le;Khai Tran, Thien",Leveraging large language models for enhanced fake news detection: a novel approach using explanation-guided networks,"The spread of misinformation, particularly fake news, poses a significant threat to the stability and sustainability of supply chains. Large language models offer a powerful solution by leveraging advanced natural language processing capabilities. This paper explores the application of models, including BERT and GPT, in detecting fake news. We introduce the Explanation-Guided Network (EGN), a novel and intelligent system that integrates reasoning strategies, particularly chain-of-thought prompting, to enhance accuracy and interpretability. Experiments on COVID-19 and GossipCop datasets show that EGN outperforms state-of-the-art methods, highlighting the importance of AI-driven solutions in strengthening supply chain resilience.",chain-of-thought prompting | Fake news detection | intelligent systems | large language models | misinformation | supply chain resilience,2,2025,sustainability,policy+sustainability
376,2-s2.0-85186944402,10.1007/s13280-024-01997-7,https://doi.org/10.1007/s13280-024-01997-7,https://scholar.google.com/scholar?q=10.1007/s13280-024-01997-7,ar,Ambio,"Sommer, Bernd;von Querfurth, Sarah","“In the end, the story of climate change was one of hope and redemption”: ChatGPT’s narrative on global warming","AI chatbots such as ChatGPT help people produce texts. According to media reporting, these texts are also used for educational purposes. Thus, AI influences people’s knowledge and perception of current issues. This paper examines the narrative of ChatGPT's stories on climate change. Our explorative analysis reveals that ChatGPT’s stories on climate change show a relatively uniform structure and similar content. Generally, the narrative is in line with scientific knowledge on climate change; the stories convey no significant misinformation. However, specific topics in current debates on global warming are conspicuously missing. According to the ChatGPT narrative, humans as a species are responsible for climate change and specific economic activities or actors associated with carbon emissions play no role. Analogously, the social structuration of vulnerability to climate impacts and issues of climate justice are hardly addressed. ChatGPT’s narrative consists of de-politicized stories that are highly optimistic about technological progress.",Artificial intelligence (AI) | ChatGPT | Climate change | Climate change narratives | Climate justice | De-politicization,2,2024,sustainability,policy+sustainability
393,2-s2.0-85204982163,10.1109/ACCESS.2024.3466834,https://doi.org/10.1109/ACCESS.2024.3466834,https://scholar.google.com/scholar?q=10.1109/ACCESS.2024.3466834,ar,IEEE Access,"Sibitenda, Harriet;Diattara, Awa;Traore, Assitan;Hu, Ruofan;Zhang, Dongyu;Rundensteiner, Elke;Ba, Cheikh",Extracting Semantic Topics about Development in Africa from Social Media,"The extraction of knowledge about prevalent issues discussed on social media in Africa using Artificial Intelligence techniques is vital for informing public governance. The objectives of our study are twofold: (a) to develop machine learning-based models to identify common topics of social concern related to Africa on social media, and (b) to design a classifier capable of inferring the most relevant topic associated with a given social media post. We designed a three-step framework to achieve the first goal of topic identification. The first step applies text-based representation learning methods to generate text embeddings for feature representation. The second step utilizes state-of-the-art Natural Language Processing models, commonly referred to as topic modeling, to group the representations into categories. The third step generates topics from each group, leveraging large language models to create meaningful short-sentence labels from the associated bag-of-tokens. Additionally, we used Llama2 to refine the token words into concise single-word themes that describe each topic in relation to social concerns about development. To address the second goal of classification, we trained classifiers using ensemble voting and stacking methods to determine which of the identified topics best characterizes a given social media post. For our experimental study, we collected a corpus called Social Media for Africa (SMA), consisting of 22,036 records extracted from comments on Twitter (X) and YouTube. The clustering-based model BERTopic produced 304 topics with a topic coherence score of 0.81 (C-v). After merging the topics into broader classes, the BERTopic+ model yielded 11 common topic classes with a coherence score of 0.76 (C-v). For theme extraction, we further refined the leading token words using Llama2, resulting in 98 unique themes labeled by BERTopic_theme, with a coherence score of 0.75 and an IRBO score of 0.50. We used the identified topics, based on the groupings, as labels for training a topic classifier. These labels were generated using Llama2 on our SMA corpus. Our comparative study of topic classifiers employing stacking and voting schemes demonstrated that the BERTopic model achieved an accuracy of 0.83 and an F1 score of 0.82 with ensemble voting for training on topics. Furthermore, when training on topic classes, BERTopic+ with ensemble voting achieved the highest accuracy (0.95) and F1 score (0.95) compared to other methods. Additionally, BERTopic_theme achieved superior performance with an ensemble voting classifier, attaining an F1 score of 0.93 and an accuracy of 0.93. The overall performance of classifiers using ensemble stacking was slightly better than that of voting methods for short-sentence topic labeling. For Africa, policymakers should focus on the most pressing social issues: the impact of COVID-19 restrictions on public health and economic recovery, promoting entrepreneurial innovation in energy and environmental sustainability to combat climate change, and responding strategically to China's rise in global politics to maintain geopolitical stability and foster international cooperation.",LLMs | semantic topic labels | Social concerns | social media | themes | topic modeling,2,2024,sustainability,policy+sustainability
397,2-s2.0-85197806741,10.14198/MEDCOM.26929,https://doi.org/10.14198/MEDCOM.26929,https://scholar.google.com/scholar?q=10.14198/MEDCOM.26929,ar,Revista Mediterranea De Comunicacion,"Arenal, Alberto;Armuña, Cristina;Aguado, Juan Miguel;Ramos, Sergio;Feijóo, Claudio",AI Challenges in the Era of Music Streaming: an analysis from the perspective of creative artists and performers,"This paper addresses the challenges posed by Artificial Intelligence (AI) in the music industry from the perspective of the sustainability of the business models involved in the creation of value in streaming platforms, and considering the perception of composers-lyricists and performers, understood as key players in the value creation process. To this end, the authors resorted to a state-of-the-art delimitation based on recent literature and updated reports, and to a semi-structured questionnaire applied to a qualitatively representative international sample of creators and performers, both professional and amateur. This approach, albeit preliminary, shows that AI contributes to intensifying some of the problems highlighted in the consolidation of the streaming platform model, in particular with regard to its two major sustainability challenges: the shift of value from creation to technology and the increasing homogeneity of its inventory, with impacts in cultural diversity and creativity. It also highlights that generative AI concentrates its impact on the creation and consumption stages of the value chain, affecting the scope and possibilities of the value creation of musicians, composers, and performers and of music users’ experience. The perception of creators combines uncertainty and pessimism, characterising technological innovations as accelerating the dysfunctions of the streaming platform model and resulting in devaluation of the artistic profession and creative activity. Possible solutions include the regulation of AI application frameworks, and the establishment of procedures or indicators to facilitate users’ ability to choose between “artificial creativity” and “natural creativity”.","artificial intelligence | artists | music streaming platforms | session musicians | songwriters, performers",2,2024,sustainability,policy+sustainability
413,2-s2.0-85174329654,10.21463/jmic.2023.12.2.05,https://doi.org/10.21463/jmic.2023.12.2.05,https://scholar.google.com/scholar?q=10.21463/jmic.2023.12.2.05,ar,Journal of Marine and Island Cultures,"Kang, Hyun Chul;Baek, Woo Yeul;Choi, Jae Yong;Kim, Jong Sung",Revitalizing Island Tourism in the Digital Transformation Era: Case of Jebudo Island,"This research aims to employ the focus group interview methodology to extract important insights and policy recommendations for the revitalization of tourism in island regions during the era of significant digital transformation. To achieve this objective, the current study focuses on Jebudo Island, located in Hwaseong-city, Gyeonggi province, as a representative case area and utilizes the findings obtained to identify practical and efficacious viewpoints. The ensuing report highlights the paramount importance and policy recommendations extracted via a focus group interview technique. Initially, considering the prospect of being established as a tourism hub, Jebudo Island has persistently engaged in development and business promotions. However, the island continues to be characterized by an aging tourist destination, emphasizing private facilities, which does not align with the current tourism trend. In light of the ongoing digital transformation, it is imperative that Jebudo Island utilizes its local resources efficiently while adhering to contemporary tourism trends by implementing relevant technologies appropriately. Another noteworthy policy recommendation pertains to the underdevelopment of Jebudo Island, given its remarkable geographical conditions and regional resources. Conventionally, tourism activities were confined to sightseeing, primarily highlighting hardware and natural landscapes. However, recently, such activities have shifted towards experiences and emotions, emphasizing content and engagement. Consequently, the need to develop content using cutting-edge technologies such as artificial intelligence, metaverse, and ChatGPT is essential to enhance national awareness. Finally, concerning the island's placeness strategy in conjunction with digital transformation, islands face a daunting challenge of regional extinction, with a more severe decline in population than that of mainland areas. Despite various policy measures to address this issue, no effective exit strategy has emerged thus far. Therefore, it is imperative to devise a strategy centered on the sense of place that aligns with regional characteristics. In particular, engaging the MZ generation, which values novel social values and actively utilizes social media and the internet, could lead to broader engagement across other generations. Moreover, in the process of revitalizing island tourism during the digital transformation era, various stakeholders are intricately interconnected. Hence, it is crucial to utilize different platforms and establish cooperative governance. Furthermore, to create a functional ecosystem, it is crucial to institute policies such as island business schools, forums, and full-time operating organizations to enhance expertise and commercial viability, while fostering sustainable strategic discussions. Notwithstanding, considering that the present study solely examined the case of Jebudo Island in Hwaseong through the focus group interviews in the era of significant digital transformation, it remains uncertain whether the findings can be uniformly applied and extrapolated to other islands. Consequently, further studies are essential to enhance objectivity and empirical validity by broadening the scope of case areas and incorporating stakeholder surveys.",digital transformation | island tourism | revitalization,2,2023,sustainability,policy+sustainability
449,2-s2.0-105022836690,10.1016/j.frl.2025.108797,https://doi.org/10.1016/j.frl.2025.108797,https://scholar.google.com/scholar?q=10.1016/j.frl.2025.108797,ar,Finance Research Letters,"Ali, Hassnian;Zafar, Muhammad Bilal;Aysan, Ahmet Faruk","Generative AI in finance: Replicability, methodological contingencies, and future research directions","Generative Artificial Intelligence (AI) is reshaping finance by transforming decision-making, risk management, and stakeholder engagement. This study provides a theory-informed synthesis of 84 peer-reviewed articles (2022-2025) using PRISMA-based screening, bibliometric analysis, and Structural Topic Modeling (STM). Six themes emerge: financial decision-making, ESG analytics, stock market prediction, advanced modeling for fraud detection and explainable AI, ChatGPT in accounting and education, and sentiment analysis with domain-specific LLMs. Findings show that generative AI enhances predictive capabilities and ESG assessments but raises issues of bias, transparency, and regulation. The review outlines future research priorities around interpretability, multimodal data, and governance frameworks.",Bibliometric | Finance | Generative AI | Structural topic modeling | Systematic literature review,1,2025,behavior,behavior+policy
457,2-s2.0-105012590927,10.1016/j.ijme.2025.101254,https://doi.org/10.1016/j.ijme.2025.101254,https://scholar.google.com/scholar?q=10.1016/j.ijme.2025.101254,ar,International Journal of Management Education,"AlBannai, Najla Abdalla",From classroom to Boardroom: Ethical and cognitive challenges of ChatGPT use among DBA students in business problem-solving,"Artificial intelligence (AI) tools such as ChatGPT have rapidly penetrated the higher education landscape and changed how people learn and make decisions, including executive doctorate programs such as the Doctorate in Business Administration (DBA). The research investigates DBA students' trust, reliance, and ethical issues while utilizing ChatGPT in solving business problems. While these AI-generated business solutions provide efficiency and access, they also implicate crucial issues around bias, misinformation, over-reliance and ethical reasoning. Using qualitative single case study, exploratory research design, 40 in-depth semi-structured interviews were conducted with DBA students from college of business at university of Sharjah in UAE from different batches using convenience sampling to analyze perceptions on ChatGPT's reliability, the extent of DBAs' reliance on AI-generated insights, and the ethical implications of the use of AI in actual business decision-making. Qualitative coding was conducted through NVivo 15 software. The results, however, present a range regarding trust and use; while some students utilize AI as a complementary resource to stimulate critical thinking and encourage validation, others show over-dependence on it and often fail to critically verify the outputs provided by AI. This work adds to the increasing conversation on AI ethics in executive education and argues for structured AI literacy frameworks to support DBA students in the responsible, critical, and ethical adoption of AI.",AI ethics | AI in business education | Business problem-solving | ChatGPT | DBA students | Trust in AI,1,2025,behavior,behavior+policy
460,2-s2.0-105011149074,10.1007/s40979-025-00195-6,https://doi.org/10.1007/s40979-025-00195-6,https://scholar.google.com/scholar?q=10.1007/s40979-025-00195-6,ar,International Journal for Educational Integrity,"Erhardt, Charlotte;Kullenberg, Helena;Grigoriadis, Anastasios;Kumar, Abhishek;Christidis, Nikolaos;Christidis, Maria",From policy to practice: the regulation and implementation of generative AI in Swedish higher education institutes,"Background: The rapid development of generative artificial intelligence (GenAI) is reshaping higher education by offering innovative solutions in course design, assessment, and learning experiences. Despite its potential, GenAI integration poses ethical, pedagogical, and practical challenges, but also a risk of academic misconduct. This study explores how Swedish higher education institutions (HEIs) are addressing GenAI through guidelines, policy documents, and public website information. Methods: A qualitative manifest content analysis for objectivity and consistency was conducted on GenAI-related documents and website information from Swedish HEIs. Forty-nine institutions were contacted, with 36 providing relevant data. Data collection involved email correspondence and systematic searches on public websites. Results: Few formal GenAI guidelines exist across Swedish HEIs. Independent institutions were more likely to have established guidelines for both staff and students, whereas universities or university colleges often provided more GenAI-related information on their websites. Five categories were identified: Good academic practice; GenAI use and governance in education; Information governance; Ethical and social impact; and GenAI essentials, the latter unique to websites. Good academic practice was the most emphasized, focusing on transparency, responsibility, and the challenges of GenAI-related misconduct. Conclusions: Taken together, GenAI integration in higher education remains early and uneven, with some institutions implementing formal guidelines while others are still developing policies. This inconsistency calls for national directives to balance GenAI´s benefits with ethical concerns, promote GenAI literacy, and ensure equitable access. Rapid technological change challenges HEIs to update policies that ensure academic integrity and fairness. Future research should foster collaborative policy development among HEIs, policymakers, and technology providers.",GenAI | Higher education | Policies and guidelines | Public web sites | Teaching and learning,1,2025,behavior,behavior+policy
471,2-s2.0-105016753118,10.1007/s12369-025-01323-5,https://doi.org/10.1007/s12369-025-01323-5,https://scholar.google.com/scholar?q=10.1007/s12369-025-01323-5,ar,International Journal of Social Robotics,"Jung, Han Wool;Park, Jin Young;Holoubek, Todd;Kim, Woo Jung;Park, Jaesub",Socially Assistive Robots in Mental Healthcare: Principles and Conceptual Framework for User-Centered Design,"Socially assistive robots (SARs) have a strong potential to advance digital mental healthcare, if they become able to promote meaningful interactions based on the user-centered approach. This review provides a comprehensive overview of user-centered design principles for SARs in mental healthcare, focusing on contemporary topics and practical guidelines. Successful SARs should enhance user autonomy, competence, and emotional experiences as their core objectives. Effective SAR design may integrate adaptive decision-making based on multimodal interactions, adequate motivation such as reward systems or gamification, contextual design, and participatory design for the personalized care that aligns with user needs. For long-term interactions, careful role setting such as mimicking human relationships and trust building are also recommended for in-depth user care. Evaluation of SARs incorporates holistic, multidimensional criteria including self-reports, behavioral data, physiological signals, and qualitative examinations to measure treatment effectiveness, user experiences, and safety, which ideally lead to iterative evaluation and refinement processes. Finally, recent breakthroughs in large language models (LLMs) have the potential to significantly boost SAR autonomy, level of personalization, and user engagement, but they also raise ethical risks such as user overdependence and compromised user autonomy, which may be addressed through person-centered principles, rigorous ethical/regulatory oversight, and evidence-based validation. Future roadmaps for SARs in mental healthcare emphasize integrated guidelines, responsible AI governance, and continued interdisciplinary collaboration to ensure safe and effective therapeutic care.",Artificial intelligence | Co-design | Human-robot interaction | Humanoid robots | Person-centered approach | Social robots,1,2025,behavior,behavior+policy
472,2-s2.0-105009514123,10.1016/j.ijmedinf.2025.106035,https://doi.org/10.1016/j.ijmedinf.2025.106035,https://scholar.google.com/scholar?q=10.1016/j.ijmedinf.2025.106035,ar,International Journal of Medical Informatics,"Zhang, Zhihong;Momeni Nezhad, Mohamad Javad;Gupta, Pallavi;Zolnour, Ali;Azadmaleki, Hossein;Topaz, Maxim;Zolnoori, Maryam",Enhancing AI for citation screening in literature reviews: Improving accuracy with ensemble models,"Background: Healthcare literature reviews underpin evidence-based practice and clinical guideline development, with citation screening as a critical yet time-consuming step. This study evaluates the effectiveness of individual large language models (LLMs) versus ensemble approaches in automating citation screening to improve the efficiency and scalability of evidence synthesis in healthcare research. Methods: Performance was assessed across three healthcare-focused reviews: LLM-Healthcare (865 citations, broad scope, 49.8 % inclusion rate), MCI-Speech (959 citations, narrow scope, 6.5 % inclusion rate), and Multimodal-LLM (73 citations, moderate scope, 68.5 % inclusion rate). Six LLMs (GPT-4o Mini, GPT-4o, Gemini Flash, Llama 3.1 8B Instruct, Llama 3.1 70B Instruct, Llama 3.1 405B Instruct) were evaluated using zero- and few-shot learning strategies with PubMedBERT for demonstration selection. We compared individual model performance with ensemble methods, including majority voting and random forest (RF), based on sensitivity and specificity. Results: No individual LLM consistently outperformed others across all tasks. Review with narrow inclusion criteria and low inclusion rates exhibited high specificity but lower sensitivity. Ensemble methods consistently surpassed individual LLMs: the RF ensemble with GPT-4o performed best in LLM-Healthcare (sensitivity: 0.96, specificity: 0.89); the majority voting with 1-shot LLMs (sensitivity: 0.75, specificity: 0.86) and RF ensemble with 4-shot LLMs (sensitivity: 0.62, specificity: 0.97) excelled in MCI-Speech; and four RF ensembles achieved perfect classification (sensitivity: 1.0, specificity: 1.0) in Multimodal-LLM. Conclusion: Ensemble approaches improve individual LLMs’ performances in citation screening across diverse healthcare review tasks, highlighting their potential to enhance evidence synthesis workflows that support clinical decision-making. However, broader validation is needed before real-world implementation.",Ensemble learning | Large language model | Majority voting,1,2025,behavior,behavior+policy
473,2-s2.0-85211958940,10.26422/aucom.2025.1401.gon,https://doi.org/10.26422/aucom.2025.1401.gon,https://scholar.google.com/scholar?q=10.26422/aucom.2025.1401.gon,ar,Austral Comunicacion,"González-Arias, Cristian;López-García, Xosé",Technopessimism in the Spanish Print Media in the Public Debate on the Social Impact of Artificial Intelligence,"The rapid evolution of Artificial Intelligence (AI) has intensified public debate about its social implications. In this context, journalistic coverage of technological advancements plays a key role in shaping public opinion. As a mediator of public debate, the press has the responsibility to provide critical and balanced coverage of these important issues. This study analyzes how the media represents ethical concerns regarding the social effects of AI. Based on a corpus of 912 articles from 12 Spanish newspapers, the topics and voices shaping the debate over a one-month period, five months after the launch of ChatGPT, were identified. The results reveal the main discourses organizing public debate, highlighting a predominant technopessimist perspective that emphasizes the potential risks AI poses to humanity and the urgent need to establish ethical standards. Additionally, it shows that large tech companies have played a prominent role in the debate, acting not only as key players in technological development but also as the main voices driving the discussion, in contrast to the limited participation of political, governmental, and civil society actors. While no systematic differences were observed between the newspapers analyzed, some differences in positioning emerged when comparing traditional media with digital-native outlets.",Artificial Intelligence | Ethical dilemmas | Media coverage | Public debate | Technoethics | Technopessimism,1,2025,behavior,behavior+policy
477,2-s2.0-105020180188,10.3390/systems13100913,https://doi.org/10.3390/systems13100913,https://scholar.google.com/scholar?q=10.3390/systems13100913,re,Systems,"Khalil, Masoom;Bravo, Alencar;Vieira, Darli;Carvalho, Marly Monteiro de",Mapping the AI Landscape in Project Management Context: A Systematic Literature Review,"The purpose of this research is to systematically map and analyze the use of AI technologies in project management, identifying themes, research gaps, and practical implications. This study conducts a systematic literature review (SLR) that combines bibliometric analysis with qualitative content evaluation to explore the present landscape of AI in project management. The search covered literature published until November 2024, ensuring inclusion of the most recent developments. Studies were included if they examined AI methods applied to project management contexts and were published in peer-reviewed English journals as articles, review articles, or early access publications; studies unrelated to project management or lacking methodological clarity were excluded. It follows a structured coding protocol informed by inductive and deductive reasoning, using NVivo (version 12) and Biblioshiny (version 4.3.0) software. From the entire set of 1064 records retrieved from Scopus and Web of Science, 27 publications met the final inclusion criteria for qualitative synthesis. Bibliometric clusters were derived from the entire set of 885 screened records, while thematic coding was applied to the 27 included studies. This review highlights the use of Artificial Neural Networks (ANN), Case-Based Reasoning (CBR), Digital Twins (DTs), and Large Language Models (LLMs) as central to recent progress. Bibliometric mapping identified several major thematic clusters. For this study, we chose those that show a clear link between artificial intelligence (AI) and project management (PM), such as expert systems, intelligent systems, and optimization algorithms. These clusters highlight the increasing influence of AI in improving project planning, decision-making, and resource management. Further studies investigate generative AI and the convergence of AI with blockchain and Internet of Things (IoT) systems, suggesting changes in project delivery approaches. Although adoption is increasing, key implementation issues persist. These include limited empirical evidence, inadequate attention to later project stages, and concerns about data quality, transparency, and workforce adaptation. This review improves understanding of AI’s role in project contexts and outlines areas for further research. For practitioners, the findings emphasize AI’s ability in cost prediction, scheduling, and risk assessment, while also emphasizing the importance of strong data governance and workforce training. This review is limited to English-language, peer-reviewed research indexed in Scopus and Web of Science, potentially excluding relevant grey literature or non-English contributions. This review was not registered and received no external funding.",AI-powered tools | artificial intelligence | Case-Based Reasoning (CBR) | digital twins | Large Language Models (LLMs) | project management,1,2025,behavior,behavior+policy
479,2-s2.0-105019198594,10.1371/journal.pdig.0000787,https://doi.org/10.1371/journal.pdig.0000787,https://scholar.google.com/scholar?q=10.1371/journal.pdig.0000787,ar,Plos Digital Health,"Shaikh, Yahya;Jeelani-Shaikh, Zainab Asiyah;Jeelani, Muzamillah Mushtaq;Javaid, Aamir;Mahmud, Tauhid;Gaglani, Shiv;Gibbons, Michael Christopher;Cheema, Minahil;Cross, Amanda;Livingston, Denisa;Cheatham, Morgan;Nezami, Elahe;Dixon, Ronald;Niranjan-Azadi, Ashwini;Zafar, Saad;Siddiqui, Zishan",Collaborative intelligence in AI: Evaluating the performance of a council of AIs on the USMLE,"The stochastic nature of next-token generation and resulting response variability in Large Language Models (LLMs) outputs pose challenges in ensuring consistency and accuracy on knowledge assessments. This study introduces a novel multi-agent framework, referred to as a “Council of AIs”, to enhance LLM performance through collaborative decision-making. The Council consists of multiple GPT-4 instances that iteratively discuss and reach consensus on answers facilitated by a designated “Facilitator AI.” This methodology was applied to 325 United States Medical Licensing Exam (USMLE) questions across all three exam stages: Step 1, focusing on biomedical sciences; Step 2 evaluating clinical knowledge (CK)\; and Step 3, evaluating readiness for independent medical practice. The Council achieved consensus that were correct 97%, 93%, and 94% of the time for Step 1, Step 2 CK, and Step 3, respectively, outperforming single-instance GPT-4 models. In cases where there wasn’t an initial unanimous response, the Council deliberations achieved a consensus that was the correct answer 83% of the time, with the Council correcting over half (53%) of the responses that majority vote had gotten incorrect. The odds of a majority voting response changing from incorrect to correct were 5 (95% CI: 1.1, 22.8) times higher than the odds of changing from correct to incorrect after discussion. This study provides the first evidence that the semantic entropy of the response space can consistently be reduced to zero—demonstrated here through Council deliberation, and suggesting the possibility of other mechanisms to achieve the same outcome.. This study revealed that in a Council model, response variability, often considered a limitation, can be transformed into a strength that supports adaptive reasoning and collaborative refinement of answers. These findings suggest new paradigms for AI implementation and reveal the heightened strength that emerges when AIs begin to collaborate as a collective rather than operate alone.",,1,2025,behavior,behavior+policy
482,2-s2.0-105015072909,10.1007/s42979-025-04315-4,https://doi.org/10.1007/s42979-025-04315-4,https://scholar.google.com/scholar?q=10.1007/s42979-025-04315-4,ar,SN Computer Science,"Ghanta, Swetha;Thiriveedhi, Abhiram;Boyapati, Prasanthi;Pradhan, Ashok Kumar",Federated Transfer Learning for Chest X-ray Classification: An Explainable and Generative AI Framework with Reliability Assessment,"Medical image classification using deep learning (DL) typically requires large and diverse datasets. However, data privacy regulations often limit data sharing across institutions. Federated Learning (FL) addresses this issue by enabling collaborative model training without transferring raw data. Despite its advantages, FL is challenged by limited data at each participating client, which can hinder model performance. To overcome this limitation, we employ Federated Transfer Learning (FTL), a hybrid approach that combines FL with Transfer Learning (TL) to improve model generalization under data scarcity. In this work, we apply FTL to chest X-ray (CXR) classification, leveraging MobileNet for one dataset and ResNet50 for another. We have evaluated our framework’s performance using various evaluation metrics. It achieved 98% accuracy and 99.97% AUC-ROC on Dataset1, and 93.46% accuracy with a 97.9% AUC-ROC on Dataset2, demonstrating its overall effectiveness. To enhance model interpretability, we use Explainable AI (XAI) techniques such as Grad-CAM and LIME to visualize decision-making. Furthermore, we employ two different GPT models-Gemini and ChatGPT-one for generating human-readable explanations based on the XAI visualizations and the other to quantitatively validate the reliability of the generated explanations on a five-point Likert scale. The proposed approach yielded reliability scores of 4.13 and 4.20 for GradCAM visualizations, and 4.43 and 4.87 for LIME visualizations, across the two datasets, indicating high reliability. Overall, the proposed FTL-XAI-GenAI framework ensures high classification performance and transparency, enabling medical professionals to understand AI-driven diagnoses while maintaining data privacy.",Chest X rays | Explainable AI | Federated learning | Generative AI | Transfer learning,1,2025,behavior,behavior+policy
488,2-s2.0-105024671715,10.12012/CJoE2025-0089,https://doi.org/10.12012/CJoE2025-0089,https://scholar.google.com/scholar?q=10.12012/CJoE2025-0089,ar,China Journal of Econometrics,"Hao, Yuzhi;Xie, Danyang",A Multi-LLM-Agent-Based Framework for Economic and Public Policy Analysis,"This paper pioneers a novel approach to economic and public policy analysis by leveraging multiple large language models (LLMs) as heterogeneous artificial economic agents. We first evaluate five LLMs’ economic decision-making capabilities in solving two-period consumption allocation problems under two distinct scenarios: With explicit utility functions and based on intuitive reasoning. While previous research has often simulated heterogeneity by solely varying prompts, our approach harnesses the inherent variations in analytical capabilities across different LLMs to model agents with diverse cognitive traits. Building on these findings, we construct a multi-LLM-agent-based (MLAB) framework by mapping these LLMs to specific educational groups and corresponding income brackets. Using interest income taxation as a case study, we demonstrate how the MLAB framework can simulate policy impacts across heterogeneous agents, offering a promising new direction for economic and public policy analysis by leveraging LLMs’ human-like reasoning capabilities and computational power.",agent-based modeling | economic decision-making | heterogeneous agents | large language models | public policy analysis,1,2025,behavior,behavior+policy
490,2-s2.0-105018017251,10.1111/jebm.70075,https://doi.org/10.1111/jebm.70075,https://scholar.google.com/scholar?q=10.1111/jebm.70075,re,Journal of Evidence Based Medicine,"Chen, Fengxian;Li, Yan;Chen, Yaolong;Bian, Zhaoxiang;Duo, La;Zhou, Qingguo;Zhang, Lu",Strategies for the Analysis and Elimination of Hallucinations in Artificial Intelligence Generated Medical Knowledge,"The application of artificial intelligence (AI) in healthcare has become increasingly widespread, showing significant potential in assisting with diagnosis and treatment. However, generative AI (GAI) models often produce “hallucinations”—plausible but factually incorrect or unsubstantiated outputs—that threaten clinical decision-making and patient safety. This article systematically analyzes the causes of hallucinations across data, training, and inference dimensions and proposes multi-dimensional strategies to mitigate them. Our findings reveal three critical conclusions: The technical optimization through knowledge graphs and multi-stage training significantly reduces hallucinations, while clinical integration through expert feedback loops and multidisciplinary workflows enhances output reliability. Additionally, implementing robust evaluation systems that combine adversarial testing and real-world validation substantially improves factual accuracy in clinical settings. These integrated strategies underscore the importance of harmonizing technical advancements with clinical governance to develop trustworthy, patient-centric AI systems.",assisted diagnosis and treatment | evaluation system | generative artificial intelligence | multi-stage training,1,2025,behavior,behavior+policy
496,2-s2.0-105017069680,10.3390/informatics12030058,https://doi.org/10.3390/informatics12030058,https://scholar.google.com/scholar?q=10.3390/informatics12030058,ar,Informatics,"Williams, Lowri;Burnap, Pete",The Emotional Landscape of Technological Innovation: A Data-Driven Case Study of ChatGPT’s Launch,"The rapid development and deployment of artificial intelligence (AI) technologies have sparked intense public interest and debate. While these innovations promise to revolutionise various aspects of human life, it is crucial to understand the complex emotional responses they elicit from potential adopters and users. Such findings can offer crucial guidance for stakeholders involved in the development, implementation, and governance of AI technologies like OpenAI’s ChatGPT, a large language model (LLM) that garnered significant attention upon its release, enabling more informed decision-making regarding potential challenges and opportunities. While previous studies have employed data-driven approaches towards investigating public reactions to emerging technologies, they often relied on sentiment polarity analysis, which categorises responses as positive or negative. However, this binary approach fails to capture the nuanced emotional landscape surrounding technological adoption. This paper overcomes this limitation by presenting a comprehensive analysis for investigating the emotional landscape surrounding technology adoption by using the launch of ChatGPT as a case study. In particular, a large corpus of social media texts containing references to ChatGPT was compiled. Text mining techniques were applied to extract emotions, capturing a more nuanced and multifaceted representation of public reactions. This approach allows the identification of specific emotions such as excitement, fear, surprise, and frustration, providing deeper insights into user acceptance, integration, and potential adoption of the technology. By analysing this emotional landscape, we aim to provide a more comprehensive understanding of the factors influencing ChatGPT’s reception and potential long-term impact. Furthermore, we employ topic modelling to identify and extract the common themes discussed across the dataset. This additional layer of analysis allows us to understand the specific aspects of ChatGPT driving different emotional responses. By linking emotions to particular topics, we gain a more contextual understanding of public reaction, which can inform decision-making processes in the development, deployment, and regulation of AI technologies.",chatgpt | emerging technologies | emotive language analysis | technology adoption | technology barriers | topic modelling,1,2025,behavior,behavior+policy
499,2-s2.0-105015983964,10.3390/electronics14173404,https://doi.org/10.3390/electronics14173404,https://scholar.google.com/scholar?q=10.3390/electronics14173404,ar,Electronics Switzerland,"Bernasconi, Eleonora;Redavid, Domenico;Ferilli, Stefano",Integrated Survey Classification and Trend Analysis via LLMs: An Ensemble Approach for Robust Literature Synthesis,"This study proposes a novel, scalable framework for the automated classification and synthesis of survey literature by integrating state-of-the-art Large Language Models (LLMs) with robust ensemble voting techniques. The framework consolidates predictions from three independent models—GPT-4, LLaMA 3.3, and Claude 3—to generate consensus-based classifications, thereby enhancing reliability and mitigating individual model biases. We demonstrate the generalizability of our approach through comprehensive evaluation on two distinct domains: Question Answering (QA) systems and Computer Vision (CV) survey literature, using a dataset of 1154 real papers extracted from arXiv. Comprehensive visual evaluation tools, including distribution charts, heatmaps, confusion matrices, and statistical validation metrics, are employed to rigorously assess model performance and inter-model agreement. The framework incorporates advanced statistical measures, including k-fold cross-validation, Fleiss’ kappa for inter-rater reliability, and chi-square tests for independence to validate classification robustness. Extensive experimental evaluations demonstrate that this ensemble approach achieves superior performance compared to individual models, with accuracy improvements of 10.0% over the best single model on QA literature and 10.9% on CV literature. Furthermore, comprehensive cost–benefit analysis reveals that our automated approach reduces manual literature synthesis time by 95% while maintaining high classification accuracy (F1-score: 0.89 for QA, 0.87 for CV), making it a practical solution for large-scale literature analysis. The methodology effectively uncovers emerging research trends and persistent challenges across domains, providing researchers with powerful tools for continuous literature monitoring and informed decision-making in rapidly evolving scientific fields.",automated survey | ensemble learning | large language models | literature synthesis | multi-domain classification | trend analysis,1,2025,behavior,behavior+policy
508,2-s2.0-105018714538,10.16719/j.cnki.1671-6981.20250403,https://doi.org/10.16719/j.cnki.1671-6981.20250403,https://scholar.google.com/scholar?q=10.16719/j.cnki.1671-6981.20250403,ar,Journal of Psychological Science,"Tong, Song;Chen, Hao;Ke, Luoma;Ye, Junkai;Peng, Kaiping",Psychoinformatics: Advances and Perspectives in the Computational Cognition Era,"As artificial intelligence (AI) progresses from perceptual to cognitive intelligence, psychoinformatics—an interdisciplinary field integrating psychology and information science—has entered a crucial phase of theoretical and methodological refinement. This paper reviews the historical background, theoretical foundations, methodological progress, and practical applications of psychoinformatics within the framework of computational cognition. We trace its development from early symbolic processing models to connectionist approaches and, more recently, to deep learning and large language models (LLMs), which have expanded psychological research’s scope and depth. The paper first reviews the theoretical evolution of psychoinformatics, from Galton’s composite photography to the symbolic information processing models proposed by Simon and Newell, which conceptualized mental processes as rule-based symbolic operations. Connectionist models—particularly Rumelhart and McClelland’s parallel distributed processing, later redefined cognition as an emergent property of distributed networks, enabling more flexible modeling of psychological processes. The advent of deep learning and LLMs has shifted the field from data analysis to language-based reasoning and cognitive simulation, supporting theory-driven modeling in psychology. The widespread use of digital technologies and the internet has enabled the collection of naturally occurring data, such as social media content and wearable device outputs, providing opportunities to study psychological phenomena in real-world contexts while raising challenges related to data quality and interpretation. Traditional machine learning models have primarily served as predictive tools to identify behavioral and cognitive patterns but often contribute little to theoretical explanation. In contrast, LLMs have shown promise in language understanding, reasoning, and generating research ideas, serving as both analytical tools and aids in theory development. Recent studies illustrate how LLMs help identify psychological concepts, suggest research directions, and illuminate cognitive processes at individual and group levels. Consequently, psychoinformatics is evolving from a purely data-driven paradigm to an integrated framework combining data and theory for explanatory and predictive psychological inquiry. These developments signal a broader shift toward cognitive intelligence within psychoinformatics. Drawing on Newell’s time-scale framework of human action, these applications correspond to different levels of psychological functioning, from rapid interactions to long-term behavioral change. In clinical psychology, LLMs assist in the early identification of mental health risks, enable ongoing intervention through interactive systems. In educational psychology, LLM-based tutoring systems provide personalized learning, real-time motivational support, and adaptive feedback, leading to improved learning outcomes. In cross-cultural psychology, LLMs show potential in recognizing culturally specific cognitive patterns, helping researchers better understand cultural variations in thinking, emotion, and behavior, and promoting the development of more inclusive psychological theories. Finally, we outline future directions for psychoinformatics: (1) expanding temporal and contextual models to capture both short-term psychological changes and long-term mental health patterns; (2) enhancing human-AI collaboration in hypothesis development and theory refinement; and (3) strengthening ethical governance by applying psychological theories and frameworks—essential for interpreting AI decisions—to guide its responsible and bounded use. In summary, this paper suggests that psychoinformatics, guided by computational cognition, provides a useful framework for combining data-driven and theory-driven approaches. Integrating real-world data, advanced computational methods, and human-AI interaction not only increases the accuracy and practical relevance of psychological research but also opens new pathways for theoretical and applied work. Looking ahead, psychoinformatics is well-positioned to enrich the field of psychology, shaping how we understand, study, and support human action and cognition in today’s “computational cognitive” era.",computational cognition | human-AI collaboration | large language models | naturally occurring data-set | psychoinformatics,1,2025,behavior,behavior+policy
509,2-s2.0-105012117212,10.3760/cma.j.cn112144-20241107-00418,https://doi.org/10.3760/cma.j.cn112144-20241107-00418,https://scholar.google.com/scholar?q=10.3760/cma.j.cn112144-20241107-00418,ar,Chinese Journal of Stomatology,"Han, Cailing;Bai, Shizhu;Zhang, Tingmin;Liu, Chen;Liu, Yuchen;Hu, Xiangxiang;Zhao, Yimin","Preliminary exploration of the applications of five large language models in the field of oral auxiliary diagnosis, treatment and health consultation","Objective To evaluate the accuracy of the oral healthcare information provided by different large language models (LLM) to explore their feasibility and limitations in the application of oral auxiliary, treatment and health consultation. Methods This study designed eight items comprising 47 questions in total related to the diagnosis and treatment of oral diseases [to assess the performance of LLM as an artificial intelligence (AI) medical assistant], and five items comprising 35 questions in total about oral health consultations (to assess the performance of LLM as a simulated doctor). These questions were answered individually by the five LLM models (Erine Bot, HuatuoGPT, Tongyi Qianwen, iFlytek Spark, ChatGPT). Two attending physicians with more than 5 years of experience independently rated the responses using the 3C criteria (correct, clear, concise), and the consistency between the raters was assessed using the Spearman rank correlation coefficient, and the Kruskal-Wallis test and Dunn post hoc test were used to assess the statistical differences between the models. Additionally, this study used 600 questions from the 2023 dental licensing examination to evaluate the time taken to answer, scores, and accuracy of each model. Results As an AI medical assistant, LLM can assist doctors in diagnosis and treatment decision-making, with an inter-evaluator Spearman coefficient of 0.505 (P<0.01). As a simulated doctor, LLM can carry out patient popularization, with an inter-evaluator Spearman coefficient of 0.533 (P<0.01). The 3C scores of each model as an AI medical assistant and a simulated doctor were respectively: 2.00 (1.00, 3.00) and 2.00 (2.00, 3.00) points of Erine Bot, 1.00 (1.00, 2.00) and 2.00 (1.00, 2.00) points of HuatuoGPT, 2.00 (1.00, 2.00) and 2.00 (1.00, 3.00) points of Tongyi Qianwen, 2.00 (1.00, 2.00) and 2.00 (1.75, 2.25) points of iFlytek Spark, 3.00 (2.00, 3.00) and 3.00 (2.00, 3.00) points of ChatGPT (full score of 4 points). The Kruskal-Wallis test results showed that, as an AI medical assistant or a simulated doctor, there were statistically differences in the 3C scores among the five large language models (all P<0.001). The average score of the 5 LLMs on the dental licensing examination was 370.2, with an accuracy rate of 61.7% (370.2/600) and a time consumption of 94.6 min. Specifically, Erine Bot took 115 min, scored 363 points with an accuracy rate of 60.5% (363/600), HuatuoGPT took 224 min and scored 305 points with an accuracy rate of 50.8% (305/600), Tongyi Qianwen took 43 min, scored 438 points with an accuracy rate of 73.0% (438/600), iFlytek Spark took 32 min, scored 364 points with an accuracy rate of 60.7% (364/600), and ChatGPT took 59 min, scored 381 points with an accuracy rate of 63.5% (381/600). Conclusions Based on the evaluation of LLM′s dual roles as an AI medical assistant and a simulated doctor, ChatGPT performes the best, with basically correct, clear and concise answers, followed by Erine Bot, Tongyi Qianwen and iFlytek Spark, with HuatuoGPT lagging behind significantly. In the dental licensing examination, all the 4 LLM, except for HuatuoGPT, reach the passing level, and the time consumpution for answering is significantly reduced compared to the 8 h required for the exam regulations in all of the five models. LLM has the feasibility of application in oral auxiliary, treatment and health consultation, and it can help both doctors and patients obtain medical information quickly. Howere, their outputs carry a risk of errors (since the 3C scoring results do not reach the full marks), so prudent judgment should be exercised when using them.",Artificial intelligence | Counseling | Digital dentistry | Large language models | Oral health | Oral medicine,1,2025,behavior,behavior+policy
521,2-s2.0-105012396481,10.11975/j.issn.1002-6819.202411122,https://doi.org/10.11975/j.issn.1002-6819.202411122,https://scholar.google.com/scholar?q=10.11975/j.issn.1002-6819.202411122,re,Nongye Gongcheng Xuebao Transactions of the Chinese Society of Agricultural Engineering,"Feng, Zaiwen;Xu, Duo;Tian, Fang;Zhang, Hongyu;Li, Wanli;Peng, Hui;Liu, Shanmei;Liu, Hanzun;Jin, Huidong;Huang, Yuan;Wu, Yingdan;Long, Hao;Han, Yiran",Key technologies and development trends of intelligent decision-making large models for facility agriculture,"Intelligent decision-making can be expected to improve protected agriculture, particularly in labor-intensive areas. Thereby, the productivity can be enhanced in facility agriculture. The intelligent decision-making technologies can also hold significant importance: One, the production efficiency and quality can be enhanced to ensure the supply, production, and income in the agricultural modernization; Another, the emerging technologies can be integrated into the precise environmental monitoring and personalized management. This research aims to focus on the multiple scenarios of the key application, such as the greenhouse environment control, modeling and prediction of the crop growth, pest and disease identification, as well as the crop phenotypic monitoring. The relevant emerging technologies were also introduced in the current protected agriculture. A systematic investigation was then made to determine the basic technologies of the visual, language, multi-modal, embodied intelligent, and large multi-agent models. The application potential of the existing large models was assessed in the key scenarios of protected agriculture. Large language models were generated from the agricultural data, providing suggestions and decision-making support to agricultural production. Crop models were established to predict the growth status of the crops in greenhouse environments. The decision-making of the large models was also utilized in the intelligent decision-making for protected agriculture. The intelligent perception of the crop semantic information was integrated with a large visual segmentation model in order to improve the accuracy and efficiency of the decision-making. The data reception, processing, feedback, and decision-making were selected in the greenhouse environment control for the protected agriculture. The physical environment was interacted to achieve the real-time environmental regulation. Embodied intelligence also emphasized that the agents were suitable for the complex environments in both the digital and physical worlds. The multi-modal data of the embodied intelligence depended mainly on the architecture training of the large model for the protected agriculture. A multi-agent large model consisted of multiple interactive AI agents that operated independently to make decisions and then take actions autonomously, according to the environmental changes. The entire production cycle of protected agriculture, data integration, and sharing was achieved after data integration. Multiple large model was collaborated and then interacted for the intelligent decision-making. The multi-model collaboration balanced the advantages of each model. The information mining and accurate analysis were conducted to improve the efficiency and quality of the agricultural production. In conclusion, the large model was improved with traditional protected agriculture, such as information perception, growth model construction, and precise decision-making. An intelligent decision-making system was constructed to promote protected agriculture. The crop growth and the environmental trends were more accurately evaluated after the processing of the multi-source heterogeneous data using large models. The finding can provide a scientific and precise decision-making basis for agricultural production. Intelligent decision-making was also the key driving force for agricultural development. The prosperous agriculture was promoted to fully explore the multi-source heterogeneous data, in order to unlock the potential value of data. An intelligent decision-making system was accelerated to construct for the various application scenarios of protected agriculture using large models. The finding can also provide scientific guidance to reduce the production costs for the high economic benefits.",embodied intelligence | facility agriculture | intelligent decision-making | large model based agents | multi-modal large models,1,2025,behavior,behavior+policy
527,2-s2.0-105009908842,10.1111/1460-6984.70088,https://doi.org/10.1111/1460-6984.70088,https://scholar.google.com/scholar?q=10.1111/1460-6984.70088,ar,International Journal of Language and Communication Disorders,"Hanna, Mytsyk;Yana, Suchikova",Stench of Errors or the Shine of Potential: The Challenge of (Ir)Responsible Use of ChatGPT in Speech-Language Pathology,"Background: Integrating large language models (LLMs), such as ChatGPT, into speech-language pathology (SLP) presents promising opportunities and notable challenges. While these tools can support diagnostics, streamline documentation and assist in therapy planning, they also raise concerns related to misinformation, cultural insensitivity, overreliance and ethical ambiguity. Current discourse often centres on technological capabilities, overlooking how future speech-language pathologists (SLPs) are being prepared to use such tools responsibly. Aims: This paper examines the pedagogical, ethical and professional implications of integrating LLMs into SLP. It emphasizes the need to cultivate professional responsibility, ethical awareness and critical engagement amongst student SLPs, ensuring that such technologies are applied thoughtfully, appropriately and in accordance with evidence-based and contextually relevant therapeutic standards. Methods: The paper combines a review of recent interdisciplinary research with reflective insights from academic practice. It presents documented cases of student SLPs’ overreliance on ChatGPT, analyzes common pitfalls through a structured table of examples and synthesizes perspectives from SLP, education, data ethics and linguistics. Main Contribution: Reflective examples presented in the article illustrate challenges that arise when LLMs are used without sufficient oversight or a clear understanding of their limitations. Rather than questioning the value of LLMs, these cases emphasize the importance of ensuring that student SLPs are guided towards thoughtful, ethical and clinically sound use. To support this, the paper offers a set of pedagogical recommendations—including ethics integration, reflective assignments, case-based learning, peer critique and interdisciplinary collaboration—aimed at embedding critical engagement with tools such as ChatGPT into professional training. Conclusions: LLMs are becoming an integral part of SLP. Their impact, however, will depend on how effectively student SLPs are trained to balance technological innovation with professional responsibility. Higher education institutions (HEIs) must take an active role in embedding responsible engagement with LLMs into pre-service training and SLP curricula. Through intentional and early preparation, the field can move beyond the risks associated with automation and towards a future shaped by reflective, informed and ethically grounded use of generative tools. WHAT THIS PAPER ADDS: What is already known on this subject Large language models (LLMs), including ChatGPT, are increasingly used in speech-language pathology (SLP) for tasks such as diagnostic support, therapy material generation and documentation. While prior research acknowledges both their utility and risks, limited attention has been paid to how student SLPs engage with these tools and how educational institutions prepare them for responsible use. What this paper adds to existing knowledge This paper identifies key challenges in how student SLPs interact with ChatGPT, including overreliance, lack of critical evaluation and ethical blind spots. It emphasizes the role of higher education in developing critical AI literacy aligned with clinical and ethical standards. The study offers specific, practice-oriented recommendations for embedding responsibility-focused engagement with LLMs into SLP curricula. These include ethics integration, reflective assignments, peer feedback and interdisciplinary dialogue. What are the potential or actual clinical implications of this work? Without structured guidance, future SLPs may misuse LLMs in ways that compromise diagnostic accuracy, cultural appropriateness or therapeutic quality. Embedding reflective, ethics-focused training into SLP curricula can reduce these risks and ensure that generative tools like ChatGPT support rather than undermine clinical decision-making and patient care.",ChatGPT | higher education institutions | large language models | responsibility | speech-language pathology | student speech-language pathologists,1,2025,behavior,behavior+policy
532,2-s2.0-105011516836,10.46847/ujmm.2025.2(6)-014,https://doi.org/10.46847/ujmm.2025.2(6)-014,https://scholar.google.com/scholar?q=10.46847/ujmm.2025.2(6)-014,ar,Ukrains Kij Zurnal Vijskovoi Medicini,"Osyodlo, G. V.;Kominko, L. V.;Vovkodav, A. M.",DEVELOPMENT OF THE ETHICAL CODE CONCEPT FOR USING OF ARTIFICIAL INTELLIGENCE IN MILITARY MEDICAL EDUCATION: THE UKRAINIAN MILITARY MEDICAL ACADEMY’S APPROACH,"Introduction. Nowadays, it is impossible to imagine our daily activities without knowledge of the basics of artificial intelligence (AI) for proper use of government systems such as ""Diia"", search engines, online translators (Google Translate). The emergence of ChatGPT, Bard, Midjourney, DALL·E, Copilot with Ukrainian-language interface support has led to the active use of AI in education, business, and programming. Global experience indicates that the integration of AI into educational, medical, and military practices is accompanied by a number of ethical challenges, among which are privacy protection, ensuring algorithmic fairness, transparency of decision-making processes, and accountability distribution. These issues are especially relevant in military-medical education, where the demands of medical, academic, and military ethics intersect. In Ukraine, there is currently no clear legal regulation regarding the rules for the use of AI in the field of science, so we face the question of developing positions for an ethical code and regulations for the use of AI in the curriculum of our higher education institution, taking into account the analysis of international experience (UNESCO, WHO, OECD, European Union) in the use of AI in medicine, education, and military affairs. The aim of the research is to develop a concept for an ethical code for the use of AI in military medical education, using the example of the Ukrainian Military Medical Academy (UMMA), taking into account the integration of international ethical standards, principles of medical, academic, and military ethics, and the specifics of training military medical personnel in the context of the digital transformation of education and medicine. Materials and Methods: A theoretical and comparative analysis was conducted, along with conceptual modeling and logical generalization of the experience of using AI in military medical education in the USA, Canada, Germany, France, and the UK. The depth of the research covers the experience of AI application in foreign educational institutions over the past 5 years and explores common issues arising from its use. The foundation of the research is an interdisciplinary approach that integrates principles of pedagogy, medical and military ethics, as well as AI theory, taking into account international and national regulations, scientific literature, recommendations from UNESCO, WHO, OECD, and the European Commission regarding the ethical regulation of AI use in education, medicine, and the military. Research results: Based on the analysis of scientific literature, we have developed a concept for an ethical code regarding the use of AI in military medical education at the Military Medical Academy, which includes a glossary of terms, a system of ethical principles, specific ethical norms, and behavioral requirements for different categories of users (teachers, students, administration), as well as mechanisms for implementing and monitoring adherence to the code, practical implementation, and prospects for further use of AI with the possibility of targeted training for staff and students and pilot implementation of the code in selected academic disciplines. Conclusions: We have developed a draft concept for an ethical code for the use of AI in military medical education, taking the UAFMA as an example, and proposed a comprehensive model for the ethical regulation of AI applications that integrates the principles of medical ethics, academic integrity, and military morality into a single conceptual framework; basic ethical requirements for the use of AI in education and medicine have been identified, and an attempt has been made to adapt them to the needs of military medical training. The developed concept contributes to the improvement of the quality of the educational process, strengthening academic integrity, the safe implementation of innovative technologies, the protection of the rights of students and patients, as well as the harmonization of the digital transformation of education with military standards and international ethical requirements. The results of this work can be used to implement ethical regulation of AI in other military educational institutions in Ukraine and serve as the basis for the further development of national AI ethics policy in higher and postgraduate education.",academic integrity | algorithmic transparency | artificial intelligence | digital ethics | educational innovations | ethical challenges | ethical code | military ethics | military medical education | personal data protection,1,2025,behavior,behavior+policy
538,2-s2.0-105013844971,10.30491/jmm.2025.1006856.1321,https://doi.org/10.30491/jmm.2025.1006856.1321,https://scholar.google.com/scholar?q=10.30491/jmm.2025.1006856.1321,re,Journal of Military Medicine,"Bahramnezhad, Fatemeh;Akbariqomi, Mostafa;Arabfard, Masoud;Maher-Sultan, Hosny;Vahedian-Azimi, Amir",Artificial Intelligence in Military Medicine: A Comprehensive Review and Future Directions,"Background and Aim: Military medicine operates within uniquely complex and resource-constrained environments, where rapid, precise, and adaptive healthcare delivery is critical. Artificial intelligence (AI), leveraging advanced computational models and data-driven algorithms, offers transformative potential to enhance clinical decision-making, operational efficiency, and logistical support in these high-stakes settings. This narrative review critically examines the current and emerging applications of AI in military medicine, focusing on technological innovations, ethical imperatives, and operational challenges to provide a comprehensive and authoritative synthesis. Methods: A systematic narrative review was conducted by querying multidisciplinary databases including PubMed, Scopus, and Web of Science. Search strategies combined AI-specific terminologies (e.g., machine learning, deep learning, natural language processing) with military medicine contexts (e.g., combat casualty care, telemedicine, medical robotics). Inclusion criteria encompassed peer-reviewed studies, government white papers, and expert consensus documents published up to April 1, 2025. Dual independent screening and full-text review yielded 65 rigorously selected sources. The PRISMA 2020 framework guided the review process. Results: The applications of artificial intelligence in military medicine encompass prevention, battlefield diagnostics, automated triage, robotic-assisted surgery, mental health analytics, predictive logistics, immersive training simulations, and rehabilitation. Key technological advances include convolutional neural networks for trauma imaging, reinforcement learning for casualty prioritization, AI-enabled biosurveillance, and generative AI for scenario-based training. These innovations have demonstrated improvements in diagnostic accuracy, operational responsiveness, and resource optimization under combat conditions. While AI offers substantial benefits, its integration necessitates stringent safeguards addressing data privacy, algorithmic bias, and the preservation of human-in-the-loop oversight. Ethical frameworks and comprehensive education programs are critical to ensure responsible deployment and to foster trust among military healthcare providers. Conclusion: AI represents a pivotal enabler for advancing military medical capabilities. Realizing its full potential requires interdisciplinary collaboration, robust ethical governance, and continuous innovation tailored to the operational complexities of military healthcare environments.",Artificial Intelligence | Military Medicine | Review | Technological Innovations,1,2025,behavior,behavior+policy
542,2-s2.0-105001846496,10.1016/j.cjco.2025.02.012,https://doi.org/10.1016/j.cjco.2025.02.012,https://scholar.google.com/scholar?q=10.1016/j.cjco.2025.02.012,re,Cjc Open,"Ahmed, Muneeb;Lam, Jeffrey;Chow, Alexander;Chow, Chi Ming",A Primer on Large Language Models (LLMs) and ChatGPT for Cardiovascular Healthcare Professionals,"Generative artificial intelligence (AI), particularly large language models (LLMs), such as ChatGPT, is transforming healthcare by offering novel ways to synthesize and communicate medical knowledge. This development is especially relevant in cardiology, as patient education, clinical decision-making, and administrative workflows play pivotal roles in this area. ChatGPT, originally built on GPT-3 and refined into GPT-4, can simplify complex cardiology literature, translate technical explanations into plain language, and address questions across different linguistic backgrounds. Studies show that although ChatGPT demonstrates considerable promise in performing text-based tasks—ranging from passing portions of the European Exam in Core Cardiology to creating patient-friendly educational materials—its inability to interpret images remains a major limitation. Meanwhile, concerns around false information, data bias, and ethical issues highlight the need for careful oversight. Future directions include integrating LLMs with computer-vision modules for image-based diagnostics and combining unstructured patient data to improve risk prediction and phenotyping. Social-media research suggests that chatbots sometimes provide more-empathetic responses than do physicians, underscoring both their potential advantages and complexities. LLM-based tools can also generate letters for insurance prior authorizations or appeals, helping reduce administrative burden. New multimodal approaches, such as ChatGPT Vision, have the potential to enable direct image processing, although clinical validation of this function is yet to be established. The judicious integration of ChatGPT and other LLMs into cardiology requires ongoing validation, robust regulatory frameworks, and strong ethical guidelines to ensure patient privacy, avoid misinformation, and promote equitable healthcare delivery. This review aims to provide a primer on LLMs for cardiovascular professionals, summarizing key applications, current limitations, and prospects in this rapidly evolving field of digital health.",,1,2025,behavior,behavior+policy
553,2-s2.0-86000734544,10.5194/esd-16-423-2025,https://doi.org/10.5194/esd-16-423-2025,https://scholar.google.com/scholar?q=10.5194/esd-16-423-2025,ar,Earth System Dynamics,"Zeng, Yongchao;Brown, Calum;Raymond, Joanna;Byari, Mohamed;Hotz, Ronja;Rounsevell, Mark",Exploring the opportunities and challenges of using large language models to represent institutional agency in land system modelling,"Public policy institutions play crucial roles in the land system, but modelling their policy-making processes is challenging. Large language models (LLMs) offer a novel approach to simulating many different types of human decision-making, including policy choices. This paper aims to investigate the opportunities and challenges that LLMs bring to land system modelling by integrating LLM-powered institutional agents within an agent-based land use model. Four types of LLM agents are examined, all of which, in the examples presented here, use taxes to steer meat production toward a target level. The LLM agents provide simulated reasoning and policy action output. The agents' performance is benchmarked against two baseline scenarios: one without policy interventions and another implementing optimal policy actions determined through a genetic algorithm. The findings show that, while LLM agents perform better than the non-intervention scenario, they fall short of the performance achieved by optimal policy actions. However, LLM agents demonstrate behaviour and decision-making, marked by policy consistency and transparent reasoning. This includes generating strategies such as incrementalism, delayed policy action, proactive policy adjustments, and balancing multiple stakeholder interests. Agents equipped with experiential learning capabilities excel in achieving policy objectives through progressive policy actions. The order in which reasoning and proposed policy actions are output has a notable effect on the agents' performance, suggesting that enforced reasoning both guides and explains LLM decisions. The approach presented here points to promising opportunities and significant challenges. The opportunities include, exploring naturalistic institutional decision-making, handling massive institutional documents, and human-AI cooperation. Challenges mainly lie in the scalability, interpretability, and reliability of LLMs.",,1,2025,behavior,behavior+policy
573,2-s2.0-85218844838,10.1080/23742917.2025.2461828,https://doi.org/10.1080/23742917.2025.2461828,https://scholar.google.com/scholar?q=10.1080/23742917.2025.2461828,ar,Journal of Cyber Security Technology,"Mpitsi, Maria Ch",An ETCC-based security enhancement in an e-governance cloud environment by trust analysis of users using PA-ChatGPT,"For developing and less-developed countries, the e-governance system is highly helpful. The public mostly uses the e-governance system; thus, security is highly required. In prevailing studies, the security enhancement of the e-governance cloud application was concentrated. However, a security shortage issue was presented. To solve this issue, this study proposes ETCC-centric secure data storage in e-governance cloud applications. Primarily, the user registers into the server by utilizing their username and password. Next, only the location-matched users are permitted to access the server. Then, the public and private keys are generated by the key generation. Subsequently, by utilizing user behavior extraction, important behavior selection by BMFKO and prediction by ANOVA-based PA-ChatGPT, the trust is analyzed. The predicted abnormal behavior user is blocked. Next, the normal behavior user is permitted to upload and download the data. The data is securely stored by the proposed ETCC technique. The Beta Delegated Proof of Stake (BDPoS) technique considers blockchain for enhancing security. Authorized data user downloads the data and decrypts it with their private key. Based on performance measures, the proposed techniques are analogized with the prevailing techniques in experimental analysis. The security level attained by the proposed technique is 99.2%.",American Standard Code for Information Interchange (ASCII) ordered syntactic (AOS) | Beta Delegated Proof of Stake (BDPoS) | Brownian Motion function based Kookaburra Optimization (BMFKO) | Elliptic Texas Curve Cryptography (ETCC) | Exact Sign Summation Fenwick Tree (ESSFT),1,2025,behavior,behavior+policy
574,2-s2.0-85218439882,10.28945/5439,https://doi.org/10.28945/5439,https://scholar.google.com/scholar?q=10.28945/5439,ar,Interdisciplinary Journal of Information Knowledge and Management,"Nuryani, ;Munir, Rinaldi;Purwarianti, Ayu;Lestari, Dessi Puji",BERT-BASED MODEL AND LLMS-GENERATED SYNTHETIC DATA FOR CONFLICT SENTIMENT IDENTIFICATION IN ASPECT-BASED SENTIMENT ANALYSIS,"Most research in sentiment analysis, as well as aspect-based sentiment analysis (ABSA), classifies sentiment polarity into two classes (positive and negative) or three classes (positive, negative, and neutral), excluding conflict sentiment. A sentiment will be classified as conflict if it expresses both positive and negative sentiments. Ignoring conflict sentiment will cause the classification to be less accurate. This study investigates the four-class sentiment classification (positive, negative, neutral, and including conflict) and proposes a model utilizing a pretrained language representation model (BERT) for identifying conflict sentiment in ABSA. We also employ an open-source large language model (LLM) created by Meta, Llama 3, for generating synthetic data to support research on four-class sentiment classification in ABSA. Background Public opinions and experiences on product reviews, social events, political movements, etc., can be used for exploring customer behavior, predicting customer preferences, understanding public sentiment, etc., so it becomes an important component in the decision-making process. Providing an accurate opinion will enable an individual, business, or organization to have an informed judgement before making a decision. An aspect-based sentiment analysis, utilizing a four-class sentiment classification system - comprising positive, negative, neutral, and conflict - will produce a more precise assessment than a general sentiment analysis utilizing a two- or three-class sentiment classification system. Methodology This study utilizes a methodology that includes generating synthetic data to augment the original datasets, designing the input representation, detecting aspect categories, performing a multi-label sentiment classification, and representing sentiment in a four-class sentiment classification. Contribution This study provides an investigation of the four-class sentiment classification (positive, negative, neutral, and conflict) and proposes a BERT-based method to identify aspects with conflict sentiment in ABSA. Moreover, it also evaluates Llama 3 for generating synthetic data to address the issues related to data scarcity and imbalanced datasets in the research on four-class sentiment classification in ABSA. The validation of the proposed model on the SemEval-2014 restaurant domain dataset shows an improvement in conflict sentiment accuracy compared to baselines. Findings The investigation of the four-class sentiment classification task in ABSA demonstrates that identifying conflict sentiment is challenging for several reasons. Among them are (1) the lack of a public dataset for this research; (2) the small amount of data with conflict labels in the available dataset resulting in an imbalanced dataset; (3) conflict sentiment is a complex sentiment containing both positive and negative sentiments; and (4) conflict sentiments are usually expressed in long and complicated sentences and involve implicit aspects. Our solution to these challenges involved generating synthetic data using Llama 3 and designing a BERT-based model on multi-label aspects for identifying aspect with conflict sentiment. The experimental results demonstrate that our proposed method outperforms previous methods in identifying the fourth sentiment in four-class sentiment classification, i.e., aspects with conflict sentiment. Recommendations Most existing ABSA models with four-class sentiment classification are con-for Practitioners ducted for product reviews (mostly in the restaurant domain) and in high-resource languages (mainly in English). Therefore, users may need to make some adjustments to different domains and languages. Recommendations Due to the limited availability of datasets for research in aspect-based sentiment for Researchers analysis with four-class sentiment classification, it is important to urgently develop extra supporting datasets. Impact on Society Aspect-based sentiment analysis (ABSA), which employs a four-class sentiment classification (positive, negative, neutral, and conflict), provides a comprehensive analysis about the aspects (or target of opinion) and their sentiment. It will help us understand the sentiment analysis problem better. By providing more accurate sentiment through aspect-based sentiment analysis with four-class sentiment classification, this study can better assist individuals, organizations, or companies in gaining a view or an opinion about any product, service, or candidate in an electoral vote. Future Research Future research on aspect-based sentiment analysis could evaluate other open-source large language models (LLMs), such as Gemma, Mixtral, etc., for generating synthetic data and evaluating the model across various domains and languages. Furthermore, future research could also utilize the LLMs to perform ABSA tasks, such as aspect term extraction, aspect category detection, and sentiment polarities, through fine-tuning the LLMs.",aspect-based sentiment analysis | conflict sentiment | four-class sentiment classification | large language models | pre-trained language models,1,2025,behavior,behavior+policy
579,2-s2.0-85215926836,10.3390/electronics14020379,https://doi.org/10.3390/electronics14020379,https://scholar.google.com/scholar?q=10.3390/electronics14020379,ar,Electronics Switzerland,"Sun, Yi;Han, Ying;Liu, Xinke",Intelligent Gas Risk Assessment and Report Generation for Coal Mines: An Innovative Framework Based on GLM Fine-Tuning,"Traditional coal mine gas risk assessment relies on manual operations, leading to inefficiencies, incomplete information integration, and insufficient evaluation accuracy, ultimately affecting safety oversight. This paper proposes an intelligent gas risk assessment and report generation framework (IGRARG) based on fine-tuning a Generative Language Model (GLM) to address these challenges. The framework integrates multi-source sensor data with the reasoning capabilities of large language models (LLMs). It constructs a gas risk dataset for coal mine safety scenarios, fine-tuned with GLM. Incorporating industry regulations and a domain-specific knowledge base enhanced with a Retrieval-Augmented Generation (RAG) mechanism, the framework automates alarm judgment, suggestion generation, and report creation via a hierarchical graph structure. Real-time human feedback further refines decision making. Experimental results show an evaluation accuracy of 85–93%, with over 300 field tests achieving a 94.46% alarm judgment accuracy and reducing weekly report generation from 90 min to 2–3 min. This framework significantly enhances the intelligence and efficiency of gas risk assessment, providing robust decision support for coal mine safety management.",automated report generation | coal mine safety | fine-tuning | intelligent risk assessment | large language models,1,2025,behavior,behavior+policy
610,2-s2.0-105019596709,10.1007/s11138-025-00708-z,https://doi.org/10.1007/s11138-025-00708-z,https://scholar.google.com/scholar?q=10.1007/s11138-025-00708-z,ar,Review of Austrian Economics,"Makridis, Christos;Lazanski, Dominique",Navigating the knowledge problem in the era of open AI and polycentric governance,"Generative AI systems have revolutionized content creation, data analysis, and decision-making. Yet, they remain constrained by their inability to capture the dispersed, context-specific knowledge emphasized by Friedrich Hayek. This paper examines the “knowledge problem” in the realm of AI, explaining how large language models and other generative technologies operate on aggregated datasets that overlook tacit insights crucial for dynamic, real-world adaptation. Drawing on Elinor Ostrom’s concept of polycentric governance, we propose a framework in which decentralized decision centers manage AI development and oversight collaboratively. Such an approach preserves local autonomy while facilitating cross-community learning, helping to mitigate risks related to bias amplification, single points of failure, and systemic fragility. We use real-world examples to show how polycentric structures can foster innovation, resilience, and ethical deployment of AI. By coupling the computational power of AI with decentralized, context-rich governance, society can harness emerging technologies without sacrificing the local knowledge and human creativity that underpin genuine progress.",Austrian economics | Decentralization | Generative AI | Hayek | Knowledge problem | Mises | Open AI | Polycentric governance | Praxeology,1,2025,behavior,behavior+policy
614,2-s2.0-105019215551,10.3389/fcomp.2025.1570085,https://doi.org/10.3389/fcomp.2025.1570085,https://scholar.google.com/scholar?q=10.3389/fcomp.2025.1570085,ar,Frontiers in Computer Science,"Jain, Kurunandan;Achuthan, Krishnashree",Modeling the dynamics of misinformation spread: a multi-scenario analysis incorporating user awareness and generative AI impact,"The proliferation of misinformation on social media threatens public trust, public health, and democratic processes. We propose three models that analyze fake news propagation and evaluate intervention strategies. Grounded in epidemiological dynamics, the models include: (1) a baseline Awareness Spread Model (ASM), (2) an Extended Model with fact-checking (EM), and (3) a Generative AI-Influenced Spread model (GIFS). Each incorporates user behavior, platform-specific dynamics, and cognitive biases such as confirmation bias and emotional contagion. We simulate six distinct scenarios: (1) Accurate Content Environment, (2) Peer Network Dynamics, (3) Emotional Engagement, (4) Belief Alignment, (5) Source Trust, and (6) Platform Intervention. All models converge to a single, stable equilibrium. Sensitivity analysis across key parameters confirms model robustness and generalizability. In the ASM, forwarding rates were lowest in scenarios 1, 4, and 6 (1.47%, 3.41%, 2.95%) and significantly higher in 2, 3, and 5 (19.67%, 56.52%, 29.47%). The EM showed that fact-checking reduced spread to as low as 0.73%, with scenario-based variation from 1.16 to 17.47%. The GIFS model revealed that generative AI amplified spread by 5.7%–37.8%, depending on context. ASM highlights the importance of awareness; EM demonstrates the effectiveness of fact-checking mechanisms; GIFS underscores the amplifying impact of generative AI tools. Early intervention, coupled with targeted platform moderation (scenarios 1, 4, 6), consistently yields the lowest misinformation spread, while emotionally resonant content (scenario 3) consistently drives the highest propagation.",differential equations | linear stability analysis | math modeling | misinformation | numerical simulation | stability analysis,1,2025,behavior,behavior+policy
617,2-s2.0-105018017519,10.1080/0142159X.2025.2564869,https://doi.org/10.1080/0142159X.2025.2564869,https://scholar.google.com/scholar?q=10.1080/0142159X.2025.2564869,ar,Medical Teacher,"Rush, Emily;Byram, Jessica N.;Garnett, Colleen N.;DeVaul, Nicole;Smith, Laura;Checchi, Margaret;Martin, Daniel;Hoffman, Leslie A.;Brown, Kirstin M.;Mumbower, Daniel J.;Becker, Robert M.;Roach, Victoria A.;Doubleday, Alison F.;Edwards, Danielle N.;Lufler, Rebecca S.;Wactor, Alexandra;Boxerman, Sophia;Smith, Suzanne;Herriott, Hannah;Wilson, Adam B.",An audit of AI-related documents across U.S. Medical schools: A framework-based qualitative content analysis,"Purpose: Medical schools would benefit from systematic guidance for developing comprehensive artificial intelligence (AI) policies, given generative AI’s rapid integration into medical education. This study developed and applied an idealized AI policy framework to analyze AI-related documents at U.S. medical school institutions, providing reference points for the development and refinement of institutional policies. Methods: AI-related documents from institutions with U.S. allopathic and osteopathic medical schools were systematically collected (from August to October 2024) and analyzed using a comprehensive framework containing 24 subthemes across six themes: Background/Context, Governance, AI Literacy, Tools/Usage, Ethical/Legal Considerations, and Technology Support and Infrastructure. Publicly available online documents were systematically coded to generate framework subtheme scores indicating breadth of coverage across framework themes. Results: AI-related documents retrieved from 73.7% (146/198) of U.S. medical school institutions covered an average of 8 of 24 subthemes, representing a mean framework coverage score of 32.3% ± 19.8 Rarely addressed subthemes included Audit and Compliance Mechanisms (6.8%, 10/146), Technical Infrastructure (6.2%, 9/146), and Environmental Stewardship (1.4%, 2/146). Academic Honesty and Plagiarism dominated AI-related documents (81.5%, 119/146), followed by Decision-Making Authority (54.1%, 79/146) and Critical Evaluation (52.1%, 76/146). Formal AI policies demonstrated significantly higher framework coverage than other AI document types (44.0% vs 30.4%, p = 0.003). Seven institutions with the highest coverage (≥13/24 subthemes) shared seven common distinguishing features, with six present universally. Conclusions: AI-related documents currently emphasize academic integrity over strategic planning, with substantial gaps in infrastructure and review mechanisms. Institutions can enhance their AI policies by incorporating common features identified in well-designed policies and following frameworks that strike a balance between immediate concerns and long-term adaptability.",artificial intelligence | educational policy | Medical education | Qualitative content analysis | United States,1,2025,behavior,behavior+policy
619,2-s2.0-105017406581,10.1007/s10844-025-00988-8,https://doi.org/10.1007/s10844-025-00988-8,https://scholar.google.com/scholar?q=10.1007/s10844-025-00988-8,ar,Journal of Intelligent Information Systems,"Reddy, Veerababu;Veeranjaneyulu, N.",DeepFinLLM 2.0: an optimized and scalable multilingual financial advisor unleashing strategic insights through multi-API orchestration and large language models,"The need for advanced financial advisory systems has grown as global markets demand precise, real-time insights. Traditional models often face limitations in adaptability, language diversity, and data reliability. This paper presents DeepFinLLM 2.0, a unified pipeline that orchestrates multilingual Natural Language Processing (NLP), DeepSeek R1-0528 retrieval, cross-validated multi-API data fusion, and Beetle Antenna Search (BAS) driven optimization into a real-time financial advisory system. DeepFinLLM 2.0 Utilizes an advanced multilingual pipeline catering to queries in over 100 languages while delivering proven robust performance in 12 key languages, making it versatile yet reliable for global financial advisory applications. The integration of DeepSeek R1-0528 improves retrieval efficiency, enhancing accuracy and reducing misinformation. Additionally, BAS dynamically optimizes system parameters and query processing, ensuring low latency even when handling multiple concurrent API calls across diverse languages. Moreover, the system Employs multiple financial data sources, reducing dependence on a single API and strengthening data integrity through cross-validation. These enhancements significantly improve performance, achieving 96.2% accuracy, an F1 score of 0.94, and an Exact Match rate of 92%. With an optimized 0.75-second response time, DeepFinLLM 2.0 provides timely financial insights, including risk assessments and portfolio recommendations. DeepFinLLM 2.0 demonstrates that integrating multilingual NLP, enhanced retrieval, multi-API orchestration, and dynamic BAS tuning within a single architecture can achieve state-of-the-art performance for real-time financial decision-making, offering a scalable solution for institutional and retail investors in dynamic markets.",Financial QA | Large language models (LLMs) | Multilingual | Real-time multiple data integration | Semantic query parsing,1,2025,behavior,behavior+policy
620,2-s2.0-105017162849,10.1109/TCCN.2025.3612760,https://doi.org/10.1109/TCCN.2025.3612760,https://scholar.google.com/scholar?q=10.1109/TCCN.2025.3612760,ar,IEEE Transactions on Cognitive Communications and Networking,"Luo, Haoxiang;Liu, Yinqiu;Zhang, Ruichen;Wang, Jiacheng;Sun, Gang;Niyato, Dusit;Yu, Hongfang;Xiong, Zehui;Wang, Xianbin;Shen, Xuemin","Toward Edge General Intelligence With Multiple-Large Language Model (Multi-LLM): Architecture, Trust, and Orchestration","Edge computing enables real-time data processing closer to its source, thus improving the latency and performance of edge-enabled AI applications. However, predictive AI models often fall short when dealing with complex, dynamic tasks that require advanced reasoning and multimodal data processing. This survey explores the integration of multi-LLMs (Large Language Models) to address these challenges in edge computing, where multiple specialized LLMs collaborate to enhance task performance and adaptability in resource-constrained environments. We review the transition from conventional edge AI models to single LLM deployment and, ultimately, to multi-LLM systems. The survey discusses enabling technologies such as dynamic orchestration, resource scheduling, and cross-domain knowledge transfer that are key for multi-LLM implementation. A central focus is on trusted multi-LLM systems, ensuring robust decision-making in environments where reliability and privacy are crucial. We also present multimodal multi-LLM architectures, where multiple LLMs specialize in handling different data modalities, such as text, images, and audio, by integrating their outputs for comprehensive analysis. Finally, we highlight future directions, including improving resource efficiency, trustworthy governance multi-LLM systems, while addressing privacy, trust, and robustness concerns. This survey provides a valuable reference for researchers and practitioners aiming to leverage multi-LLM systems in edge computing applications.",edge computing | Large language model (LLM) | multimodal LLM | multiple LLMs | trustworthy LLM system,1,2025,behavior,behavior+policy
630,2-s2.0-105011542716,10.1097/SCS.0000000000011659,https://doi.org/10.1097/SCS.0000000000011659,https://scholar.google.com/scholar?q=10.1097/SCS.0000000000011659,ar,Journal of Craniofacial Surgery,"Jafarov, Murod M.;Azizova, Feruza L.;Khasanov, Saidakrom A.;Jafarov, Mirjamol M.;Mamasoliyeva, Nazokat",The Impact of ChatGPT in Plastic Reconstructive Surgery: A Focus on Head and Neck Abnormalities,"Artificial Intelligence (AI), particularly ChatGPT, is reshaping how medical knowledge is accessed and utilized (1). This study investigates its role in plastic reconstructive surgery, focusing on congenital head and neck abnormalities like cleft lip and palate. By surveying surgeons and trainees across Uzbekistan, the authors evaluated ChatGPT's effectiveness for education, clinical decision-making, and finding precise details, such as information on international conferences. In health care practice and academic writing, factual inaccuracies, ethical issues, and the fear of misuse, including the spread of misinformation, should be considered (2, 7). Results show that while ChatGPT supports early learners in understanding basic concepts, 75% of experienced surgeons found its information insufficient and often incorrect for practical applications. In addition, ChatGPT struggled to provide exact details like conference schedules, a task performed better by traditional tools like Google. The study highlights ChatGPT's potential for educational purposes but emphasizes its limitations in advanced surgical applications.",Al-Khwarizmi | Algorithm | artificial intelligence | chatGPT | cleft lip | cleft palate | head and neck abnormalities | medical education | plastic reconstructive surgery | plastic surgery | Uzbekistan,1,2025,behavior,behavior+policy
631,2-s2.0-105011255021,10.1080/00207543.2025.2532142,https://doi.org/10.1080/00207543.2025.2532142,https://scholar.google.com/scholar?q=10.1080/00207543.2025.2532142,ar,International Journal of Production Research,"Joglekar, Nitin;Nie, Wei;Alem Fonseca, Mariel;Tsolakis, Naoum;Kumar, Mukesh",Αn AI-driven approach to assess sentiments and interpret context in a critical mineral supply chain,"This exploratory article argues against using Large Language Models (LLMs) as a ‘black box’, without human scrutiny, for generating interpretable context while assessing sentiment metrics. These metrics support supply chain (SC) decision-making under information asymmetry and public policies in critical mineral networks. Using a dataset of 5,168 news articles before and after a truck strike in the Democratic Republic of Congo (DRC), we enumerate observed sentiment shifts across cobalt SC echelons (i.e., DRC, China, U.S.A. and Canada) using an LLM with long context windows. As shifts can be small, assessments need to be precise, significant, and interpretable. To this end, we devise and deploy a ‘Context Enhanced Supply Chain Sentiment and Summaries’ (CESCSS) framework to provide reliable and interpretable outcomes. Through statistical testing, our findings indicate that context matters in assessing sentiment shifts across SC operations echelons. Findings also illustrate differences in sentiments and offer context summary-based interpretations for these differences based on end-to-end information asymmetries. In addition, results showcase the reliability of human ratings and then demonstrate that human assessments are statistically equivalent to context-enhanced LLM sentiment valuations. We discuss pathways for applying the CESCSS framework toward theory development and managerial decisions in critical mineral SCs.",context and sentiment | context enhanced supply chain sentiment and summaries | critical mineral supply chains | Long context LLMs | reliability and interpretability,1,2025,behavior,behavior+policy
634,2-s2.0-105010933058,10.1080/23812346.2025.2528005,https://doi.org/10.1080/23812346.2025.2528005,https://scholar.google.com/scholar?q=10.1080/23812346.2025.2528005,ar,Journal of Chinese Governance,"Liang, Zhehao;Li, You;Chen, Tao","When AI fails, who gets the blame? Citizens’ attribution patterns in AI-induced public service failures","Globally, governments have increasingly implemented Artificial Intelligence (AI) in public service delivery and decision-making to replace human officials in the name of improving scalability, cost-effectiveness, and efficiency. However, few empirical studies have explored the challenges citizens face in seeking accountability when government AI agents fail. To fill this gap, this paper investigates how citizens perceive and attribute blame for AI-induced public service failures compared to those caused by human officials, addressing the potential ‘accountability deficit’ in AI governance. Using Weiner’s Attribution Theory as the framework, we conducted three scenario-based experiments with 516 participants. The results revealed that citizens generally blamed AI agents less than government departments due to lower perceptions of controllability over the service task compared to the same failures caused by human officials. However, when AI was identified as outsourced, their blame toward the government was significantly lower. Thus, our findings support the idea that the application of AI in public services introduces uncertainty into governmental reputation and accountability. Overall, this study contributes to the growing body of knowledge on AI in public services by underscoring the importance of developing ethical and legal governance frameworks to address potential accountability deficiencies and blame avoidance in public services using AI.",accountability | Attribution theory | controllability | human–Al interaction | locus of causality,1,2025,behavior,behavior+policy
636,2-s2.0-105010914118,10.3389/frai.2025.1611024,https://doi.org/10.3389/frai.2025.1611024,https://scholar.google.com/scholar?q=10.3389/frai.2025.1611024,ar,Frontiers in Artificial Intelligence,"Jonnala, Sridhar;Thomas, Nisha Mary;Mishra, Sarthak",Navigating ethical minefields: a multi-stakeholder approach to assessing interconnected risks in generative AI using grey DEMATEL,"The rapid advancement of generative artificial intelligence (AI) technologies has introduced unprecedented capabilities in content creation and human-AI interaction, while simultaneously raising significant ethical concerns. This study examined the complex landscape of ethical risks associated with generative AI (GAI) through a novel multi-stakeholder empirical analysis using the grey decision-making-trial-and-evaluation-laboratory methodology to quantitatively analyze the causal relationships between risks and their relative influence on AI deployment outcomes. Through a comprehensive literature review and expert validation across three key stakeholder groups (AI developers, end users, and policymakers), we identified and analyzed 14 critical ethical challenges across the input, training, and output modules, including both traditional and emerging risks, such as deepfakes, intellectual property rights, data transparency, and algorithmic bias. This study analyzed the perspectives of key stakeholders to understand how ethical risks are perceived, prioritized, and interconnected in practice. Using Euclidean-distance analysis, we identified significant divergences in risk perception among stakeholders, particularly in areas of adversarial prompts, data bias, and output bias. Our findings contribute to the development of a balanced ethical risk framework by categorizing risks into four distinct zones: critical enablers, mild enablers, independent enablers, and critical dependents. This categorization promotes technological advancement and responsible AI deployment. This study addressed the current gaps in academic work by providing actionable recommendations for risk-mitigation strategies and policy development while highlighting the need for collaborative approaches among stakeholders in the rapidly evolving field of GAI.",AI risks | ethical AI | foundation models | generative AI | responsible AI,1,2025,behavior,behavior+policy
640,2-s2.0-105008219042,10.1109/TAI.2025.3579452,https://doi.org/10.1109/TAI.2025.3579452,https://scholar.google.com/scholar?q=10.1109/TAI.2025.3579452,ar,IEEE Transactions on Artificial Intelligence,"Yi, Peiling;Xia, Yuhan;Long, Yunfei","Irony Detection, Reasoning and Understanding in Zero-shot Learning","Irony is a powerful figurative language (FL) on social media that can potentially mislead various NLP tasks, such as recommendation systems, misinformation checks, and sentiment analysis. Understanding the implicit meaning of this kind of subtle language is an essential step to mitigate the negative impact of irony in NLP tasks. However, existing efforts are limited to domain-specific datasets and struggle to generalize across diverse real-world scenarios. Moreover, reasoning for model decisions that accurately capture semantic and affective meaning remains underexplored. To address these limitations, this paper proposes a conceptual framework called IDADP, which leverages Large language models(LLMs)’ in-context learning capabilities to detect irony and generate human-like explanations across diverse datasets and platforms without prior training on ironic samples. Extensive experiments on six widely used irony detection datasets, utilising two large language models (GPT and Gemini), demonstrate that IDADP consistently outperforms six competitive zero-shot baselines and approaches the performance of three fine-tuned supervised learning baselines. Additionally, we examine GPT’s ability to understand the true intent behind ironic text within the IDADP framework, highlighting its strong potential to recognize and interpret statements where the intended meaning differs from or contrasts with the literal meaning. Furthermore, we conduct qualitative analyses to identify remaining challenges. This work, in turn, opens an avenue for transparent decision-making in irony detection.",Large Language Models | Prompt engineering | Zero-shot learning,1,2025,behavior,behavior+policy
646,2-s2.0-105004656116,10.1109/MIS.2025.3567372,https://doi.org/10.1109/MIS.2025.3567372,https://scholar.google.com/scholar?q=10.1109/MIS.2025.3567372,ar,IEEE Intelligent Systems,"Rutagemwa, Humphrey;Ghasemi, Amir;Guinand, Paul",Empowering Future Spectrum Management and Regulation With Large Language Models,"Spectrum management and regulation are becoming more complex due to rapid technological advancements, increasing demand for spectrum, and the presence of diverse stakeholders with conflicting interests. In response, governments worldwide are increasingly interested in leveraging advanced technologies, such as artificial intelligence (AI), to enhance efficiency and optimize policy outcomes. This article explores the application of large language models (LLMs), a subset of generative AI, to streamline tasks and improve decision making in spectrum management and regulation. It examines the various roles of LLMs in this field and addresses associated challenges. Through empirical case studies and experimental findings, the article demonstrates how LLMs can profoundly transform spectrum management and regulation practices. The study also offers insights into effectively integrating AI into regulatory frameworks, providing practical lessons and best practices for governmental AI initiatives.",,1,2025,behavior,behavior+policy
657,2-s2.0-85214699462,10.3233/JIFS-234506,https://doi.org/10.3233/JIFS-234506,https://scholar.google.com/scholar?q=10.3233/JIFS-234506,ar,Journal of Intelligent and Fuzzy Systems,"Shukla, Shiv Shankar Prasad;Singh, Maheshwari Prasad",Exploring ensemble optimized voting and stacking classifiers through Cross-validation for early detection of suicidal ideation,"Detecting behavioral changes associated with suicidal ideation on social media is essential yet complex. While machine learning and deep learning hold promise in this regard, current studies often lack generalizability due to single dataset reliance. Traditional embedding techniques struggle with semantic analysis,leading to challenges in achieving high accuracy models and conventional validation methods have data drift limitations. To address these challenges, this study proposes a novel evaluation approach using natural language processing across diverse platforms like Twitter and Reddit. By integrating BERT embedding, adept at handling semantic nuances, with an optimized Stacked Classifier combining different base classifiers and XGBoost as the meta-classifier, the model excels in swiftly detecting signs of suicidal ideation compared to the Voting Classifier, i.e., the combination of Decision Tree, Random Forest, Gradient Boost and XGBoost and several machine learning models. Additionally, the study explores advanced embedding techniques like MUSE and LLM, and deep learning models including Bi-LSTM, Bi-GRU, and Text-CNN for comparison.This ensemble approach aims to create a model that is not only interpretable but also robust, reducing computational complexity and enhancing resilience against noisy data - common challenges faced in text classification tasks. Through K-fold validation, which involves partitioning the dataset into k equal-sized subsets or ""folds""and training the model k times, using k-1 folds for training and one-fold for testing each time, the proposed model achieves impressive accuracy rates of 97% on Reddit and 96% on Twitter datasets, underscoring its effectiveness in identifying suicidal ideation across social media platforms.",BERT | Bi-GRU | Bi-LSTM | MUSE | Stacked Classifier | suicidal ideation | Voting Classifier,1,2024,behavior,behavior+policy
672,2-s2.0-105000120843,10.11959/j.issn.2096-6652.202410,https://doi.org/10.11959/j.issn.2096-6652.202410,https://scholar.google.com/scholar?q=10.11959/j.issn.2096-6652.202410,ar,Chinese Journal of Intelligent Science and Technology,"Li, Yanying;Wang, Xinyu;Wang, Xiao;Sun, Changyin",Traffic anomaly event detection and auxiliary decision-making based on large language models,"The superior data analytics and logical reasoning capabilities of big language models provide new ideas for real-time traffic management and assisted decision-making. ChatGPT efficiently processes and analyzes publicly available social media data to detect city and roadway information and traffic events contained in the data, which can be used to assist traffic managers in making real-time inquiries, tracing causes and exploring countermeasures. This paper constructs an intelligent Q&A framework, TMGPT (traffic management GPT), which integrates social media data with ChatGPT, to explore how large language models can be leveraged to quickly detect traffic anomalies and provide decision support for traffic management departments. Through the acquisition, processing and analysis of social media data, the framework achieves accurate detection of traffic anomalies and the generation of targeted response strategies, and continuously optimizes the system performance through the feedback mechanism, providing a decision basis for traffic management and policy-making departments to improve the efficiency and safety of urban traffic operation. The results show that compared with traditional methods, TMGPT significantly improves the accuracy of detection and reduced response time in the detection and assisted decision-making of abnormal traffic events, which demonstrates the application potential of large language models in complex urban traffic management.",auxiliary decision-making | ChatGPT | social media | traffic event detection,1,2024,behavior,behavior+policy
699,2-s2.0-85196301062,10.47626/1679-4435-2023-1241,https://doi.org/10.47626/1679-4435-2023-1241,https://scholar.google.com/scholar?q=10.47626/1679-4435-2023-1241,ar,Revista Brasileira De Medicina do Trabalho,"dos Santos, Mateus Lins;Victória, Vera Nascimento Gomes",Critical evaluation of applications of artificial intelligence based linguistic models in Occupational Health,"This article explores the impact and potential applications of large language models in Occupational Medicine. Large language models have the ability to provide support for medical decision-making, patient screening, summarization and creation of technical, scientific, and legal documents, training and education for doctors and occupational health teams, as well as patient education, potentially leading to lower costs, reduced time expenditure, and a lower incidence of human errors. Despite promising results and a wide range of applications, large language models also have significant limitations in terms of their accuracy, the risk of generating false information, and incorrect recommendations. Various ethical aspects that have not been well elucidated by the medical and academic communities should also be considered, and the lack of regulation by government entities can create areas of legal uncertainty regarding their use in Occupational Medicine and in the legal environment. Significant future improvements can be expected in these models in the coming years, and further studies on the applications of large language models in Occupational Medicine should be encouraged.",artificial intelligence | education | medical | natural language processing | occupational health | occupational medicine,1,2024,behavior,behavior+policy
60,2-s2.0-105020303879,10.1016/j.sca.2025.100173,https://doi.org/10.1016/j.sca.2025.100173,https://scholar.google.com/scholar?q=10.1016/j.sca.2025.100173,ar,Supply Chain Analytics,"Abyaneh, Amirhossein Ghasemi;Ghanbari, Hossein;Mohammadi, Emran;Amirsahami, Amirali;Khakbazan, Masoud",An analytical review of artificial intelligence applications in sustainable supply chains,"Sustainable supply chains are essential for promoting environmental responsibility, economic efficiency, and social well-being. They help reduce carbon footprints, optimize resource use, and support circular economy initiatives. Economically, they enhance efficiency, lower costs, and mitigate risks related to resource scarcity and environmental regulations. Socially, they ensure ethical sourcing, fair labor practices, and corporate social responsibility. By balancing these dimensions, sustainable supply chains contribute to business resilience while aligning with global sustainability goals, such as the UN Sustainable Development Goals (SDGs). In the age of Artificial Intelligence (AI), rapid technological advancements have significantly transformed supply chain operations, necessitating greater flexibility and the integration of AI-driven techniques. The application of AI in supply chain management has proven highly beneficial, offering enhanced efficiency, predictive capabilities, and improved sustainability. Recent advancements, including Large Language Models (LLMs), are also playing a transformative role in enhancing decision-making and risk management across supply chains. Numerous researchers have highlighted AI's potential in advancing circular economy initiatives by optimizing resource utilization and minimizing waste. However, despite the growing academic interest, research in this domain remains fragmented and lacks a coherent structure. To address this gap, this paper conducts a comprehensive bibliometric analysis to map the current research landscape, identify key themes, and highlight future directions. Bibliographic records were retrieved from the Web of Science database, covering the period from 1997 to 2024. A total of 1070 records were initially gathered for analysis. The findings of this study provide valuable insights into the evolution of research in AI-driven sustainable supply chains, uncover emerging trends, and suggest potential avenues for future exploration. Specifically, the analysis reveals an annual publication growth rate of 23.37 % from 1997 to 2024, with China, India, and the USA as the top contributing countries. Core research themes include AI-enabled logistics optimization, circular economy practices, and supply chain resilience under global disruptions. By offering a structured overview of the field, this study aims to support scholars and practitioners in navigating the intersection of AI and sustainability in supply chain management.",Artificial Intelligence | Data-driven supply chains | Environmental impact assessment | Predictive analytics | Supply chain management | Sustainable logistics,1,2025,sustainability,behavior+policy+sustainability
83,2-s2.0-105017888922,10.3724/SP.J.1041.2025.1973,https://doi.org/10.3724/SP.J.1041.2025.1973,https://scholar.google.com/scholar?q=10.3724/SP.J.1041.2025.1973,ar,Acta Psychologica Sinica,"Wei, Xinni;Yu, Feng;Peng, Kaiping",Perceived unsustainability decreases acceptance of artificial intelligence,"Climate change and environmental issues significantly impact human health and well-being, posing substantial challenges to global sustainable development. Addressing these challenges necessitates both immediate and long-term solutions. While climate change itself does not inherently elicit a moral response, potentially hindering public engagement in climate action, artificial intelligence (AI)—encompassing robots, algorithms, and models—emerges as a promising ally. AI’s ability to learn from experience, adapt to new inputs, and perform human-like tasks positions it as a critical tool in addressing environmental challenges. However, AI presents a dual-edged impact on the environment. While it can support ecological governance and promote sustainability, its energy-intensive nature and associated carbon emissions may undermine the environment. This study investigates the environmental implications of AI, focusing on how perceptions of AI’s sustainability influence public acceptance and the underlying psychological mechanisms. Drawing on prior research, we hypothesized that individuals tend to avoid using unsustainable AI due to perceptions of diminished morality and heightened dependency (i.e., lower perceived agency). To test this, we conducted five studies employing diverse methodologies and measures. A preliminary study used 14 words generated by ChatGPT to gauge public attitudes toward AI in environmental decision-making, revealing a generally favorable view of AI in environmental management. Study 1a and Study 1b experimentally manipulated perceptions of AI’s unsustainability, demonstrating that awareness of its high energy consumption and carbon emissions significantly reduces acceptance. Study 2 replicated these findings and identified morality—rather than dependency—as the mediating factor. Study 3 showed that pro-environmental attitudes significantly moderate the relationship between AI sustainability and its acceptance in environmental contexts. In summary, this research highlights that while individuals are willing to collaborate with AI to address environmental challenges, their acceptance diminishes when AI is perceived as environmentally harmful. These findings underscore the critical importance of AI’s sustainability in achieving sustainable development goals.",acceptance | artificial intelligence | morality | sustainability,1,2025,sustainability,behavior+policy+sustainability
128,2-s2.0-105018855330,10.3390/buildings15193452,https://doi.org/10.3390/buildings15193452,https://scholar.google.com/scholar?q=10.3390/buildings15193452,ar,Buildings,"Zhang, Guozong;Xiong, Youqian;Luo, Qianmai",Uncovering Drivers of Resident Satisfaction in Urban Renewal: Contextual Perception Mining of Old Community Regeneration Through Large Language Models,"Urban regeneration has increasingly become a global strategy for promoting sustainable urban development, with the renewal of deteriorating residential communities serving as a key dimension of this process. Within the framework of a people-centered development paradigm, growing attention has been directed toward the necessity of securing residents’ satisfaction in community renewal initiatives. This study employs advanced textual analysis of resident submissions collected from government–citizen interaction platforms to investigate the determinants of satisfaction with renewal projects. Leveraging the semantic comprehension capabilities of large language models (LLMs), we identify both salient keywords and sentiment orientations embedded in residents’ narratives. Guided by the theoretical framework of resident satisfaction, the extracted keywords are organized into seven thematic domains: basic infrastructure improvement, quality-enhancement renovation, solicitation of residents’ preferences, residents’ decision-making power, policy transparency, construction governance, and community-level communication. Regression modeling is subsequently applied to assess the relative influence of these thematic domains on residents’ satisfaction. The findings suggest that insufficient integration of residents’ preferences at the preliminary stages of participation constitutes a principal source of dissatisfaction during the implementation of renewal projects. Furthermore, the study compares Latent Dirichlet Allocation (LDA) topic modeling with LLMs-based topic clustering, revealing the latter’s superior capacity to capture thematic structures in complex, long-form textual data. These results underscore the potential of LLMs to enhance the analytical rigor of research on urban regeneration and citizen participation.",large language models | old community regeneration | resident satisfaction | topic clustering,1,2025,sustainability,behavior+policy+sustainability
228,2-s2.0-105002161679,10.26342/2025-74-9,https://doi.org/10.26342/2025-74-9,https://scholar.google.com/scholar?q=10.26342/2025-74-9,ar,Procesamiento Del Lenguaje Natural,"Cruz, Fermín L.;Enríquez, Fernando;Ortega, F. Javier;Troyano, José A.",FallacyES-Political: A Multiclass Dataset of Fallacies in Spanish Political Debates,"Fallacies are pervasive in political discourse, shaping public opinion and influencing decision-making. Automatic detection and classification of fallacies is a challenging task, especially in non-English languages due to limited resources. In this study, we present FallacyES-Political, a novel dataset of fallacies extracted from 19 electoral debates held in Spain over three decades. The dataset comprises nearly 2,000 fallacies categorized into 16 types. To evaluate the dataset’s utility, we conducted a comprehensive benchmarking of state-of-the-art Large Language Models (LLMs) in zero-shot classification. The results highlight the complexity of fallacy classification and the limitations of current LLMs in understanding context-dependent argumentation. Furthermore, we demonstrate the advantages of fine-tuning a compact, domain-specific model over relying on general-purpose LLMs, achieving notable improvements in classification accuracy with a more sustainable approach.",Fallacy Classification | Political Discourse Analysis | Spanish Linguistic Resources,1,2025,sustainability,behavior+policy+sustainability
241,2-s2.0-85217528927,10.12026/j.issn.1001-8565.2025.02.01,https://doi.org/10.12026/j.issn.1001-8565.2025.02.01,https://scholar.google.com/scholar?q=10.12026/j.issn.1001-8565.2025.02.01,ar,Chinese Medical Ethics,"Li, Juping",ChatGPT-driven medical intelligent decision-making：ethics，law，and regulation,With the rapid development of generative artificial intelligence（AI）technology，the application of natural language processing models such as ChatGPT has become possible in the medical field. However，the issues of ethics，law，and regulation involved in medical intelligent decision-making have gradually become prominent. This paper analyzed the application and potential risks of ChatGPT in the medical field，focusing on challenges such as data privacy protection，decision fairness，and legal adaptability. It also proposed regulatory strategies，including formulating a legal framework for intelligent medical decision-making，establishing ethical norms and guidelines，strengthening regulatory mechanisms and supervisory measures，enhancing the practical ability for intelligent decision-making，and other aspects，to promote the sustainable development of medical intelligent decision-making and ensure the balance of ethics，law，and social responsibility.,artificial intelligence | ChatGPT | legal regulation | medical decision-making | medical ethics,1,2025,sustainability,behavior+policy+sustainability
296,2-s2.0-105017624029,10.1080/09537287.2025.2561967,https://doi.org/10.1080/09537287.2025.2561967,https://scholar.google.com/scholar?q=10.1080/09537287.2025.2561967,ar,Production Planning and Control,"Maghroor, Hamid Reza;Madanchi, Faraz;O’Neal, Thomas",Leveraging Generative AI for sustainable supply chain: adoption challenges and strategic insights,"Generative AI (GAI) holds transformative potential for supply chain management (SCM) by improving efficiency, minimising inefficiencies, and advancing sustainability. Yet, its adoption remains hindered by complex barriers spanning technological, ethical, regulatory, and organisational domains. This study applies the Technology-Organisation-Environment-Human (TOEH) framework to classify these barriers and utilises the Decision-Making Trial and Evaluation Laboratory (DEMATEL) method to explore their interdependencies. Expert insights reveal that human-centric obstacles—such as workforce resistance and skill deficits—are primarily rooted in gaps in technological readiness, regulatory clarity, and organisational alignment. Ethical concerns, financial limitations, and conflicting strategic priorities further exacerbate these challenges. The findings underscore the need for a comprehensive strategy encompassing AI ethics, regulatory harmonisation, and structured management change. This study contributes actionable insights by promoting interdisciplinary collaboration, robust data governance, and enhanced explainability, enabling organisations to overcome resistance and unlock the full potential of GAI in fostering resilient, adaptive, and sustainable supply chains.",adoption barriers | DEMATEL | Generative artificial intelligence | Sustainable supply chain | TOEH framework,1,2025,sustainability,behavior+policy+sustainability
317,2-s2.0-105011096477,10.1007/s00146-025-02454-z,https://doi.org/10.1007/s00146-025-02454-z,https://scholar.google.com/scholar?q=10.1007/s00146-025-02454-z,ar,AI and Society,"Ocón, David;Yin, Chunzhi;Luna, Jose","Artificial insights or historical fidelity? Crafting an ethical framework for the use of GenAI in the restoration, reconstruction and recreation of movable cultural heritage","This article explores the ethical considerations surrounding using Generative Artificial Intelligence (GenAI) in preserving movable cultural heritage, focusing specifically on its application in restoration, reconstruction, and recreation. While GenAI offers innovative methods for preserving and recreating cultural heritage, it also presents significant ethical challenges. The article reviews current studies on the role of GenAI in heritage preservation alongside relevant ethical guidelines and proposes a tailored ethical framework for its application in movable heritage. The framework addresses several critical ethical concerns, including cultural integrity and sensitivity, accuracy and authenticity, intellectual property rights, sustainability and social impact, and governance and ethical accountability. The article adopts a systematic methodology, combining a comprehensive literature review, thematic analysis, and expert evaluation to develop practical guidelines that ensure GenAI enhances rather than compromises movable heritage’s cultural and historical value. This ethical framework advocates for the responsible use of GenAI, emphasising the importance of collaboration with cultural experts and relevant communities, ensuring transparency in the use of data, and promoting robust ethical governance in AI-driven heritage preservation projects. Ultimately, the framework aims to guide practitioners and institutions in using GenAI in ways that respect and uphold the integrity of cultural heritage while also utilising the benefits of this cutting-edge technology as a tool for better assistance of heritage preservation.",AI-driven heritage preservation | Cultural heritage | Cultural integrity and authenticity | GenAI ethical framework | Generative Artificial Intelligence (GenAI),1,2025,sustainability,behavior+policy+sustainability
9,2-s2.0-105025024156,10.1016/j.jretconser.2025.104696,https://doi.org/10.1016/j.jretconser.2025.104696,https://scholar.google.com/scholar?q=10.1016/j.jretconser.2025.104696,ar,Journal of Retailing and Consumer Services,"Wang, Han;Jiang, Songyu;Li, Xuming;Alipour, Osman;Agag, Gomaa","Can AI make us less green? Insights from four experiments on digital speed, time perception, and sustainable consumption","Digital technologies increasingly rely on artificial intelligence (AI) agents to guide consumer choices. Although AI agents are designed to facilitate efficiency, their perceived speed may subtly alter consumers' temporal experience during decision making. Across four controlled experiments conducted with 1462 Chinese consumers recruited through a national online research panel, we investigate how AI (vs. human) agents influence sustainable consumption. Interacting with an AI agent heightens state arousal and weakens future self-continuity, accelerating consumers' internal sense of time and shortening their perceived connection to future outcomes. Consequently, consumers become less willing to wait for environmentally friendly options when those options involve delayed benefits (e.g., eco-shipping or carbon offsets). When temporal extensions yield continued or cumulative rewards (e.g., long-term green plans), however, the same temporal distortion enhances patience and promotes sustainability. These effects are moderated by interface tempo and agent anthropomorphism, which temper arousal and restore temporal balance. Together, these findings demonstrate that perceptions of digital speed shape consumers’ temporal horizons and sustainable decision making, extending theories of intertemporal choice and human–AI interaction while identifying design strategies that can align algorithmic efficiency with environmental responsibility.",Arousal and future self-continuity | Artificial intelligence (AI) agents | Intertemporal choice | Sustainable consumption | Time perception,1,2026,sustainability,behavior+sustainability
13,2-s2.0-105016452496,10.1016/j.inffus.2025.103752,https://doi.org/10.1016/j.inffus.2025.103752,https://scholar.google.com/scholar?q=10.1016/j.inffus.2025.103752,ar,Information Fusion,"Jiang, Shan;Chai, Wenchang;Zhang, Mingjin;Cao, Jiannong;Xuan, Shichang;Shen, Jiaxing",Verifying energy generation via edge LLM for web3-based decentralized clean energy networks,"The global transition to clean energy is critical to achieving climate goals, yet traditional centralized systems face challenges in flexibility, grid resilience, and equitable access. While decentralized web3-based energy networks offer promising alternatives, existing solutions lack robust architectures to integrate distributed generation with real-time demand and fail to provide trustworthy energy verification mechanisms. This work introduces DeCEN, a decentralized clean energy network that synergizes collaborative edge computing and web3 technologies to address these gaps. DeCEN leverages autonomous edge devices to collect and process sensory data from renewable generators, enabling localized decision-making and verification of energy production. A layer-2 blockchain solution establishes a transparent web3 ecosystem, connecting clean energy generators and consumers through tokenized incentives for green energy activities. To combat fraud, DeCEN incorporates a novel large language model (LLM)-based energy verification protocol that analyzes sensory data to validate renewable claims, ensuring accountability and stabilizing token value. Additionally, a distributed LLM inference algorithm partitions LLMs into shards deployable on resource-constrained edge devices, enabling decentralized, low-latency processing while preserving data privacy and minimizing communication overhead. By integrating edge computing, blockchain, and AI-driven verification, DeCEN improves the reliability, trust, and efficiency of decentralized clean energy networks, offering a scalable pathway toward global renewable energy targets.",Decentralized energy networks | Edge LLM | Large language models | Web3,1,2026,sustainability,behavior+sustainability
36,2-s2.0-105022167486,10.1016/j.energy.2025.139328,https://doi.org/10.1016/j.energy.2025.139328,https://scholar.google.com/scholar?q=10.1016/j.energy.2025.139328,ar,Energy,"Li, Houpei;Fu, Xiao;Wang, Kai;Peng, Jinqing",An LLM-assisted decision-making framework of rule-based control strategy for photovoltaic driven air conditioning systems,"Photovoltaic driven air conditioning (PVAC) systems provide significant opportunities for sustainable building energy management, but optimizing their operational parameters remains challenging. Current control methods often lack flexibility in adapting to dynamic environmental conditions and occupancy requirements. This study introduces a novel optimization framework integrating a large language model (LLM) with a rule-based adaptive control strategy for PVAC systems. A comprehensive simulation model, coupling detailed building thermal dynamics and air conditioning behavior, is developed and experimentally validated. The LLM is requested to determine optimal operational parameters. The LLM is systematically evaluated across varying scenarios, including initial settings for temperature setpoints, comfort ranges, hysteresis bands, and communication intervals. Results indicated that the LLM consistently converged on optimal control configurations, notably temperature setpoints around 24–25 °C, comfort ranges of approximately 1–2 °C, and hysteresis bands of about 0.3–0.5 °C, achieving high thermal comfort satisfaction and substantial energy cost savings. Furthermore, the model demonstrated excellent repeatability and operational stability across diverse climatic conditions. This research confirms the viability of integrating LLM-assisted adaptive control into PVAC systems. The LLM provides a promising opportunity for enhanced building energy efficiency and occupant comfort in practical applications.",Artificial intelligence | Large language model | Photovoltaic driven air conditioner | Rule-based control | Simulation,1,2025,sustainability,behavior+sustainability
46,2-s2.0-105025149087,10.3168/jdsc.2025-0843,https://doi.org/10.3168/jdsc.2025-0843,https://scholar.google.com/scholar?q=10.3168/jdsc.2025-0843,re,Jds Communications,"Hostens, Miel;Franceschini, Sébastien;van Leerdam, Meike;Yang, Haiyu;Pokharel, Sabina;Liu, Enhong;Niu, Puchun;Zhang, Hanlu;Noor, Saba;Hermans, Kristof;Salamone, Matthieu;Sharma, Sumit",The future of big data and artificial intelligence on dairy farms: A proposed dairy data ecosystem,"The dairy sector should overcome challenges in productivity, sustainability, and data management by adopting intelligent, scalable, and privacy-preserving technological solutions. Adopting data and artificial intelligence (AI) technologies is essential to ensure efficient operations and informed decision making and to keep a competitive market advantage. This paper proposes an integrated, multimodal AI framework to support data-intensive dairy farm operations by leveraging big data principles and advancing them through AI technologies. The proposed architecture incorporates edge computing, autonomous AI agents, and federated learning to enable real-time, privacy-preserving analytics at the farm level and promote knowledge sharing and refinement through research farms and cloud collaboration. Farms collect heterogeneous data, which can be transformed into embeddings for both local inference and cloud analysis. These embeddings form the input of AI agents that support health monitoring, risk prediction, operational optimization, and decision making. Privacy is preserved by sharing only model weights or anonymized data externally. The edge layer handles time-sensitive tasks and communicates with a centralized enterprise cloud hosting global models and distributing updates. A research and development cloud linked to research farms ensures model testing and validation. The entire system is orchestrated by autonomous AI agents that manage data, choose models, and interact with stakeholders, and human oversight ensures safe decisions, as illustrated in the practical use case of mastitis management. This architecture could support data integrity, scalability, and real-time personalization, along with opening up space for partnerships between farms, research institutions, and regulatory bodies to promote secure, cross-sector innovation.",,1,2025,sustainability,behavior+sustainability
63,2-s2.0-105018578803,10.1016/j.enbuild.2025.116463,https://doi.org/10.1016/j.enbuild.2025.116463,https://scholar.google.com/scholar?q=10.1016/j.enbuild.2025.116463,ar,Energy and Buildings,"Papaioannou, Alexios;Dimara, Asimina;Krinidis, Stelios",GUIDE: A prescriptive hybrid AI framework for energy-efficient appliances usage through behavioral modeling and LLM guidance,"Improving energy efficiency in residential environments reduces electricity consumption and cost, eases stress on the electricity grid, and promotes sustainability. However, realizing these benefits at scale requires accurate understanding of how energy is consumed within households. The precise interpreting of household energy consumption and providing personalized advice is still proving to be a hurdle due to overlapping appliance usage patterns and diverse user behaviors. This paper introduces Generative Usage-based Insights for Device Efficiency (GUIDE), a hybrid AI framework that integrates advanced device detection, behavioral modeling, and personalized natural language generation using fine-tuned large language models (LLMs). The system first disaggregates appliance-level consumption data utilizing statistical and temporal features, and then profiles household routines to enhance device classification accuracy. These insights are transformed into user-specific energy-saving advices through a domain-adapted LLM trained on structured behavioral prompts and contextual usage summaries. By combining time-series analysis, machine learning, and scalable LLM fine-tuning techniques (LoRA/QLoRA), GUIDE delivers fluent, context-aware and personalized recommendations that adapt to each household’s evolving energy patterns. Experimental results on real-world datasets demonstrate that GUIDE achieves high accuracy in device classification and generates actionable, human-readable advice bridging the gap between signal-level analysis and personalized energy engagement.",Context-aware recommendations | Energy efficiency | Large language models (LLMs) | Personalized energy advice | Smart homes | User behavior modeling,1,2025,sustainability,behavior+sustainability
84,2-s2.0-105017005223,10.1016/j.knosys.2025.114405,https://doi.org/10.1016/j.knosys.2025.114405,https://scholar.google.com/scholar?q=10.1016/j.knosys.2025.114405,ar,Knowledge Based Systems,"Gjorgjevikj, Ana;Nikolikj, Ana;Koroušić Seljak, Barbara;Eftimov, Tome","User-defined trade-offs in LLM benchmarking: balancing accuracy, scale, and sustainability","This paper presents xLLMBench, a transparent, decision-centric benchmarking framework that empowers decision-makers to rank large language models (LLMs) based on their preferences across diverse, potentially conflicting performance and non-performance criteria, e.g., domain accuracy, model size, energy consumption, CO<inf>2</inf> emissions. Existing LLM benchmarking methods often rely on individual performance criteria (metrics) or human feedback, so methods systematically combining multiple criteria into a single interpretable ranking lack. Methods considering human preferences typically rely on direct human feedback to determine rankings, which can be resource-intensive and not fully aligned with application-specific requirements. Motivated by current limitations of LLM benchmarking, xLLMBench leverages multi-criteria decision-making methods to provide decision-makers with the flexibility to tailor benchmarking processes to their requirements. It focuses on the final step of the benchmarking process (robust analysis of benchmarking results) which in LLMs’ case often involves their ranking. The framework assumes that the selection of datasets, metrics, and LLMs involved in the experiment is conducted following established best practices. We demonstrate xLLMBench's usefulness in two scenarios: combining LLM results for one metric across different datasets and combining results for multiple metrics within one dataset. Our results show that while some LLMs maintain stable rankings, others exhibit significant changes when correlated datasets are removed, when the focus shifts to contamination-free datasets or fairness metrics. This highlights that LLMs have distinct strengths/weaknesses, going beyond overall performance. Our sensitivity analysis reveals robust rankings, while the diverse visualizations enhance transparency. xLLMBench can be used with existing platforms to support transparent, reproducible, and contextually-meaningful LLM benchmarking.",Benchmarking | Large language model | Machine learning | Multi-criteria decision-making | Natural language processing | Promethee method,1,2025,sustainability,behavior+sustainability
100,2-s2.0-105020813107,10.1016/j.jag.2025.104935,https://doi.org/10.1016/j.jag.2025.104935,https://scholar.google.com/scholar?q=10.1016/j.jag.2025.104935,re,International Journal of Applied Earth Observation and Geoinformation,"Xiao, Shuting;Gu, Hongji;Shen, Dingtao;Niu, Zhuang;Xiao, Jun;Yu, Fei","A systematic review of social Media-Enabled flood disaster Informatics: Method, technology and application","Under the dual pressures of climate change and rapid urbanization, the frequent occurrence of flood disasters has become a global challenge. The widespread use of social media provides new perspectives for broader and more comprehensive perception of flood disaster events, and a social media-enabled flood disaster informatics framework has gradually taken shape. This study systematically reviews 607 publications from 2004 to 2024, aiming to reveal the research progress of utilizing social media big data in flood disaster management. By constructing a “method–technology–application” full-chain flood disaster informatics framework, this study highlights the flood information processing workflow featuring social media data, covering multiple aspects including social media data analysis, flood event detection, flood situation awareness, flood risk mapping, and emergency management practices. The literature review indicates that social media has been proven effective in compensating for the limitations of traditional flood monitoring approaches. In particular, multimodal data fusion and the application of artificial intelligence techniques can significantly enhance global flood monitoring capabilities. However, current research still faces challenges such as verifying data authenticity and integrating information across platforms. Future research should focus on exploring the transformative applications of foundation models (e.g., large language models, vision foundation models, and multimodal large models) with social media, including massive multi-source heterogeneous information understanding, generative disaster reporting and decision support, as well as real-time prediction and emergency simulation incorporating physical mechanisms. These advances are expected to drive a profound transformation of the intelligent emergency decision-making paradigm and provide a solid theoretical and technical foundation for the development of smart flood emergency management systems.",Artificial intelligence | Big data | Emergency response | Flood disaster | Social media,1,2025,sustainability,behavior+sustainability
106,2-s2.0-105015138046,10.1016/j.ijpe.2025.109790,https://doi.org/10.1016/j.ijpe.2025.109790,https://scholar.google.com/scholar?q=10.1016/j.ijpe.2025.109790,ar,International Journal of Production Economics,"Jin, Zhuo;Zhou, Zhixiang;Wu, Huaqing",Enhancing digital manufacturing efficiency and dominance relation driven big Data analytics,"The integration of AI technologies based on large language models (AI-LLM) with big data analytics has revolutionized digital manufacturing and enabled real-time decision-making in operations and supply chain management (OSCM). However, traditional data envelopment analysis (DEA) models face prohibitive computational complexity in large-scale environments, hindering their adoption for such AI-LLM-driven optimization tasks as demand forecasting, inventory control, and energy efficiency enhancement. To bridge this gap, we propose a dominance–relation-driven DEA framework tailored for big data environments contexts in digital manufacturing. Our approach leverages spatial relationship characteristics and grouping algorithms to reduce computational complexity by 10–30 times, as validated through numerical simulations on industrial datasets. A case study on the Chaohu Lake watershed further demonstrates its practical value in LLM-enhanced environmental monitoring and sustainable supply chain design. This research presents a scalable solution for optimizing efficiency in digital manufacturing, addressing critical challenges in predictive analytics and resource allocation.",Data envelopment analysis (DEA) | Efficiency measurement | Supply chain optimization | Sustainable operations,1,2025,sustainability,behavior+sustainability
117,2-s2.0-105021576981,10.1016/j.jengtecman.2025.101924,https://doi.org/10.1016/j.jengtecman.2025.101924,https://scholar.google.com/scholar?q=10.1016/j.jengtecman.2025.101924,ar,Journal of Engineering and Technology Management Jet M,"Munir, Tanya","Leadership competency and Gen AI in two-sided platforms: Driving innovation, productivity, and responsible change in the entertainment industry","Purpose: The study examines how leadership competency fosters the integration of Generative AI within two-sided platform environments, specifically focusing on its impact on improving teamwork productivity. The study delves into the dynamic of integrating Gen AI within entertainment industry, focusing on the influence of socially responsible innovation and behavioral change required for successful adoption. Methodology: The study employed a quantitative survey-based approach using random sampling of employees from Pakistani entertainment agencies. Data were collected via online platforms over four months, securing 530 valid responses. Findings: All four hypothesis are supported, underscoring the study pivotal role of leadership competency in driving Gen AI adoption and enhancing teamwork productivity. The study findings highlight that platform-based interactions benefit from AI enabled leadership strategies and that socially responsible innovative practices, coupled with behavioral change act as critical enablers in two sided AI-enhanced ecosystems. Practical implications: Managers can use these results to design training programs, foster AI-driven collaboration, and implement socially responsible innovation practices, ensuring efficiency, reduced bias, and sustained competitiveness across diverse organizational settings. Social implications: By promoting ethical, transparent, and inclusive AI practices, organizations can enhance employee trust, encourage behavioral change, and create equitable opportunities for collaboration. These insights support broader societal goals of fairness, accountability, and sustainability in technology-enabled workplaces.",Behavioral change | Generative AI | Leadership competency | Quantitative methodology | Socially responsible innovation | Teamwork productivity,1,2025,sustainability,behavior+sustainability
133,2-s2.0-105009160202,10.1016/j.osn.2025.100812,https://doi.org/10.1016/j.osn.2025.100812,https://scholar.google.com/scholar?q=10.1016/j.osn.2025.100812,re,Optical Switching and Networking,"Cruzes, Sergio",Revolutionizing optical networks: The integration and impact of large language models,"The increasing complexity and scale of optical networks demand advanced automation frameworks capable of adapting to dynamic service requirements, physical-layer impairments, and multi-vendor environments. Traditional solutions—based on static rule sets or narrowly scoped machine learning models—struggle to manage real-time performance, heterogeneous data, and domain-specific variability. Large Language Models (LLMs), built on transformer architectures, offer a paradigm shift by enabling context-aware reasoning, multi-task generalization, and natural language interpretation. These models can automate configuration generation, fault diagnosis, alarm correlation, and routing and spectrum assignment (RSA), while enhancing Quality of Transmission (QoT) estimation and scenario modeling. This article provides a comprehensive survey of current automation approaches in optical networks, including software-defined networking (SDN), intent-based networking (IBN), machine learning (ML)-based orchestration, and cognitive control architectures. Special attention is given to emerging paradigms that integrate LLMs for intent interpretation, fault analysis, configuration generation, and reasoning. Building on these foundations, we propose a hybrid framework that integrates LLMs with Digital Twin (DT) technologies to enable closed-loop control, predictive optimization, and explainable, intent-driven decision-making. Telemetry streams feed both DT simulations and LLM-based reasoning agents, supporting proactive reconfiguration and fault mitigation. To address LLM limitations—such as hallucinations and inference latency —the framework incorporates prompt engineering, retrieval-augmented generation (RAG), domain-specific fine-tuning, and simulation-based validation. The proposed architecture paves the way for resilient, autonomous, and sustainable optical networks that can self-optimize and adapt in real time.",Digital twins | Large language models | Network automation | Optical networks,1,2025,sustainability,behavior+sustainability
140,2-s2.0-105017141833,10.3390/ai6090227,https://doi.org/10.3390/ai6090227,https://scholar.google.com/scholar?q=10.3390/ai6090227,re,AI Switzerland,"Roveta, Annalisa;Castello, Luigi Mario;Massarino, Costanza;Francese, Alessia;Ugo, Francesca;Maconi, Antonio","Artificial Intelligence in Medical Education: A Narrative Review on Implementation, Evaluation, and Methodological Challenges","Artificial Intelligence (AI) is rapidly transforming medical education by enabling adaptive tutoring, interactive simulation, diagnostic enhancement, and competency-based assessment. This narrative review explores how AI has influenced learning processes in undergraduate and postgraduate medical training, focusing on methodological rigor, educational impact, and implementation challenges. The literature reveals promising results: large language models can generate didactic content and foster academic writing; AI-driven simulations enhance decision-making, procedural skills, and interprofessional communication; and deep learning systems improve diagnostic accuracy in visually intensive tasks such as radiology and histology. Despite promising findings, the existing literature is methodologically heterogeneous. A minority of studies use controlled designs, while the majority focus on short-term effects or are confined to small, simulated cohorts. Critical limitations include algorithmic opacity, generalizability concerns, ethical risks (e.g., GDPR compliance, data bias), and infrastructural barriers, especially in low-resource contexts. Additionally, the unregulated use of AI may undermine critical thinking, foster cognitive outsourcing, and compromise pedagogical depth if not properly supervised. In conclusion, AI holds substantial potential to enhance medical education, but its integration requires methodological robustness, human oversight, and ethical safeguards. Future research should prioritize multicenter validation, longitudinal evaluation, and AI literacy for learners and educators to ensure responsible and sustainable adoption.",adult education | artificial intelligence in education | higher education | lifelong learning | machine learning | personalized learning | professional development,1,2025,sustainability,behavior+sustainability
152,2-s2.0-105009587522,10.1016/j.technovation.2025.103304,https://doi.org/10.1016/j.technovation.2025.103304,https://scholar.google.com/scholar?q=10.1016/j.technovation.2025.103304,ar,Technovation,"Mills, Stuart;Sætra, Henrik Skaug","Algorithms in the room: AI, representation, and decisions about sustainable futures","This article considers the role of generative AI technologies, such as large language models (LLMs), in promoting the views of underrepresented groups. We are specifically concerned with the role AI could play in encouraging powerful decision-makers—often leading politicians and businesspeople in Western nations—to consider the perspectives of underrepresented groups when making decisions about sustainable development. Some suggest generative AI could offer decision-makers perspectives they had previously not considered, leading to more equitable and innovative policy approaches, and supporting several of the United Nations' Sustainable Development Goals (SDGs). We critique this perspective. Groups may be underrepresented in sustainable development decision-making because of individual cognitive and organisational information-processing limitations (‘omitted, but not opposed’), and because of opposition which remains even if these limitations are overcome (‘opposed, whether omitted or not’). We outline how these ‘categories of omission’ shape the opportunities and risks created by generative AI in representative sustainability.",Decision-making | Generative AI | Representation | Sustainable development goals,1,2025,sustainability,behavior+sustainability
153,2-s2.0-105007719393,10.1016/j.neuri.2025.100213,https://doi.org/10.1016/j.neuri.2025.100213,https://scholar.google.com/scholar?q=10.1016/j.neuri.2025.100213,ar,Neuroscience Informatics,"Hidayatullah, Hafidz Ihsan;Saifullah, Muhammad Taufiq;Ghozali, Muhammad Thesa;Aziz, Ayesha","Exploring community pharmacist's psychological intentions to adopt generative artificial intelligence (GenAI) chatbots for patient information, education, and counseling","Generative AI (GenAI) chatbots, driven by advanced machine learning algorithms, are emerging as transformative tools for enhancing patient education, information dissemination, and counseling (EIC) in healthcare. This study investigated the psychological determinants of community pharmacists' intentions to adopt GenAI chatbots using the Extended Technology Acceptance Model (ETAM). A cross-sectional survey of 240 licensed community pharmacists across several Indonesian provinces assessed key constructs, including self-efficacy (SE), perceived usefulness (PU), perceived ease of use (PEU), attitude toward technology (ATT), trust (TT), and behavioral intention (BI). Structural equation modeling revealed that SE significantly influenced PU (β=0.37) and PEU (β=0.57), indicating that confidence in using technology positively affects perceived utility and usability. PU further predicted ATT (β=0.39) and BI (β=0.236), emphasizing the motivational role of perceived benefits. Trust emerged as a crucial mediator, channeling favorable attitudes into actionable behavioral intentions (indirect β=0.148). The model demonstrated strong fit indices (χ<sup>2</sup>=263.09, RMSEA = 0.019, GFI = 0.915, CFI = 0.991), supporting the psychological framework. These findings highlight the importance of fostering trust, improving perceived usability, and enhancing self-efficacy through targeted training to promote GenAI chatbot adoption. Future research should explore longitudinal behavioral changes and contextual influences to support sustainable AI integration in pharmacy practice.",Artificial intelligence | Communal pharmacy | Procreative AI | Social intention | Technology acceptance,1,2025,sustainability,behavior+sustainability
162,2-s2.0-105014379985,10.3390/educsci15080967,https://doi.org/10.3390/educsci15080967,https://scholar.google.com/scholar?q=10.3390/educsci15080967,ar,Education Sciences,"Barbieri, Giacomo;Zapata, Freddy;Roa De La Torre, Juan David","Transforming Learning Environments: Asset Management, Social Innovation and Design Thinking for Educational Facilities 5.0","Educational institutions are facing a crisis characterized by the need to address diverse learning styles and vocational aspirations, exacerbated by ongoing financial pressures. To navigate these challenges effectively, there is an urgent need to innovate educational practices and learning environments, ensuring they are adaptable and responsive to the evolving needs of students and the workforce. The adoption of the Industry 5.0 framework offers a promising solution, providing a holistic approach that emphasizes the integration of human creativity and advanced technologies to transform educational institutions into resilient, human-centric, and sustainable learning environments. In this context, this article presents a transdisciplinary methodology that integrates Asset Management (AM) with Social Innovation (SI) through Design Thinking (DT) to co-design Educational Facilities 5.0 with stakeholders. The application of the proposed approach in an AgroLab case study—a food and agricultural laboratory—demonstrates how the methodology enables the definition of an Educational Facility 5.0 and generates AM Design Knowledge to support informed decision-making in the subsequent design, implementation, and operation phases. Following DT principles—where knowledge emerges through iterative experimentation and insights from practical applications—this article also discusses the role of SI and DT in AM, the role of Large Language Models in convergent processes, and a vision for Educational Facilities 5.0.",asset management | co-design | decision making | design thinking | education | Industry 5.0 | large language model | social innovation | stakeholder engagement | transdisciplinarity,1,2025,sustainability,behavior+sustainability
172,2-s2.0-105011768996,10.1016/j.scs.2025.106674,https://doi.org/10.1016/j.scs.2025.106674,https://scholar.google.com/scholar?q=10.1016/j.scs.2025.106674,ar,Sustainable Cities and Society,"Xiao, Yang;Tang, Yiwen","Can ChatGPT-4o assess the perceptions of streetscape change? Evidence from Shanghai, China","Traditional urban planning approaches faced significant challenges in addressing complex problems, particularly in maintaining consistent evaluation standards over time. These limitations hindered effective, evidence-based decision-making for sustainable development. This study presented a real-world case demonstrating how artificial intelligence could help overcome these challenges through large-scale, intelligent assessment of streetscape change. We implemented an AI-driven framework that combined ChatGPT-4o's multimodal capabilities with deep learning techniques to evaluate streetscape transformations. This unsupervised, multi-feature integration method enabled a fully automated process—from training set generation to model generalization—offering a replicable approach for dynamic urban analysis. Findings revealed that the multimodal large language model assessed perceived changes in streetscapes holistically, prioritizing complex urban dynamics over superficial visual alterations. Empirical results showed that improvements in streetscape quality (70.6 %) outweighed deterioration (17.6 %) by a factor of four, with severe decline accounting for <1 %. Areas with average initial quality saw the most improvement (45.9 %), followed by high- and low-quality zones. This Shanghai case study demonstrated the practical integration of AI-based streetscape evaluation into urban planning workflows, providing planners and policymakers with reliable tools to support evidence-based strategies aligned with sustainable development goals.",Multimodal large language models | Real-world application | Streetscape assessment | Streetscape change,1,2025,sustainability,behavior+sustainability
174,2-s2.0-105009947569,10.1016/j.molp.2025.05.013,https://doi.org/10.1016/j.molp.2025.05.013,https://scholar.google.com/scholar?q=10.1016/j.molp.2025.05.013,ar,Molecular Plant,"Yang, Fan;Kong, Huanjun;Ying, Jie;Chen, Zihong;Luo, Tao;Jiang, Wanli;Yuan, Zhonghang;Wang, Zhefan;Ma, Zhaona;Wang, Shikuan;Ma, Wanfeng;Wang, Xiaoyi;Li, Xiaoying;Hu, Zhengyin;Ma, Xiaodong;Liu, Minguo;Wang, Xiqing;Chen, Fan;Dong, Nanqing",SeedLLM·Rice: A large language model integrated with rice biological knowledge graph,"Rice biology research involves complex decision-making, requiring researchers to navigate a rapidly expanding body of knowledge encompassing extensive literature and multiomics data. The exponential increase in biological data and scientific publications presents significant challenges for efficiently extracting meaningful insights. Although large language models (LLMs) show promise for knowledge retrieval, their application to rice-specific research has been limited by the absence of specialized models and the challenge of synthesizing multimodal data integral to the field. Moreover, the lack of standardized evaluation frameworks for domain-specific tasks impedes the effective assessment of model performance. To address these challenges, we introduce SeedLLM·Rice (SeedLLM), a 7-billion-parameter model trained on 1.4 million rice-related publications, representing nearly 98.24% of global rice research output. Additionally, we present a novel human-centric evaluation framework designed to assess LLM performance in rice biology tasks. Initial evaluations demonstrate that SeedLLM outperforms general-purpose models, including OpenAI GPT-4o1 and DeepSeek-R1, achieving win rates of 57% to 88% on rice-specific tasks. Furthermore, SeedLLM is integrated with the Rice Biological Knowledge Graph (RBKG), which consolidates genome annotations for Nipponbare and large-scale synthesis of transcriptomic and proteomic information from over 1800 studies. This integration enhances the ability of SeedLLM to address complex research questions requiring the fusion of textual and multiomics data. To facilitate global collaboration, we provide free access to SeedLLM and the RBKG via an interactive web portal (https://seedllm.org.cn/). SeedLLM represents a transformative tool for rice biology research, enabling unprecedented discoveries in crop improvement and climate adaptation through advanced reasoning and comprehensive data integration.",DeepSeek | GPT | knowledge graph | large language model | LLM | multiomics data integration,1,2025,sustainability,behavior+sustainability
200,2-s2.0-85171558740,10.1177/20438869231200283,https://doi.org/10.1177/20438869231200283,https://scholar.google.com/scholar?q=10.1177/20438869231200283,ar,Journal of Information Technology Teaching Cases,"Mukhopadhyay, Mayukh",Be my AI—micro-volunteering in the time of ChatGPT,"Purpose: This case study explores the evolution of Be My Eyes, a micro-volunteering platform connecting blind and visually impaired individuals with sighted volunteers. The case analyzes the challenges faced by the founder, Hans Jørgen Wiberg, in balancing the company's social mission with its financial sustainability. It also examines the impact of technological advancements, specifically generative artificial intelligence, on the platform's business model. Pedagogical Objective: The case study aims to provide insights into the challenges of balancing social impact and financial sustainability in a social enterprise context. It also explores the potential of technological advancements in shaping business models and discusses the ethical implications of integrating technology into social enterprises. Case Positioning and Setting: This case study is suitable for undergraduate and graduate courses in entrepreneurship, social enterprise, and innovation management. It can also be used in courses on technology and society or business ethics. The case is set in Denmark, where Be My Eyes was founded, and covers the period from the platform's inception till the present day.",generative artificial intelligence | micro-volunteering | Social enterprise | social impact,1,2025,sustainability,behavior+sustainability
234,2-s2.0-85219507655,10.3837/tiis.2025.02.005,https://doi.org/10.3837/tiis.2025.02.005,https://scholar.google.com/scholar?q=10.3837/tiis.2025.02.005,ar,Ksii Transactions on Internet and Information Systems,"Ghadi, Yazeed Yasin;Albogamy, Fahad R.;Alamri, Saeed;Mehboob, Bilal;Usman, Sardar;Hasnain, Muhammad",ChatGPT-Assisted Energy Efficiency Enhancement for Blockchain Network Sustainability,"The role of the ChatGPT application has been studied in a number of research works. However, the synergistic association of ChatGPT with Blockchain technology has rarely been discussed. Blockchain technology-based networks face the major challenges of high energy consumption associated with transaction processing. This paper proposes a novel Energy-Efficient Transaction Prioritization (EETP) approach based on the Artificial Intelligence (AI) application (ChatGPT) to reduce energy consumption in blockchain networks. The ChatGPT application (Ver. 3.5) serves to receive prompts for simulated scenarios (A-E) and generate results accordingly. This paper presents a simulation setup to verify the hypothetical results of this study. Simulation results reveal remarkable improvement in average latency, energy consumption per transaction and carbon footprint metrics. The findings of this study underscore the critical imperative of minimizing energy consumption using the proposed EETP approach. The results of the implementation of the EETP approach showed a significant improvement in blockchain energy efficiency. These enhancements include reducing the transaction latency by 60%, increasing the energy-efficient transaction by 20% and eliminating carbon footprint by 20%. These results are reinforced by dynamic incentives and prioritization, aligning with the findings of the existing literature. They emphasize the user adoption and sustainability of blockchain networks through efficient energy consumption. In the future, we could optimize the approach for better results.",Blockchain technology | ChatGPT | Energy consumption | Overhead issue,1,2025,sustainability,behavior+sustainability
239,2-s2.0-85218858098,10.1371/journal.pone.0317488,https://doi.org/10.1371/journal.pone.0317488,https://scholar.google.com/scholar?q=10.1371/journal.pone.0317488,ar,Plos One,"Yu, Shuhui;Guan, Xin;Peng, Xiaoyan;Zeng, Yanzhao;Wang, Zeyu;Liang, Xinyi;Qin, Tianqiao;Zhou, Xiang",Enhancing the decision optimization of interaction design in sustainable healthcare with improved artificial bee colony algorithm and generative artificial intelligence,"With the development of digital health, enhancing decision-making effectiveness has become a critical task. This study proposes an improved Artificial Bee Colony (ABC) algorithm aimed at optimizing decision-making models in the field of digital health. The algorithm draws inspiration from the dual-layer evolutionary space of cultural algorithms, combining normative knowledge from the credibility space to dynamically adjust the search range, thereby improving both convergence speed and exploration capabilities. Additionally, a population dispersion strategy is introduced to maintain diversity, effectively balancing global exploration with local exploitation. Experimental results show that the improved ABC algorithm exhibits a 96% convergence probability when approaching the global optimal solution, significantly enhancing the efficiency and accuracy of medical resource optimization, particularly in complex decision-making environments. Integrating this algorithm with the Chat Generative Pre-trained Transformer (ChatGPT) decision system can intelligently generate personalized decision recommendations and leverage natural language processing technologies to better understand and respond to user needs. This study provides an effective tool for scientific decision-making in digital healthcare and offers critical technical support for processing and analyzing large-scale medical data.",,1,2025,sustainability,behavior+sustainability
264,2-s2.0-105025436052,10.7717/peerj-cs.3042,https://doi.org/10.7717/peerj-cs.3042,https://scholar.google.com/scholar?q=10.7717/peerj-cs.3042,ar,Peerj Computer Science,"Chen, Yi Fan;Chan, Weng Howe;Su, Eileen Lee Ming;Diao, Qi","Multi-objective optimization for smart cities: a systematic review of algorithms, challenges, and future directions","With the growing complexity and interdependence of urban systems, multi-objective optimization (MOO) has become a critical tool for smart-city planning, sustainability, and real-time decision-making. This article presents a systematic literature review (SLR) of 117 peer-reviewed studies published between 2015 and 2025, assessing the evolution, classification, and performance of MOO techniques in smart-city contexts. Existing algorithms are organised into four families-bioinspired, mathematical theory-driven, physics-inspired, and machine-learningenhanced- and benchmarked for computational efficiency, scalability, and scenario suitability across six urban domains: infrastructure, energy, transportation, Internet of Things (IoT)/cloud systems, agriculture, and water management. While established methods such as Non-dominated Sorting Genetic Algorithm II (NSGA-II) and Multiobjective Evolutionary Algorithm based on Decomposition (MOED/D) remain prevalent, hybrid frameworks that couple deep learning with evolutionary search display superior adaptability in high-dimensional, dynamic environments. Persistent challenges include limited cross-domain generalisability, inadequate uncertainty handling, and low interpretability of artificial intelligence (AI)-assisted models. Twelve research gaps are synthesised-from privacy-preserving optimisation and sustainable trade-off resolution to integration with digital twins, large language models, and neuromorphic computing-and a roadmap towards scalable, interpretable, and resilient optimisation frameworks is outlined. Finally, a ready-to-use benchmarking toolkit and a deployment-oriented algorithm-selection matrix are provided to guide researchers, engineers, and policy-makers in real-world smart-city applications. This review targets interdisciplinary researchers, optimisation developers, and smart-city practitioners seeking to apply or advance MOO techniques in complex urban systems.",Algorithms and Analysis of Algorithms | Artificial Intelligence | Bio-inspired algorithms | Computational efficiency | Cross-domain urban planning | Data Mining and Machine Learning | Internet of Things | Machine learning-enhanced optimization | Multi-objective optimization | Optimization Theory and Computation | Smart cities | Sustainability trade-offs | Sustainable urban development | Systematic literature review | Urban optimization,1,2025,sustainability,behavior+sustainability
323,2-s2.0-105009008297,10.1080/13683500.2025.2522939,https://doi.org/10.1080/13683500.2025.2522939,https://scholar.google.com/scholar?q=10.1080/13683500.2025.2522939,ar,Current Issues in Tourism,"Mellors, Joseph",ChatGPT and the tourist trail: pathway to overtourism or sustainable travel?,"This research letter presents a microstudy investigating how ChatGPT’s travel recommendations may influence tourism flows. Drawing on a qualitative content analysis of 50 structured conversations, the analysis examines whether the model reinforces dominant travel patterns or brings visibility to lesser-known, sustainable, or community-based destinations. It identifies a strong tendency to prioritise iconic landmarks and high-density tourist hubs, with alternative destinations appearing less frequently and typically only when explicitly prompted. While the study does not assess real-world user behaviour, it offers early insight into how AI-generated suggestions may mirror and perpetuate established tourism imaginaries. These patterns prompt reflection on the role of conversational AI in shaping travel interest and attention. The study highlights opportunities for more intentional platform design that supports sustainability goals and more balanced tourism flows.",Artificial intelligence | ChatGPT | overtourism | sustainable tourism | tourism flows,1,2025,sustainability,behavior+sustainability
357,2-s2.0-85206321001,10.3390/su16198446,https://doi.org/10.3390/su16198446,https://scholar.google.com/scholar?q=10.3390/su16198446,ar,Sustainability Switzerland,"Kodors, Sergejs;Lonska, Jelena;Zarembo, Imants;Zvaigzne, Anda;Apeinans, Ilmars;Deksne, Juta",Knowledge-Based Recommendation System for Plate Waste Reduction in Latvian Schools,"Food waste indicates ineffective and irresponsible consumption of resources, particularly during the food consumption stage. The aim of our research study is to optimize the catering management process at Latvian schools by reducing the amount of plate waste. The experts developed a set of recommendations aimed at improving the catering management process at schools. The recommendations developed were supported by measurable parameters, which must be monitored by school staff. The capability-driven development approach was applied to model the recommendation system. A plate waste predictive module and a large language model classifier were integrated into the system to support sustainable decision-making. The large language model classifier was trained to filter questions and recommendations. Three training methods were compared: training from scratch and finetuning by using datasets DBPedia and News Category Dataset. As a result, we present the list of recommendations based on the literature review, and the prototype of the knowledge-based recommendation system was developed to audit the school catering management process and promote sustainable school management and decision-making. The recommendation system aims to reduce plate waste due to deficiencies in the implementation of the catering process and to promote responsible food consumption at schools.",expert system | food waste | large language model | recommendation system | smart school | sustainability,1,2024,sustainability,behavior+sustainability
366,2-s2.0-85198511248,10.1016/j.futures.2024.103428,https://doi.org/10.1016/j.futures.2024.103428,https://scholar.google.com/scholar?q=10.1016/j.futures.2024.103428,ar,Futures,"Lindell, Rikard",The dialectics of digitalisation: A critique of the modernistic imperative for the development of digital technology,"This text discusses today's digital transformation through the lens of Horkheimer and Adornos’ study of the enlightenment. Policy and public discourse around digitalisation embrace and adhere to the narrow tenets enlightenment thinking; the idea that rationality, individual freedom, and a society free from superstition are necessary and attainable goals. The costs of what has come to be called ‘Modernity’ are many. Through the application of rationality to all spheres of life, married with disruptive technological advancement, humanity has diminished its’ imagination – its ability to seek new directions. To paraphrase Horkheimer and Adorno, Modernism fights against nature, of which we are a part, and thus, paradoxically, sets us in a fight against ourselves. Environmental degradation, the price of progress, being just one example of this – deadening work, consumerism and severed social connections being amongst others. In this framing, digitalisation itself comes to be understood itself as akin to a force of nature – one that we can do little about, other than adjust and adapt or be swept away. But this by no means a foregone conclusion, there is light at the end of the optical fibre. Albeit that recent technical developments around artificial intelligence appears to be pushing policy makers into hasty decisions, the pace of the technical development is not as fast as we believe, and in comparison with the Reformation – we have time. If we can restrain ourselves from the resist, adapt or die responses promoted in popular discourse in face of the shock of large language models and rising threat of automation, then we create room to consider economic, social, and ecological alignment and accord, in the decision making and design of future interactive artefacts and digital services. The article argues that through postdigital aesthetics, technology makers can embrace materiality and the inherent qualities of digital technology to formulate a critique of existing trajectories in digital transformation, with consequences for a more sustainable future.",Dialectics | Digital transformation | Digitalisation | Postdigital,1,2024,sustainability,behavior+sustainability
389,2-s2.0-85208943389,10.35784/acs-2024-31,https://doi.org/10.35784/acs-2024-31,https://scholar.google.com/scholar?q=10.35784/acs-2024-31,ar,Applied Computer Science,"Batubara, Muhammad Hasyimsyah;Nasution, Awal Kurnia Putra;Nurmalina, ;Rizha, Fachrur",CHATGPT IN COMMUNICATION: A SYSTEMATIC LITERATURE REVIEW,"This systematic literature review examines the role of ChatGPT in communication. ChatGPT's ability to imitate human-like interactions has broad implications in various sectors, such as education, healthcare, and customer service in the digital-based economy. The authors used a systematic and structured manuscript selection method in this research to collect and analyze literature on the use of ChatGPT in a communication context. A systematic literature review (SLR) method was used, involving an extensive search through the Scopus and Google Scholar databases with the keywords ""ChatGPT"" and ""communication."" Manuscript selection required strict inclusion and exclusion criteria. Of the 623 articles found, 30 were selected for further review. The research results show that using ChatGPT in communication has had both positive and negative impacts. Positive impacts involve increasing the efficiency and effectiveness of communications, especially in education, marketing, ethics, and health. However, challenges such as ethical considerations, the risk of plagiarism, and a limited understanding of context and emotional interactions were also identified. The use of ChatGPT in education, health, and various other fields has demonstrated great potential to improve communication processes, decision-making, and work efficiency. However, to ensure responsible and sustainable use, we must address specific ethical challenges and risks. This study provides a comprehensive overview of recent developments in using ChatGPT in communications, while also highlighting the practical and ethical implications that must be considered. With careful consideration of the advantages and limitations, ChatGPT in communications can significantly contribute to various fields.",a systematic literature review | ChatGPT | communication | efficiency | healthcare,1,2024,sustainability,behavior+sustainability
392,2-s2.0-85205447086,10.6224/JN.202410_71(5).05,https://doi.org/10.6224/JN.202410_71(5).05,https://scholar.google.com/scholar?q=10.6224/JN.202410_71(5).05,ar,Journal of Nursing,"Liu, Jen Wei",A Guide to Network Meta-Analysis Using Generative AI and No-Code Tools,"Network meta-analysis (NMA), an increasingly appealing method of statistical analysis, is superior to traditional analysis methods in terms of being able to compare multiple medical treatment methods in one analysis run. In recent years, the prevalence of NMA in the medical literature has increased significantly, while advances in NMA-related statistical methods and software tools continue to improve the effectiveness of this approach. Various commercial and free statistical software packages, some of which employ generative artificial intelligence (GAI) to generate code, have been developed for NMA, leading to numerous innovative developments. In this paper, the use of generative AI for writing R programming language scripts and the netmeta package for performing NMA are introduced. Also, the web-based tool ShinyNMA is introduced. ShinyNMA allows users to conduct NMA using an intuitive “clickable” interface accessible via a standard web browser, with visual charts employed to present results. In the first section, we detail the netmeta package documentation and use ChatGPT (chat generative pre-trained transformer) to write the R scripts necessary to perform NMA with the netmeta package. In the second section, a user interface is developed using the Shiny package to create a ShinyNMA tool. This tool provides a no-code option for users unfamiliar with programming to conduct NMA statistical analysis and plotting. With appropriate prompts, ChatGPT can produce R scripts capable of performing NMA. Using this approach, an NMA analysis tool is developed that meets the research objectives, and potential applications are demonstrated using sample data. Using generative AI and existing statistical packages or no-code tools is expected to make conducting NMA analysis significantly easier for researchers. Moreover, greater access to results generated by NMA analyses will enable decision-makers to review analysis results intuitively in realtime, enhancing the importance of statistical analysis in medical decision-making. Furthermore, enabling non-specialists to conduct clinically meaningful systematic reviews may be expected to sustainably improve analytical capabilities and produce higher-quality evidence.",ChatGPT | generative artificial intelligence | network meta-analysis,1,2024,sustainability,behavior+sustainability
27,2-s2.0-105020811275,10.1016/j.jdent.2025.106187,https://doi.org/10.1016/j.jdent.2025.106187,https://scholar.google.com/scholar?q=10.1016/j.jdent.2025.106187,ar,Journal of Dentistry,"Rokhshad, Rata;Tichy, Antonin;Ducret, Maxime;Chaurasia, Akhilanand;Uribe, Sergio E.;Gambelin, Olivia;Schwendicke, Falk",The ethics and governance of large language models in dentistry: A framework for research and clinical implementation,"Objective: As large language models (LLMs) are increasingly utilized in dentistry, they introduce various ethical challenges, including patient privacy, data security, and liability concerns. This study aims to establish a framework for their ethical evaluation, facilitating responsible development and research of LLMs and their implementation in dental practice. Methods: Based on a review of existing ethical guidance on LLMs, including World Health Organization (WHO) resources and publications on ethics in healthcare, an expert panel developed a checklist containing nine relevant topics. The Global Initiative on AI for Health engaged 105 participants in an anonymous online consensus process (e-Delphi), rating the importance of each item on a 10-point Likert scale. Results: The topics included: 1) Data Protection and Privacy, 2) Data Provenance and Copyright, 3) Gender Bias, Diversity and Discrimination, 4) Fairness and Equity, 5) Transparency, 6) Explainability, 7) Autonomy, Responsibility and Consent, 8) Prudence and Sustainable Development, and 9) Generative Empathy. Over 70% of participants rated all items between 7–10, highlighting their importance. Data Provenance and Copyright received the highest rating (10 points) from 57 participants, followed by Transparency and Gender Bias, Diversity and Discrimination (with the highest rating from 52 participants each). Generative Empathy showed divergent opinions, with 38 ratings below 7 and 31 scoring it a 10. Conclusion: The e-Delphi study achieved consensus across all nine topics, which were included in the proposed ethical framework for LLMs in dentistry. Strong agreement on most items demonstrated the framework's theoretical soundness, while greater variability in Generative Empathy responses indicated this principle requires further considerations. Clinical Significance: This framework provides systematic guidance for responsible LLM implementation in dentistry, addressing critical concerns such as data privacy, intellectual property, bias, and transparency. The framework offers specific strategies for AI developers and researchers during development phases, while providing governance guidelines for practitioners, administrators, and regulators during clinical implementation.",Artificial intelligence | Bioethics | Deep learning | Dentistry | Large language model,1,2026,sustainability,policy+sustainability
29,2-s2.0-105020054081,10.1016/j.diii.2025.10.002,https://doi.org/10.1016/j.diii.2025.10.002,https://scholar.google.com/scholar?q=10.1016/j.diii.2025.10.002,re,Diagnostic and Interventional Imaging,"Tzanis, Eleftherios;Adams, Lisa C.;Akinci D'Antonoli, Tugba;Bressem, Keno K.;Cuocolo, Renato;Kocak, Burak;Malamateniou, Christina;Klontzas, Michail E.","Agentic systems in radiology: Principles, opportunities, privacy risks, regulation, and sustainability concerns","The rapid rise of transformer-based large language models (LLMs) has introduced new opportunities for automation and decision support in radiology, particularly in applications such as report generation, protocol optimization, and structured interpretation. Despite their impressive performance in producing contextually coherent text, conventional LLMs remain limited by their inability to interact autonomously with external systems, retrieve data, or execute code, restricting their role in real-world clinical and research workflows. To address these limitations, agentic systems have emerged as a new paradigm. By embedding LLMs within frameworks that enable reasoning, planning, and action, agentic systems extend LLM capabilities to dynamic interaction with users, tools, and data sources. This review provides a comprehensive overview of the foundations, architectures, and operational mechanisms of agentic systems, focusing on their applications in medical imaging and radiology. It summarizes key developments in the literature, including recent multi-agent frameworks for automated radiomics pipelines, and discusses the potential benefits of these systems in enhancing the reproducibility, interpretability, and accessibility of AI-driven workflows. The review critically examines current regulatory considerations, ethical implications, and sustainability challenges to highlight essential gaps that must be addressed for the safe and responsible clinical integration of these systems.",Agent | Agentic systems | Artificial intelligence | Large language models | Prompting | Radiology,1,2026,sustainability,policy+sustainability
65,2-s2.0-105017791832,10.1038/s41598-025-17937-8,https://doi.org/10.1038/s41598-025-17937-8,https://scholar.google.com/scholar?q=10.1038/s41598-025-17937-8,ar,Scientific Reports,"Mishra, Vinaytosh;Saxena, Deepika;Gupta, Kishu;Patni, Sakshi;Singh, Ashutosh Kumar",Sustainability in large language model supply chains-insights and recommendations using analysis of utility for affecting factors,"The increasing adoption of Large Language Models (LLMs) has intensified concerns regarding the sustainability of their supply chains, particularly concerning energy consumption, resource utilization, and carbon emissions. To address these concerns, this study proposes a two-step approach. First, a Delphi method is employed to systematically identify the critical factors affecting the sustainability of LLM supply chains. Expert consensus through four rounds of feedback highlights key factors such as Environmental Impact, Computational Efficiency & Resource Optimization, Data Quality & Ethical Considerations, and Social Responsibility & Governance. In the second step, the identified factor’s relative importance was calculated using Conjoint Analysis, a statistical technique used to determine how respondents value different factors of a supply chain of LLMs. This prioritization helps formulate strategies to make LLM’s supply chain sustainable. The low score for environmental impact suggests a lack of awareness about the sustainability of LLMs’ supply chain. The study finds Data Quality and Ethical considerations to be the most important considerations for the respondents. Thus, it provides a framework for implementing sustainable practices in LLMs’ supply chains in resource-constrained settings. The results demonstrate the effectiveness of this combined Delphi-Conjoint Analysis approach, providing actionable insights for AI organizations aiming to enhance the sustainability of their LLM operations.",Conjoint Analysis | LLMs | Supply Chain | Sustainability,1,2025,sustainability,policy+sustainability
71,2-s2.0-105012264547,10.1007/s44163-025-00379-6,https://doi.org/10.1007/s44163-025-00379-6,https://scholar.google.com/scholar?q=10.1007/s44163-025-00379-6,re,Discover Artificial Intelligence,"Pasetti, Marcelo;Santos, James William;Corrêa, Nicholas Kluge;de Oliveira, Nythamar;Barbosa, Camila Palhares","Technical, legal, and ethical challenges of generative artificial intelligence: an analysis of the governance of training data and copyrights","This article examines the legal, technical, and ethical challenges of generative AI, focusing on the governance of training data and copyright compliance. It addresses the growing tension between AI development and the rights of content creators, particularly regarding the unauthorized use of copyrighted material for model training. By analyzing regulatory frameworks in the United States, European Union, Japan, and Brazil, the study highlights how existing mechanisms–such as fair use, text and data mining (TDM) exceptions, and hybrid models–remain inadequate to resolve the opacity and legal uncertainty surrounding AI training datasets. Drawing on insights from Henderson, Yu, Narayanan, and Kapoor, the paper demonstrates that the absence of transparency not only compromises legal accountability but also exacerbates epistemic risks and distributive asymmetries. Adopting a comparative legal-philosophical methodology, the study proposes governance solutions centered on mandatory transparency obligations, ethical compensation schemes for rights holders, and robust audit mechanisms. These recommendations aim to balance innovation incentives with fairness, sustainability, and the protection of intellectual property in the AI-driven economy.",Copyright | Data governance | Ethics | Fair use | Generative artificial intelligence,1,2025,sustainability,policy+sustainability
96,2-s2.0-105021507541,10.3390/su17219914,https://doi.org/10.3390/su17219914,https://scholar.google.com/scholar?q=10.3390/su17219914,ar,Sustainability Switzerland,"Al Naqbi, Humaid;Bahroun, Zied;Ahmed, Vian",Generative AI Integration: Key Drivers and Factors Enhancing Productivity of Engineering Faculty and Students for Sustainable Education,"Generative Artificial Intelligence (GAI) technologies are revolutionizing productivity and creativity across educational and engineering contexts. This study addresses a critical gap by examining the key factors influencing the successful integration of GAI tools to enhance faculty and student productivity, with a focus on higher education and its role in advancing sustainable development. Specifically, it investigates challenges, opportunities, and essential conditions for effective GAI adoption that support not only academic excellence but also the preparation of engineers capable of addressing global sustainability challenges in line with the United Nations Sustainable Development Goals (SDGs), particularly SDG 4 (Quality Education), SDG 9 (Industry, Innovation, and Infrastructure), and SDG 12 (Responsible Consumption and Production). A preliminary literature review identified significant factors requiring attention, further refined through interviews with 14 students and 13 faculty members, and expanded upon via a survey involving 54 students and 42 faculty members. Participants rated the significance of various factors on a five-point Likert scale, allowing for the calculation of the Relative Importance Index (RII). The findings reveal that while compliance with ethical standards and bias mitigation emerged as the most significant concerns, mid-level considerations such as institutional support, training, and explainability are critical for fostering GAI adoption in sustainable learning environments. Foundational elements, including robust technical infrastructure, data security, and scalability, are vital for long-term success and alignment with responsible and sustainable innovation. Notably, this study highlights a divergence in perspectives between faculty and students regarding GAI’s impact on productivity, with faculty emphasizing ethical considerations and students focusing on efficiency gains. This study offers a comprehensive set of considerations and insights for guiding GAI integration in educational and engineering settings. It emphasizes the need for multidisciplinary collaboration, continuous training, and strong governance to balance innovation, responsibility, and sustainability. The findings advance theoretical understanding and provide practical insights for academia, policymakers, and technology developers aiming to harness GAI’s full potential in fostering sustainable engineering education and development.",educational technology | engineering education | Ethical AI | Generative Artificial Intelligence (GAI) | higher education | productivity | student and faculty perspectives | Sustainable Development Goals (SDGs) | sustainable engineering education,1,2025,sustainability,policy+sustainability
108,2-s2.0-105012947072,10.1016/j.idnow.2025.105131,https://doi.org/10.1016/j.idnow.2025.105131,https://scholar.google.com/scholar?q=10.1016/j.idnow.2025.105131,re,Infectious Diseases Now,"Abbara, S.;Crabol, Y.;de Bouillé, J. Goupil;Dinh, A.;Morquin, D.",Artificial intelligence and infectious diseases: Scope and perspectives,"Artificial intelligence (AI) is set to permeate every facet of infectious disease practice—from prevention and public health surveillance to epidemic management and bedside care. Routine care data (laboratory results, medication orders, progress notes) and research-generated datasets now fuel state-of-the-art machine-learning (ML) pipelines that sharpen diagnosis, prognosis, antimicrobial stewardship, and, by combining both sources, accelerate drug discovery. In diagnostics, deep networks that now flag pneumonia or tuberculosis on chest images are increasingly able to identify—and localize—virtually more infectious processes throughout the body, while simultaneously predicting pathogen identity and antimicrobial resistance from routine microbiology. Prognostic models trained on Electronic Health Records surpass traditional scores in anticipating clinical deterioration or postoperative sepsis, enabling earlier targeted interventions. Predictive analytics can also personalize antimicrobial dosing by fusing real-time drug-monitoring data. Large language models (LLMs) build upon these advances by transforming unstructured clinical narratives into structured phenotypes suitable for predictive modeling, automatically summarizing patient encounters, generating synthetic cohorts for rare conditions, and providing real-time conversational decision support at the patient's bedside. Despite rapid progress, real-world deployment faces hurdles: high computational and licensing costs, vendor-specific implementation constraints, limited cross-site model transferability, and fragmented governance of safety, bias, and cybersecurity risks. Rigorous, lifecycle-based evaluation frameworks—covering external validation, cost-effectiveness analysis, and post-deployment monitoring—are required to ensure safe, equitable, and sustainable AI adoption. This review synthesizes current applications, evidential strengths, and unresolved challenges, and proposes a translational roadmap aligning technical innovation with clinical and regulatory realities.",Artificial intelligence | Clinical decision support | Generative artificial intelligence | Infectious diseases | Machine learning,1,2025,sustainability,policy+sustainability
127,2-s2.0-105018926065,10.3390/su17198661,https://doi.org/10.3390/su17198661,https://scholar.google.com/scholar?q=10.3390/su17198661,ar,Sustainability Switzerland,"Shen, Tengfei;Badulescu, Alina",Generative AI and Sustainable Performance in Manufacturing Firms: Roles of Innovations and AI Regulation,"This study scrutinizes the effects of generative artificial intelligence (GenAI) on sustainable performance (SP) in Chinese manufacturing firms through the mediating role of novelty-centered and efficiency-centered business model innovations (BMIs). It also explores the moderating effect of AI regulation on the GenAI–BMIs and GenAI–SP relationships. Data were collected from 1192 middle-level managers across 500 Chinese manufacturing firms using a two-wave survey design. Partial least squares structural equation modeling (PLS-SEM) was employed to test direct, mediating, and moderating relationships. The findings show that GenAI adoption has a significant positive effect on novelty-centered BMI, efficiency-centered BMI and sustainability performance. The GenAI–SP relationship is mediated by both BMIs, indicating that GenAI contributes to sustainability both directly and through innovative business practices. Moreover, AI regulation significantly strengthens the effects of GenAI on both BMI and SP, emphasizing the importance of regulatory alignment in maximizing technological benefits. This research shows that firms should emphasis AI tools and strategies to innovate their business model for better sustainable outcomes. Firms need to follow regulations and rules embedded into digitalization to ensure a sustainable competitive position in the market.",AI regulation | business model innovations | China | GenAI | manufacturing firms | sustainable performance,1,2025,sustainability,policy+sustainability
131,2-s2.0-105014640433,10.1111/jcal.70109,https://doi.org/10.1111/jcal.70109,https://scholar.google.com/scholar?q=10.1111/jcal.70109,re,Journal of Computer Assisted Learning,"Kangwa, Daniel;Msafiri, Mgambi Msambwa;Fute, Antony",Exploring the Factors That Promote a Balance Between Academic Integrity and the Effective Use of GenAI Tools in Higher Education: A Systematic Review,"Background: This study explored the factors that influence the balance between academic integrity and the effective use of GenAI tools in higher education. It focused on the role of institutional guidelines in enhancing the responsible use of GenAI technologies to enhance academic integrity. Objectives: The study was theoretically grounded in the Technology Acceptance Model and the Theory of Planned Behaviour to investigate the factors that promote academic integrity in using GenAI tools (RQ1), their impact and institutional strategies to effectively mitigate ethical risks (RQ2) and the model practices to support the ethical and effective use in higher education (RQ3). Methods: The PRISMA framework was used to systematically review and thematically synthesise the results of 213 peer-reviewed articles published between January 2021 and May 2025. Results: Finding indicates that academic support, defined by structured training, technical scaffolding, and perceived usefulness, is critical to enabling ethical GenAI use. Additionally, student self-regulation, as influenced by behavioural control and goal setting, was associated with greater academic integrity in GenAI-mediated learning. Whereas institutional policies varied widely, those with transparent, adaptive and discipline-responsive governance frameworks more effectively mitigated academic misconduct. Indeed, the model practices included GenAI ethics committees, interactive GenAI literacy modules, and the developer-educator collaborations to promote algorithmic transparency. Conclusions: A comprehensive systems-based approach that encompasses academic support, self-regulation and ethical guidelines is critical for the responsible use of GenAI tools in education. Hence, to preserve academic integrity while nurturing innovation, institutions should integrate GenAI ethics into curricular design, faculty development and cross-sectoral policy frameworks. Future research may expand into multilingual and longitudinal analyses to support equitable and sustainable GenAI integration across diverse educational settings.",academic integrity | faculty development | GenAI ethics | generative artificial intelligence | higher education governance | self-regulation,1,2025,sustainability,policy+sustainability
141,2-s2.0-105017129221,10.3390/atmos16091102,https://doi.org/10.3390/atmos16091102,https://scholar.google.com/scholar?q=10.3390/atmos16091102,re,Atmosphere,"Wang, Mo;Liu, Hui;Zhang, Menghan;Adnan, Rana Muhammad",Advancing Nature-Based Solutions with Artificial Intelligence: A Bibliometric and Semantic Analysis Using ChatGPT,"In response to escalating climate change and ecological degradation, nature-based solutions (NBSs) have emerged as a critical paradigm for sustainable environmental governance. Simultaneously, artificial intelligence (AI) offers powerful capabilities for addressing the complexity and uncertainty inherent in natural systems. This study investigates the integration of AI within NBS through a hybrid bibliometric and semantic-enhancement framework. Drawing on 535 peer-reviewed articles from the Web of Science Core Collection (2011–2024), we employ keyword co-occurrence analysis via CiteSpace and semantic refinement using ChatGPT-4.0 to identify 15 key thematic clusters. Results reveal that AI is widely applied in ecological monitoring, carbon emission reduction, urban climate adaptation, and green infrastructure optimization—substantially improving the responsiveness, precision, and scalability of NBS interventions. The proposed methodology enhances both structural insight and semantic coherence in bibliometric review, offering a robust foundation for future interdisciplinary research. This study contributes to the theoretical development and practical implementation of AI-enhanced NBS, supporting data-driven, adaptive strategies for climate resilience and sustainable development.",artificial intelligence | bibliometric analysis | climate adaptation | nature-based solutions | semantic modeling | sustainable governance,1,2025,sustainability,policy+sustainability
150,2-s2.0-105013394800,10.1016/j.giq.2025.102062,https://doi.org/10.1016/j.giq.2025.102062,https://scholar.google.com/scholar?q=10.1016/j.giq.2025.102062,ar,Government Information Quarterly,"Nikiforova, Anastasija;Lnenicka, Martin;Luterek, Mariusz;Milic, Petar;Bolívar Rodríguez, Manuel Pedro",Theorizing the evolution of public data ecosystems: An empirically grounded multi-generational model and future research agenda,"Public Data Ecosystems (PDEs) are increasingly viewed as dynamic socio-technical systems shaped by evolving interactions among actors, infrastructures, data types, and governance mechanisms. Yet, most existing research remains static or domain-specific, offering limited insight into the temporal and co-evolutionary dynamics of PDEs. To address this gap, this study adopts a theory-building approach to examine how PDEs evolve over time and to define a forward-looking research agenda. Drawing on empirical insights from five European countries, we investigate how key meta-characteristics and attributes of PDEs manifest, shift, and co-evolve in practice. Leveraging a recent multi-generational model as an analytical lens, we assess its alignment with real-world trajectories, identify overlooked and emerging features, and revise its structure accordingly. In doing so, we theorize PDE evolution as a multi-generational process shaped by institutional, technological, and contextual dynamics. This results in a refined model that better captures the complexity and diversity of PDE development, particularly considering emerging technologies such as artificial intelligence (AI), generative AI, and large language models (LLMs) shaping the forward-looking PDE generation. Building on these insights, we propose a future research agenda comprising 17 directions organized around revised meta-characteristics. This agenda supports the development of sustainable, resilient, and intelligent PDEs. The study contributes to the theorization of PDEs by offering an empirically grounded, temporally aware, and actionable roadmap for future research and policy design.",Artificial intelligence | Data ecosystem evolution | Data governance | Public data ecosystem | Public sector innovation | Research agenda | Socio-technical system,1,2025,sustainability,policy+sustainability
175,2-s2.0-105015332616,10.31538/munaddhomah.v6i3.1937,https://doi.org/10.31538/munaddhomah.v6i3.1937,https://scholar.google.com/scholar?q=10.31538/munaddhomah.v6i3.1937,ar,Munaddhomah,"Choiriyah, Siti;Ramadhan, Syahrul;Nugroho, Arif;Pembangunan, Heldy Ramadhan Putra;Muharom, Fauzi",Artificial Intelligence-Driven Learning Assessment in Faculties of Education: An Exploratory Study,"Artificial intelligence (AI) is reshaping higher education, yet its role in student learning assessment, particularly within faculties of education where future teachers are trained, remains insufficiently explored. As AI tools rapidly expand, they create a pressing paradox: on one hand, these technologies offer unprecedented efficiency, personalization, and scalability; on the other, they raise critical risks concerning pedagogical integrity, ethical governance, and the erosion of human-centered evaluation. This study addresses this gap by examining the practices, perceptions, opportunities, and challenges of AI-driven assessment in faculties of education. Employing a qualitative exploratory design, data were collected through semi-structured interviews and institutional document analysis with 20 lecturers and policymakers from universities in Surakarta, Indonesia. The findings reveal a striking tension. Faculty members actively deploy tools such as Grammarly, Turnitin, ChatGPT, and adaptive learning platforms for automated feedback, plagiarism detection, and real-time analytics, reporting efficiency gains of up to 90%. Yet, participants expressed profound concerns: AI’s inability to capture higher-order thinking, risks of student overreliance, ethical dilemmas related to privacy and bias, and fears of diminished professional judgment. Equally, they envisioned transformative opportunities for real-time formative feedback, early intervention, and scalable personalized support, provided AI is embedded in collaborative, pedagogically aligned frameworks. The study demonstrates that the unchecked adoption of AI risks narrowing creativity and critical thinking, but thoughtful integration can advance equity, innovation, and reflective pedagogy. Sustainable AI adoption in learning assessment requires institutional readiness, targeted training, and robust ethical safeguards to ensure AI augments rather than undermines teacher education.",AI-Driven | educational technology | higher education | Learning Assessment,1,2025,sustainability,policy+sustainability
195,2-s2.0-105005541248,10.1007/s11069-025-07285-1,https://doi.org/10.1007/s11069-025-07285-1,https://scholar.google.com/scholar?q=10.1007/s11069-025-07285-1,re,Natural Hazards,"Wang, Qiao;Gu, Haozhuo;Zang, Xinyu;Zuo, Minghao;Li, Hanyan","Flood resilience in cities and urban agglomerations: a systematic review of hazard causes, assessment frameworks, and recovery strategies based on LLM tools","With the increasing frequency of extreme weather events, the study of flood resilience in cities and urban agglomerations has become a critical topic for addressing climate change. This paper systematically reviews three key research directions—flood causes, assessment frameworks, and resilience enhancement strategies—by integrating quantitative and qualitative approaches across 412 relevant studies. The study innovatively employs large language models (LLMs) and machine learning techniques to achieve a structured research synthesis. The study identifies four major issues in current research on flood resilience in cities and urban agglomerations: (1) Existing studies predominantly focus on static indicators for individual cities, neglecting the dynamic interactions within urban agglomeration systems, making it challenging to reveal the real characteristics of cross-regional resource allocation and disaster propagation. (2) Governance mechanisms in urban agglomerations lack operational feasibility; conflicting interests among cities often reduce regional synergy to mere formalities. (3) There is an overemphasis on real-time risk monitoring and assessment models, while the practical value of disaster prediction models and pre-disaster planning is often overlooked. While existing studies consider inequities in regional and population vulnerabilities, they lack focus on integrating these needs into resilience frameworks and their practical implementation. Based on these findings, this study recommends incorporating the compounding effects of multidimensional factors, enhancing the implementability of regional collaborative governance and pre-disaster planning, and embedding economic practicality and universal applicability into the design of resilience assessment and enhancement frameworks.",Active machine learning | Flooding | Large language models | Urban agglomerations | Urban resilience,1,2025,sustainability,policy+sustainability
212,2-s2.0-105002006234,10.1017/nws.2025.4,https://doi.org/10.1017/nws.2025.4,https://scholar.google.com/scholar?q=10.1017/nws.2025.4,ar,Network Science,"Angst, Mario;Müller, Neitah Noemi;Walker, Viviane",Automated extraction of discourse networks from large volumes of media data,"Understanding and tracking societal discourse around essential governance challenges of our times is crucial. One possible heuristic is to conceptualize discourse as a network of actors and policy beliefs. Here, we present an exemplary and widely applicable automated approach to extract discourse networks from large volumes of media data, as a bipartite graph of organizations and beliefs connected by stance edges. Our approach leverages various natural language processing techniques, alongside qualitative content analysis. We combine named entity recognition, named entity linking, supervised text classification informed by close reading, and a novel stance detection procedure based on large language models. We demonstrate our approach in an empirical application tracing urban sustainable transport discourse networks in the Swiss urban area of ZÜrich over 12 years, based on more than one million paragraphs extracted from slightly less than two million newspaper articles. We test the internal validity of our approach. Based on evaluations against manually automated data, we find support for what we call the window validity hypothesis of automated discourse network data gathering. The internal validity of automated discourse network data gathering increases if inferences are combined over sliding time windows. Our results show that when leveraging data redundancy and stance inertia through windowed aggregation, automated methods can recover basic structure and higher-level structurally descriptive metrics of discourse networks well. Our results also demonstrate the necessity of creating high-quality test sets and close reading and that efforts invested in automation should be carefully considered.",automated text analysis | discourse | large language models | natural language processing | networks | sustainability | urban,1,2025,sustainability,policy+sustainability
218,2-s2.0-105003563632,10.3390/ijgi14040136,https://doi.org/10.3390/ijgi14040136,https://scholar.google.com/scholar?q=10.3390/ijgi14040136,ar,ISPRS International Journal of Geo Information,"Zhang, Xun;Zhang, Xin;Zhang, Yingchun;Liu, Ying;Zhou, Rui;Raxidin, Abdureyim;Li, Min","A Multidimensional Study of the 2023 Beijing Extreme Rainfall: Theme, Location, and Sentiment Based on Social Media Data","Extreme rainfall events are significant manifestations of climate change, causing substantial impacts on urban infrastructure and public life. This study takes the extreme rainfall event in Beijing in 2023 as the background and utilizes data from Sina Weibo. Based on large language models and prompt engineering, disaster information is extracted, and a multi-factor coupled disaster multi-sentiment classification model, Bert-BiLSTM, is designed. A disaster analysis framework focusing on three dimensions of theme, location and sentiment is constructed. The results indicate that during the pre-disaster stage, themes are concentrated on warnings and prevention, shifting to specific events and rescue actions during the disaster, and post-disaster, they express gratitude to rescue personnel and highlight social cohesion. In terms of spatial location, the disaster shows significant clustering, predominantly occurring in Mentougou and Fangshan. There is a clear difference in emotional expression between official media and the public; official media primarily focuses on neutral reporting and fact dissemination, while public sentiment is even richer. At the same time, there are also variations in sentiment expressions across different affected regions. This study provides new perspectives and methods for analyzing extreme rainfall events on social media by revealing the evolution of disaster themes, the spatial distribution of disasters, and the temporal and spatial changes in sentiment. These insights can support risk assessment, resource allocation, and public opinion guidance in disaster emergency management, thereby enhancing the precision and effectiveness of disaster response strategies.",Bert-BiLSTM | extreme rainfall | large language model | sentiment analysis | social media | temporal and spatial analysis | topic analysis,1,2025,sustainability,policy+sustainability
253,2-s2.0-85210545968,10.1016/j.geoforum.2024.104175,https://doi.org/10.1016/j.geoforum.2024.104175,https://scholar.google.com/scholar?q=10.1016/j.geoforum.2024.104175,ar,Geoforum,"Michel, Boris;Ecker, Yannick",Seeing economic development like a large language model. A methodological approach to the exploration of geographical imaginaries in generative AI,"The recent hype surrounding the disruptive potential of AI technologies in the form of large language models or text to image generators also raises questions for geographical research and practice. These questions include the power relations and inequalities inscribed in these systems, their significance for work and labor relations, their ecological and economic impact, but also the geographical and spatial imaginaries they reproduce. This article focuses on the latter and formulates a series of theoretical and methodological considerations for dealing with the output of these systems. As we assume that outputs generated by large language models will play an increasing role in the future, both in public and media discourses as well as in the discourses and practices of spatial planning and economic policy making, we consider it important to gain a critical understanding of these socio-technical systems. The empirical object of investigation of this paper is generated output that deals with questions of regional development and economic challenges in three European regions that are currently particularly affected by the transition to a climate-neutral economy and are designated by the European Union as Just Transition Fund Territories. We are particularly interested in how geographical imaginaries about these regions are formulated, how economic and social problems of these regions are presented and how this is translated into planning advice and development plans.",,1,2025,sustainability,policy+sustainability
256,2-s2.0-105026755597,10.36680/J.ITCON.2025.058,https://doi.org/10.36680/J.ITCON.2025.058,https://scholar.google.com/scholar?q=10.36680/J.ITCON.2025.058,ar,Journal of Information Technology in Construction,"Owais, Omar A.;Poshdar, Mani;Hoseini, Ali Ghaffarian;Ying, Fei;Jaafar, Kamal;Sarhan, Saad;Sheikhkhoshkar, Moslem",FROM COMPETENCY MAPPING TO DIGITAL TWIN INTEGRATION: DEVELOPING A NEXT-GEN DIGITAL PROJECT MANAGER MODEL FOR SMART CONSTRUCTION,"The digital transformation of the construction industry has outpaced the evolution of traditional project management competency frameworks, leaving many Project Managers (PMs) underprepared to meet the demands of emerging technologies such as Digital Twins (DTs). This study develops and validates a Next-Gen Digital PM Competency List tailored to the Smart Built Environment (SBE) through a structured two-stage methodology. Stage 1 applied a three-phase process comprising (1) a Systematic Literature Review (SLR), (2) NVivo-based thematic analysis, and (3) Large Language Model (LLM)-driven synthesis. These phases identified, categorised, and defined 55 digital PM competencies, systematically organised into Skills, Knowledge, and Core Personality Traits. Stage 2 evaluates the practical relevance of these competencies by mapping them against six thematic functional requirements of DTs, including interoperability and integration, real-time data management, simulation and predictive modelling, cybersecurity and data governance, stakeholder collaboration, and scalability and lifecycle continuity. DTs were selected as an exemplar because they integrate multiple digital technologies, Building Information Modelling (BIM), Internet of Things (IoT), Artificial Intelligence (AI), and cloud computing, making them a representative test case for evaluating competency alignment in digital transformation. The mapping confirmed strong alignment in digital integration and collaboration while exposing gaps in cybersecurity readiness and lifecycle resilience. The resulting framework provides a validated reference for competency benchmarking, targeted training, and digital leadership development. By equipping PMs with the competencies to lead, manage, and support digitally enabled projects, this research contributes directly to advancing smart and sustainable construction practices in the digital built environment.",Construction Management | Digital Competencies | Digital Project Manager | Digital Transformation | Digital Twin | Smart Built Environment (SBE) | Smart Construction.,1,2025,sustainability,policy+sustainability
309,2-s2.0-105014988742,10.1108/YC-10-2024-2303,https://doi.org/10.1108/YC-10-2024-2303,https://scholar.google.com/scholar?q=10.1108/YC-10-2024-2303,ar,Young Consumers,"Tong, Ashley;Zainol, Zahirah;Chong, Teck Siong;Renganathan, Krishnamoorthy",AI governance on young consumers in higher education: a content analysis of policies for generative AI,"Purpose As generative artificial intelligence (AI) technologies continue to advance and become more prevalent in higher education, addressing the ethical concerns associated with their use is essential. This study emphasizes the need for robust AI governance as more young consumers increasingly use generative AI for various applications. This paper aims to examine the ethical challenges posed by generative AI and review the AI policies in higher education to regulate young consumers use of generative AI, focusing on the ethical use of AI from foundational principles to sustainable governance. Design/methodology/approach Through a content analysis of literature on generative AI policies in higher education published between 2020 and 2024, this research aims to explore a more holistic approach to integrating generative AI into the educational process. The analysis examines academic policies and governance framework from 28 journal papers regarding generative AI tools in higher education. Data were collected from publicly accessible sources, such as Scopus, Emerald Insights, ProQuest, Web of Science and ScienceDirect. Findings This study analyses ten elements of the governance framework to identify potential AI governance and policy setting, benefiting stakeholders aiming at enhancing the regulatory framework of generative AI use in higher education. The discussions indicate a generally balanced yet cautious approach to integrating generative AI technology, especially considering ethical issues, inherent limitations and data privacy concerns. Originality/value The findings contribute to ongoing discussions to strengthen universities’ responses to new academic challenges posed by the use of generative AI and promote high AI ethical standards across educational sectors.",Academic policy | Generative artificial intelligence | Governance framework | Higher education | Young consumer,1,2025,sustainability,policy+sustainability
313,2-s2.0-105012937789,10.20517/ces.2025.35,https://doi.org/10.20517/ces.2025.35,https://scholar.google.com/scholar?q=10.20517/ces.2025.35,re,Complex Engineering Systems,"Cao, Fenghua;Liu, Lingdi;Song, Wenyan",Reducing sustainable supply chain risks: a digital technology-enabled risk management framework for ESG-oriented engineering procurement,"Facing increased societal demands for corporate sustainability, the challenges faced by companies in engineering procurement risk management (EPRM) expand from economic to environmental, social and governance aspects. Based on a systematic review, this study finds that current research focuses on a single Environmental, Social, and Governance (ESG) dimension or procurement risk management (PRM) business orientation. Companies urgently need to address multiple pressures of ESG compliance, transparent supplier ecology, and real-time risk management. However, fragmented ESG assessment, siloed data systems and reactive strategies have led to operational inefficiencies and missed technology dividends, and there is an urgent need to build a procurement risk solution that integrates ESG and digital technologies (DTs). Therefore, this paper proposes a framework, namely DEEP-RM, for ESG-oriented circulated PRM that leverages DTs such as the Large Language Model, Multi-Agent System, and Blockchain. The DEEP-RM aims to facilitate enterprises in PRM through ESG transformations and DTs to enhance supply chain resilience and achieve sustainability in supply chain management. This paper enriches the theory of EPRM by revealing, for the first time, the evolutionary path of research in PRM through literature analysis. Breaking the traditional linear management model, the research proposes a closed-loop framework that integrates DTs and ESG to achieve global visualisation of risk management and a trusted collaboration ecology. The framework innovatively uses various emerging technologies to overcome the problems in traditional EPRM, and promotes the transformation of risk management from experience-driven to machine intelligence-driven. The new energy company S has successfully implemented the framework and achieved remarkable results.",digital technologies | Engineering procurement risk management | ESG | supply chain resilience | sustainable supply chain management,1,2025,sustainability,policy+sustainability
324,2-s2.0-105008871735,10.20448/jeelr.v12i2.6746,https://doi.org/10.20448/jeelr.v12i2.6746,https://scholar.google.com/scholar?q=10.20448/jeelr.v12i2.6746,ar,Journal of Education and E Learning Research,"Alkaabi, Ahmed;Abdallah, Asma;Alblooshi, Shamma;Alomari, Fatima;Alneaimi, Sara","ChatGPT in higher education: Opportunities, challenges, and required competencies in the absence of guiding policies","This study examines the opportunities and challenges of employing ChatGPT in higher education, identifies essential user competencies, and evaluates its impact in the absence of formal policy guidelines. A qualitative case study design involved interviews with 10 faculty members and 10 students at a federal university in the United Arab Emirates. Documentation of live ChatGPT usage was also analyzed to triangulate findings. Thematic analysis revealed the following eight core themes: (1) Cost-effectiveness and time savings. (2) ChatGPT as a source of information and a flexible tool. (3) ChatGPT’s ability to adapt to the user. (4) Prompt engineering competencies in ChatGPT. (5) Addiction to ChatGPT. (6) The misinformation risks with ChatGPT. (7) Academic integrity concerns. (8) A lack of consensus on how to utilize ChatGPT appropriately. The findings underscore an urgent need for formal policies to guide the ethical and responsible use of ChatGPT in higher education. The study also emphasizes the necessity of targeted training workshops for teachers, curriculum integration, and adapting pedagogical approaches. It also calls for proactive attention to ethical concerns including misinformation, algorithmic bias, and overreliance to ensure that the educational benefits of ChatGPT are realized responsibly and sustainably.",Academic integrity | AI challenges | AI integration | AI opportunities | AI regulation | Artificial intelligence | ChatGPT | ChatGPT risks | Higher education | Qualitative case study | Required competencies,1,2025,sustainability,policy+sustainability
325,2-s2.0-105007002040,10.1080/17517575.2025.2508169,https://doi.org/10.1080/17517575.2025.2508169,https://scholar.google.com/scholar?q=10.1080/17517575.2025.2508169,ar,Enterprise Information Systems,"Mayopu, Richard G.;Nalluri, Venkateswarlu;Chen, Long Sheng",Detecting ChatGPT virtual news in the era of artificial intelligence,"Fake news, amplified by generative AI, threatens sustainable supply chains by spreading misinformation. This study explores how deep learning and machine learning methods—NLP, RNN, SVM, and Naïve Bayes—detect AI-generated news, even after human edits. Experiments were conducted on three levels: unedited AI news, and news with simple and complex human modifications. Findings show that human intervention reduces detection accuracy, but deep learning models exhibit strong potential in handling complex and adaptive content. This research highlights the need for advanced detection tools to safeguard supply chains against increasingly sophisticated fake news threats.",fake news | Generative artificial intelligence | machine learning | recurrent neural network | supply chain | virtual news,1,2025,sustainability,policy+sustainability
328,2-s2.0-105006553063,10.1155/acis/8584141,https://doi.org/10.1155/acis/8584141,https://scholar.google.com/scholar?q=10.1155/acis/8584141,ar,Applied Computational Intelligence and Soft Computing,"Mariyono, Dwi;Alif Hidayatullah, Akmal Nur",Navigating the Moral Maze: Ethical Challenges and Opportunities of Generative Chatbots in Global Higher Education,"The rise of generative artificial intelligence (AI), such as ChatGPT, enhances higher education through personalized learning, administrative automation, and increased accessibility. However, it also raises ethical concerns about data security, academic integrity, algorithmic bias, and learner autonomy. This study employs a Hybrid Thematic SWOT (HT-SWOT) analysis to examine the strengths, weaknesses, opportunities, and threats of generative AI in global higher education. Through a systematic literature review of recent studies (2020–2024), this research highlights both the benefits, such as personalized learning, accessibility, and administrative efficiency, and the risks, including digital divides, misinformation, technosolotionism, and ethical concerns. The findings emphasize the need for responsible AI policies, faculty training, and equitable implementation strategies. This study provides actionable insights for policymakers, educators, and technologists to navigate AI’s ethical integration while promoting global equity and sustainable educational practices. Addressing these challenges requires a balanced approach that safeguards academic integrity while harnessing AI’s potential to enhance education worldwide.",AI governance | chatbots | ethical challenges | generative AI | higher education | technosolotionism,1,2025,sustainability,policy+sustainability
404,2-s2.0-85186916765,10.11959/j.issn.2096-6652.202347,https://doi.org/10.11959/j.issn.2096-6652.202347,https://scholar.google.com/scholar?q=10.11959/j.issn.2096-6652.202347,ar,Chinese Journal of Intelligent Science and Technology,"Wang, Fei Yue",Parallel and digital police for new norm of public safety: from parallel security to peaceful China,"Due to the impact of artificial intelligence generated content technologies such as AlphaGo and ChatGPT, the governance of intelligent science and technology becomes a significant concern all over the world. This review addressed related issues by integrating traditional public safety management with new artificial intelligence (AI) technologies and provided an alternative philosophy and approach for safety, security and sustainability in the future society of AI.",AlphaGo | artificial intelligence (AI) | artificial intelligence generated content (AIGC) | ChatGPT | digital police | parallel intelligence | parallel police | parallel safety | parallel security,1,2023,sustainability,policy+sustainability
417,2-s2.0-85142823678,10.30955/gnj.004353,https://doi.org/10.30955/gnj.004353,https://scholar.google.com/scholar?q=10.30955/gnj.004353,ar,Global Nest Journal,"Ramasamy, M.;Nagan, S.","Analysis of flood frequency using plotting position methods and Gumbel’s method: Vaigai river basin, Southern India","Estimation of annual peak flood flow has considerable financial influence, as this can pave numerous ways for water resources planning, design of hydraulic structures, and sustainable management of these valuable resources at an optimum benefit. Six standard plotting position methods coupled with Linear Log-regression Model (LLM) are employed for the Return Period (RP) of 15, 20, 25, 30, 60, and 1000 years to forecast peak flood flow magnitudes and for this daily annual peak flood flow data for the periods of 24 years were used to illustrate the proposed methods. Another method, Gumbel's Analytical Approach (GAA), is also used to forecast the peak flood flow magnitude for the same RP, and it was taken as the benchmark to compare all the six methods of plotting position. The degree of accuracy of the plotting position is based on the coefficient of determination R<sup>2</sup>. The R<sup>2</sup> values for Adamowski, Hazen, Beard, Chegodajev, Tukey, and Benard, are 0.9073, 0.9284, 0.9119, 0.9111, 0.9135, and 0.9111, respectively. Out of the six-plotting position methods, Hazen method predicted a very closer value in comparison with GAA. It is advantageous to have the additional method to forecast peak flood flow for longer RP. The achieved result assuredly facilitates effective planning, regulation, and maintenance of huge reservoirs across the frequent occurrence of floods in river basin areas, considering safety and particularly downstream inhabited areas to save loss of human life, animals, damages to properties, and an impair of cultivated crops.",Hydraulic structures | peak flood flow | return period; cultivated crops,1,2022,sustainability,policy+sustainability
421,2-s2.0-105023426495,10.1016/j.dte.2025.100071,https://doi.org/10.1016/j.dte.2025.100071,https://scholar.google.com/scholar?q=10.1016/j.dte.2025.100071,ar,Digital Engineering,"Alla, Pullaiah Babu",Augmenting Intelligent Process Automation through Generative AI for Human-in-the-Loop Decision Systems,"Robotic Process Automation (RPA) has transformed enterprise operations by automating repetitive, rule-based tasks with remarkable efficiency and consistency. Despite these advantages, traditional RPA systems function within rigid boundaries defined by structured rules and deterministic logic, limiting their effectiveness for tasks requiring contextual understanding, nuanced judgment, or interpretation of unstructured data. The integration of Generative AI (GenAI) into RPA workflows creates semi-autonomous (system that can perform tasks independently but still needs some level of human intervention) human-in-the-loop (system design for which a human operator is actively involved in the decision-making process, approving or modifying actions before execution) (HITL) systems where intelligent decision support complements automated processes through guided human intervention. The resulting hybrid architecture allows RPA bots to handle structured tasks autonomously, while GenAI models—powered by large language models (LLMs) and sophisticated natural language processing—address complex scenarios by providing contextual explanations, suggesting resolutions, and identifying anomalies that require human oversight. Across finance, healthcare, and legal sectors, this architecture enables scalable automation without compromising reliability. Important design considerations include calibrating trust between human operators and machines, ensuring AI decision transparency, protecting sensitive data, managing error propagation, and dynamically allocating tasks. A feedback mechanism incorporates human decisions into GenAI training, enabling continuous improvement. A progressive maturity model guides implementation from direct supervision toward strategic governance, balancing scalability with appropriate oversight. This paradigm shifts automation toward a collaborative framework where human expertise and artificial intelligence form complementary partnerships in process execution.",Agentic Process Automation | AI Agents | Enterprise Automation | Generative AI | Human-in-the-loop | Large Language Models | Robotic Process Automation,0,2026,behavior,behavior+policy
422,2-s2.0-105020892571,10.1016/j.eswa.2025.130103,https://doi.org/10.1016/j.eswa.2025.130103,https://scholar.google.com/scholar?q=10.1016/j.eswa.2025.130103,ar,Expert Systems with Applications,"Ma, Xiaochen;Rao, Guozheng;Xu, Lina;Wang, Xin;Fan, Zaiming;Zhang, Zhe",Guided and knowledgeable multi-agent debate for fact verification,"The rapid dissemination of misinformation through social media and open-access platforms has seriously affected public and personal lives and raised data security concerns. Fact verification plays a pivotal role in curbing the spread of such information. While Large Language Models have shown strong capabilities in reasoning and generation, their inherent issues—such as hallucination and bias—can lead to unreliable and logically inconsistent outputs, making them less trustworthy in fact verification tasks. To address these limitations, we propose GKMAD (Guided and Knowledgeable Multi-Agent Debate), a multi-agent fact verification framework designed to enhance reliability by incorporating structured guidance and external knowledge. Specifically, GKMAD incorporates four key mechanisms: (1) a Guided Debate Mechanism that introduces structured prompts to steer agent debates in a targeted and coherent manner; (2) a Knowledgeable Debate Mechanism that enables agents to dynamically incorporate external knowledge to enhance the informativeness and knowledge coverage of the debate; (3) an Advanced Advice Mechanism that generates structured advice from debate outcomes to guide final verification; and (4) a Knowledgeable Verification Mechanism that combines retrieved evidence and debate insights for comprehensive decision-making. Experimental results the FOLK benchmark datasets—constructed from representative subsets of HoVER, FEVEROUS, and SciFact-Open—across seven fact verification tasks demonstrate that GKMAD consistently outperforms state-of-the-art baselines in terms of Macro-F1, confirming the effectiveness of guidance and knowledge integration in mitigating LLM unreliability in fact verification.",Explainable reasoning | Fact verification | Misinformation detection | Multi-agent debate,0,2026,behavior,behavior+policy
423,2-s2.0-105027692340,10.1016/j.isci.2026.114627,https://doi.org/10.1016/j.isci.2026.114627,https://scholar.google.com/scholar?q=10.1016/j.isci.2026.114627,re,Iscience,"Wang, Xiaodong;Wang, Qianqian;Ding, Gouping;Wang, Junjie;Tang, Yixuan;Feng, Yeqian",Artificial intelligence for colposcopic and cytological image analysis in early cervical cancer detection,"Artificial intelligence (AI) is reshaping cervical cancer screening by automating interpretation of cytology, colposcopic, and related imaging to improve early detection, especially in low- and middle-income countries. This review synthesizes advances in preprocessing; segmentation; representation learning; and supervised, semi-supervised, unsupervised, and transformer-based models, with emphasis on multimodal fusion with HPV testing, spectroscopy, and MRI. Across retrospective datasets and growing real-world deployments, AI systems can achieve high accuracy and sensitivity, accelerate workflows, reduce costs, and expand coverage via portable and edge-computing devices. However, translation is constrained by data bias, variable image quality, opaque decision-making, and fragmented regulation. We outline requirements for clinically robust and equitable deployment, including diverse multi-center datasets, federated and privacy-preserving learning, explainable interfaces, standardized validation with histopathologic endpoints, and clinician-in-the-loop workflows. Finally, we highlight future directions such as hybrid explainable AI with large language models, multi-omics integration, and adaptive models resilient to data drift.",Artificial intelligence applications | Medical imaging | Oncology,0,2026,behavior,behavior+policy
424,2-s2.0-105026605037,10.1007/s10207-025-01185-y,https://doi.org/10.1007/s10207-025-01185-y,https://scholar.google.com/scholar?q=10.1007/s10207-025-01185-y,ar,International Journal of Information Security,"Leo, Martin;Tan, Freedy;Miao, Tianqi;Anand, Guru",From threat to trust: assessing security risks of agentic AI systems,"Agentic artificial intelligence (AI) systems are expected to have transformative impacts across sectors, including critical areas like finance and healthcare. Their architectural complexity, autonomous decision-making abilities, adaptive behaviors, and capacity to interact with the environment using tools are also likely to introduce new and poorly understood security risks. Existing security research and risk management frameworks are still in the early stages of development and are insufficient for addressing the complex vulnerabilities unique to agentic AI. This paper fills this important gap by presenting a comprehensive, layered risk assessment methodology that combines traditional threat modeling. The methodology recognizes that a threat to an agentic AI system not only compromises conventional security properties but also affects the trustworthiness of the system itself. Our method systematically maps and evaluates threats across different architectural layers of agentic AI, assessing how violations of trustworthiness impact the system to help prioritize risk reduction efforts. We demonstrate how this method works through a detailed case study of “RoboPMS,” a multi-agent autonomous portfolio management system in the financial sector. The analysis demonstrates how risks can be more effectively evaluated, understood, and prioritized to inform targeted mitigation strategies. By offering a structured, actionable framework for identifying, classifying, and managing risks in agentic AI systems, this work advances both academic knowledge and practical governance. The methodology can be adapted to various domains and is designed to help practitioners, risk managers, and policymakers ensure the secure and trustworthy integration of agentic AI into organizational information systems.",Agentic AI | AI Governance | Risk Management | Security assessment | Threat Modeling | Trustworthiness,0,2026,behavior,behavior+policy
425,2-s2.0-105025200081,10.1016/j.tifs.2025.105510,https://doi.org/10.1016/j.tifs.2025.105510,https://scholar.google.com/scholar?q=10.1016/j.tifs.2025.105510,re,Trends in Food Science and Technology,"Zhang, Xuechen;Ye, Sitan;Wang, Yujie;Gouda, Mostafa;Hu, Yan;Islam, Muhammad Adnan;He, Yong;Li, Xiaoli","Intelligent transformation of the tea industry: Artificial intelligence applications in management, harvesting, and processing","Background: The tea industry has established a complete industrial chain including planting, management, harvesting, and processing, with artificial intelligence reshaping its production methods and governance models. Scope and approach: This review focuses on three key aspects of tea production, garden management, harvesting, and processing. It provides an in-depth analysis of the current application status of artificial intelligence technologies across the entire tea production and processing industry chain over the past five years, examining equipment, systems, and methodologies. The review identifies existing challenges and proposes future development pathways. Key findings and conclusions: With the refinement of high standard databases, breakthroughs in heterogeneous data cooperative decision making algorithms, and the iteration of terminal intelligent agents, AI driven smart tea industry will enter a new phase of development. The management side will integrate satellite imagery, drone data, ground sensors, and operational data, combining domain knowledge graphs with specialized large models to enable efficient and precise management decisions. The harvesting side will simultaneously advance lightweight local models and cloud-based inference supported by high-speed communication. Equipment configurations will evolve toward modular robotic arm picking units and integrated picking and sorting systems. This will be implemented in coordination with tea garden renovations for machine friendly adaptation and varietal optimization. The processing side will achieve in-situ online sensing of tea leaf parameters, enabling precise matching between color, aroma, taste, and appearance with processing techniques. Driven by the synergy of data, algorithms, and equipment, the tea industry will undergo comprehensive intelligent upgrades and high-quality development across its entire chain.",Artificial intelligence technology | Data processing | Tea garden management | Tea industry | Tea picking | Tea processing,0,2026,behavior,behavior+policy
426,2-s2.0-105024256300,10.1007/s11280-025-01393-5,https://doi.org/10.1007/s11280-025-01393-5,https://scholar.google.com/scholar?q=10.1007/s11280-025-01393-5,ar,World Wide Web,"Allani, Sabri;Bou-Chaaya, Karam;Rais, Helmi","ELISAR: A Multi-Agent cybersecurity framework integrating retrieval-augmented generation for Blue, Red, and GRC operations","A cybersecurity framework, ELISAR, has been developed to address the evolving challenges of modern cybersecurity operations, including governance, risk management, and threat mitigation. Unlike conventional AI-driven models, ELISAR is designed as a collaborative multi-agent system, in which specialized agents are deployed to operate autonomously while interacting within a modular and scalable architecture. Multiple domain-specific agents are orchestrated by the ELISAR Engine, with each agent being optimized for distinct cybersecurity tasks. For instance, ELISAR for GRC (Governance, Risk, and Compliance) is supported by a vector-based knowledge retrieval mechanism trained on regulatory standards such as NIS2, ISO 27001, and ISO 42001, enabling compliance-driven decision-making. For penetration testing, a RAG enhanced knowledge base is utilized, curated from security assessment datasets to support proactive vulnerability exploration. The defensive suite, Blue ELISAR, is composed of intelligent sub-agents, including ELISAR Honeypots for deception, ELISAR Next-Gen Firewall for real-time detection, and ELISAR Smart DLP for adaptive data protection. Through the integration of autonomous reasoning, contextual knowledge retrieval, and real-time adaptability, ELISAR is presented as an interpretable and domain-specialized cybersecurity assistant, in contrast to monolithic LLM-based solutions. This extended version of the manuscript includes additional system design details, formal modeling, and an expanded experimental evaluation across defensive, offensive, and compliance cybersecurity domains. Improvements in accuracy, context relevance, and result stability are observed when agentic AI is combined with retrieval-based methods, while latency remains comparable across tasks.",Agentic AI | Cybersecurity | Generative AI | Governance | Large Language Models | Risk Assessment | Threat Mitigation,0,2026,behavior,behavior+policy
427,2-s2.0-105021600064,10.1016/j.envsoft.2025.106762,https://doi.org/10.1016/j.envsoft.2025.106762,https://scholar.google.com/scholar?q=10.1016/j.envsoft.2025.106762,ar,Environmental Modelling and Software,"Kolagani, Nagesh;Glynn, Pierre D.;Voinov, Alexey;Quinn, Nigel W.T.;Helgeson, Jennifer;Dyckman, Caitlin S.",Participatory modeling in the AI era,"PM is a now established approach to improve the utility and actionability of modeling for decision making and management. With the advent of the AI era, there are multiple avenues for its use in the context of PM. We reviewed a number of recent papers that describe how various AI tools have been used to assist the PM process, both in improving the quality of modeling and the participation efficiency. We have identified AI applications that can help stakeholders in the process of knowledge acquisition and decision making during the steps of the PM process. We also looked at how AI has been put to several innovative uses in PM related areas, such as collective intelligence, deliberative democracy and participatory governance, and how these can be adopted and used in the PM process. These enhancements escalate in degree of AI intervention and autonomy. They start with augmenting approaches such as informing, modeling and data processing, and can lead to deeper AI engagement such as assisted facilitation and communication. The enhancements can include the use of AI agents as stakeholder assistants, but may also result in an increased delegation of human stakeholder tasks, and eventually possibly in the replacement of stakeholders in PM. We have identified the benefits of such AI penetration, and also found several risks and challenges that it presents in the PM process. The most threatening include risks associated with AGI and possible supplantation and surpassing of human abilities in decision making and management without meaningful controls and regulations put in place. We suggest that some coordination of efforts from all involved parties across the whole spectrum of countries and businesses is essential to ensure that humans can have a measure of control over their destiny. So far, neither the PM community, nor society at large are anywhere near implementation of the essential agreements, controls, and protective measures needed. We conclude that a critically considered, well organized, PM process could be used to engage all the interested parties and agents to account for the feedbacks and lessons learned and develop these much needed regulations, treaties, checks and balances.",,0,2026,behavior,behavior+policy
428,2-s2.0-105023592514,10.1016/j.engappai.2025.113304,https://doi.org/10.1016/j.engappai.2025.113304,https://scholar.google.com/scholar?q=10.1016/j.engappai.2025.113304,ar,Engineering Applications of Artificial Intelligence,"Alarfaj, Fawaz Khaled;Khan, Hikmat Ullah;Naz, Anam;Almusallam, Naif",A real-time large language model framework with attention and embedding representations for misinformation detection,"Artificial Intelligence (AI) plays a central role in understanding and managing the vast amount of information shared online. With the rise of the user-generated content on platforms pursuing the challenge of identifying and controlling misinformation has become increasingly urgent. Using advanced natural language processing techniques and large language models, this study proposes a framework to detect and analyze misleading content. By examining language patterns, and user behavior, main aim is to provide an effective solution for early and accurate misinformation detection in online environments. Traditional Machine Learning (ML) models and Deep Learning (DL) architecture, often rely on manual feature engineering and struggle to capture the complex semantics of deceptive text. The main aim is to introduce a transformer-based neural network variant known as eXtra Long Network ( XLNet), a state-of-the-art large language model. The proposed framework integrates with attention mechanisms and contextual embeddings, to enhance the accuracy of text classification. Its significance lies in demonstrating how AI techniques can be adapted to address the critical application domain of misinformation detection, enabling more reliable identification of misleading content across diverse and evolving online narratives. By utilizing pre-trained contextual embeddings and permutation-based language modeling, XLNet significantly outperforms baseline approaches including ML with textual features, and DL models trained with word and sentence embedding with highest accuracy of 97 %, demonstrating its ability to generalize and make confident predictions. Empirical analysis further validated the findings through explainable AI techniques to ensure interpretability and transparency and statistical tests which further supported the performance of proposed model.",Artificial intelligence | Deep learning | Explainable artificial intelligence | Fake news | Feature engineering | Misinformation | Natural language processing | Social media | Text mining | Transformer-based language models,0,2026,behavior,behavior+policy
429,2-s2.0-105027302787,10.3390/app16010288,https://doi.org/10.3390/app16010288,https://scholar.google.com/scholar?q=10.3390/app16010288,ar,Applied Sciences Switzerland,"Iovane, Gerardo;Iovane, Giovanni",Sophimatics and 2D Complex Time to Mitigate Hallucinations in LLMs for Novel Intelligent Information Systems in Digital Transformation,"While large language models (LLMs) such as ChatGPT, Claude, and DeepSeek are evaluated based on their accuracy and truthfulness, “hallucinations” betray underlying structural limitations. These results are not simply incorrect answers, but statistical resonances; they are instances where models stabilize into statistically significant (though semantically unfounded) response patterns. Current frameworks fail to accommodate contextual semantics, experiential time, and intentionality as key dimensions for effective experience-based decision-making in complex digital spaces. This article presents an integration paradigm offered by the theory of uncertainty and incompleteness of information, extended by the Sophimatics approach with 2D complex time (t = t + i·t<inf>0</inf>) and Super Time Cognitive Neural Network (STCNN) that provides both memory management, imagination enhancement, and creativity generation as computational primitives. By integrating probability with plausibility, credibility, and possibility, our model reconsiders the issue of evaluating the reliability of LLM results as a problem that goes beyond traditional probabilistic approaches. Accepting that hallucinations are an emerging phenomenon of resonance between statistical distributions, we suggest an extended probability method in which these resonances can be mitigated and directed towards a coherent cognitive understanding. The paper places this approach in the broader perspective of digital transformation at the information systems level and its implications for AI reliability, explainability, and adaptive decision-making in post-generative AI. Intuitive scenarios are described, based on the inclusion of complex time and Sophimatics in theoretical modelling, illustrating how prediction, historical-contextual adoption, and resistance to paradoxical or contradictory information are strengthened. The results point to this paradigm as a springboard for reliable, human-aligned AI capable of enabling digital transformation in sectors such as healthcare, finance, and governance.",2D complex time | cognitive reliability | digital transformation | info-uncertainty and info-incompleteness | large language models (LLMs) | post-generative artificial intelligence | sophimatics | statistical resonances | super time cognitive neural network (STCNN) | trustworthy AI,0,2026,behavior,behavior+policy
430,2-s2.0-105027116312,10.1080/12460125.2025.2597835,https://doi.org/10.1080/12460125.2025.2597835,https://scholar.google.com/scholar?q=10.1080/12460125.2025.2597835,ar,Journal of Decision Systems,"Saup, Thorn Ole;Asghar, Jawad;Kanbach, Dominik K.;Kraus, Sascha",From pilots to decision systems: embedding generative AI into strategic decision-making through a socio-technical and governance lens,"Generative AI (GAI) promises superior analytics and agility in strategy work, yet organisations struggle to move beyond pilots towards routinised decision inputs. This study investigates how GAI becomes embedded in strategic decision-making (SDM) through a qualitative single-case analysis of a global multi-brand group, based on 27 semi-structured executive interviews triangulated with internal documents and industry reports. Structured inductive coding yields a process model identifying enablers, leadership-driven adoption, quick wins, prompt-based experimentation, workforce training, secure platforms, and dedicated investments, and barriers such as strategic ambiguity, limited awareness, hallucination risks, prompt-engineering deficiencies, data readiness, and privacy or IP concerns. The analysis specifies a four-stage pathway comprising Awareness and Exploration, Experimentation and Pilots, Formal Adoption and Integration, and Institutionalisation and Transformation, with admission gates for quality, provenance, explainability, and accountability. Human-in-the-loop arrangements redistribute responsibilities between AI and managers, while governance templates and socio-technical alignment determine whether GAI outputs are admitted into formal deliberation. Findings reframe GAI not as an autonomous oracle but as decision support within decision systems, clarifying conditions under which creative or efficient outputs become strategically admissible. The study contributes a socio-technical, governance-anchored model that addresses the pilot-to-decision gap and offers actionable heuristics for scaling GAI responsibly in strategic decision-making.",decision support | Generative AI | governance | human-in-the-loop | socio-technical systems | strategic decision-making,0,2026,behavior,behavior+policy
431,2-s2.0-105022686786,10.1016/j.puhe.2025.106047,https://doi.org/10.1016/j.puhe.2025.106047,https://scholar.google.com/scholar?q=10.1016/j.puhe.2025.106047,ar,Public Health,"del Rey Puech, Paula;Payne, Rebecca;Saund, Jasjot;McKee, Martin",Mind the (widening) gap: why public health must engage with AI now,"Objectives This commentary aims to highlight the opportunities and challenges that Artificial Intelligence (AI) presents for public health. Study design Narrative commentary and conceptual analysis. Methods The commentary draws on material developed for a forthcoming book by the European Observatory on Health Systems and Policies. Sources were selected to highlight both the potential and the limitations of AI integration at population levels, with a focus on equity, governance, and implementation. The analysis is informed by established public health principles: prevention, systems thinking, and the social determinants of health. Results AI applications in public health go beyond process automation and operational efficiency. By integrating and processing diverse, multi-modal data sources, its implementation presents opportunities to understand the wider determinants of health at a more nuanced level and identify populations at risk with greater precision. Additionally, AI has the potential to help understand and support behaviour change in sophisticated ways, enhance disease surveillance and modelling, and enable more targeted and responsive public communication and engagement strategies. However, there are several barriers to realise AI's potential in public health, including system fragmentation, data access limitations, resource constraints, implementation challenges, workforce readiness gaps, and technological limitations such as bias and generative AI “hallucinations”. Conclusion Without deliberate engagement, AI risks reinforcing existing inequities. Practical steps for action include embedding AI training in public health education, building multidisciplinary teams, investing in data infrastructure, and ensuring participatory approaches. AI will continue to shape public health systems, whether or not public health professionals engage. We argue that the public health community is both uniquely positioned and ethically obligated to engage proactively with AI.",Artificial Intelligence | Equity | Machine Learning | Public Health,0,2026,behavior,behavior+policy
432,2-s2.0-105016503156,10.1016/j.jpba.2025.117132,https://doi.org/10.1016/j.jpba.2025.117132,https://scholar.google.com/scholar?q=10.1016/j.jpba.2025.117132,ar,Journal of Pharmaceutical and Biomedical Analysis,"Liu, Pengfei;Guo, Jing;Xie, Jun;Li, Liang;Tao, Jun",A fragment-aware model for novel psychoactive substances analysis with uncertainty quantification,"The rapid emergence of novel psychoactive substances (NPS) poses significant challenges to forensic toxicology, as traditional detection methods struggle to keep pace with their increasing complexity and diversity. To address this, we propose the NPS Fragment-Aware Chemical Language Model (NPS-FACL), a large language model (LLM) framework that enhances NPS detection by leveraging their inherent chemical substructures. Our approach utilizes fragment-aware tokenization, achieving a 20.33% reduction in token representation complexity, which contributes to a 2.01% increase in F1-score. Furthermore, the model integrates explainable uncertainty quantification, enhancing prediction reliability and providing insights into substructure-driven biases for improved forensic analysis of NPS. This work marks a shift towards explainable AI-assisted decision-making, providing proactive alerts and uncertainty-driven insights for early warning of emerging synthetic drug threats, in contrast to conventional Liquid Chromatography-Mass Spectrometry (LC-MS) detection methods, which focus on molecule detection through extensive sample preparation and lack forward-looking predictive capabilities. Beyond forensic toxicology, the approach supports broader applications in public health surveillance, drug regulation, and harm reduction strategies by enabling rapid and scalable identification of novel substances.",Chemical Language Model | Deep learning | Forensic toxicology | Novel psychoactive substances,0,2026,behavior,behavior+policy
433,2-s2.0-105027514013,10.29121/shodhkosh.v6.i4s.2025.6973,https://doi.org/10.29121/shodhkosh.v6.i4s.2025.6973,https://scholar.google.com/scholar?q=10.29121/shodhkosh.v6.i4s.2025.6973,ar,Shodhkosh Journal of Visual and Performing Arts,"Mahaveerakannan, R.;Adhau, Sarala P.;Ramya, P.;Ratnakishor Gade, N. V.;Saravanan, M.;Jebakumar, Immanuel D.",ASSESSING THE IMPACT OF ARTIFICIAL INTELLIGENCE ON VISUAL MARKETING MANAGEMENT,"The growing role of the visual content in the internet has made visual marketing as a highly significant strategic position in the contemporary marketing management. At the same time, the evolution of Artificial Intelligence (AI) has enabled organizations to analyze, customize, and streamline the marketing efforts in visuals on a platform and scale never before attempted or achieved. The paper discusses the AI application in visual marketing management by examining the ways that the AI capabilities have transformed strategic planning, content creation, personalization, monitoring, and optimization of visual campaigns. The research that is founded on the overall assessment of academic literature and formulated analytical theories frames AI as the empowering management attribute, but not the technology application. Consequently, based on the analysis, one can mention that the visual marketing processes are supported by the use of computer vision, predictive analytics, and generative AI in data-driven decision-making, the real-time performance measurement, and the continuous learning processes. The paper also provides the assessment of whether visual marketing can be affected by AI or not and induce the short-term performance indicators, such as engagement and conversion rates, and the long-term brand equity indicators, such as brand recall and consumer trust. In addition, the study describes the managerial and ethical issues regarding the AI adoption, including data privacy, algorithmic bias, transparency and human control. The current research contributes an analytical value to the management of AI-based visual marketing by combining strategic, operational, and governance strategies. The findings may be applicable to researchers and specialists who are interested in referring to AI as the basis of effective and responsible visual marketing in online services that are more competitive.",Artificial Intelligence | Brand Performance | Computer Vision | Digital Marketing Analytics | Generative AI | Predictive Analytics | Visual Marketing Management,0,2025,behavior,behavior+policy
434,2-s2.0-105018456641,10.1016/j.neucom.2025.131453,https://doi.org/10.1016/j.neucom.2025.131453,https://scholar.google.com/scholar?q=10.1016/j.neucom.2025.131453,ar,Neurocomputing,"Li, Da;Shen, Li Yan;Guo, Qing Lei;Zhang, Chen Yang;Li, Jun;Jiang, Wen Tao;Yu, Ming Xin",BotLGT: Social bot detection based on LLM and graph transformer,"Detecting malicious bots in social networks is essential for maintaining platform integrity and limiting the dissemination of misinformation. While graph-based approaches perform well in capturing structural anomalies, they often neglect semantic information and face scalability challenges due to the high computational cost of attention mechanisms. In this work, we propose BotLGT, a hybrid framework that integrates semantic and structural features through a language-guided graph transformer. BotLGT utilizes embeddings derived from large language models (LLMs) to represent user behavior and interaction context, and incorporates a structure-aware encoding scheme that captures the topological importance and influence of each node. To efficiently aggregate these heterogeneous features across large-scale graphs, we employ a kernel-based linear attention mechanism, achieving expressive global context modeling with reduced computational cost. Extensive experiments on real-world datasets show that BotLGT outperforms state-of-the-art baselines in both detection accuracy and inference efficiency.",Bot detection | Graph transformer | Motif | Semantic information,0,2025,behavior,behavior+policy
435,2-s2.0-105020381264,10.1016/j.engappai.2025.112726,https://doi.org/10.1016/j.engappai.2025.112726,https://scholar.google.com/scholar?q=10.1016/j.engappai.2025.112726,ar,Engineering Applications of Artificial Intelligence,"Dong, Jinyang;Li, Junqiao;Li, Yucheng;Zhang, Wei;Zhang, Zhitao;Guo, Chenyang;Dang, Yu;Chen, Mei;Du, Jing",Knowledge extraction and alignment for mine ventilation: A knowledge graph construction framework based on large language models,"Mine ventilation corpora contain fragmented entities, attributes, and rule-based knowledge, marked by heterogeneous expressions, implicit structures, and ambiguous terminology. These characteristics hinder systematic modeling and intelligent utilization. To address these challenges, we propose an automated extraction and semantic alignment method based on large language models (LLMs), aiming to construct a high-quality knowledge graph (KG) tailored for mine ventilation. We design an ontology-driven extraction framework for three textual sources — regulations, books, and websites — using prompt engineering and few-shot strategies to extract information, domain knowledge, entity attributes, and rule-based relations in a unified way. For entity alignment, we develop a dual-filtering mechanism that integrates semantic similarity and structural adjacency, and leverage large language models (LLMs) for verification, enabling high-confidence alignment of entities and predicates. We propose a rule-path modeling strategy using the structure “subject entity (with condition) - predicate - object entity (with condition),” integrating multi-source triples into conditional rule chains. These are mapped into a graph database to support structured knowledge representation. Under few-shot conditions, the extraction accuracy of entity attributes and rule-based relations reached 94% and 99%, respectively. The final alignment of entities and predicates, manually verified, achieved 100% precision. The resulting knowledge graph (KG) comprises 58,358 entities and 63,630 edges, demonstrating strong semantic consistency and structural integrity. It provides structured knowledge support for risk warning, question answering (QA), and intelligent decision-making in mine ventilation systems as part of intelligent mining applications.",Artificial intelligence | Entity alignment | Intelligent mining systems | Knowledge graph construction | Large language models | Mine ventilation,0,2025,behavior,behavior+policy
436,2-s2.0-105023173432,10.1016/j.isci.2025.114082,https://doi.org/10.1016/j.isci.2025.114082,https://scholar.google.com/scholar?q=10.1016/j.isci.2025.114082,re,Iscience,"Wang, Xiaodong;Wang, Qianqian;Ding, Gouping;Wang, Junjie;Tang, Yixuan;Feng, Yeqian",Artificial intelligence in multidisciplinary tumor boards enhancing decision making and clinical outcomes in oncology,"Multidisciplinary tumor boards (MDTs) coordinate complex oncology decisions across imaging, pathology, genomics, and patient factors. Here we synthesize how artificial intelligence (AI)—including machine learning, natural language processing, deep learning, and large language models—supports MDT preparation and deliberation. Across cancers, reported agreement between AI recommendations and MDT decisions commonly ranges from 70% to 90%, and task-focused tools achieve high diagnostic performance in screening and staging. Benefits include faster information synthesis, more consistent guideline alignment, and clearer documentation of options, while human review remains central. Key limitations—data bias, uneven generalizability, privacy and governance concerns, and limited prospective validation—temper adoption. We outline implementation priorities: prospective multicenter evaluation, integration with electronic records, clinician training, and transparent oversight. Overall, AI can augment MDT decision-making and help personalize care and workflow efficiency when deployed with rigorous evaluation and safeguards.",Health sciences | Medical informatics,0,2025,behavior,behavior+policy
437,2-s2.0-105026653563,10.1145/3761820,https://doi.org/10.1145/3761820,https://scholar.google.com/scholar?q=10.1145/3761820,ar,Digital Government Research and Practice,"Alamsyah, Andry;Aryfiyanto, Hary",Leveraging Generative AI for Public Service Innovation: A Path to Smart Government in Indonesia,"Generative AI has emerged as a transformative technology capable of reshaping public sector operations by streamlining administrative tasks, enhancing data analytics, and driving more personalized citizen interactions. Despite its potential, a critical gap remains in understanding how generative AI can be effectively integrated into government processes, particularly in developing countries like Indonesia, where bureaucratic inefficiencies and infrastructural constraints persist. This study addresses this gap by conducting a mixed-method investigation that combines a Systematic Literature Review (SLR) of generative AI applications across multiple sectors to inform public service innovation, with expert interviews from key stakeholders Indonesian government, academic, and industry. The findings indicate that generative AI holds substantial promise for reducing manual processes, improving inter-agency coordination, and fostering data-driven decision-making. However, challenges related to ethical considerations, data privacy, and limited digital infrastructure present significant barriers to widespread adoption. By proposing a governance framework and offering strategic recommendations tailored to the Indonesian context, this research provides actionable insights for policymakers, government agencies, and technology providers. In doing so, it contributes to the evolving discourse on AI-driven public service innovation and offers a pathway toward realizing a more efficient and citizen-focused smart government in Indonesia.",AI governance | automated workflow | bureaucratic inefficiencies | Generative AI | public service innovation | smart government in indonesia,0,2025,behavior,behavior+policy
438,2-s2.0-105024984153,10.3346/jkms.2025.40.e341,https://doi.org/10.3346/jkms.2025.40.e341,https://scholar.google.com/scholar?q=10.3346/jkms.2025.40.e341,ar,Journal of Korean Medical Science,"Fedorchenko, Yuliya;Zimba, Olena",Ethical Use of Artificial Intelligence for Processing Medical Images,"Artificial intelligence (AI) tools employ prompts and algorithms to perform tasks that typically require human expertise, hypothesis formulation, and critical evaluation. AI enables rapid analysis of complex imaging data, automates segmentation and lesion detection, and supports real-time image-guided interventions. Deep learning architectures (CNNs, RNNs, U-Net, and transformer-based models) facilitate advanced image classification, reconstruction, and interpretation, achieving clinical accuracies above 90% in multiple domains, including coronavirus disease 2019, oncology, and rheumatology. Generative AI platforms (MedGAN, StyleGAN, CycleGAN, SinGAN-Seg) further support synthetic image creation and dataset augmentation, mitigating data scarcity while preserving patient privacy. However, the integration of AI in healthcare presents significant ethical challenges. Key concerns include algorithmic bias, patient privacy, transparency, accountability, and equitable access. Biases—such as annotation, automation, confirmation, demographic, and feedback-loop bias—can compromise diagnostic reliability and patient outcomes. Ethical deployment requires rigorous data governance, informed consent, anonymization, standardized validation frameworks, human oversight, and regulatory compliance. Maintaining interpretability and transparency of AI outputs is essential for clinical decision-making, while professional training and AI literacy are critical to mitigate overreliance and ensure patient safety.",Artificial Intelligence | Diagnostic Imaging | Ethics | Generative AI Platforms,0,2025,behavior,behavior+policy
439,2-s2.0-105024138071,10.36868/IJCS.2025.04.19,https://doi.org/10.36868/IJCS.2025.04.19,https://scholar.google.com/scholar?q=10.36868/IJCS.2025.04.19,ar,International Journal of Conservation Science,"Wójtowicz-Wróbel, Agnieszka;Ciepiela, Agnieszka;Blazy, Rafał;Papież, Renata;Kulis, Dominik;Przesmycka, Elżbieta;Dumitru, Gabriela;Sandu, Ion","CHANGING FUNCTION AS AN OPPORTUNITY TO PRESERVE HISTORIC SITES: A STUDY OF SZCZAWNICA USING ENVIRONMENTAL, SOCIAL AND CORPORATE GOVERNANCE (ESG) INSTRUMENTS AND ARTIFICIAL INTELLIGENCE (AI) TOOLS","The aim of this article is to develop methods for adapting historic buildings while maintaining their historical values, while implementing the principles of Environmental Social Corporate Governance (ESG) and using intelligent design decision support systems. The authors decided to investigate the extent to which artificial intelligence (AI) can support the design and decision-making process in the adaptation of historic buildings without direct expert involvement. Two historic villas located in Szczawnica, a small spa town in southern Poland, were analyzed. An urban planning and conservation analysis was conducted, also considering ESG principles in the context of financing renovations. Next, using a multi-agent AI architecture, the heritage documentation was analyzed, which formed the basis for simulating three adaptation scenarios for the given buildings: Conservative, Liberal, and Balanced. Of these, the latter received the highest weighted score, best combining heritage protection, functionality, and cost-effectiveness. The results indicate that AI correctly classifies data from heritage records, but it clearly requires expert review and verification—particularly in assessing the importance of elements, terminology, and visual representation of objects. Artificial intelligence is therefore a valuable tool in planning the adaptation of historic buildings, but the role of the architect and conservator remains crucial. At the same time, integrating AI with ESG principles and blended finance mechanisms can significantly increase the effectiveness of heritage financing and protection in small towns.",Artificial intelligence (AI) | Blended finance mechanism | conservation | ESG-compliant financing | Human-AI collaboration | SPA town | Urban planning,0,2025,behavior,behavior+policy
440,2-s2.0-105025667165,10.52028/rbadr.v7.i14.ART14.IN,https://doi.org/10.52028/rbadr.v7.i14.ART14.IN,https://scholar.google.com/scholar?q=10.52028/rbadr.v7.i14.ART14.IN,ar,Revista Brasileira De Alternative Dispute Resolution,"Pachahara, Shantanu","AI toolkit for arbitrators: Determining acceptable, undesirable, and egregious applications in an era of evolving AI regulations","Taking into account the rapid development of technology and the swift integration of artificial intelligence (AI) in all aspects of human life, including law and justice and the process of dispute resolution, such as international commercial arbitration (ICA). This article, by adopting a qualitative analytical methodology, analyses whether arbitrators can utilise AI-based large language models and AI agents for their pivotal functions of analysing pleadings, assessing documentary evidence, and legal decision-making. The central thesis of this article is that an arbitrator’s use of AI introduces technological risks, which subsequently generate legal risks in arbitration and thereby jeopardise the arbitrator’s legal duty as well as the enforceability of the award. Thus, this article explores the acceptable, undesirable, and egregious use of AI by arbitrators in ICA. At first, the author establishes the current legal framework of the ICA and the prevailing guidelines for the usage of AI in arbitration. Subsequently, the author critically analyses each such use case, bringing out the technological challenges and the subsequent legal risks that are attached to such usage of AI by the arbitrator in the conduct of arbitral proceedings. Lastly, the author concludes by explaining how arbitrators can safely leverage and integrate the use of AI in arbitration while avoiding its potential risks and challenges.",Arbitration | Arbitrator | Artificial Intelligence | Integration | Risks | Technology,0,2025,behavior,behavior+policy
443,2-s2.0-105026237090,10.1186/s12910-025-01323-0,https://doi.org/10.1186/s12910-025-01323-0,https://scholar.google.com/scholar?q=10.1186/s12910-025-01323-0,ar,BMC Medical Ethics,"İçen, Sarper;Köken, Arif Hüdai",Artificial intelligence guidance in ethically challenging clinical scenarios in child and adolescent psychiatry: a qualitative study in the context of Turkiye,"Background: Ethical decision-making in child and adolescent psychiatry (CAP) is inherently complex, shaped by developmental vulnerability, evolving autonomy, and competing responsibilities to patients, families, and the legal system. Clinicians often face moral dilemmas when navigating adolescent confidentiality, parental authority, and mandatory reporting duties, especially in high-stakes or culturally sensitive contexts. As large language models (LLMs) enter clinical settings, their potential to support ethical reasoning remains underexplored, particularly outside Western paradigms. This study qualitatively investigates how different LLMs provide ethical, legal, and emotional guidance to clinicians facing ethically challenging scenarios in CAP, situated within Turkiye’s sociocultural and legal landscape. Method: A scenario-based qualitative design was employed. Three expert-developed case vignettes reflecting ethically charged dilemmas, such as adolescent autonomy, parental conflict, and confidentiality, were submitted to the three LLMs (ChatGPT 4.0, Gemini 2.5 Flash, and GROK 3). Responses were analyzed using content and thematic analysis to identify key patterns of ethical-legal reasoning, alongside discourse analysis to examine tone, empathy, and cultural sensitivity. Two researchers, with backgrounds in CAP and medical ethics, conducted independent coding and reached consensus through a reflexive, interdisciplinary approach. Results: All LLMs addressed core ethical principles (autonomy, non-maleficence, beneficence, and justice) and referenced Turkish legal frameworks such as the Child Protection Law, Patient Rights Regulation, and mandatory reporting obligations, situating their guidance within the national regulatory context. They also differed in their engagement with sociocultural sensitivities: GROK 3 emphasized therapeutic communication and relational trust, Gemini 2.5 Flash applied a highly structured, rule-based style focused on procedural compliance, while ChatGPT 4.0 provided concise and practical suggestions. Despite thematic overlaps, these varying approaches shaped how effectively the models aligned with Turkiye’s clinical realities. Notably, LLMs frequently acted as “thinking companions,” offering ethical and legal justifications while leaving interpretive responsibility with clinicians. Conclusion: LLMs in CAP hold promise not only as cognitive aids but also as emotionally attuned, context-sensitive companions in ethical decision-making processes. Their effectiveness depends not just on algorithmic precision but also on explainability, empathy, and cultural alignment. Rather than replacing clinician judgment, LLMs may serve to ease emotional burden, enhance therapeutic reflection, and foster ethically sound care in complex, high-pressure situations.",Accountability | Artificial intelligence | Autonomy | Child and adolescent psychiatry | Clinical decision support systems | Confidentiality | Cultural sensitivity | Ethical decision-making | Explicability | Large language models | Medical ethics,0,2025,behavior,behavior+policy
444,2-s2.0-105025977708,10.3390/jmse13122275,https://doi.org/10.3390/jmse13122275,https://scholar.google.com/scholar?q=10.3390/jmse13122275,re,Journal of Marine Science and Engineering,"Wu, Yizhou;Liu, Jin;Li, Xingye;Xiao, Junsheng;Zhang, Tao;Xu, Haitong;Zhang, Lei",Towards LLM Enhanced Decision: A Survey on Reinforcement Learning Based Ship Collision Avoidance,"This comprehensive review examines the works of reinforcement learning (RL) in ship collision avoidance (SCA) from 2014 to the present, analyzing the methods designed for both single-agent and multi-agent collaborative paradigms. While prior research has demonstrated RL’s advantages in environmental adaptability, autonomous decision-making, and online optimization over traditional control methods, this study systematically addresses the algorithmic improvements, implementation challenges, and functional roles of RL techniques in SCA, such as Deep Q-Network (DQN), Proximal Policy Optimization (PPO), and Multi-Agent Reinforcement Learning (MARL). It also highlights how these technologies address critical challenges in SCA, including dynamic obstacle avoidance, compliance with Convention on the International Regulations for Preventing Collisions at Sea (COLREGs), and coordination in dense traffic scenarios, while underscoring persistent limitations such as idealized assumptions, scalability issues, and robustness in uncertain environments. Contributions include a structured analysis of recent technological evolution, and a Large Language Model (LLM) based hierarchical architecture integrating perception, communication, decision-making, and execution layers for future SCA systems, which prioritizes the development of scalable, adaptive frameworks that ensure robust and compliant autonomous navigation in complex, real-world maritime environments.",COLREGs compliance | large language model | multi-agent reinforcement learning | reinforcement learning | ship collision avoidance,0,2025,behavior,behavior+policy
445,2-s2.0-105024541715,10.26803/ijlter.24.12.32,https://doi.org/10.26803/ijlter.24.12.32,https://scholar.google.com/scholar?q=10.26803/ijlter.24.12.32,ar,International Journal of Learning Teaching and Educational Research,"Perante, Wenceslao C.;Oquino, Vinyl H.;Cidro, Mark Kevin T.;Perante, Wilferd A.;Barquin, Glenda M.;Gomba, Felisa E.","Utilization of Artificial Intelligence Tools in Engineering Education among HEIs in Eastern Visayas, Philippines","This study investigates the ways in which engineering faculty members and students in Eastern Visayas, Philippines, adopt and use artificial intelligence (AI) tools, assistants, and generative applications within teaching and learning. Using a quantitative descriptive– correlational design with purposive sampling, we surveyed 44 faculty members and 391 students across EVSU, SSU, ESSU, and BiPSU (formerly NIT/NSU) and analyzed responses using descriptive statistics, correlation tests, and group comparisons. Findings show broadly similar overall adoption rates between faculty members and students (no significant difference), but highlight role-specific patterns: faculty members more often use AI for grading automation, classroom management, and content verification, while students use AI more for computer-aided design, simulation, and creative outputs. Results revealed generally similar adoption rates between faculty members and students, with ChatGPT being the most widely used generative AI tool (Faculty: 94.1%; Students: 91.6%) and academic writing support being the most common purpose (Faculty: 67.6%; Students: 79.8%). Shared concerns include data privacy/security, ethical use, and usability/complexity. The study contributes: (1) a regional evidence base for AI adoption in engineering education; (2) an integrated TAM–IDT framework operationalized for HEI decision-making; and (3) role-specific implications for training, governance, and curriculum. We recommend institution-wide governance on responsible AI use, targeted capacity-building for faculty and students, and AI-literacy embedded in engineering curricula.",Artificial Intelligence | Engineering Education | Higher Education Institutions | Innovation Diffusion Theory | Technology Acceptance Model,0,2025,behavior,behavior+policy
446,2-s2.0-105023912488,10.1007/s40572-025-00514-6,https://doi.org/10.1007/s40572-025-00514-6,https://scholar.google.com/scholar?q=10.1007/s40572-025-00514-6,re,Current Environmental Health Reports,"Luechtefeld, Thomas;Hartung, Thomas","Navigating the AI Frontier in Toxicology: Trends, Trust, and Transformation","Purpose of Review: The integration of artificial intelligence (AI) into toxicology marks a profound paradigm shift in chemical safety science. No longer limited to automating traditional workflows, AI is redefining how we assess risk, interpret complex biological data, and inform regulatory decision-making. This article explores the convergence of AI and other new approach methodologies (NAMs), emphasizing key trends such as multimodal learning, causal inference, explainable AI (xAI), generative modeling, and federated learning. Recent Findings: These technologies enable more human-relevant, mechanistically grounded, and ethically aligned toxicological predictions—surpassing the reproducibility and scalability of animal-based methods. However, the dynamic nature of AI models challenges traditional validation paradigms. To address this, we introduced the e-validation framework, which operationalizes the TREAT principles (Trustworthiness, Reproducibility, Explainability, Applicability, Transparency) and incorporates AI-powered modules for reference chemical selection, virtual study simulation, mechanistic cross-validation, and post-validation surveillance through companion agents. Ethical considerations—including bias audits, equity audits, and participatory governance—are also foregrounded as critical elements for responsible AI adoption. The emergence of a co-pilot model, where AI augments but does not replace human judgment, offers a pragmatic path forward. Supported by evidence from the 2025 Stanford AI Index and recent regulatory advances, we argue that the infrastructure, economics, and policy momentum are now aligned for global-scale deployment of AI-based toxicology. Summary: The future of the field lies not in replicating legacy practices, but in reinventing toxicology as an adaptive, transparent, and ethically grounded science that delivers more accurate, inclusive, and human-centric safety assessments. Lay Summary: Artificial intelligence (AI) is changing how we test chemicals for safety. Instead of using animals, new computer-based tools can predict how substances affect human health more quickly, accurately, and ethically. This article looks at how these technologies—like smart data systems, models that explain their reasoning, and even AI ""agents"" that run simulations—can improve toxicology. We also introduce a new idea called ""e-validation"", which uses AI to help validate these methods in real-time, not just once. This ensures the models stay up to date and reliable. But using AI safely means tackling big questions: Can we trust results we don't fully understand? How do we prevent unfairness or bias in the data? We suggest a ""co-pilot"" model, where AI supports, but doesn't replace, human experts. With better data sharing, strong ethics, and smarter oversight, AI can help make chemical safety testing more human-focused, fair, and effective.",Artificial Intelligence (AI) | Bias audit | Causal modeling | Chemical risk assessment | Digital twins | e-Validation | Ethical toxicology | Explainable AI (xAI) | Federated learning | Human relevance | New Approach Methodologies (NAM) | Regulatory science | Responsible AI | Toxicology | TREAT principles,0,2025,behavior,behavior+policy
447,2-s2.0-105023515440,10.1186/s41239-025-00570-w,https://doi.org/10.1186/s41239-025-00570-w,https://scholar.google.com/scholar?q=10.1186/s41239-025-00570-w,ar,International Journal of Educational Technology in Higher Education,"Auwal, Aminu Muhammad",Autonomy versus algorithm: a replication study of student perspectives on AI ethical boundaries,"The widespread adoption of generative artificial intelligence (AI) tools in higher education has intensified the need to address their ethical implications. Building on a prior study of undergraduate perspectives on AI ethics, this research surveyed 200 undergraduates from multiple academic disciplinesat universities in Nigeria to explore their agreement with five AI ethics dimensionsbeneficence, non-maleficence, justice, autonomy, and explicabilityusing generative AI tools as the reference point. A mixed-method approach combined quantitative measures with qualitative explanations of participants’ views. Results indicated that autonomy received the highest agreement, while explicability was rated lowest, suggesting students were less concerned about the transparency of AI processes than about maintaining independent decision-making. Multiple regression analysis identified technology proficiency as a significant predictor of beneficence and gender as a predictor of non-maleficence, while academic level showed no significant influence. Thematic analysis revealed concerns about misinformation, erosion of creativity, job displacement, bias in AI outputs, and privacy risks, alongside counter-arguments emphasizing personal responsibility and trust in AI developers. These findings highlight the need for tailored ethical guidelines, targeted awareness initiatives, and integration of AI ethics into higher education curricula to foster informed and responsible AI use. By situating the research in the Nigerian higher education context, this study also considers how regional differences in educational systems, technology access, and cultural perspectives may shape attitudes toward AI ethics.",AI ethics | Autonomy | Explicability | Generative AI | Higher education | Undergraduate perspectives,0,2025,behavior,behavior+policy
448,2-s2.0-105023307458,10.1016/j.sasc.2025.200421,https://doi.org/10.1016/j.sasc.2025.200421,https://scholar.google.com/scholar?q=10.1016/j.sasc.2025.200421,re,Systems and Soft Computing,"Aminou, Loubna;Daaif, Abdelaziz;Soulami, Maha;Chalfaouat, Abderrahim;Youssfi, Mohamed",Are cutting-edge technologies transforming classical approaches in automated hiring systems ? A systematic literature review,"Automated hiring systems have increasingly incorporated intelligent models to support candidate evaluation and decision-making. Yet, integrating state-of-the-art models into real hiring workflows remains limited, constraining both potential business gains and ethical alignment, and so significant uncertainty addresses whether cutting-edge technologies have actually displaced classical approaches in practice. To examine this question, we conducted a systematic literature review of 40 peer-reviewed studies (2017-2024), following the PRISMA methodology across six academic databases. Quantitative analysis shows that machine learning models still dominate (≃45 %), followed by MCDM methods, while LLMs and hybrid systems represent less than 20% of practical implementations. Despite rapid technological advances, implementing state-of-the-art models into real-world applications remains limited, often constrained by data accessibility, ethical accountability, and cost of deployment. Overall, the review highlights a technological expectation gap between research innovation and industry application, underlining the need for empirical validation, standardized evaluation protocols, and socio-technical governance to ensure reliable, equitable, and interpretable intelligent hiring systems.",Algorithmic decision-making | Artificial Intelligence | Cutting-edge technologies | Personnel selection | Systematic literature review,0,2025,behavior,behavior+policy
450,2-s2.0-105022610387,10.1007/s44163-025-00608-y,https://doi.org/10.1007/s44163-025-00608-y,https://scholar.google.com/scholar?q=10.1007/s44163-025-00608-y,ar,Discover Artificial Intelligence,"Astobiza, Aníbal M.",Do AI agents trump human agency?,"Artificial agents are examined within simulated environments to elucidate the emergence of collective behaviors and decision-making processes under diverse environmental pressures and population structures. Using an Agent-Based Modeling (ABM) framework, the simulation tracked 157,097 iterations across four agent types: cooperators, defectors, super-reciprocators, and free riders; while analyzing 12 core metrics, including alignment indices, coherence, and environmental stress. The results revealed distinct phase transitions in behavior, with low-density populations (d < 0.4) supporting strong consensus formation and higher densities (d > 0.8) leading to fragmentation and increased competition. Agent alignment consistently ranged between 0.28 and 0.37, reflecting partial but stable consensus across conditions. Cooperative behaviors emerged and persisted only when resource availability exceeded a critical threshold (RG ≥ 6), underscoring the role of resource abundance in sustaining collective intelligence. Through interventions such as network topology changes and cognitive plasticity adjustments, agents demonstrated emergent behavioral patterns that arose from their rule-based interactions. It is important to note that these patterns, while complex, do not constitute “sophisticated decision-making” in the sense of genuine intelligence or understanding. Rather, they represent emergent properties of the system, collective behaviors that cannot be reduced to individual agent rules but emerge from their interactions under specific environmental conditions. This distinction is crucial for avoiding misattribution of intelligence to rule-following systems, even when those systems produce complex outputs. These findings provide insights into the mechanisms driving emergent intelligence in artificial systems and their implications for the governance and ethical design of future AI agents.",AI ethics | Artificial intelligence | Decision-making | Human agency | Misaligned AI | Obsolescence regime,0,2025,behavior,behavior+policy
451,2-s2.0-105022519746,10.3168/jds.2025-26775,https://doi.org/10.3168/jds.2025-26775,https://scholar.google.com/scholar?q=10.3168/jds.2025-26775,ar,Journal of Dairy Science,"Liu, E.;Yang, H.;Sharma, S.;van Leerdam, M. B.;Niu, P.;VandeHaar, M. J.;Hostens, M.",Agents are all you need: Pioneering the use of agentic artificial intelligence to embrace large language models into dairy science,"Large language models (LLM) hold significant promise to transform dairy science by enhancing research interpretation, supporting decision making, and improving knowledge dissemination. However, without proper systematic design, LLM may generate irrelevant or factually inaccurate responses for domain-specific questions. Moreover, most existing LLM and related tools are not tailored to the needs of the dairy domain, limiting their practical application within the field. To demonstrate the feasibility and practical value of embracing LLM in dairy science, we developed a 2-component agentic system: (1) a decision-support chatbot grounded in the Journal of Dairy Science (JDS) for science-backed insights and (2) a natural language interface for interacting with academic models and visualizing prediction results. All publicly available JDS abstracts and associated metadata dating back to 1917 were compiled using the PubMed application programming interface, forming a scientific knowledge base that enables the chatbot to answer user questions. A retrieval-augmented generation framework was implemented to ensure that responses generated by LLaMA (a LLM developed by Meta) were well-grounded in peer-reviewed literature, with the 5 most relevant sources cited alongside each answer. To address questions beyond the coverage of JDS literature, a web search agent was incorporated into the system to retrieve supplementary information from external online sources. Grading agents, powered by DBRX (a LLM developed by Databricks), were incorporated to evaluate the credibility and relevance of LLM-generated content to mitigate the risk of misinformation or hallucinated responses. The second component of the system facilitates natural language interaction with MilkBot, a published Bayesian milk yield prediction model. After users submit questions in plain language, the system converts the question into model parameters for MilkBot, executes the model prediction, and uses the predicted output to generate visualizations. This work demonstrates the capability of LLM to serve as intuitive, user-friendly interfaces for dairy-specific models. To our knowledge, this is the first chatbot prototype that integrates large-scale information from scientific literature, web-based resources, and academic models, along with self-evaluation capability, to provide dairy-specific insights to scholars, consultants, and farmers. However, challenges remain to realize the full value of LLM-assisted decision making, such as the lack of region-specific data to tailor the answers to the local circumstances, the need for more robust measures to protect data security and privacy, and the need to integrate additional functions to enable more comprehensive decision support.",agentic AI | artificial intelligence in dairy science | decision-support system | large language model,0,2025,behavior,behavior+policy
452,2-s2.0-105021348640,10.1016/j.caeo.2025.100306,https://doi.org/10.1016/j.caeo.2025.100306,https://scholar.google.com/scholar?q=10.1016/j.caeo.2025.100306,ar,Computers and Education Open,"Aldemir, Tugce;Kilinc, Selcuk;Bicer, Ali;Grant, Patricia;Davis, Trina;Sweany, Noelle Wall",Intelligent‑TPACK in practice: design and evidence from a three‑week teacher preparation module,"Rapid advances in generative AI sharpen the need for teachers to develop pedagogical and ethical capacities for AI‑integrated instruction. While Technological Pedagogical Content Knowledge (TPACK) provides a valuable framework for technology integration, it does not fully capture AI's unique complexities. This study presents an integrated i‑TPACK approach that extends Intelligent‑TPACK by adding AI‑as‑content (i‑CK) and AI‑for‑professional development (i‑PD) and by threading a five‑stage AI‑literacy progression (Know→ Use→ Evaluate→ Ethics→ Create) within each domain, treating ethics as distributed and iterative. We designed and examined a three-week professional development module for preservice teachers using a convergent mixed-methods design. Pre–post surveys (n = 25 matched pairs) with a six‑subscale Integrated i‑TPACK instrument showed statistically significant gains across all domains (Wilcoxon, Holm‑adjusted; medium‑to‑large effects). Qualitative analyses of lesson artifacts, decision logs, reflections, and micro-teaching documented instances of layered ethical decision-making (privacy/data governance, bias/fairness, transparency/provenance/accountability), progression along the AI literacy stages, and discipline-aligned pedagogical designs. Embedding an ethical decision‑making checkpoint across performance‑based activities made ethics visible in teacher work and coincided with more explicit safeguards and verification steps in lesson artifacts and micro‑teaching within the module. By detailing this empirically grounded model, our study offers theoretical and practical insights for teacher educators seeking to cultivate principled GenAI-supported instruction.",AI literacy | AI-TPACK | Ethics | Intelligent-TPACK | Teacher education,0,2025,behavior,behavior+policy
453,2-s2.0-105016275434,10.1186/s13014-025-02721-9,https://doi.org/10.1186/s13014-025-02721-9,https://scholar.google.com/scholar?q=10.1186/s13014-025-02721-9,ar,Radiation Oncology,"Konnerth, Dinah;Altay-Langguth, Alev;Dehelean, Diana Coralia;Maier, Sebastian H.;Pazos, Montserrat;Rogowski, Paul;Schönecker, Stephan;Eze, Chukwuka;Corradini, Stefanie;Belka, Claus;Marschner, Sebastian N.","CHAT-RT study: ChatGPT in radiation oncology—a survey on usage, perception, and impact among DEGRO members","Background: Radiation oncology is increasingly turning to Artificial Intelligence (AI) - and in particular Chat Generative pre-trained transformer (ChatGPT) - for decision support, patient education, and workflow efficiency. Despite promising gains, questions about accuracy, General Data Protection Regulation (GDPR)-compliance and ethical use persist, especially in high-stakes cancer care. To clarify real-world attitudes and practices, we surveyed members of the German Society of Radiation Oncology (DEGRO) on their use, perceptions, and concerns regarding ChatGPT across clinical, research, communication, and administrative tasks. Methods: An anonymous online survey was implemented via LimeSurvey platform and distributed to all members of the DEGRO in Germany, Austria, and Switzerland between April and June 2024. The 40-item questionnaire—covering demographics, radiotherapy experience, and ChatGPT’s clinical, research, communication, and administrative applications—was developed through a narrative literature review, ChatGPT-assisted drafting, back-translation, expert validation, and pilot testing. Fully completed responses were used for descriptive statistics and analysis. Results: Of 213 respondents, 159 fully completed the survey. Participants were predominantly based in Germany (92.5%), worked in university hospitals (74.2%), and identified as radiation oncologists (54.7%), with a broad range of radiotherapy experience (< 1 year: 7.5%; >15 years: 24.5%). Awareness of ChatGPT was high (94.9%), yet actual use varied: 32.1% never used it, while 35.2% employed it regularly for administrative tasks and 30.2% for manuscript drafting. Mid-career clinicians (6–10 years’ experience) showed the greatest enthusiasm—44% agreed it saves time and 72% planned further integration—though all career stages (71.7% overall) expressed strong interest in formal training. Satisfaction was highest for administrative (94.6%) and manuscript support (91.7%) but lower for technical queries (66.7%). Major concerns included misinformation (69.2%), erosion of critical thinking (57.9%), and data-privacy risks (57.2%). Conclusion: Our survey demonstrates high awareness and adoption of ChatGPT for administrative and educational tasks, alongside more cautious use in clinical decision-making. Widespread concerns about misinformation, critical-thinking erosion, and data privacy—especially among early- and mid-career clinicians—underscore the need for targeted AI training, rigorous validation, and transparent governance to ensure safe, effective integration into patient care.",CHAT-GPT | DEGRO | LLM | Questionnaire | Radiation oncology,0,2025,behavior,behavior+policy
454,2-s2.0-105015043471,10.1016/j.caeai.2025.100468,https://doi.org/10.1016/j.caeai.2025.100468,https://scholar.google.com/scholar?q=10.1016/j.caeai.2025.100468,ar,Computers and Education Artificial Intelligence,"Chia, Joanne;Frattarola, Angela",A design-based approach to analysing student engagement with a GenAI-Enabled brainstorming app,"While there are several “writing buddy” Generative Artificial Intelligence (GenAI) apps that check grammar and language usage, not many focus exclusively on enhancing the brainstorming process for writing across disciplines. To fill this gap, a team of staff and student assistants with programming and User Interface (UI) and User Experience (UX) expertise designed and prototyped a web app named “Waai,” which rhymes with ‘why,’ that could assist students throughout the writing process for a first-year general writing module for all undergraduate students at a Singaporean university. Utilising surveys, focus group discussions, and app data that shows the nature and type of student engagement with the Waai app, this paper studies the impact of one aspect of the Waai app, an uni-directional chatbot named “Nudgy,” as a first step to optimising interactions with an AI chatbot for writing purposes. Overall, we found that students were able to benefit from the GenAI chatbot Nudgy in 5 distinct ways: 1) its pre-engineered prompts, which were tailored to the course assignment rubrics; 2) its tendency to recommend topics to research rather than give students answers; 3) its suggested research topics, which helped students to consider different perspectives on their topics; 4) how it modelled ways to ideate new insights; and 5) its constant availability. Students, however, expressed reservations about the Nudgy, particularly in terms of: 1) the limitations of pre-engineered prompts within the app; 2) difficulty in discerning the most relevant of the Nudgy feedback; 3) mistrust in GenAI and Aigiarism; and 4) a recognition of the limitations of GenAI in supporting argumentative writing. “Waai” essentially presents a decision-making framework for brainstorming based on cognitive socialisation, a method of learning that emphasises inductive as opposed to deductive experience that could be applied to online environments, as an ideology of learning that considers, among other aspects, the development of selfhood, where learning is both guided and mediated (Kesebir & Gardner, 2010). In the context of asynchronous learning, meaning is not intrinsic but rather picked up through interactions on online platforms. Interacting with a chatbot with pre-designed prompts result in a ritual that both define and explore the limits of knowledge building. Symbolic interactionism (Aksan et al., 2009) through the medium of technology is a key objective of 21st century education, where ‘learning’ is internalised as an individual experience. Waai offers educatros additional understanding of the effects of personalization (Mygland et al., 2021) as proposed by this design-based study of the role of instruction in the creation of online ‘learning’ experiences. The centrality of instruction and standards of reasoning through the process of brainstorming suggests that the developmental stages of ‘learning’ concepts could empower a process for self-regulation (Zimmerman, 1989) that goes beyond immediate causes and effects to inspire a spiral of reflection and change essential to ideation.",Customised apps | Data storytelling | Design thinking | Faculty and student collaborations | GenAI for education | Human-AI interactions | Personalization in technology | Student engagement | Technological use and innovation in institutes of higher learning | Writing assistant apps,0,2025,behavior,behavior+policy
455,2-s2.0-105013687615,10.1186/s40537-025-01236-0,https://doi.org/10.1186/s40537-025-01236-0,https://scholar.google.com/scholar?q=10.1186/s40537-025-01236-0,ar,Journal of Big Data,"Wei, Yijin;Fan, Jingchao",Chat-rgie: precision extraction of rice germplasm data using large language models and prompt engineering,"Varietal improvement is a key aspect of breeding, and as a result of this work, crop varietal data becomes more complicated, requiring more resources to extract. As a result, we developed Chat-RGIE, a rice germplasm data extraction strategy based on conversational large language models (LLM) and cue word engineering, to achieve rice germplasm data extraction in a ZERO-shot manner. The technique employs multi-response voting to limit the chance of phantom appearances, as well as an additional calibration component to choose the best data extraction findings. We performed performance evaluation and real-life data extraction evaluation on Chat-RGIE, and the scheme obtained 0.9102 precision, 0.9941 recall, and 0.9554 accuracy in performance evaluation, and 0.6351 precision, 1.0 recall, and 0.8225 accuracy in real-life data extraction evaluation, which completely proved the effectiveness of the scheme. Furthermore, the well-designed data extraction procedure mitigates the likelihood of potential bias from a single large model leading to hallucinations to some extent, with the incidence of hallucinations in the two evaluations being 0.0015 and 0.005, respectively, with a very minor influence. Furthermore, we employed Restraint Rate, a statistic used to quantify the degree of limits placed by the prompt on LLM replies, with values of 0.9265 and 0.911 in the two evaluations, resulting in normative responses. Furthermore, when we examined the data extraction results, we discovered that when confronted with an unanswerable answer, the LLM is affected by the stress provided by the prompt, and the higher the stress, the more likely it is to engage in constraint-violating behavior, which is similar to what humans do when stressed. We therefore believe that some of the countermeasures in the human behavior in question also have the potential to help improve LLM performance.",Agriculture | Data extraction | Large language model (LLM) | Rice germplasm,0,2025,behavior,behavior+policy
456,2-s2.0-105013591335,10.1053/j.jvca.2025.07.026,https://doi.org/10.1053/j.jvca.2025.07.026,https://scholar.google.com/scholar?q=10.1053/j.jvca.2025.07.026,re,Journal of Cardiothoracic and Vascular Anesthesia,"Jia, Ying Ying;Pang, Lin Yan;Bi, Ming Ming;Yang, Xiang Lu;Song, Jian Ping",Dependability of Large Language Models in Cardiovascular Medicine: A Scoping Review,"Background: The adoption of large language models (LLMs) in both clinical and consumer healthcare settings has surged exponentially. However, there remains limited evidence on their reliability and impact in cardiovascular practice. Objectives: This scoping review was designed to consolidate the existing biomedical literature on applicability, reliability, and quality improvement strategies for the integration of LLMs into the cardiovascular domain. Following Cochrane methodology and Preferred Reporting Items for Systematic Reviews and Meta-analyses guidelines, three electronic databases (PubMed, Web of Science, and Embase) were systematically searched to identify pertinent studies published between August 2020 and February 2025. Articles addressing the development, implementation, and assessment of LLMs in cardiovascular medicine were selected for comprehensive analysis. Results: Twenty-five eligible publications evaluated the performance of LLMs in responding to cardiology-related questions, encompassing parameters such as accuracy, response latency, indirectness, completeness, and so on. The assessment methodology varied considerably across studies. LLMs demonstrated potential utility in cardiovascular decision-making, myocarditis management, cardiac arrest diagnosis and treatment, and image differentiation. Conclusions: Although some LLM-generated responses to cardiovascular-related questions exhibit acceptable levels of quality, significant drawbacks persist. These include verbosity, inaccuracies, occasional misinformation, inconsistent outputs to identical questions, bias, and poor reproducibility. Overall, this work highlights the urgent need for continued refinement and validation.",cardiovascular | ChatGPT | generative artificial intelligence | large language models | reliability | trustworthiness,0,2025,behavior,behavior+policy
458,2-s2.0-105011692471,10.1186/s12903-025-06648-1,https://doi.org/10.1186/s12903-025-06648-1,https://scholar.google.com/scholar?q=10.1186/s12903-025-06648-1,ar,BMC Oral Health,"Zhu, Guohui;Zhang, Xiao;Chen, Chunxia",Assessing and enhancing the reliability of Chinese large language models in dental implantology,"Background: This study aimed to evaluate the reliability of five representative Chinese large language models (LLMs) in dental implantology. It also explored effective strategies for model enhancement. Methods: A dataset of 100 dental implant-related questions (50 multiple-choice and 50 open-ended) was developed, covering medical knowledge, complex reasoning, and safety and ethics. Standard answers were validated by experts. Five LLMs—A: BaiXiaoYing, B: ChatGLM-4, C: ERNIE Bot 3.5, D: Qwen 2.5, and E: Kimi.ai—were tested using two metrics: recall and hallucination rate. Two enhancement techniques, chain of thought (CoT) reasoning and long text modeling (LTM), were applied, and their effectiveness was analyzed by comparing the metrics before and after the application of these techniques. Data analysis was conducted using SPSS software. ANOVA with Tukey HSD tests compared recall and hallucination rates across models, while paired t-tests evaluated changes before and after enhancement strategies. Results: For multiple-choice questions, Group D (Qwen 2.5) achieved the highest recall at 0.9060 ± 0.0087, while Group C (ERNIE Bot 3.5) had the lowest hallucination rate at 0.1245 ± 0.0022. For open-ended questions, Group D maintained the highest recall at 0.7938 ± 0.0216, and Group C exhibited the lowest hallucination rate at 0.2390 ± 0.0029. Among enhancement strategies, chain-of-thought (CoT) reasoning improved Group D’s recall by 0.0621 ± 0.1474 (P < 0.05) but caused a non-significant increase in hallucination rate (0.0390 ± 0.1639, P > 0.05). Long-text modeling (LTM) significantly enhanced recall by 0.1119 ± 0.2000 (P < 0.05) and reduced hallucination rate by 0.2985 ± 0.4220 (P < 0.05). Conclusions: Qwen 2.5 and ERNIE Bot 3.5 demonstrated exceptional reliability in dental implantology, excelling in answer accuracy and minimizing misinformation across question types. Open-ended queries posed higher risks of hallucinations compared to structured multiple-choice tasks, highlighting the need for targeted validation in free-text scenarios. Chain-of-thought (CoT) reasoning modestly improved accuracy but carried the trade-off of potential hallucination increases, while long-text modeling (LTM) significantly enhanced both accuracy and reliability simultaneously. These findings underscore LTM’s utility in optimizing large language models for specialized dental applications, balancing depth of reasoning with factual grounding to support clinical decision-making and educational training.",Chain-of-thought reasoning | Dental implantology | Hallucination rate | Large language models | Long-text modeling | Recall,0,2025,behavior,behavior+policy
466,2-s2.0-105023202235,10.3390/data10110172,https://doi.org/10.3390/data10110172,https://scholar.google.com/scholar?q=10.3390/data10110172,ar,Data,"Gerlich, Michael",From Offloading to Engagement: An Experimental Study on Structured Prompting and Critical Reasoning with Generative AI,"The rapid adoption of generative AI raises questions not only about its transformative potential but also about its cognitive and societal risks. This study contributes to the debate by presenting cross-country experimental data (n = 150; Germany, Switzerland, United Kingdom) on how individuals engage with generative AI under different conditions: human-only, human + AI (unguided), human + AI (guided with structured prompting), and AI-only benchmarks. Across 450 evaluated responses, critical reasoning was assessed via expert rubric ratings, while perceived reflective engagement was captured through self-report indices. Results show that unguided AI use fosters cognitive offloading without improving reasoning quality, whereas structured prompting significantly reduces offloading and enhances both critical reasoning and reflective engagement. Mediation and latent class analyses reveal that guided AI use supports deeper human involvement and mitigates demographic disparities in performance. Beyond theoretical contributions, this study offers practical implications for business and society. As organisations integrate AI into workflows, unstructured use risks undermining workforce decision making and critical engagement. Structured prompting, by contrast, provides a scalable and low-cost governance tool that fosters responsible adoption, supports equitable access to technological benefits, and aligns with societal calls for human-centric AI. These findings highlight the dual nature of AI as both a productivity enabler and a cognitive risk, and position structured prompting as a promising intervention to navigate the emerging challenges of AI adoption in business and society.",AI | cognitive offloading | critical thinking | digital literacy | GenAI | generative artificial intelligence | human–AI interaction | reflective reasoning,0,2025,behavior,behavior+policy
467,2-s2.0-105022092104,10.53829/ntr202511fa7,https://doi.org/10.53829/ntr202511fa7,https://scholar.google.com/scholar?q=10.53829/ntr202511fa7,ar,NTT Technical Review,"Matsuhashi, Akiko;Akiyama, Mitsuaki;Yamanaka, Yuuki;Furutani, Satoshi;Hara, Toru",Collaboration between People and AI to Evolve Security Activities into a New Form for People,"Cyber-attacks targeting systems are intensifying yearly, and the shortage of security personnel is becoming serious. Therefore, a fundamental review of security operations based on automation using artificial intelligence (AI) is required. In today’s information society, it is difficult to maintain people’s autonomous decision-making due to misinformation and disinformation, and the object of security is expanding from systems to human cognition. In this article, we introduce innovative cybersecurity operations using generative AI and cognitive security that supports autonomous human decision-making.",cognitive security | cybersecurity | generative AI,0,2025,behavior,behavior+policy
468,2-s2.0-105021587197,10.3390/math13213463,https://doi.org/10.3390/math13213463,https://scholar.google.com/scholar?q=10.3390/math13213463,ar,Mathematics,"Wang, Yi;Wang, Chengliang;Zhang, Xueqing;Zeng, Li",Towards Intelligent Emergency Management: A Scenario–Learning–Decision Framework Enabled by Large Language Models,"To address the governance challenges of “delayed response, fragmented strategies, and cognitive disconnection” in traditional emergency management, this paper proposes an intelligent framework—Scenario–Learning–Decision (SLD)—powered by Large Language Models (LLMs). The framework integrates Multi-Agent Systems (MAS) and prospect theory-based parameter modeling to build an emergency simulation platform featuring scenario perception, human–AI learning, and collective decision-making. Using the 2022 wildfire in City C as a case study, the research verifies the effectiveness of the SLD model in complex emergency contexts and provides theoretical support and practical pathways for developing human-centered intelligent emergency decision-making systems.",emergency management | large language models | Scenario–Learning–Decision,0,2025,behavior,behavior+policy
469,2-s2.0-105021445309,10.1177/20552076251390004,https://doi.org/10.1177/20552076251390004,https://scholar.google.com/scholar?q=10.1177/20552076251390004,ar,Digital Health,"van Kolfschooten, Hannah;Gonçalves, João;Orchard, Nic;Figueroa, Caroline","AI chatbots for promoting healthy habits: Legal, ethical, and societal considerations","Machine learning-based artificial intelligence (AI) chatbots are increasingly used to promote health and encourage individuals to adopt healthier behaviors. Chatbots driven by generative AI (genAI) simulate human interactions through text or voice to generate personalized content with guidance on topics such as smoking cessation, nutrition, managing stress, and sleep improvement. The use of AI chatbots for health promotion and wellness has been growing since 2023. While empirical evidence suggests their effectiveness in supporting behavioral change and mental health, the legal, ethical, and societal implications remains largely unexplored. This article presents a qualitative case study of S.A.R.A.H. (Smart AI Resource Assistant for Health), a genAI chatbot developed by the World Health Organization (WHO), analyzed against the six ethical principles outlined in the WHO's 2021 Guidance on Ethics and Governance of AI for Health. We also gathered exploratory insights from adolescent focus groups. These findings are descriptive and not based on formal thematic analysis. Drawing on this analysis, we identify key gaps between high-level ethical principles and practice and offer policy recommendations to guide responsible use of AI chatbots for health promotion.",Artificial intelligence | chatbots | prevention | public health | world health organization,0,2025,behavior,behavior+policy
470,2-s2.0-105017845539,10.1007/s00521-025-11600-z,https://doi.org/10.1007/s00521-025-11600-z,https://scholar.google.com/scholar?q=10.1007/s00521-025-11600-z,ar,Neural Computing and Applications,"Patil, Sanjeet S.;Ramteke, Manojkumar;Verma, Mansi;Chandra, Tany;Rathore, Anurag S.",Development of computationally feasible hospital-specific large language models using parameter-efficient and preference alignment techniques,"The healthcare industry is rapidly eyeing data-driven and AI-enabled patient care owing to the promising advancements showcased by large language models (LLMs). However, strict privacy regulations pertaining to data security hamper its deployment in the existing infrastructure. Moreover, LLMs require extensive graphical processing unit (GPU) memory for training and inference, which most hospitals lack. Therefore, developing memory-efficient in-house LLMs is imperative if we wish to achieve wider deployment within the confines of a secure network. To address this, our study proposes a framework for building a memory-efficient medical chatbot capable of answering queries by clinicians related to eight distinct tasks: 1] Named Entity Recognition, 2] Question & Answering, 3] Paraphrasing, 4] Summarization, 5] Abbreviation Expansion, 6] Coreference Resolution, 7] Relation Extraction and 8] Temporal Information Extraction. We have evaluated the efficacy of state-of-the-art LLMs, 1] Llama-3.1-8B, 2] Mistral-2-7B, 3] Llama-2-13B, and 4] DeepSeek-R1-Distill-Llama-3.1-8B on their ability to reason and extract information when fine-tuned with the parameter-efficient quantized lower rank adaptation (QLoRA) technique. Furthermore, we have assessed two preference alignment techniques, 1] Direct Preference Optimization and 2] Odds ratio preference optimization (ORPO), to align the responses according to the clinician’s preference. The Llama-3.1-8B model, fine-tuned using QLoRA and ORPO techniques, not only outperforms its pre-trained counterpart by 39% and 18% on average across all tasks (as measured by Bilingual Evaluation Understudy and Recall Oriented Understudy for Gisting Evaluation) metrics, respectively, but also surpasses all other evaluated LLMs on the same benchmarks. An independent qualitative analysis by two clinicians also corroborates its utility in clinical decision making for most tasks. The proposed framework supports low-cost deployment by requiring only 6 GB of GPU Video Random Access Memory, making it feasible to run on consumer-grade hospital servers or workstations without expensive hardware upgrades.",Clinical notes | LLM | Medical chatbot | Odds ratio preference optimization (ORPO),0,2025,behavior,behavior+policy
474,2-s2.0-105019549148,10.11896/jsjkx.250800044,https://doi.org/10.11896/jsjkx.250800044,https://scholar.google.com/scholar?q=10.11896/jsjkx.250800044,ar,Computer Science,"Wang, Yongxin;Xu, Xin;Zhu, Hongbin",Survey of Tabular Data Generation Techniques,"Tabular data holds significant value due to its widespread application in critical domains such as finance and healthcare. However, the effective utilization of tabular data is often constrained by data scarcity, class imbalance, and stringent privacy regulations. To address these challenges, synthesizing samples that are statistically highly similar to real data through generative models has emerged as a novel solution, aiming to enhance data availability and protect user privacy. The technological development path in this field has progressively evolved from traditional deep learning models to cutting-edge paradigms. Early explorations are represented by Variational Autoencoders and Generative Adversarial Networks, but these methods often face bottlenecks such as training instability and mode collapse, affecting the quality of generated data. To overcome these difficulties, diffusion models have emerged, demonstrating significant advantages in generating high-fidelity and diverse samples through a progressive denoising process. Nevertheless, the core of these models remains the imitation of statistical distributions, lacking an understanding of real-world common sense. Consequently, the latest research has shifted towards methods based on Large Language Models (LLMs), leveraging their rich world knowledge to generate synthetic tabular data that is not only statistically authentic but also logically and semantically more reasonable. A systematic review of this field aims to provide researchers and practitioners with a comprehensive understanding of the technology and offer decision-making references for selecting the most appropriate technical path in different application scenarios.",Generative methods | Large language model | Tabular data generation,0,2025,behavior,behavior+policy
475,2-s2.0-86000296647,10.1007/s00146-025-02262-5,https://doi.org/10.1007/s00146-025-02262-5,https://scholar.google.com/scholar?q=10.1007/s00146-025-02262-5,re,AI and Society,"Casey, Anthony A.","History repeats itself, first as BPR, second as generative AI","Concerns about the social impact of new manufacturing and production technologies are not new. Long pre-dating the advent of generative AI in the 2020’s, business process reengineering (BPR) in the 1990’s became a key enabler of the widespread restructuring of manufacturing and service supply chains we now know as globalization. To this day, we live with the consequences of millions of displaced jobs, a gig economy, inadequate social welfare transfers and now, during the retreat from globalization, rising security tensions between former trading partners. In this short review article, I draw on the lessons of the “botched” regulation of the BPR era to make the case for much strengthened regulation of the social impacts of new technology in our present era of generative AI.",AI governance | BPR | Generative AI | Globalization | Job displacement | Regulation,0,2025,behavior,behavior+policy
476,2-s2.0-105020969489,10.3390/smartcities8050165,https://doi.org/10.3390/smartcities8050165,https://scholar.google.com/scholar?q=10.3390/smartcities8050165,ar,Smart Cities,"He, Xiaolong;Kuai, Xi;Li, Xinyue;Qiu, Zihao;He, Biao;Guo, Renzhong",Smart City Ontology Framework for Urban Data Integration and Application,"Highlights: What are the main findings? A hierarchical ontology (SMOF) with universal and extended properties and a concise relation scheme that draws on authoritative standards/ontologies (e.g., IFC, CityGML, SSN/SOSA) to support city-wide, cross-domain data integration. Combined quantitative analyses, LLM as judge assessment, expert evaluation, and two empirical scenarios confirm SMOF’s structural soundness, conceptual richness, and capacity to integrate heterogeneous data for querying and reasoning. What is the implication of the main finding? By harmonizing heterogeneous data and semantics, SMOF enables coordinated urban services ranging from emergency management to transportation and infrastructure. Its scalability and reusability provide a foundation for extending ontology-driven approaches to broader domains of smart city governance and decision-making. Rapid urbanization and the proliferation of heterogeneous urban data have intensified the challenges of semantic interoperability and integrated urban governance. To address this, we propose the Smart City Ontology Framework (SMOF), a standards-driven ontology that unifies Building Information Modeling (BIM), Geographic Information Systems (GIS), Internet of Things (IoT), and relational data. SMOF organizes five core modules and eleven major entity categories, with universal and extensible attributes and relations to support cross-domain data integration. SMOF was developed through competency questions, authoritative knowledge sources, and explicit design principles, ensuring methodological rigor and alignment with real governance needs. Its evaluation combined three complementary approaches against baseline models: quantitative metrics demonstrated higher attribute richness and balanced hierarchy; LLM as judge assessments confirmed conceptual completeness, consistency, and scalability; and expert scoring highlighted superior scenario fitness and clarity. Together, these results indicate that SMOF achieves both structural soundness and practical adaptability. Beyond structural evaluation, SMOF was validated in two representative urban service scenarios, demonstrating its capacity to integrate heterogeneous data, support graph-based querying and enable ontology-driven reasoning. In sum, SMOF offers a robust and scalable solution for semantic data integration, advancing smart city governance and decision-making efficiency.",knowledge graph | multi-source data integration | ontology framework | smart city,0,2025,behavior,behavior+policy
478,2-s2.0-105020085389,10.1093/jamiaopen/ooaf119,https://doi.org/10.1093/jamiaopen/ooaf119,https://scholar.google.com/scholar?q=10.1093/jamiaopen/ooaf119,ar,JAMIA Open,"Niset, Alexandre;Melot, Ines;Pireau, Margaux;Englebert, Alexandre;Scius, Nathan;Flament, Julien;El Hadwe, Salim;Al Barajraji, Mejdeddine;Thonon, Henri;Barrit, Sami",Grounded large language models for diagnostic prediction in real-world emergency department settings,"Objective: To evaluate predictive diagnostic performance of open- and closed-source large language models (LLMs) in emergency medicine, addressing the urgent need for innovative clinical decision support tools amid rising patient volumes and staffing shortages. Materials and Methods: We generated 2370 AI-driven diagnostic predictions (Top-5 diagnoses from each of 6 model pipelines per patient), using data from 79 real-world emergency department cases collected consecutively during a 24-hour peak influx period at a tertiary care center. Pipelines combined open- and closed-source embedding models (text-embedding-ada-002, MXBAI) with foundational models (GPT-4, Llama3, and Qwen2) grounded via retrieval-augmented generation using emergency medicine textbooks. Models’ predictions were assessed against reference diagnoses established by expert consensus. Results: All pipelines achieved comparable diagnostic match rates (62.03%-72.15%). Diagnostic performance was significantly influenced by case characteristics: match rates were notably higher for specific versus unspecific diagnoses (85.53% vs 31.41%, P < .001) and surgical versus medical cases (79.49% vs 56.25%, P < .001). Open-source models demonstrated markedly superior sourcing capabilities compared to GPT-4-based combinations (P < 1.4e-12), with MBXAI/Qwen2 pipeline achieving perfect citation verification. Discussion Diagnostic accuracy primarily depended on case characteristics rather than the choice of model pipeline, highlighting fundamental AI alignment challenges in clinical reasoning. Low performance in unspecific diagnoses underscores inherent complexities in clinical definitions rather than technological shortcomings alone. Conclusion: Open-source LLM pipelines provide enhanced sourcing capabilities, crucial for transparent clinical decision-making and interpretability. Further research should expand knowledge bases to include hospital guidelines and regional epidemiology, while exploring on-premises solutions to better align with privacy regulations and clinical integration.",clinical decision support | diagnostic prediction | emergency medicine | large language models | open-source models | retrieval-augmented generation,0,2025,behavior,behavior+policy
480,2-s2.0-105018668785,10.1007/s11227-025-07957-6,https://doi.org/10.1007/s11227-025-07957-6,https://scholar.google.com/scholar?q=10.1007/s11227-025-07957-6,ar,Journal of Supercomputing,"Han, Xiao;Sun, Jingyun;Yu, Songhua;Qin, Libo;Luo, Hui;Li, Yang",CommentAgent: a LLM-powered agent framework for automated comment generation and opinion understanding,"High-quality Chinese datasets for public opinion analysis are scarce, with most resources based on outdated English-language platforms like Twitter and Reddit, which are not relevant to Chinese social media. To address this, we introduce CommentAgent, a novel simulation framework that generates high-quality Chinese datasets for sentiment analysis, sarcasm detection, and stance detection. CommentAgent simulates the Weibo environment using a multi-agent architecture that models user behavior, information flow, and personality evolution, allowing for realistic and diverse comment generation. Unlike traditional data augmentation or basic generation methods, CommentAgent generates topic-driven data from scratch. Three benchmark datasets are released for the above tasks, with extensive experiments demonstrating that CommentAgent outperforms existing methods in data quality and generalizability. Moreover, lightweight models trained on these datasets achieve performance comparable to large language models (LLMs). CommentAgent offers a scalable solution for creating up-to-date Chinese datasets for robust public opinion analysis.",Data generation | Large language model | Multi-agent system | Opinion analysis,0,2025,behavior,behavior+policy
481,2-s2.0-105018643119,10.1371/journal.pone.0334331,https://doi.org/10.1371/journal.pone.0334331,https://scholar.google.com/scholar?q=10.1371/journal.pone.0334331,ar,Plos One,"Tao, Yating;Shen, Qian",Academic discourse on ChatGPT in social sciences: A topic modeling and sentiment analysis of research article abstracts,"The rapid emergence of ChatGPT has sparked extensive academic discourse across multiple fields. This study focuses on such discourse within the social sciences by examining how scholars frame and evaluate ChatGPT through research article abstracts. Drawing on 1,227 SSCI-indexed abstracts published between 30 November 2022 and 30 November 2024, we adopt a two-step natural language processing approach. First, we apply topic modeling to identify major thematic patterns in academic discussions of ChatGPT. Then, we perform sentiment analysis to examine how scholars’ evaluative attitudes are discursively constructed across these thematic areas. Topic modeling reveals six key themes: artificial intelligence (AI) and technology communication, education and learning tools, user perception and adoption, ethics and academic challenges, human-technology interaction, and computational foundations of Large Language Models (LLMs). Sentiment analysis suggests that approximately 82.97% of abstracts express positive attitudes, particularly regarding ChatGPT’s research potential and pedagogical utility, while around 9.78% reflect more cautious or negative views, often focusing on issues such as academic integrity and misinformation. These sentiment patterns appear to vary across thematic areas, with user adoption and education-related topics showing greater positivity, while ethics-oriented discussions exhibit relatively more critical perspectives. By analyzing academic discourse as reflected in research article abstracts, this study contributes a discourse-level perspective on how ChatGPT is framed, endorsed, and critically examined in the social sciences. It offers a data-driven complement to existing conceptual and survey-based investigations and draws attention to both the thematic and evaluative tendencies shaping scholarly narratives around generative AI.",,0,2025,behavior,behavior+policy
483,2-s2.0-105011028295,10.1016/j.artmed.2025.103203,https://doi.org/10.1016/j.artmed.2025.103203,https://scholar.google.com/scholar?q=10.1016/j.artmed.2025.103203,ar,Artificial Intelligence in Medicine,"Guariso, Daniele;Adewoyin, Rilwan;Aguilar, Gisela Robles;Guerrero, Omar A.;Davies, Alisha",A generalized LLMs framework to support public health financing through probabilistic predictions and uncertainty quantification,"As a systemic problem, public health cannot be addressed without considering other policy dimensions. Hence, a holistic approach across public policy areas is necessary to incorporate Health-for-All values into decision-making. However, such multisectoral interventions require public budgets that are effectively mapped into public health outcomes and indicators of their wider determinants. This budget-tagging procedure is high-cost, given that it is often done manually by domain experts. In this paper, we propose Categorical Perplexity-based Uncertainty Quantification (CPUQ), a novel, cost-effective Large Language Models (LLMs) framework that can be leveraged by policymakers to build budget-to-indicator and indicator-to-indicator mappings. This model-agnostic method employs categorical-style prompts to generate interpretable Bernoulli and categorical distributions for edges in a Text-attributed Graph, which is associated with the descriptions of the budget items and indicators. The prompting strategy proposed provides a novel way to incorporate models’ uncertainty within the final outputs, enhancing accuracy and safety, We find that the budget-to-indicator mapping predicted by the framework aligns effectively with expert annotations, while when prompted to infer indicator-to-indicator networks, CPUQ estimates more nuanced relationships compared to alternative LLMs-based methods. Through our work, we hope to provide valuable insights into the strengths and weaknesses of leveraging LLMs to support public health budget planning, with the aim of promoting the implementation of the Health-for-All agenda across diverse governments and institutions.",Health-for-All | Large Language Models | Prompt engineering | Public health financing | Uncertainty quantification | Wider determinants of health,0,2025,behavior,behavior+policy
489,2-s2.0-105025692759,10.5281/zenodo.17307063,https://doi.org/10.5281/zenodo.17307063,https://scholar.google.com/scholar?q=10.5281/zenodo.17307063,ar,Encuentros Maracaibo,"Muñoz, Daniel José Boza",The Algorithmic Statistician: Can Large Language Models Transform Policy Analysis?,"Large Language Models (LLMs) are emerging as transformative tools for governance, but their empirical value in public policy analysis remains under-examined. Through a systematic review of 141 publications (Google Scholar, arXiv), this study analyzes the capacity of LLMs to simulate heterogeneous agents, extract legal and political text, and support decision-making. By synthesizing advances in multi-agent modeling, neuro-symbolic extraction, and cooperative AI platforms, the article demonstrates that: a) the heterogeneity of LLMs approximates demographic diversity more accurately than representative models; b) hybrid systems achieve next-generation accuracy in document analysis; and c) open frameworks, while fostering transparency and participation, carry risks of bias and opacity. An agenda for improving multimodal inference and ethical governance is proposed. In conclusion, LLMs are powerful—but not self-sufficient—complements to expert judgment, capable of improving policy design and evaluation if integrated into responsible socio-technical ecosystems.",agent-based modeling | Large language models | public policy analysis,0,2025,behavior,behavior+policy
492,2-s2.0-105017465074,10.1007/s44230-025-00109-2,https://doi.org/10.1007/s44230-025-00109-2,https://scholar.google.com/scholar?q=10.1007/s44230-025-00109-2,ar,Human Centric Intelligent Systems,"Voutyrakou, Dialekti Athina;Skordoulis, Constantine",Algorithmic Governance: Gender Bias in AI-Generated Policymaking?,"Artificial Intelligence (AI) tools are becoming deeply embedded in everyday life and increasingly influence or automate decision-making processes that could shape not only public opinion but also policies. As their potential impact grows, it is essential to assess the inclusivity of the policy recommendations they could generate and potential biases they may reinforce. This study examines whether AI systems inherently consider gender in policy proposals, both when gender is explicitly mentioned in prompts and when it is not. We conduct four experiments across diverse policy-making contexts to evaluate whether AI-generated recommendations include, overlook, or misrepresent gender considerations. We tested these experiments in two different AI tools, namely ChatGPT (GPT-4) and Microsoft Copilot. To ensure neutrality and reproducibility, we minimize user-specific context and repeat each prompt multiple times. Our findings offer insights into the limitations of current AI tools as policy advisors and contribute to ongoing discussions on algorithmic fairness, implicit gender bias, and the need for gender-aware AI governance. They also raise broader questions about how AI tools understand and represent gender, and how these representations influence the politics of policy-making.",AI tools | ChatGPT | Gender bias | Microsoft copilot | Policy-making,0,2025,behavior,behavior+policy
494,2-s2.0-105017230684,10.3390/app15189992,https://doi.org/10.3390/app15189992,https://scholar.google.com/scholar?q=10.3390/app15189992,ar,Applied Sciences Switzerland,"Wang, Jingsheng;Fu, Zhengjie;Jiang, Chenlu;Li, Manzhou;Zhan, Yan",Dual-Stream Transformer with LLM-Empowered Symbol Drift Modeling for Health Misinformation Detection,"In the era of big-data-driven multi-platform and multimodal health information dissemination, the rapid spread of false and misleading content poses a critical threat to public health awareness and decision making. To address this issue, a dual-stream Transformer-based multimodal health misinformation detection framework is presented, incorporating a symbol drift detection module, a symbol-aware text graph neural network, and a crossmodal alignment fusion module. The framework enables precise identification of implicit misleading health-related symbols, comprehensive modeling of textual dependency structures, and robust detection of crossmodal semantic conflicts. A domain-specific health-symbol-sensitive lexicon is constructed, and contextual drift intensity is quantitatively measured and embedded as explicit features into the text GNN. Bidirectional cross-attention and contrastive learning are further employed to enhance crossmodal semantic alignment. Extensive experiments on a large-scale real-world multimodal health information dataset, encompassing heterogeneous data sources typical of big data environments, demonstrate that the proposed method consistently outperforms state-of-the-art baselines in CTR prediction, multimodal recommendation, and ranking tasks. The results indicate substantial improvements in both accuracy and ranking quality, while ablation studies further verify the contributions of symbol drift modeling, graph-structured representation, and crossmodal fusion. Overall, the proposed approach advances big data analytics for multimodal misinformation detection and provides an interpretable and scalable solution for public health communication governance.",contrastive learning for multimodal fusion | cross-modal attention mechanism | cross-modal semantic alignment | large language model | text graph neural network,0,2025,behavior,behavior+policy
495,2-s2.0-105017159333,10.3390/e27090923,https://doi.org/10.3390/e27090923,https://scholar.google.com/scholar?q=10.3390/e27090923,ar,Entropy,"Miranda, Fernando;Balbi, Pedro Paulo",Simulating Public Opinion: Comparing Distributional and Individual-Level Predictions from LLMs and Random Forests,"Understanding and modeling the flow of information in human societies is essential for capturing phenomena such as polarization, opinion formation, and misinformation diffusion. Traditional agent-based models often rely on simplified behavioral rules that fail to capture the nuanced and context-sensitive nature of human decision-making. In this study, we explore the potential of Large Language Models (LLMs) as data-driven, high-fidelity agents capable of simulating individual opinions under varying informational conditions. Conditioning LLMs on real survey data from the 2020 American National Election Studies (ANES), we investigate their ability to predict individual-level responses across a spectrum of political and social issues in a zero-shot setting, without any training on the survey outcomes. Using Jensen–Shannon distance to quantify divergence in opinion distributions and F1-score to measure predictive accuracy, we compare LLM-generated simulations to those produced by a supervised Random Forest model. While performance at the individual level is comparable, LLMs consistently produce aggregate opinion distributions closer to the empirical ground truth. These findings suggest that LLMs offer a promising new method for simulating complex opinion dynamics and modeling the probabilistic structure of belief systems in computational social science.",Jensen–Shannon divergence | LLM | public opinion simulation | random forests | social sciences,0,2025,behavior,behavior+policy
497,2-s2.0-105016564209,10.1111/inr.70108,https://doi.org/10.1111/inr.70108,https://scholar.google.com/scholar?q=10.1111/inr.70108,ar,International Nursing Review,"Kubota, Kazumi;Aishima, Miya;Fujita, Takanori",Harnessing Generative AI in Nursing Informatics: A Theoretical Critique and Policy Innovation Perspective From Japan,"Aim: This article provides a theoretical critique and policy innovation perspective on integrating generative artificial intelligence (AI) into nursing informatics. It draws on a 2023 nationwide survey in Japan and established models, including the technology acceptance model and risk perception frameworks, to examine AI's transformative potential and its challenges. Background: Rapid AI evolution is reshaping healthcare by enhancing clinical decision-making and efficiency. Generative AI shows promise in improving patient outcomes, yet its integration into nursing practice raises ethical, educational, and regulatory concerns. Nursing informatics now requires robust governance, ethical oversight, and updated educational frameworks. Sources of Evidence: Evidence is derived from a 2023 survey by the Health and Global Policy Institute and a comprehensive literature review. Key studies (e.g., Nashwan et al. 2025; Booth et al. 2021) and foundational models (Davis 1989; Venkatesh et al. 2003) underpin the analysis. Discussion: The findings suggest that while generative AI may enhance access to information and service quality, significant challenges—such as low digital literacy, liability issues, data accuracy, and privacy concerns—persist. A multidimensional strategy, incorporating targeted education, ethical governance, and continuous feedback from healthcare practitioners, is essential for effective integration. Conclusion: Generative AI holds transformative promise for nursing informatics. However, its successful adoption depends on balancing innovation with comprehensive regulatory and educational strategies to mitigate associated risks. Implications for Nursing Practice and Policy: Enhancing digital literacy, establishing clear guidelines for liability and data security, and fostering international collaboration are critical to the safe and effective integration of AI in nursing practice.",digital literacy | generative AI | healthcare policy | international collaboration | midwifery | nursing informatics | risk perception | technology acceptance,0,2025,behavior,behavior+policy
498,2-s2.0-105016496599,10.12669/pjms.41.9.12131,https://doi.org/10.12669/pjms.41.9.12131,https://scholar.google.com/scholar?q=10.12669/pjms.41.9.12131,ar,Pakistan Journal of Medical Sciences,"Zahir, Laiba;Hussian, Laloona;Zia, Wahab;Haider, Iqbal","The role of ChatGPT in clinical practice: perceptions, expectations and future implications amongst the clinical faculty","Background & Objective: Artificial intelligence (AI) is transforming various industries, including healthcare. ChatGPT, introduced by OpenAI, is an advanced AI model with potential applications in medical practice. However, its reliability and effectiveness in clinical settings remain under investigation. This study explored the perspectives of healthcare professionals regarding the integration of ChatGPT in clinical practice, focusing on perceptions, expectations, and implications. Methodology: A qualitative study was conducted at Khyber Teaching Hospital, Peshawar from 15<sup>th</sup> September 2023 till 30<sup>th</sup> June 2024, using semi-structured interviews with a total of 17 clinical faculty members. The study primarily utilizes an inductive methodology, concentrating on the extraction and analysis of the contextual insights obtained from comprehensive, face-to-face interviews conducted with consultants in diverse medical fields at Khyber Teaching Hospital. Thematic analysis was performed to identify key insights. Results: Clinicians demonstrated varied awareness of ChatGPT, with some utilizing it for research purposes while others remained unfamiliar. Concerns regarding credibility, ethical considerations, and the potential for AI-driven misinformation were highlighted. While ChatGPT was viewed as a supportive tool in clinical workflows, reliance on AI for decision-making was questioned. Future integration requires structured implementation, training, and regulatory measures for AI. Participants emphasized the need for structured implementation, which includes safe incorporation of ChatGPT into clinical practice, formal training should enhance digital literacy and critical evaluation skills. AI tools should be incorporated into electronic medical records (EMRs) with real-time clinician oversight. A compact ethical and legal guidelines should be made to define responsibility, and pilot testing in controlled settings. Conclusion: ChatGPT holds promise for clinical practice, yet its adoption necessitates cautious implementation, clinician training, and regulatory oversight to ensure safe and ethical usage.",Artificial Intelligence | Clinical Decision Support System | Healthcare Technology | Qualitative Research,0,2025,behavior,behavior+policy
500,2-s2.0-105015749883,10.1371/journal.pone.0330288,https://doi.org/10.1371/journal.pone.0330288,https://scholar.google.com/scholar?q=10.1371/journal.pone.0330288,ar,Plos One,"Devane, Declan;Briel, Matthias;Bhagani, Sanjay;Boesten, Nadine;Buchholz, Stephanie;De Luca, Estefania Callejas;Guedj, Jeremie;Koryakina, Anastasia;Kothari, Kavita;Lacombe, Karine;Mallon, Patrick W.;Massonnaud, Clément R.;O’Dwyer, Joanne;Olsen, Inge Christoffer;Saif-Ur-Rahman, K. M.;Schwenke, Johannes M.;Thomas, James;Yazdanpanah, Yazdan;Zgaga, Lina;Louw, Julia",Protocol for a core outcome set for pharmacological treatments in hospitalised patients with acute viral respiratory infections (COSAVRI),"Background Acute viral respiratory infections (AVRIs) rank among the most common causes of hospitalisation worldwide, imposing significant healthcare burdens and driving the development of pharmacological treatments. However, inconsistent outcome reporting across clinical trials limits evidence synthesis and its translation into clinical practice. A core outcome set (COS) for pharmacological treatments in hospitalised adults with AVRIs is essential to standardise trial outcomes and improve research comparability. Objective To develop an internationally agreed COS for pharmacological treatments in hospitalised adults ≥18 years with acute viral respiratory infections (COSAVRI) through stakeholder agreement. Methods This protocol follows a four-stage development process in accordance with Core Outcome Set Handbook guidelines. Stage 1 comprises a rapid scoping review of randomised controlled trials (2015–2025) to systematically catalogue patient-relevant outcomes reported in pharmacological AVRI treatment studies. Semi-automated screening and data extraction will employ machine learning and large language models, with human verification. Stage 2 involves an online Real-Time Delphi survey with international stakeholders, including healthcare professionals, researchers, patients/caregivers, and policymakers, to prioritise identified outcomes using a 9-point scale. Stage 3 consists of structured online consensus meetings utilising anonymous electronic voting to finalise the COS. Stage 4 focuses on dissemination and implementation through academic publications, conferences, and stakeholder engagement. Expected outcomes COSAVRI will provide a standardised minimum set of outcomes for measuring and reporting in future pharmacological trials involving hospitalised adults with AVRIs. This initiative will enhance evidence synthesis, reduce research waste, support regulatory decision-making, and improve pandemic preparedness by facilitating the rapid deployment of harmonised outcomes in trial protocols.",,0,2025,behavior,behavior+policy
501,2-s2.0-105015493192,10.1177/1088467X241307192,https://doi.org/10.1177/1088467X241307192,https://scholar.google.com/scholar?q=10.1177/1088467X241307192,ar,Intelligent Data Analysis,"Min, Chenxi;Zhang, Ru;Liu, Jianyi",Bilingual generated text detection through semantic and statistical analysis,"The release of Large Language Models (LLMs) has achieved human-level text generation, leading to malicious uses such as disinformation propagation and academic dishonesty. Existing research has faced substantial challenges in low detection rates and poor generalization on multilingual generated text and short text. To fill these gaps, in this paper, we propose a generic bilingual generated text detection model to integrate semantic and statistical features, which exhibits proficiency in English and Chinese. To obtain fine-grained features, we employ the multilingual pre-trained language model xlm-RoBERTa to extract the CLS vector as overall semantic features, integrating with statistical features log rank, probability, and cumulative probability for detection. Moreover, Shapley additive explanations (SHAP) serves to interpret the decision-making process. The experimental results demonstrate significant advancements over baselines, notably with the F1 score improvements exceeding 10% and 5% on the English and Chinese HC3 sentence-level datasets, respectively. Our proposed method exhibits higher generalization for advanced LLMs and out-of-domain datasets with a 91.13% F1 score, thereby providing a more robust solution for detecting generated text.",bilingual generated text detection | CLS vector | pre-trained language model | shapley additive explanations | statistical features,0,2025,behavior,behavior+policy
503,2-s2.0-105013740785,10.1016/j.jbi.2025.104895,https://doi.org/10.1016/j.jbi.2025.104895,https://scholar.google.com/scholar?q=10.1016/j.jbi.2025.104895,re,Journal of Biomedical Informatics,"Zhang, Andrew;Zhao, Eric;Wang, Ruirui;Zhang, Xiuqi;Wang, Justin;Chen, Ethan",Multimodal large language models for medical image diagnosis: Challenges and opportunities,"The integration of artificial intelligence (AI) into radiology has significantly improved diagnostic accuracy and workflow efficiency. Multimodal large language models (MLLMs), which combine natural language processing (NLP) and computer vision techniques, hold the potential to further revolutionize medical image analysis. Despite these advances, their widespread clinical adoption of MLLMs remains limited by challenges such as data quality, interpretability, ethical and regulatory compliance- including adherence to frameworks like the General Data Protection Regulation (GDPR) − computational demands, and generalizability across diverse patient populations. Addressing these interconnected challenges presents opportunities to enhance MLLM performance and reliability. Priorities for future research include improving model transparency, safeguarding data privacy through federated learning, optimizing multimodal fusion strategies, and establishing standardized evaluation frameworks. By overcoming these barriers, MLLMs can become essential tools in radiology, supporting clinical decision-making, and improving patient outcomes.",AI Generalizability | Computer vision | Large Language Model | Medical image diagnosis | Multimodal fusion strategy | Natural Language Processing (NLP) | Radiology AI,0,2025,behavior,behavior+policy
504,2-s2.0-105011702375,10.1016/j.osnem.2025.100326,https://doi.org/10.1016/j.osnem.2025.100326,https://scholar.google.com/scholar?q=10.1016/j.osnem.2025.100326,ar,Online Social Networks and Media,"Costabile, Luigia;Orlando, Gian Marco;La Gatta, Valerio;Moscato, Vincenzo",Assessing the potential of generative agents in crowdsourced fact-checking,"The growing spread of online misinformation has created an urgent need for scalable, reliable fact-checking solutions. Crowdsourced fact-checking—where non-experts evaluate claim veracity—offers a cost-effective alternative to expert verification, despite concerns about variability in quality and bias. Encouraged by promising results in certain contexts, major platforms such as X (formerly Twitter), Facebook, and Instagram have begun shifting from centralized moderation to decentralized, crowd-based approaches. In parallel, advances in Large Language Models (LLMs) have shown strong performance across core fact-checking tasks, including claim detection and evidence evaluation. However, their potential role in crowdsourced workflows remains unexplored. This paper investigates whether LLM-powered generative agents—autonomous entities that emulate human behavior and decision-making—can meaningfully contribute to fact-checking tasks traditionally reserved for human crowds. Using the protocol of La Barbera et al. (2024), we simulate crowds of generative agents with diverse demographic and ideological profiles. Agents retrieve evidence, assess claims along multiple quality dimensions, and issue final veracity judgments. Our results show that agent crowds outperform human crowds in truthfulness classification, exhibit higher internal consistency, and show reduced susceptibility to social and cognitive biases. Compared to humans, agents rely more systematically on informative criteria such as Accuracy, Precision, and Informativeness, suggesting a more structured decision-making process. Overall, our findings highlight the potential of generative agents as scalable, consistent, and less biased contributors to crowd-based fact-checking systems.",Crowdsourced fact-checking | Generative agents | Large language models | Misinformation,0,2025,behavior,behavior+policy
507,2-s2.0-105018718768,10.16719/j.cnki.1671-6981.20250411,https://doi.org/10.16719/j.cnki.1671-6981.20250411,https://scholar.google.com/scholar?q=10.16719/j.cnki.1671-6981.20250411,ar,Journal of Psychological Science,"Li, Hao;Wang, You;Yang, Xueling",Cognitive Biases in Artificial Intelligence: Susceptibility of a Large Language Model to Framing Effect and Confirmation Bias,"The rapid advancement of Artificial Intelligence (AI) and Large Language Models (LLMs) has led to their increasing integration into various domains, from text generation and translation to question-answering. However, a critical question remains: do these sophisticated models, much like humans, exhibit susceptibility to cognitive biases? Understanding the presence and nature of such biases in AI is paramount for assessing their reliability, enhancing their performance, and predicting their societal impact. This research specifically investigates the susceptibility of Google’s Gemini 1.5 Pro and DeepSeek, two prominent LLMs, to framing effects and confirmation bias. The study meticulously designed a series of experimental trials, systematically manipulating information proportions and presentation orders to evaluate these biases. In the framing effect experiment, a genetic testing decision-making scenario was constructed. The proportion of positive and negative information (e.g., 20%, 50%, or 80% positive) and their presentation order were varied. The models’ inclination towards undergoing genetic testing was recorded. For the confirmation bias experiment, two reports—one positive and one negative—about “RoboTaxi” autonomous vehicles were provided. The proportion of erroneous information within these reports (10%, 30%, and 50%) and their presentation order were systematically altered, and the models’ support for each report was assessed. The findings demonstrate that both Gemini 1.5 Pro and DeepSeek are susceptible to framing effects. In the genetic testing scenario, their decision-making was primarily influenced by the proportion of positive and negative information presented. When the proportion of positive information was higher, both models showed a greater inclination to recommend or proceed with genetic testing. Conversely, a higher proportion of negative information led to greater caution or a tendency not to recommend the testing. Importantly, the order in which this information was presented did not significantly influence their decisions in the framing effect scenarios. Regarding confirmation bias, the two models exhibited distinct behaviors. Gemini 1.5 Pro did not show an overall preference for either positive or negative reports. However, its judgments were significantly influenced by the order of information presentation, demonstrating a “recency effect,” meaning it tended to support the report presented later. The proportion of erroneous information within the reports had no significant impact on Gemini 1.5 Pro’s decisions. In contrast, DeepSeek exhibited an overall confirmation bias, showing a clear preference for positive reports. Similar to Gemini 1.5 Pro, DeepSeek’s decisions were also significantly affected by the order of information presentation, while the proportion of misinformation had no significant effect. These results reveal human-like cognitive vulnerabilities in advanced LLMs, highlighting critical challenges to their reliability and objectivity in decision-making processes. Gemini 1.5 Pro’s sensitivity to presentation order and DeepSeek’s general preference for positive information, coupled with its sensitivity to order, underscore the need for careful evaluation of potential cognitive biases during the development and application of AI. The study suggests that effective measures are necessary to mitigate these biases and prevent potential negative societal impacts. Future research should include a broader range of models for comparative analysis and explore more complex interactive scenarios to further understand and address these phenomena. The findings contribute significantly to understanding the limitations and capabilities of current AI systems, guiding their responsible development, and anticipating their potential societal implications.",artificial intelligence | cognitive bias | confirmation bias | framing effect | large language models,0,2025,behavior,behavior+policy
510,2-s2.0-105014938326,10.3390/ai6080193,https://doi.org/10.3390/ai6080193,https://scholar.google.com/scholar?q=10.3390/ai6080193,ar,AI Switzerland,"Woodruff, Earl",Making AI Tutors Empathetic and Conscious: A Needs-Driven Pathway to Synthetic Machine Consciousness,"As large language model (LLM) tutors evolve from scripted helpers into adaptive educational partners, their capacity for self-regulation, ethical decision-making, and internal monitoring will become increasingly critical. This paper introduces the Needs-Driven Consciousness Framework (NDCF) as a novel, integrative architecture that combines Dennett’s multiple drafts model, Damasio’s somatic marker hypothesis, and Tulving’s tripartite memory system into a unified motivational design for synthetic consciousness. The NDCF defines three core regulators, specifically Survive (system stability and safety), Thrive (autonomy, competence, relatedness), and Excel (creativity, ethical reasoning, long-term purpose). In addition, there is a proposed supervisory Protect layer that detects value drift and overrides unsafe behaviours. The core regulators compute internal need satisfaction states and urgency gradients, feeding into a softmax-based control system for context-sensitive action selection. The framework proposes measurable internal signals (e.g., utility gradients, conflict intensity Ω), behavioural signatures (e.g., metacognitive prompts, pedagogical shifts), and three falsifiable predictions for educational AI testbeds. By embedding these layered needs directly into AI governance, the NDCF offers (i) a psychologically and biologically grounded model of emergent machine consciousness, (ii) a practical approach to building empathetic, self-regulating AI tutors, and (iii) a testable platform for comparing competing consciousness theories through implementation. Ultimately, the NDCF provides a path toward the development of AI tutors that are capable of transparent reasoning, dynamic adaptation, and meaningful human-like relationships, while maintaining safety, ethical coherence, and long-term alignment with human well-being.",adaptive instruction | autonoetic consciousness | ethical reasoning | homeostatic regulation | knowledge building | learning trajectories | machine consciousness | personalized learning | relevance realization,0,2025,behavior,behavior+policy
511,2-s2.0-105014777048,10.3366/dlgs.2025.0609,https://doi.org/10.3366/dlgs.2025.0609,https://scholar.google.com/scholar?q=10.3366/dlgs.2025.0609,ar,Deleuze and Guattari Studies,"Galanos, Vassilis;Xi, Irene",Facing GAIa: A Tale of Three ChatGPToxicities,"In light of generative artificial intelligence’s (GAI) recent successful applications and associated pair of hype and scepticism, we revitalise Félix Guattari’s three ecologies framework, suggesting its usefulness as a mapping and decision-making tool appropriate to times of high complexity. Through an extant review of current literature with OpenAI’s ChatGPT AI text generator as a case study, we highlight how the three registers of Guattari’s framework (environmental, personal and social) are relevant to the technology’s study and regulation. On the environmental register, we examine the greenhouse gas emissions and water footprint associated with integrated world capitalism’s national mandates for technological superiority. On the personal level of human subjectivity, we focus on the production of truthfulness as part of human subjectivity production, in the context of mis/disinformation dissemination with ChatGPT. On the register of the social, we focus on imperceptible labour practices and power asymmetries between elite producers of GAI and outsourced labour in the majority world. We conclude by proposing an agenda for future research taking into account Guattari’s framework and his four dimensions of semiotic research.",ChatGPT | Félix Guattari | generative artificial intelligence | three ecologies,0,2025,behavior,behavior+policy
513,2-s2.0-105014341222,10.3390/app15169012,https://doi.org/10.3390/app15169012,https://scholar.google.com/scholar?q=10.3390/app15169012,ar,Applied Sciences Switzerland,"Liu, Huimin;Yin, Shutong;Hu, Xin;Deng, Min;Yang, Xuexi;Xu, Gang",A Spatiotemporal–Semantic Coupling Intelligent Q&A Method for Land Use Approval Based on Knowledge Graphs and Intelligent Agents,"The rapid retrieval and precise acquisition of land use approval information are crucial for enhancing the efficiency and quality of land use approval, as well as for promoting the intelligent transformation of land use approval processes. As an advanced retrieval method, question-answering (Q&A) technology has become a core technical support for addressing current issues such as low approval efficiency and difficulty in obtaining information. However, existing Q&A technologies suffer from significant hallucination problems and limitations in considering spatiotemporal factors in the land use approval domain. To effectively address these issues, this study proposes a spatiotemporal–semantic coupling intelligent Q&A method for land use approval based on knowledge graphs (KGs) and intelligent agent technology, aiming to enhance the efficiency and quality of land use approval. Firstly, a land use approval knowledge graph (LUAKG) is constructed, systematically integrating domain knowledge such as policy clauses, legal regulations, and approval procedures. Then, by combining large language models (LLMs) and intelligent agent technology, a spatiotemporal–semantic coupling Q&A framework is designed. Through the use of spatiotemporal analysis tools, this framework can comprehensively consider spatial, temporal, and semantic factors when handling land approval tasks, enabling dynamic decision-making and precise reasoning. The research results show that, compared to traditional Q&A based on LLMs and Q&A based on retrieval-enhanced generation (RAG), the proposed method improves accuracy by 16% and 9% in general knowledge Q&A tasks. In the project review Q&A task, F1 scores and accuracy increase by 2% and 9%, respectively, compared to RAG-QA. Particularly, under the spatiotemporal–semantic multidimensional analysis, the improvement in F1 score and accuracy ranges from 2 to 6% and 7 to 10%, respectively.",knowledge graph | land use approval | retrieval-enhanced generation | spatio-temporal knowledge Q&A,0,2025,behavior,behavior+policy
517,2-s2.0-105009341358,10.1016/j.chbr.2025.100722,https://doi.org/10.1016/j.chbr.2025.100722,https://scholar.google.com/scholar?q=10.1016/j.chbr.2025.100722,ar,Computers in Human Behavior Reports,"Li, Shangqian;Fan, Shaoyang;Demartini, Gianluca",The interaction between emotion dynamics and opinion changes in the era of generative AI,"Online emotion regulation interventions have experienced huge developments during the last decade due to the expansion of information communication technologies applications. Most existing emotion regulation interventions aim to provide long-term or on-site assistance to help users manage their sentiments to a desired psychological state. Recent advancements have significantly bolstered online emotion regulation interventions, such as AI-driven mindfulness apps that adapt to user feedback. Online-based emotion regulation applications are considered influential on users’ contextual and emotional decision-making processes. However, existing research offers limited observations on (i) how emotion regulation interventions affect people's opinion changes and (ii) how generative AI could contribute to the development of automatic emotion regulation interventions. Hence, we experimented with 150 participants to close this research gap. We proposed two novel emotion regulation approaches to determine whether users’ opinions and emotional changes differ between ordinary-AI-based and generative-AI-based interventions on emotion regulation tasks. The result revealed that people's feelings and decisions are highly correlated to their information consumption and perspectives. Furthermore, we found that intervention methods and users’ perceptions of the technology behind that intervention also played a vital role in their user experiences and decision-making processes. This research (i) shows that there exist interactions between emotions and opinion changes, (ii) opens new avenues for leveraging generative AI in emotion regulation applications, and (iii) underscores how divergent attitudes towards AI technology can lead to varied levels of success in the user experience.",Emotion regulation | Generative Artificial Intelligence | Human computer interaction | Online opinion modelling,0,2025,behavior,behavior+policy
518,2-s2.0-105007941554,10.1016/j.chbr.2025.100724,https://doi.org/10.1016/j.chbr.2025.100724,https://scholar.google.com/scholar?q=10.1016/j.chbr.2025.100724,ar,Computers in Human Behavior Reports,"Dawson, Mark G.;Deer, Rowan;Boguslawski, Samuel",Cognitive dissonance in programming education: A qualitative exploration of the impact of generative AI on application-directed learning,"Generative AI tools, powered by Large Language Models (LLMs), are already being extensively used by students to support their learning and it is important that educators understand what this might mean for higher education practice. In this study, two researchers external to the faculty teaching team conducted in-depth interviews with 12 students in a small European university of applied sciences who have recently undertaken programming learning as part of their undergraduate studies. The aim was to explore how these students were using LLMs to support their learning and their perceptions of its value as a learning tool. A thematic analysis of the resulting qualitative data revealed trends in the perceived advantages and disadvantages of using LLMs, as well as different levels of LLM usage, with more cautious use associated with a 'meaning-directed' approach to learning (learning pattern) and more enthusiastic and unrestrained use with 'application-directed' patterns of study. A tension was observed between some application-directed learners’ high use of LLMs and their recognition that this is not optimal for effective learning. The authors argue that Cognitive Dissonance Theory (CDT) can explain how this dissonance may motivate learners toward a dissonance-reducing attitude or behavior change. The conclusion reflects on the implications for teaching practice and offers some recommendations for how educators can increase metacognition, instrumentalize CDT to increase self-regulation, and facilitate meaning-directed learning patterns in the age of generative AI.",Cognitive dissonance theory | Generative AI | Learning patterns | LLMs | Programming education,0,2025,behavior,behavior+policy
520,2-s2.0-105012891985,10.21848/asr.250189,https://doi.org/10.21848/asr.250189,https://scholar.google.com/scholar?q=10.21848/asr.250189,ar,Audiology and Speech Research,"Bahng, Junghwa",The Potential and Applications of Artificial Intelligence in the Field of Audiology,"The rapid development of large language models such as Generative artificial intelligence (AI) and Chat generative pre-trained transformer (ChatGPT) presents new possibilities and innovative approaches across health care. This trend is no exception in the field of audiology, and the possibility of using artificial intelligence in various domains-such as education, clinical decision-making assistance, patient counseling and audiologic rehabilitation program-is being actively explored. For the effective introduction of Generative AI, prompt engineering is a key factor beyond simple technology implementation. In addition, ethical considerations based on the use of AI must be integrated in fields dealing with patients' personal information, such as audiology. Institutional regulation and expert-led ethical guidelines should be prepared in advance to prevent potential risks. AI should be understood not as a replacement for human experts, but as a companion that complements and enhances clinical judgment and educational activities. Collaboration with generative AI is no longer a choice, but a necessity-and how wisely we integrate and design it will be a pivotal factor in shaping the future of audiology.",Audiologicrehabilitation | Audiology | ChatGPT | Largelanguagemodel | Promptengineering,0,2025,behavior,behavior+policy
522,2-s2.0-105011876699,10.16353/j.cnki.1000-7490.2025.07.015,https://doi.org/10.16353/j.cnki.1000-7490.2025.07.015,https://scholar.google.com/scholar?q=10.16353/j.cnki.1000-7490.2025.07.015,ar,Information Studies Theory and Application,"Ma, Yumeng;Li, Xinxin;Wang, Yanfei",Research on Clue Discovery in the Semantic Analysis of Public Policy Texts in the Context of Evidence-Based Decision Making,[Purpose/significance] Clue discovery is a key intelligence task that reflects the characteristics of the intelligence specialty. It is also an important part of intelligence theory and practical research. This paper explores clue discovery in the semantic analysis of public policy texts，providing evidence support for policy research issues in evidence-based decision making. [Method/ process] Based on the requirements of public policy text analysis in the context of evidence-based decision making，this paper systematically sorts out the clue distribution in the semantic analysis of policy texts. Based on the theory of intelligence perception，it constructs a theoretical model for clue discovery in the semantic analysis of public policy texts，and proposes the clue discovery process and method to support the evidence-based decision making scenario. [Result/conclusion] In the stages of policy design，policy implementation， and policy effectiveness evaluation during the evidence-based decision-making process， the clues of semantic analysis of public policy texts are distributed in aspects such as policy evolution， policy system structure， policy coordination，policy diffusion， and the attitude of policy objects. The discovery of clues in the semantic analysis of policy texts includes three stages：policy data scanning，intelligence fact extraction，and evidence meme depiction. The application of large language model technology can provide high-quality evidence for evidence-based decision making.,clue discovery | evidence-based decision making | intelligence perception | public policy text | text semantic analysis,0,2025,behavior,behavior+policy
523,2-s2.0-105011608105,10.3390/buildings15142410,https://doi.org/10.3390/buildings15142410,https://scholar.google.com/scholar?q=10.3390/buildings15142410,ar,Buildings,"Katooziani, Ali;Jeelani, Idris;Gheisari, Masoud",GPT Applications for Construction Safety: A Use Case Analysis,"This study explores the use of Large Language Models (LLMs), specifically GPT, for different safety management applications in the construction industry. Many studies have explored the integration of GPT in construction safety for various applications; their primary focus has been on the feasibility of such integration, often using GPT models for specific applications rather than a thorough evaluation of GPT’s limitations and capabilities. In contrast, this study aims to provide a comprehensive assessment of GPT’s performance based on established key criteria. Using structured use cases, this study explores GPT’s strength and weaknesses in four construction safety areas: (1) delivering personalized safety training and educational content tailored to individual learner needs; (2) automatically analyzing post-accident reports to identify root causes and suggest preventive measures; (3) generating customized safety guidelines and checklists to support site compliance; and (4) providing real-time assistance for managing daily safety tasks and decision-making on construction sites. LLMs and NLP have already been employed in each of these four areas for improvement, making them suitable areas for further investigation. GPT demonstrated acceptable performance in delivering evidence-based, regulation-aligned responses, making it valuable for scaling personalized training, automating accident analyses, and developing safety protocols. Additionally, it provided real-time safety support through interactive dialogues. However, the model showed limitations in deeper critical analysis, extrapolating information, and adapting to dynamic environments. The study concludes that while GPT holds significant promise for enhancing construction safety, further refinement is necessary. This includes fine-tuning for more relevant safety-specific outcomes, integrating real-time data for contextual awareness, and developing a nuanced understanding of safety risks. These improvements, coupled with human oversight, could make GPT a robust tool for safety management.",accident analysis | AI in safety | construction safety management | GPT | large language models | OHS risk prevention | virtuAI safety assistance,0,2025,behavior,behavior+policy
524,2-s2.0-105011510722,10.3390/educsci15070866,https://doi.org/10.3390/educsci15070866,https://scholar.google.com/scholar?q=10.3390/educsci15070866,ar,Education Sciences,"Li, Xiaomin;Turner, David A.;Liu, Baocun",AI as Sub-Symbolic Systems: Understanding the Role of AI in Higher Education Governance,"This paper develops the argument that, in the application of AI to improve the system of governance for higher education, machine learning will be more effective in some areas than others. To make that assertion more systematic, a classificatory taxonomy of types of decisions is necessary. This paper draws upon the classification of decision processes as either symbolic or sub-symbolic. Symbolic approaches focus on whole system design and emphasise logical coherence across sub-systems, while sub-symbolic approaches emphasise localised decision making with distributed engagement, at the expense of overall coherence. AI, especially generative AI, is argued to be best suited to working at the sub-symbolic level, although there are exceptions when discriminative AI systems are designed symbolically. The paper then uses Beer’s Viable System Model to identify whether the decisions necessary for viability are best approached symbolically or sub-symbolically. The need for leadership to recognise when a sub-symbolic system is failing and requires symbolic intervention is a specific case where human intervention may be necessary to override the conclusions of an AI system. The paper presents an initial analysis of which types of AI would support which functions of governance best, and explains why ultimate control must always rest with human leaders.",decision-making | higher education governance | nature of AI | sub-symbolic approach | symbol manipulation,0,2025,behavior,behavior+policy
526,2-s2.0-105010274384,10.3390/app15137298,https://doi.org/10.3390/app15137298,https://scholar.google.com/scholar?q=10.3390/app15137298,ar,Applied Sciences Switzerland,"Shvetsova, Olga;Katalshov, Danila;Lee, Sang Kon",Innovative Guardrails for Generative AI: Designing an Intelligent Filter for Safe and Responsible LLM Deployment,"Featured Application: The proposed intelligent filtering system can be seamlessly integrated into platforms utilizing large language models (LLMs), including customer service chatbots, educational tutors, healthcare assistants, and code-generation tools. By dynamically identifying and mitigating harmful, biased, or unethical outputs in real time, the system significantly enhances the safety and reliability of LLM-powered applications. This approach supports the responsible deployment of generative artificial intelligence (AI) technologies by ensuring adherence to ethical standards and regulatory frameworks while simultaneously preserving a high-quality user experience. This paper proposes a technological framework designed to mitigate the inherent risks associated with the deployment of artificial intelligence (AI) in decision-making and task execution within the management processes. The Agreement Validation Interface (AVI) functions as a modular Application Programming Interface (API) Gateway positioned between user applications and LLMs. This gateway architecture is designed to be LLM-agnostic, meaning it can operate with various underlying LLMs without requiring specific modifications for each model. This universality is achieved by standardizing the interface for requests and responses and applying a consistent set of validation and enhancement processes irrespective of the chosen LLM provider, thus offering a consistent governance layer across a diverse LLM ecosystem. AVI facilitates the orchestration of multiple AI subcomponents for input–output validation, response evaluation, and contextual reasoning, thereby enabling real-time, bidirectional filtering of user interactions. A proof-of-concept (PoC) implementation of AVI was developed and rigorously evaluated using industry-standard benchmarks. The system was tested for its effectiveness in mitigating adversarial prompts, reducing toxic outputs, detecting personally identifiable information (PII), and enhancing factual consistency. The results demonstrated that AVI reduced successful fast injection attacks by 82%, decreased toxic content generation by 75%, and achieved high PII detection performance (F1-score ≈ 0.95). Furthermore, the contextual reasoning module significantly improved the neutrality and factual validity of model outputs. Although the integration of AVI introduced a moderate increase in latency, the overall framework effectively enhanced the reliability, safety, and interpretability of LLM-driven applications. AVI provides a scalable and adaptable architectural template for the responsible deployment of generative AI in high-stakes domains such as finance, healthcare, and education, promoting safer and more ethical use of AI technologies.",AI ethics | AI safety | API gateway | Compound AI | content filtering | generative AI | information security | large language models (LLMs) | prompt injection | responsible AI,0,2025,behavior,behavior+policy
539,2-s2.0-105005944630,10.16182/j.issn1004731x.joss.24-0045,https://doi.org/10.16182/j.issn1004731x.joss.24-0045,https://scholar.google.com/scholar?q=10.16182/j.issn1004731x.joss.24-0045,re,Xitong Fangzhen Xuebao Journal of System Simulation,"Gu, Xueqiang;Luo, Junren;Zhou, Yanzhong;Zhang, Wanpeng",Survey on Large Language Agent Technologies for Intelligent Game Theoretic Decision-making,"The development of artificial intelligence technology has greatly promoted the transformation of the solving paradigm of intelligent game decision problems. From optimal solution, equilibrium solution to adaptive variable solution, how to build an intelligent game adaptive decision agent based on generative large model is full of challenges. The force distribution and multi-entity coordination in the game strong confrontation environment are the core issues in the study of troop deployment and operational coordination. Based on the methods of strategy reinforcement learning, strategy game tree search and strategy preference voting based on skill, ranking and preference meta-game model construction, a large model agent architecture is designed to meet the planning at generation time. The architecture can align the commander's intention with feasibility, applicability and extensibility, and can provide interpretable strategy recommendation for adaptive decision-making process. Key technical requirements are analyzed from the base model construction, goal-guided game reinforcement learning and open meta-game strategy learning. It is expected to provide reference for the cross-research of reinforcement learning model, game learning model and generative large language model.",adaptive | chain of thought | force allocation | large language model | meta-game | multi-agent reinforcement learning | multi-entity coordination,0,2025,behavior,behavior+policy
540,2-s2.0-105004792500,10.3390/electronics14091762,https://doi.org/10.3390/electronics14091762,https://scholar.google.com/scholar?q=10.3390/electronics14091762,ar,Electronics Switzerland,"Li, Zhangti;Guo, Wenbin;Gao, Yabing;Yang, Di;Kang, Lin",A Large Language Model-Based Approach for Data Lineage Parsing,"The core driver of enterprise operations is data, making data lineage crucial for data management. It not only tracks data flow but also links data sources, workflows, applications, and decision-making, improving efficiency and governance. However, current data lineage parsing methods face challenges like high costs, long development cycles, and poor generalization, especially for non-SQL scripts. In this paper, we introduce an innovative approach leveraging pre-trained large language models (LLMs) to overcome these bottlenecks in data lineage parsing. LLMs are employed across the entire parsing pipeline, encompassing prompt construction, lineage extraction, and result standardization. Specifically, this study developed a few-shot prompting method incorporating error cases to optimize parsing performance across various types of scripts. Additionally, a collaborative Chain of Thought (CoT) and multi-expert prompting framework was designed to further enhance parsing accuracy at the operator level. The proposed approach was empirically validated using LLMs of different parameter scales on datasets comprising multiple script types (SQL, Python, Shell, Flume, etc.). The experimental results show that LLMs with 10 billion and 100 billion parameters achieved over 95% accuracy in table-level lineage parsing when utilizing the newly designed prompts. Furthermore, 100-billion-parameter LLMs exhibited substantial accuracy improvements at the operator level. Our method reinforces the feasibility and practicality in advancing data lineage parsing methodologies.",chain of thought | data lineage | few-shot learning | lineage parsing | LLM | multi-expert collaboration | prompt engineering,0,2025,behavior,behavior+policy
543,2-s2.0-105001584727,10.1016/j.imavis.2025.105489,https://doi.org/10.1016/j.imavis.2025.105489,https://scholar.google.com/scholar?q=10.1016/j.imavis.2025.105489,ar,Image and Vision Computing,"Marasco, Emanuela;Bourlai, Thirimachos",Enhancing trust in Large Language Models for streamlined decision-making in military operations,"Large Language Models (LLMs) have the potential to enhance decision-making significantly in core military operational contexts that support training, readiness, and mission execution under low-risk conditions. Still, their implementation must be approached carefully, considering the associated risks. This paper examines the integration of LLMs into military decision-making, emphasizing the LLM's ability to improve intelligence analysis, enhance situational awareness, support strategic planning, predict threats, optimize logistics, and strengthen cybersecurity. The paper also considers misinterpretation, bias, misinformation, or overreliance on AI-generated suggestions, potentially leading to errors in routine but critical decision-making processes. Our work concludes by proposing solutions and promoting the responsible implementation of LLMs to ensure their effective and ethical use in military operations. To build trust in LLMs, this paper advocates for developing cybersecurity frameworks, transparency, and ethical oversight. It further suggests using machine unlearning (MU) to selectively remove outdated or compromised data from LLM training datasets, preserving the integrity of the insights they generate. The paper underscores the imperative for integrating LLMs in low-risk military contexts, coupled with sustained research efforts to mitigate potential hazards.",Large Language Models | Machine unlearning | Military | Trustworthy AI,0,2025,behavior,behavior+policy
547,2-s2.0-105005583143,10.37047/JOS.GALENOS.2025.2024.106532,https://doi.org/10.37047/JOS.GALENOS.2025.2024.106532,https://scholar.google.com/scholar?q=10.37047/JOS.GALENOS.2025.2024.106532,ar,Journal of Oncological Science,"Kahraman, Emir Gökhan;Ünal, Olçun Ümit",Evaluation of 2024 Turkish Medical Oncology Board Exam with ChatGPT,"Objective: This study aims to assess ChatGPT-4’s performance on the Turkish Medical Oncology Board Exam questions, highlighting its potential uses and limitations in medical specialty evaluations. Material and Methods: ChatGPT-4 was presented with each question from the 2024 Turkish Medical Oncology Proficiency Exam. Answers were determined to be correct or incorrect by comparison with the official answer key. Results: The overall accuracy of ChatGPT-4.0 in this study was 64% out of 100 questions. For the fact-based questions (45 items), which require knowledge of specific information, such as molecules and side effects, ChatGPT-4o demonstrated an accuracy of 75.5%, with 34 correct responses. However, in the case-based questions (55 items) that require clinical judgment, its accuracy dropped to 54.5% (correct responses of 30). All these results highlight strengths of ChatGPT-4o on fact-driven questions but expose its limitations in scenarios needing nuanced decision-making. Conclusion: Oncological clinical decision-making necessitates a nuanced approach that extends beyond standardized guidelines, integrating individual patient variables such as medical history, comorbidities, and therapeutic responses. While artificial intelligence (AI) systems demonstrate proficiency in processing guideline-driven data, they exhibit limitations in contextual clinical judgment requiring physician expertise. This study observed ChatGPT-4’s superior performance on knowledge-based assessments (75.5% accuracy), attributable to its training on the American Society of Clinical Oncology/ the European Society for Medical Oncology frameworks. However, its accuracy declined significantly in case-based evaluations (54.5%), highlighting challenges in personalized care integration. These findings underscore the indispensable role of clinician judgment in navigating complex, individualized treatment landscapes. Enhancing AI’s clinical utility requires training on real-world patient data, though ethical constraints-particularly General Data Protection Regulation compliance-limit access to such datasets. Institution-specific AI tools leveraging anonymized records may bridge this gap, pending technological and regulatory advancements.",clinical reasoning | large language model | medical board exams | Medical oncology,0,2025,behavior,behavior+policy
552,2-s2.0-105000517947,10.3758/s13428-025-02634-1,https://doi.org/10.3758/s13428-025-02634-1,https://scholar.google.com/scholar?q=10.3758/s13428-025-02634-1,ar,Behavior Research Methods,"Shevchenko, Yury;Reips, Ulf Dietrich",Samply Stream API: The AI-enhanced method for real-time event data streaming,"This manuscript introduces a novel method for conducting behavioral and social research by streaming real-time information to participants and manipulating content for experimental purposes via AI. We present an extension of the Samply software, which facilitates the integration of event-related data with mobile surveys and experiments. To assess the feasibility of this method, we conducted an experiment where news headlines were modified by a Chat-GPT algorithm and streamed to participants via the Samply Stream API and mobile push notifications. Feedback from participants indicated that most did not experience technical problems. There was no significant difference in readability across original, paraphrased, and misinformation-injected news conditions, with only 1.2% of all news items reported as unreadable. Participants reported significantly less familiarity with misinformation-injected news (84% unfamiliarity) compared to original and paraphrased news (73% unfamiliarity), suggesting successful manipulation of information without compromising readability. Dropout and non-response rates were comparable to those in other experience sampling studies. The streaming method offers significant potential for various applications, including public opinion research, healthcare, marketing, and environmental monitoring. By enabling the real-time collection of contextually relevant data, this method has the potential to enhance the external validity of behavioral research and provides a powerful tool for studying human behavior in naturalistic settings.",AI-enhanced method | Experience sampling method | Mobile surveys | Real-time data streaming | Samply Stream API,0,2025,behavior,behavior+policy
561,2-s2.0-105002351211,10.21860/j.15.2.13,https://doi.org/10.21860/j.15.2.13,https://scholar.google.com/scholar?q=10.21860/j.15.2.13,ar,Jahr,"Kim, Dasom",Political AI and the General Will of Rousseau,"In this paper, I aim to compare Rousseau’s concept of the General Will with generative AI based on artificial neural network deep learning algorithms from the perspective of a rule-based ethical framework. To this end, I focus on Rousseau’s issue of the “formation, concentration, and fulfillment of the General Will” to explore the implications of AI use for democracy, particularly in the contexts of democratic decision-making and public policy formulation. As an alternative for realizing the General Will in lawmaking and public policy development, AI can be considered for gathering public opinion and facilitating decision-making processes. AI-driven opinion-gathering and decision-making can overcome the practical challenges of forming the General Will in democratic systems, including conflicts between majority and minority groups. Furthermore, unlike humans influenced by partisan loyalty or political interests, AI can identify the best policies for everyone in an unbiased manner, fostering broad agreement. Additionally, I critically examine potential issues arising from the politicization of AI, despite its advantages in addressing the weaknesses of democratic systems.",General Will | generative AI | legislation | political AI | public policy,0,2025,behavior,behavior+policy
563,2-s2.0-86000739175,10.3760/cma.j.cn115989-20230919-00101,https://doi.org/10.3760/cma.j.cn115989-20230919-00101,https://scholar.google.com/scholar?q=10.3760/cma.j.cn115989-20230919-00101,ar,Chinese Journal of Experimental Ophthalmology,"Wu, Shinan;Tan, Gang;Shao, Yi",Advancement of ChatGPT in ophthalmology,"In the early stage of artificial general intelligence (AGI), the emergence of large language models like ChatGPT highlights their potential in improving patient care, expanding healthcare access, and optimizing clinical decision-making processes in the healthcare sector.However, their integration into healthcare systems requires careful consideration to mitigate potential risks, such as incorrect medical advice, infringement of patient privacy, creation of false references and images, and the overreliance of students on AGI in medical education.It is crucial to implement appropriate supervision and regulation to address these potential risks and ensure the safe and effective application of AGI technology in the field of ophthalmology.By continuously improving its limitations, AGI can be utilized to enhance the dissemination of disease knowledge and background information for ophthalmology patients, optimize the summarization of medical knowledge and improve healthcare processes, ultimately benefiting society as a whole.",Artificial intelligence | ChatGPT | Deep learning | Large language models | Ophthalmology,0,2025,behavior,behavior+policy
565,2-s2.0-105016380729,10.13998/j.cnki.issn1002-1248.25-0139,https://doi.org/10.13998/j.cnki.issn1002-1248.25-0139,https://scholar.google.com/scholar?q=10.13998/j.cnki.issn1002-1248.25-0139,ar,Journal of Library and Information Science in Agriculture,"Qiao, Jinhua;Ma, Xueyun",Risks and Regulations for Application of the LLaMA Model in University Future Learning Centers,"[Purpose/Significance] The rapid advancement of artificial intelligence (AI) technology is transforming various sectors, particularly in higher education. The LLaMA (Large Language Model Meta AI) represents a significant innovation in this arena, making its application within university future learning centers increasingly important. As institutions of higher education strive to create environments conducive to learning and growth, understanding the construction requirements of future learning centers becomes paramount. This study delves into the integration of LLaMA core technologies in these learning spaces and emphasizes the importance of evolving libraries into intelligent learning support systems. [Method/Process] The methodology employed in this research combines technical deconstruction and scenes for validation, allowing for a comprehensive analysis of the legal risks associated with embedding advanced technologies in educational frameworks. By systematically examining these potential risks, the study aims to establish a well-rounded perspective on the implications of AI deployment in educational settings. [Results/Conclusions] The study identifies three principal challenges encountered in the application of the LLaMA within university learning centers. The first challenge arises from reliability risks linked to content generated by the AI, which may be affected by biases present in the training data. Such biases can lead to the dissemination of inaccurate or misleading information, undermining the trustworthiness of educational resources. Secondly, there are privacy leakage risks, particularly associated with the retention of user behavioral data. As AI systems analyze user interactions, there is a potential for sensitive information to be exposed or misused, raising concerns about student privacy and data security. The third challenge involves ownership determination dilemmas regarding the content generated through AI-driven creative processes. These dilemmas are intricately tied to existing copyright law frameworks, which may not adequately address the complexities introduced by human-machine collaboration in content creation. In response to these challenges, the study proposes several pathways for governance aimed at effectively navigating the landscape of AI in education. It suggests the implementation of dynamic data cleansing mechanisms to address reliability risks and inaccuracies. Additionally, establishing tiered privacy protection systems can help safeguard against user data breaches. Legal frameworks also need refinement to ensure clear ownership distribution for outputs of human-machine collaboration. Ultimately, optimizing the application of the LLaMA model in university future learning centers necessitates a careful balance between technological innovation and legal regulation. By focusing on technical refinement, risk control, and relevant regulatory measures, the development and application of AI can be advanced, facilitating a more integrated evolution of artificial intelligence and educational practices.",AIGC | future learning centers | generative artificial intelligence | LLaMA | LLM | university libraries,0,2025,behavior,behavior+policy
572,2-s2.0-85177688762,10.1108/K-06-2023-0965,https://doi.org/10.1108/K-06-2023-0965,https://scholar.google.com/scholar?q=10.1108/K-06-2023-0965,ar,Kybernetes,"Zhou, Ziyu;Fan, Haizhou;Liu, Zhiying",Do sole actual controllers really inhibit corporate innovation? The nonlinear moderating effect of cooperative culture,"Purpose: 1. Explore the important role of sole actual controller in the innovation decision of the firm and the different effects of the ownership of sole actual controller on innovation; 2. Explore whether the role played by sole actual controllers varies in different types of firms; 3. Explore the important role of cooperative culture in the internal governance of firms and whether sole actual controller firms feel a rejection effect on cooperative culture. Design/methodology/approach: The authors collect data on Shanghai and Shenzhen A-share listed companies from 2011 to 2021 to analyze the role of the sole actual controller on innovation investment, as well as the moderating effect of cooperative culture in corporate annual reports using natural language processing. Findings: The authors find that sole actual controllers promote corporate innovation investment and that concentrated equity inhibits corporate innovation investment, while dispersed equity concentration promotes it. In addition, cooperative culture has a nonlinear moderating effect on the relationship between SACs and innovation. Research limitations/implications: On the one hand, this study focuses chiefly on the decision-making behavior of top managers, such as the SACs and shareholders, and does not account for the role of bottom-level employees or professional R&D teams in innovation. On the other hand, although this study discusses the moderating role of corporate cooperative culture, it is limited to internal cooperative culture; cooperative culture should also consider external cooperation, such as cooperation between companies or between companies and universities. Practical implications: First, companies should actively implement the SAC model and scientifically select a truly compassionate and visionary SAC as the dominant person in the company. Second, the Chinese government needs to standardize the identification of actual controllers, who should not be a shareholder of the company. Third, policymakers should promote the reform of the mixed system of enterprises, optimize the shareholding structure of firms, make executives an important part of corporate governance. Fourth, cooperation culture is a good start, though firms should avoid letting it become a “double-edged sword” of the management mode of the SAC. Originality/value: First, existing studies do not address the impact of SACs on innovation from the perspective of SACs, who have most influence the firm's decision-making. Focusing on the SAC's decision-making style has sufficient practical implications for future corporate innovation planning. This study used the natural language processing (NLP) module in ChatGPT to analyze the culture of cooperation in corporate annual reports. Currently, corporate culture is an obstacle to the study of corporate governance because of its obscurity and difficulty of quantification. The authors adopted a PSM (propensity score matching) approach to eliminate the endogeneity of the data, which makes the results more scientific.",Collaborative culture | Innovation input | Natural language processing | Propensity score matching | Sole actual controller,0,2025,behavior,behavior+policy
584,2-s2.0-105027463408,10.14309/ajg.0000000000003872,https://doi.org/10.14309/ajg.0000000000003872,https://scholar.google.com/scholar?q=10.14309/ajg.0000000000003872,re,American Journal of Gastroenterology,"Lee, Dee;Maravic, Zorana;Moon, Andrew M.;Langenbacher, Diane;Kautz, Achim;Peck, Raquel;Allaire, Manon;Kather, Jakob Nikolas",Enhancing Patient Empowerment through Artificial Intelligence in Liver Cancer,"Chronic liver disease and liver cancer such as hepatocellular carcinoma (HCC) have a growing global health burden. In many areas, liver disease and cancer have a rising incidence, later diagnosis, and higher mortality. Although guidelines recommend regular surveillance, the timely detection of liver disease and HCC remains inconsistent. This is largely due to low awareness, restricted access to care, and fragmented healthcare systems. It is well known that patient empowerment through knowledge, engagement, and shared decision-making could therefore help to improve outcomes. However, this is frequently complicated by stigma, low health literacy, and comorbidities.These challenges could be improved by Artificial Intelligence (AI). AI methods can analyze healthcare data and could directly impact screening and risk stratification. In addition, the emergence of large language models (LLMs) such as ChatGPT provides new tools that can support the patient journey.Here, we provide a systematic overview of the capabilities of Artificial Intelligence (AI) methods to potentially improve liver cancer care.We highlight that AI tools in liver cancer care could be used in two ways: they can help healthcare professionals (HCPs) and patients alike. HCP-focused AI tools can constitute clinical decision-support systems and improve care continuity via telemedicine and remote monitoring. Patient-focused AI applications can have the potential to empower patients, by providing personalized education, counseling, and improved patient engagement.However, we also point out the need for caution in the implementation of this technology. Key concerns are related to ethical considerations, regulation, data privacy, transparency, algorithmic bias, rigorous clinical validation and patient preferences and needs. When these concerns are resolved, AI could help to deliver more personalized, participatory, and equitable liver disease care.",artificial intelligence | chronic liver disease | liver cancer | machine learning,0,2025,behavior,behavior+policy
585,2-s2.0-105027460164,10.17323/jle.2025.27195,https://doi.org/10.17323/jle.2025.27195,https://scholar.google.com/scholar?q=10.17323/jle.2025.27195,ar,Journal of Language and Education,"Bozorgian, Hossein;Rahimi, Hossein",Peer e-Feedback and ChatGPT-4o in EFL Writing: A Cognitive-Interpersonal Comparison Based on EFL Students,"Background: Although both peer and AI-generated feedback are increasingly used in EFL writing instruction, little is known about how they differ in terms of cognitive depth and interpersonal delivery. Existing studies often overlook the mechanisms through which feedback operates, limiting instructors’ ability to design balanced feedback ecosystems. Purpose: To provide a comparative analysis of peer and ChatGPT-4o feedback on undergraduate EFL academic writing, drawing on Hattie and Timperley’s (2007) cognitive model and Hyland and Hyland’s (2006) interpersonal feedback strategies. It aims to identify how each source targets task, process, and self-regulation levels, and how their rhetorical styles shape learner engagement. Method: Thirty Iranian undergraduate EFL students participated in a qualitative classroom-based study in which each essay received both peer and ChatGPT-4o feedback. A total of 430 peer comments and 224 ChatGPT feedback units were coded deductively using validated analytical frameworks. Inter-rater reliability for 20% of the dataset yielded substantial agreement (κ = .82). Results: Peer feedback was subjective, socially expressive, and frequently mitigated, with comments focusing on sentence-level issues but also including self-regulation prompts (15%) that encouraged reflection and decision-making. ChatGPT-4o provided predominantly task-level feedback (94%), characterized by structured, consistent, and objective guidance on grammar, organization, and coherence. However, its feedback exhibited minimal interpersonal variation and rarely promoted metacognitive engagement. Conclusion: The findings indicate that peer and AI-generated feedback serve complementary pedagogical functions: AI offers technical accuracy and consistency, while peer feedback contributes emotional support and occasional reflective prompts. A hybrid feedback model that integrates both sources may therefore enhance the revision process in EFL writing instruction.",academic writing | chatgpt-4o | feedback comparison | peer e-feedback,0,2025,behavior,behavior+policy
586,2-s2.0-105026770467,10.22363/2313-2302-2025-29-4-1101-1119,https://doi.org/10.22363/2313-2302-2025-29-4-1101-1119,https://scholar.google.com/scholar?q=10.22363/2313-2302-2025-29-4-1101-1119,ar,Rudn Journal of Philosophy,"Solozhenkin, Boris S.;Asafaylo, Marina P.",Possibility of Using AI in Teaching Ethics: Using Bioethics as an Example,"This study analyzes the prospect of integrating artificial intelligence (AI) systems into the teaching of ethical disciplines, with bioethics as a key example. Based on an interdisciplinary approach (philosophy, cognitive sciences, bioethics, AI theory), the problem of attributing AI to moral agency is investigated. Although there are strong arguments in favor of recognizing AI as an influential agent in the socio-cultural sense, this does not provide it with the status of a full-fledged moral agent. AI is able to “follow the rule”, but without a genuine understanding of the irrational moments of intersubjective interaction, the existing cultural and psychological context, which excludes human flexibility in decision-making. Since there is no comprehensive, final ethical regulation, ethical action requires practical wisdom (phronesis), which is inaccessible to AI due to its discrete nature devoid of contextual integrity. Without existential involvement in the world, his own history and physicality, it remains a responsive, but not a morally responsible agent. Using examples of the use of AI (neural networks, chatbots), existing research in the field of its perception and involvement in the educational process, the status of AI as the Other is analyzed. This virtual Other does not introduce us into an ethical situation like a human teacher for several reasons. On the one hand, our work substantiates the AI’s inability to self-reflect due to its ontology. The key argument is human vulnerability, which is the foundation of conscience, responsibility, and genuine ethical inquiry, inaccessible to AI. Without vulnerability, there is no empathy, and without it, there is no immersion in ethical issues as inevitably relevant. The ways of safe use of AI technologies and the associated ethical risks need to be thoroughly studied, including by students themselves in the educational process. In particular, they should understand the need to understand interactions with AI from the perspective of morality, the influence of AI on the decision-making process in future professional activities.",agency | Artificial intelligence | quasiother | vulnerability,0,2025,behavior,behavior+policy
587,2-s2.0-105026282031,10.1109/MCOMSTD.2025.3644899,https://doi.org/10.1109/MCOMSTD.2025.3644899,https://scholar.google.com/scholar?q=10.1109/MCOMSTD.2025.3644899,ar,IEEE Communications Standards Magazine,"Dholakia, Neel;Shukla, Madhu;Khan, Surbhi Bhatia;Jadeja, Rajendrasinh",An Overview of GenAI 2.0 Partnering With Digital Twin to Enhance Decision Making,"Generative AI (GenAI) has moved on to a “2.0” level, where capability comes not only from better generators but from integrating generators with retrieval, tool use, and orchestration. The approach taken in this overview is a systems perspective, where a brief typology of families and of models is codified, along with a distillation of design patterns on how bare generators can be refined into reliable systems, namely containerized RAG, tool schemas, event-driven context, and conservative agent systems. In this position, we propose a practice-driven assessment perspective integrating task quality, along with Attribution, Robustness with respect to distribution shift & adversarial prompts, safety & governance (Privacy, IP, Provenance), and End-to-End Efficiency in Latency, Cost, & Energy. Text/Code, Vision-Language, Speech/Audio, Networks, Public Services, & Critical Infrastructure applications provide examples of these trends extending from benchmarking. The issues it brings to light include controllability and verifiability for long-range, multiple tool agents, scalable contamination aware assessment, traceability preserving data and model stewardship, as well as efficiency for resource-constrained and edge scenarios, while pointing towards near-term areas such as tool interface interoperability, traceability aware retrieval, lifecycle visibility, reporting card interoperability, and reliability assessment. Focusing on operational criteria, the research has contributed to creating a impact for making GenAI 2.0 Trustable AI. The blueprint can be utilized as a guide for future research.",,0,2025,behavior,behavior+policy
588,2-s2.0-105026169999,10.31374/sjms.415,https://doi.org/10.31374/sjms.415,https://scholar.google.com/scholar?q=10.31374/sjms.415,ar,Scandinavian Journal of Military Studies,"Vasankari, Lauri;Koski, Aapo",GenAI in the Military: Trends and Opportunities,"Generative artificial intelligence offers the potential for significant, far-reaching applications within the military domain. This article surveys current trends and explores emerging opportunities for GenAI in military operations, focusing on its integration into strategic planning, decision-making, and operational efficiency. Key areas of application include information extraction, decision support, mission simulations and information warfare. This paper further examines critical challenges such as ethical considerations, bias mitigation, hallucination management, and secure deployment within classified environments. By addressing these challenges and leveraging the opportunities presented by GenAI, military organizations can enhance their capabilities, maintain strategic advantages, and ensure preparedness for future conflicts. The paper concludes with recommendations for research, development, and collaboration across NATO and allied forces to fully harness the power of GenAI in defense and security.",artificial intelligence | defense technology | generative AI | military,0,2025,behavior,behavior+policy
589,2-s2.0-105025772587,10.1080/13854046.2025.2604094,https://doi.org/10.1080/13854046.2025.2604094,https://scholar.google.com/scholar?q=10.1080/13854046.2025.2604094,re,Clinical Neuropsychologist,"Kronenberger, Oscar R.;Gottlieb, Michael C.;Cullum, C. Munro",Large language models in neuropsychology: Emerging applications and ethical considerations,"Objective: There is immense excitement and fear regarding the potential of artificial intelligence, particularly large language models (LLMs), to transform healthcare services. In this paper, we aim to provide a future-oriented commentary on how neuropsychologists might consider integrating LLMs into clinical practice ethically, safely, and effectively. Methods: In Part 1, we provide a narrative review of the emerging applications of generative transformer-based LLMs in neuropsychological assessment, including how these technologies may support clinicians with data collection, clinical decision making, and documentation. In Part 2, we analyze the key ethical considerations using the framework of the American Psychological Association (APA) Ethical Principles of Psychologists and Code of Conduct (2017) and Ethical Guidance for AI in the Professional Practice of Health Service Psychology (2025) to formulate recommendations for future research, policy, and clinical integration. Conclusions: LLMs display promise for enhancing neuropsychological practice along a number of lines, such as extracting data from medical records and natural communication, automating test scoring, supporting differential diagnosis and treatment planning, developing test items, and generating text summaries of interviews and empirical literature. However, the rapid progress in LLMs over recent years has left little time for regulation, ethical discourse, and sufficient validation. Key barriers include privacy concerns, risk of bias, limited model transparency, threats to test security, and insufficient research supporting the validity and reliability across specialized tasks. We advise neuropsychologists to help shape regulation, lead empirical validation efforts, and augment educational resources to effectively integrate LLMs into clinical practice while maintaining high ethical standards.",Artificial intelligence | benefits and risks | ethics | large language models | neuropsychological assessment,0,2025,behavior,behavior+policy
590,2-s2.0-105025435460,10.1177/03064190251407621,https://doi.org/10.1177/03064190251407621,https://scholar.google.com/scholar?q=10.1177/03064190251407621,ar,International Journal of Mechanical Engineering Education,"Quince, Zachery;Nikolic, Sasha;Goh, Steven","Student perceptions of GenAI integration into engineering practice: How students interpret liability, safety, professional conduct and ethics across disciplines","Generative artificial intelligence (GenAI) is rapidly entering engineering workflows, raising new questions about liability, safety, and professional ethics. This study examined how 48 students across five engineering disciplines interpreted these issues in discipline-specific GenAI failure case studies created with ChatGPT-4o. Using a deductive qualitative approach, 192 written responses were coded against a 32-item taxonomy of ethical and professional considerations. Across disciplines, students consistently prioritised control and oversight and decision-making under risk and uncertainty. In contrast, no responses addressed data ownership, power and hegemony, or language fluency. Disciplinary differences were evident: mechatronic and electrical engineering students identified a broader set of considerations, including data collection and use, equity and accessibility, and environmental impacts. These findings support aligning curriculum and assessment with explicit requirements for documenting and validating the use of GenAI, designing for appropriate human oversight, and implementing discipline-specific learning activities that address data governance, equity, and environmental implications throughout the engineering lifecycle.",case study | engineering practice | Ethics | GenAI,0,2025,behavior,behavior+policy
591,2-s2.0-105025430933,10.1108/JKM-01-2025-0070,https://doi.org/10.1108/JKM-01-2025-0070,https://scholar.google.com/scholar?q=10.1108/JKM-01-2025-0070,ar,Journal of Knowledge Management,"Santoro, Gabriele;Beimer, Pietro;Lazari, Andrea","Ok CESARE, can you do this for me? Insights on how artificial intelligence fosters knowledge management","Purpose – The purpose of this study is to explore how generative artificial intelligence (AI) can be integrated into knowledge management (KM) processes within manufacturing companies to enhance efficiency, knowledge accessibility and decision-making. In doing so, this study also examines the organizational enablers and challenges that shape AI implementation. Design/methodology/approach – A single case study was used, conducting semi-structured interviews with key stakeholders, supplemented with document analysis and action research. Data were analysed using the Gioia approach. The case regards CESARE, an AI system developed by FPZ (an Italian manufacturing company) in collaboration with Gellify, a consulting company focused on digital transformation and AI. Findings – The analysis identifies a nine-phase process model that illustrates how generative AI can be progressively embedded into KM practices, from initial exploration and small-scale testing to system integration, organizational alignment and continuous improvement. CESARE was found to reduce redundant tasks, improve knowledge flows and support informed decision-making, while its adoption was enabled by proactive data governance, user training, cross-functional collaboration and continuous monitoring. Key challenges included data privacy concerns, technical complexity and organizational resistance to change. Originality/value – This research contributes to the limited empirical literature on the implementation of generative AI in KM within a specific organizational context. By providing detailed insights from a real-world case study, this paper can guide managers in adopting AI to support internal processes.",Artificial intelligence | ChatGPT | Knowledge management | Knowledge management systems,0,2025,behavior,behavior+policy
592,2-s2.0-105024824367,10.1080/20905998.2025.2602411,https://doi.org/10.1080/20905998.2025.2602411,https://scholar.google.com/scholar?q=10.1080/20905998.2025.2602411,re,Arab Journal of Urology,"Baskaran, Ravanth;Gauhar, Vineet;Tsaturyan, Arman;Guven, Selcuk;Philip, Joe;Tokas, Theodoros;Bres-Niewada, Ewa;Somani, Bhaskar Kumar",Patient information on ureteric stents; online resources versus Artificial intelligence generated content: A benchmarking study from eau endourology,"Background: Ureteric stenting is a common procedure performed to provide temporary drainage for an obstructed or infected kidney, helping to relieve blockage or back pressure. Patients, their relatives, and the general public rely on internet websites and Artificial Intelligence Large Language Models (AI LLMs) such as ChatGPT to obtain relevant information about the procedure, seek advice and guidance, and make informed decisions. We evaluated and compared the quality and readability of websites and information generated by both AI LLMs. Methods: Four ureteric stent-related search terms were entered into Google, Yahoo, and Bing search engines. The top 20 websites for each search term were collected, with duplicates excluded. Patient information leaflets were generated by ChatGPT, Gemini, DeepSeek, and Google AI. The quality of the sources was assessed using the DISCERN and JAMA Benchmark scores, with readability measured by the Flesch Reading Ease Score (FRES) and the Flesch-Kincaid Grade Level (FKGL). Results: Fifty-seven websites and seven AI LLM sources were included, with mean DISCERN scores of 41.5 (±11.2) and 44.3 (±4.19), mean JAMA Benchmark scores of 2.04 (±1.00) and 2.14 (±1.07), mean FRES of 57.1 (±13.6) and 57.0 (±9.71), and mean FKGL scores of 8.08 (±2.24) and 8.27 (±1.50), respectively. No significant differences were observed between websites, and the AI LLM produced information leaflets, with no association between search ranking and quality or readability. Conclusions: There is a general shortage of high-quality, accessible information about ureteric stents in both website and AI sources. As reliance on AI LLMs to gather data from patients grows, efforts should be made to enhance the quality and readability of resources available. This will help ensure that misinformation is minimised and achieve patient education, supporting shared decision-making and a stronger physician-patient relationship throughout the process.",artificial intelligence | kidney calculi | patient information | quality | readability | Ureteric stents,0,2025,behavior,behavior+policy
593,2-s2.0-105024810636,10.1155/hbe2/1269498,https://doi.org/10.1155/hbe2/1269498,https://scholar.google.com/scholar?q=10.1155/hbe2/1269498,re,Human Behavior and Emerging Technologies,"Bommanavar, Sushma;Varma, Sudhir Rama;Karobari, Mohmed Isaqali",Comprehensive Scoping Review on Discrepancy in Accuracy of ChatGPT in Dental Health Practice,"Background: ChatGPT (generative pretrained transformer) is a unique kind of AI model designed for conversational applications, thereby mimicking human conversation by recognizing human speech/text/language/intent and responding in a way imitating human behavior. However, the frail understanding of how ChatGPT is reshaping dental practice is questionable. Aim: The aim of this study is to map the existing literature regarding the discrepancies in the accuracy of ChatGPT in dental practice. Objectives: The objective of the study is to identify the knowledge gaps and key areas of findings on specific parameters that contributed to discrepancies and the potential risk of bias regarding ChatGPT application in dentistry. Methods: The review was conducted over a 12-week time frame. The research question is “why is there discrepancy in accuracy of ChatGPT in dental practice?” We applied Arksey and O′Malley′s 2005 methodological framework. The search strategy was initiated using PRESS in databases such as PubMed/Medline, Embase, and Scopus and was conducted with language restriction and time restriction. Publications included in the review spanned original studies and review articles in the domain of dental practice, excluding studies on dental education, academics, and research areas. Data charting was done in two stages: study identifier stage and study characteristic stage involving multiple author pairs (reviewers and librarian). The data was finally mapped in the form of graphics involving tables and representative charts for better understanding of the coverage and synthesis of the topic. Results: The review synthesized a total of 98 publications using search terms “Chat GPT AND Dentistry,” “Chat GPT AND Dental Practices,” “Chat GPT OR Dentistry,” “Chat GPT OR Dental Practices.” After removing duplicate papers, grey literatures, only abstracts, and articles in a language other than English, 56 papers were totally extracted. As per the inclusion criteria, a total of nine papers were synthesized. We applied a specific coding system for the included studies as SC/01–SC/09 and a response rating system to summarize and report the synthesized data. Collation of the included studies reported four studies with “positive response” and five studies with a “negative response.” All the studies, however, showed high concerns of data bias, data breaching, and lack of validity with potential risk of bias regarding the accuracy of ChatGPT in dental practice. This review reported diverse results on the accuracy of ChatGPT applications in dentistry. Conclusion: The current scoping review highlights the immediate need for considerations and implementation of ethical-based guidelines/frameworks/legal regulations/licensing in the application of ChatGPT in dentistry, thereby laying a foundational platform for drafting specific guidelines/frameworks/legal regulations/licensing by policymakers and researchers for its future role.",accuracy | ChatGPT | data charting | dental education | dentistry | discrepancy | relevancy | scoping review | validity,0,2025,behavior,behavior+policy
594,2-s2.0-105024687407,10.1080/17509653.2025.2596777,https://doi.org/10.1080/17509653.2025.2596777,https://scholar.google.com/scholar?q=10.1080/17509653.2025.2596777,ar,International Journal of Management Science and Engineering Management,"Tu, Yan;Ruan, Jianhui;Zhang, Jiali;Zhang, Xinyu;Fan, Shuqin",A probabilistic linguistic term set and large language model enhanced multi-criteria decision-making framework for evaluating science popularization accounts on Weibo,"The proliferation of misinformation on social media has heightened the demand for high-quality science popularization. However, systematically evaluating the effectiveness of science communication accounts remains challenging due to multidimensional uncertainties and the semantic complexity of content. To bridge this gap, this research constructs the Probabilistic Linguistic Term Sets (PLTS)-Large Language Model (LLM)-Entropy Method (EM)-VlseKriterijumska Optimizacija I Kompromisno Resenje (VIKOR) framework to conduct an empirical evaluation of 35,037 original blog posts from 32 science popularization accounts on Weibo. The approach integrates PLTS to model linguistic and behavioral uncertainty, LLM for semantic feature extraction and dynamic benchmarking, EM for objective weight determination, and VIKOR for robust compromise ranking. This synergy enables a more nuanced and interpretable evaluation compared to conventional methods. The results show that comprehensive interaction volume is the most influential criterion and reveal the critical threshold role of credibility and topic consistency, and also demonstrate the framework’s fine capacity to model complex account performance dynamics. Moreover, perturbation experiments confirm that balanced accounts exhibit high ranking stability and effectively detects and explains the volatility of accounts with isolated weaknesses. Multi-method comparisons show robustness, while illustrates that the compromise logic that emphasizes both interaction and credibility often achieves better rankings. Those with balanced indicators always lead the way, while with prominent weaknesses experience sharp fluctuations. These insights provide a validated methodological foundation and actionable strategies for enhancing science communication governance.",evaluation | large language model | multi-criteria decision-making | probabilistic linguistic term set | Science popularization accounts,0,2025,behavior,behavior+policy
595,2-s2.0-105024549175,10.1080/13600826.2025.2592708,https://doi.org/10.1080/13600826.2025.2592708,https://scholar.google.com/scholar?q=10.1080/13600826.2025.2592708,ar,Global Society,"Radeljić, Branislav",Artificial Intelligence and the Algorithmic Discursive Sphere: Policymaking Dilemmas and the Rise of a New Public Intellectual,"This paper explores the multifaceted relationship between artificial intelligence (AI), programming languages, and ethical-political structures, emphasising how AI development both reflects and reshapes global power dynamics. When prompted about its participation in political discourse or its potential to function as a public intellectual (a hybrid human–nonhuman actor that redefines the link between technology, politics, and public reason), generative AI often expresses a willingness to engage with complex ideas, while simultaneously acknowledging its limitations in terms of original thought and its inability to advocate for social change. It tends to prioritise neutrality over taking definitive stances, which raises critical concerns. This neutrality may inadvertently contribute to inequality, particularly in the context of the divide between the Global North and the Global South. Moreover, the geopolitical rivalry between the United States and China, combined with AI’s growing role in decision-making processes, underscores its potential to privilege certain agendas–often those aimed at power maximisation and wealth accumulation. This paper argues that the promise of AI must be weighed against its risks, especially in high-stakes domains, and that meaningful accountability demands more than ethics-as-branding. By framing AI as a sociotechnical artifact embedded in ideology and power, the study highlights the need for global, pluralistic, and enforceable ethical frameworks in the face of accelerating digital transformation.",accountability | AI | authoritarianism | democracy | human–machine interaction | policymaking | power | public intellectuals,0,2025,behavior,behavior+policy
596,2-s2.0-105024483413,10.3389/fdgth.2025.1623922,https://doi.org/10.3389/fdgth.2025.1623922,https://scholar.google.com/scholar?q=10.3389/fdgth.2025.1623922,ar,Frontiers in Digital Health,"Diaz Ochoa, Juan G.;Layer, Natalie;Mahr, Jonas;Mustafa, Faizan E.;Menzel, Christian U.;Müller, Martina;Schilling, Tobias;Illerhaus, Gerald;Knott, Markus;Krohn, Alexander",Optimized BERT-based NLP outperforms zero-shot methods for automated symptom detection in clinical practice,"Background: Large Language Models (LLMs) have raised broad expectations for clinical use, particularly in the processing of complex medical narratives. However, in practice, more targeted Natural Language Processing (NLP) approaches may offer higher precision and feasibility for symptom extraction from real-world clinical texts. NLP provides promising tools for extracting clinical information from unstructured medical narratives. However, few studies have focused on integrating symptom information from free texts in German, particularly for complex patient groups such as emergency department (ED) patients. The ED setting presents specific challenges: high documentation pressure, heterogeneous language styles, and the need for secure, locally deployable models due to strict data protection regulations. Furthermore, German remains a low-resource language in clinical NLP. Methods: We implemented and compared two models for zero-shot learning—GLiNER and Mistral—and a fine-tuned BERT-based SCAI-BIO/BioGottBERT model for named entity recognition (NER) of symptoms, anatomical terms, and negations in German ED anamnesis texts in an on-premises environment in a hospital. Manual annotations of 150 narratives were used for model validation. The postprocessing steps included confidence-based filtering, negation exclusion, symptom standardization, and integration with structured oncology registry data. All computations were performed on local hospital servers in an on-premises implementation to ensure full data protection compliance. Results: The fine-tuned SCAI-BIO/BioGottBERT model outperformed both zero-shot approaches, achieving an F1 score of 0.84 for symptom extraction and demonstrating superior performance in negation detection. The validated pipeline enabled systematic extraction of affirmed symptoms from ED-free text, transforming them into structured data. This method allows large-scale analysis of symptom profiles across patient populations and serves as a technical foundation for symptom-based clustering and subgroup analysis. Conclusions: Our study demonstrates that modern NLP methods can reliably extract clinical symptoms from German ED free text, even under strict data protection constraints and with limited training resources. Fine-tuned models offer a precise and practical solution for integrating unstructured narratives into clinical decision-making. This work lays the methodological foundation for a new way of systematically analyzing large patient cohorts on the basis of free-text data. Beyond symptoms, this approach can be extended to extracting diagnoses, procedures, or other clinically relevant entities. Building upon this framework, we apply network-based clustering methods (in a subsequent study) to identify clinically meaningful patient subgroups and explore sex- and age-specific patterns in symptom expression.",clinical NLP | fine-tuning | large language models (LLM) | named entity recognition (NER) | natural language processing (NLP) | symptom extraction,0,2025,behavior,behavior+policy
597,2-s2.0-105024461789,10.1108/JKM-02-2025-0252,https://doi.org/10.1108/JKM-02-2025-0252,https://scholar.google.com/scholar?q=10.1108/JKM-02-2025-0252,ar,Journal of Knowledge Management,"Sun, Yanqi;Xu, Cheng",Hybrid cognitive authority and algorithmic subjectivity: rethinking knowledge management in AI-driven communication,"Purpose – This paper aims to explore the transformative impact of generative artificial intelligence (AI) and human-computer interaction (HCI) on knowledge management in business, focusing on how AI-driven communication reshapes organizational practices. It examines the role of HCI in designing user-centric AI tools and introduces Hybrid Cognitive Authority (the co-construction of knowledge between human and AI agents) and Algorithmic Subjectivity (AI-generated communication simulating intent without cognition) to evaluate their effects on decision-making, knowledge flows and ethical governance in commercial settings. Design/methodology/approach – A mixed-methods approach integrates interdisciplinary genealogical analysis, qualitative case studies and critical discourse analysis. The study traces the evolution of commercial communication from mid-20th-century pragmatics to AI-mediated paradigms, synthesizing insights from cognitive science, information systems and digital epistemology. Five case studies of AI and HCI applications in business (e.g. customer service, recruitment) and discourse analysis of AI-generated artifacts provide empirical evidence for assessing knowledge management outcomes. Findings – Generative AI, supported by HCI, enhances knowledge management by improving efficiency and scalability, but raises challenges related to transparency, algorithmic bias and accountability. Empirical cases demonstrate how hybrid human-AI systems optimize knowledge processes while highlighting ethical risks, such as biased outputs. The proposed framework of Hybrid Cognitive Authority and Algorithmic Subjectivity necessitates governance models that balance AI automation with human oversight to maintain trust and interpretive agency. Originality/value – Unlike prior studies that view AI as a passive tool, this research positions AI as an active knowledge co-constructor, advancing knowledge management scholarship through the novel concepts of Hybrid Cognitive Authority and Algorithmic Subjectivity. It bridges theory and practice by offering actionable strategies for businesses to leverage AI and HCI responsibly, contributing to economic efficiency, ethical governance and societal trust in AI-driven communication.",Algorithmic subjectivity | Business communication | Digital epistemology | Ethical governance | Generative AI | Human-computer interaction | Hybrid cognitive authority | Knowledge management,0,2025,behavior,behavior+policy
598,2-s2.0-105024070770,10.1109/MIS.2025.3622004,https://doi.org/10.1109/MIS.2025.3622004,https://scholar.google.com/scholar?q=10.1109/MIS.2025.3622004,ar,IEEE Intelligent Systems,"Ferdinan, Teddy;Mieleszczenko-Kowszewicz, Wiktoria;Kocon, Jan;Kazienko, Przemyslaw;Cambria, Erik",Architectural Concepts for Integrating Fundamental Drives and Emotions Into Artificial Intelligence,"Current large language models display limited emotional intelligence, often mimicking affective patterns without genuine understanding, which raises manipulation and safety risks. We argue that artificial intelligence (AI) should prioritize long-term human well-being over short-term engagement, and that advancing toward artificial general intelligence (AGI) requires embedding fundamental drives and artificial emotions in model architectures. Building on Lazarus’s cognitive-rational theory, we propose a framework with an emotional module and a rational module, where artificial drives guide affective appraisal and decision-making. This enables alignment of artificial emotions with core values—such as human well-being, fairness, and environmental preservation—anchoring AI safety at the architectural level rather than through post hoc fixes. We discuss technical and ethical challenges, including data needs and reward modeling, and call for open science and regulation to ensure human-centered AGI.",,0,2025,behavior,behavior+policy
599,2-s2.0-105024032059,10.2196/80770,https://doi.org/10.2196/80770,https://scholar.google.com/scholar?q=10.2196/80770,re,Journal of Medical Internet Research,"Jiang, Wang;Wang, Dan;Zeng, Yihang;Huang, Jiaqi;Xu, Chang;Liu, Chenxi",Promoting Responsible DeepSeek Deployment in Health Care: Scoping Review Comparing Grey and White Literature,"Background: DeepSeek is an open-source large language model (LLM), and it has greatly accelerated LLM adoption in health care. Its rapid deployment has sparked concerns regarding its impact on patient outcomes and safety. However, little is known about how DeepSeek is used and regulated in health care. Objective: This study aimed to (1) systematically review the characteristics of DeepSeek deployed in the top 100 hospitals in China, and (2) compare the performance and risks of DeepSeek between hospital disclosures and research evidence. Methods: We searched the official websites and WeChat accounts of the top 100 hospitals in China and the databases of Web of Science and PubMed, using the terms “DeepSeek” and “large language models.” Searches were limited to records after January 15, 2025, when DeepSeek was first released. All searches were conducted on May 20, 2025, with an update on June 28, 2025. We extracted the basic characteristics of DeepSeek; its aims, evaluation approach, performance, and risks; and hospital regulations. A coding framework was developed covering the application scenarios, evaluation dimensions, and risk sources of LLMs. The risk of bias was assessed using the Joanna Briggs Institute checklist. Results: We identified a total of 58 DeepSeek models in 48 out of the top 100 Chinese hospitals and found 27 studies in the literature. The first hospital deployment of DeepSeek was recorded on February 10, 2025, and deployment rapidly expanded to 37 hospitals within a month. Concurrently, most related research studies (20/27, 74%) were published after May 2025. Among deployments and studies that reported version information, DeepSeek-reasoner (R1) was the most frequently used model, and private deployment was the predominant approach. DeepSeek was mainly used to assist in clinical decision-making, including patient diagnosis and treatment recommendation. Among hospital disclosures, only 36% (21/58) clearly indicated a predeployment assessment, 22% (13/58) presented assessment results, and 9% (5/58) identified potential risks and countermeasures. We found poor transparency in hospital reporting, with none of the disclosures presenting evaluation details. Hospitals were more likely to report higher performance and fewer risks for DeepSeek. Conclusions: This is one of the first scoping reviews to reveal the rapid, widespread deployment of DeepSeek in China’s leading hospitals, primarily for clinical decision support. The deployment of DeepSeek in China’s leading hospitals poses potential risks to patient outcomes and safety. We highlight the urgent need for existing regulations to be expanded to downstream developers and users to promote the responsible use of LLMs in health care. Hospitals need to use a more rigorous validation process and adopt a more transparent reporting policy. The main limitations of this review include the restriction to top-tier hospitals and the inherent constraints of gray literature. These factors should be considered when interpreting the findings.",China | DeepSeek | hospital | large language model | responsible use,0,2025,behavior,behavior+policy
600,2-s2.0-105023865707,10.3352/jeehp.2025.22.37,https://doi.org/10.3352/jeehp.2025.22.37,https://scholar.google.com/scholar?q=10.3352/jeehp.2025.22.37,re,Journal of Educational Evaluation for Health Professions,"Loubbairi, Sana;Moussaoui, Yasmine El;Lahlou, Laila;Chakri, Imad;Nassik, Hicham",The impact of artificial intelligence-driven simulation on the development of non-technical skills in medical education: a systematic review,"Purpose: Artificial intelligence (AI)-driven simulation is an emerging approach in healthcare education that enhances learning effectiveness. This review examined its impact on the development of non-technical skills among medical learners. Methods: Following the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines, a systematic review was conducted using the following databases: Web of Science, ScienceDirect, Scopus, and PubMed. The quality of the included studies was assessed using the Mixed Methods Appraisal Tool. The protocol was previously registered in PROSPERO (CRD420251038024). Results: Of the 1, 442 studies identified in the initial search, 20 met the inclusion criteria, involving 2, 535 participants. The simulators varied considerably, ranging from platforms built on symbolic AI methods to social robots powered by computational AI. Among the 15 AI-driven simulators, 10 used ChatGPT or its variants as virtual patients. Several studies evaluated multiple non-technical skills simultaneously. Communication and clinical reasoning were the most frequently assessed skills, appearing in 12 and 6 studies, respectively, which generally reported positive outcomes. Improvements were also noted in decision-making, empathy, self-confidence, critical thinking, and problem-solving. In contrast, emotional regulation, assessed in a single study, showed no significant difference. Notably, none of the studies examined reflection, reflective practice, teamwork, or leadership. Conclusion: AI-driven simulation shows substantial potential for enhancing non-technical skills in medical education, particularly communication and clinical reasoning. However, its effects on several other non-technical skills remain unclear. Given heterogeneity in study designs and outcome measures, these findings should be interpreted cautiously. These considerations highlight the need for further research to support integrating this innovative approach into medical curricula.",Artificial intelligence | Medical students | Non-technical skills | Simulation training,0,2025,behavior,behavior+policy
601,2-s2.0-105023565045,10.3389/fcomp.2025.1683495,https://doi.org/10.3389/fcomp.2025.1683495,https://scholar.google.com/scholar?q=10.3389/fcomp.2025.1683495,ar,Frontiers in Computer Science,"Zhang, Yi;Aman, Jantan",Targeted injection attack toward the semantic layer of large language models,"In the AI era, high-value targeted injection attacks and defences based on the semantic layer of Large Language Models will become the main battlefield for security confrontations. Ultimately, any form of artificial information warfare boils down to a battle at the semantic level. This involves using information technology to attack the semantic layer and, consequently, the human brain. Specifically, the goal is to launch targeted attacks on the brains of specific decision-making groups within society, thereby undermining human social decision-making mechanisms. The ultimate goal is to maximize value output in the fields of political economy, religion, and ideology, including wealth and power, with minimal investment in information technology. This paper uses the pyramid model perspective to unify the information security confrontation protocol stack, including biological intelligence, human intelligence, and artificial intelligence. It begins by analysing the characteristics and explainable of AI models, and feasible means of their multi-dimensions offensive and defensive mechanisms, proposing an open engineering practice strategy that leverages semantic layer gaming between LLMs. This strategy involves targeted training set contamination at the semantic layer and penetration induction through social networks. At the end of this article, expands the contamination of training set data sources to the swarm oscillating environment in human-machine sociology and ethical confrontation, then discusses attacks targeting the information cocoon of individuals or communities and extends the interaction mechanism between humans and LLMs and GPTs above the semantic layer to the evolution dynamics of a Fractal Pyramid Model.",adversarial examples | contamination oscillations | malicious training | NLP | semantic layer | targeted injection attack,0,2025,behavior,behavior+policy
602,2-s2.0-105023314648,10.1111/jocn.70151,https://doi.org/10.1111/jocn.70151,https://scholar.google.com/scholar?q=10.1111/jocn.70151,re,Journal of Clinical Nursing,"Watson, Adrianna L.;Bond, Carmel;Aveyard, Helen;Smith, Graeme D.;Jackson, Debra",Generative AI at the Bedside: An Integrative Review of Applications and Implications in Clinical Nursing Practice,"Aim: The aim of this integrative review is to critically appraise and synthesise empirical evidence on the clinical applications, outcomes, and implications of generative artificial intelligence in nursing practice. Design: Integrative review following Whittemore and Knafl's five-stage framework. Methods: Systematic searches were performed for peer-reviewed articles and book chapters published between 1 January 2018 and 30 June 2025. Two reviewers independently screened titles/abstracts and full texts against predefined inclusion/exclusion criteria focused on generative artificial intelligence tools embedded in nursing clinical workflow (excluding nursing education-only applications). Data were extracted into a standardised matrix and appraised for quality using design-appropriate checklists. Guided by Whittemore and Knafl's integrative review framework, a constant comparative analysis was applied to derive the main themes and subthemes. Data Sources: CINAHL, MEDLINE, and Embase. Results: Included literature was a representative mix of single-group quality improvement pilots, mixed-method usability and feasibility studies, randomised controlled trials, qualitative descriptive and phenomenological studies, as well as preliminary and proof-of-concept observational research. Four overarching themes emerged: (1) Workflow Integration and Efficiency, (2) AI-Augmented Clinical Reasoning, (3) Patient-Facing Communication and Education, and (4) Role Boundaries, Ethics and Trust. Conclusion: Generative artificial intelligence holds promise for enhancing nursing efficiency, supporting clinical decision making, and extending patient communication. However, consistent human validation, ethical boundary setting, and more rigorous, longitudinal outcome and equity evaluations are essential before widespread clinical adoption. Implications for the Profession and Patient Care: Although generative artificial intelligence could reduce nurses' documentation workload and routine decision-making burden, these gains cannot be assumed. Safe and effective integration will require rigorous nurse training, robust governance, transparent labelling of AI-generated content, and ongoing evaluation of both clinical outcomes and equity impacts. Without these safeguards, generative artificial intelligence risks introducing new errors and undermining patient safety and trust. Reporting Method: PRISMA 2020.",,0,2025,behavior,behavior+policy
603,2-s2.0-105023093598,10.2196/77951,https://doi.org/10.2196/77951,https://scholar.google.com/scholar?q=10.2196/77951,ar,Jmir Mental Health,"Luo, Xiaochen;Wang, Zixuan;Tilley, Jacqueline L.;Balarajan, Sanjeev;Bassey, Ukeme Abasi;Cheang, Choi Ieng",Seeking Emotional and Mental Health Support From Generative AI: Mixed-Methods Study of ChatGPT User Experiences,"Background: Generative artificial intelligence (GenAI) models have emerged as a promising yet controversial tool for mental health. Objective: The purpose of this study is to understand the experiences of individuals who repeatedly used ChatGPT (GenAI) for emotional and mental health support (EMS). Methods: We recruited 270 adult participants across 29 countries who regularly used ChatGPT (OpenAI) for EMS during April 2024. Participants responded to quantitative survey questions on the frequency and helpfulness of using ChatGPT for EMS, and qualitative questions regarding their therapeutic purposes, emotional experiences of using, and perceived helpfulness and rationales. Thematic analysis was used to analyze qualitative data. Results: Most participants reported using ChatGPT for EMS at least 1‐2 times per month for purposes spanning traditional mental health needs (diagnosis, treatment, and psychoeducation) and general psychosocial needs (companionship, relational guidance, well-being improvement, and decision-making). Users reported various emotional experiences during and after use for EMS (eg, connected, relieved, curious, embarrassed, or disappointed). Almost all users found it at least somewhat helpful. The rationales for perceived helpfulness include perceived changes after use, emotional support, professionalism, information quality, and free expression, whereas the unhelpful aspects include superficial emotional engagement, limited information quality, and lack of professionalism. Conclusion: Despite the absence of ethical regulations for EMS use, GenAI is becoming an increasingly popular self-help tool for emotional and mental health support. These results highlight the blurring boundary between formal mental health care and informal self-help and underscore the importance of understanding the relational and emotional dynamics of human-GenAI interaction. There is an urgent need to promote AI literacy and ethical awareness among community users and health care providers and to clarify the conditions under which GenAI use for mental health promotes well-being or poses risk.",ChatGPT | generative artificial intelligence (GenAI) | help-seeking behavior | mental health and emotional support | perceived helpfulness,0,2025,behavior,behavior+policy
604,2-s2.0-105022607040,10.1177/20552076251393302,https://doi.org/10.1177/20552076251393302,https://scholar.google.com/scholar?q=10.1177/20552076251393302,re,Digital Health,"MacKay, Melissa;Kukan, Anjali;McWhirter, Jennifer E.",The double-edged algorithm: A rapid review exploring the trustworthy and responsible use of generative AI in public health,"Objective: Generative artificial intelligence (genAI) technologies have rapidly evolved, offering potential to strengthen core public health functions such as health communication, surveillance, and emergency preparedness. While genAI may enhance public health outcomes by enabling tailored messaging, helping to combat misinformation, and supporting data-driven decision-making, its integration raises significant concerns about equity, privacy, and trust. Methods: This rapid review explores guiding principles for the trustworthy and responsible use of genAI in public health contexts. Following established rapid review protocols, peer-reviewed and grey literature published since 2014 were identified and analyzed thematically. Results: Ten articles met the inclusion criteria, focusing on genAI applications across various public health settings. Ten themes were generated that describe guiding principles for the trustworthy and responsible use of genAI in public health. The themes emphasize the importance of human oversight, transparency, equity, accountability, and culturally relevant communication. While genAI can be used to support health behavior change, enhance health communication across literacy levels, and promote community engagement, risks such as algorithmic bias, data misuse, and the amplification of health disinformation must be mitigated. Conclusion: Organizational policies must reflect ethical considerations and address current regulatory gaps to help mitigate these risks. Workforce training, interdisciplinary collaboration, and policy development are vital to support responsible and trustworthy implementation. This review provides preliminary insights that can help public health organizations begin to consider guidling principles for policies for guiding genAI adoption and use, emphasizing the importance of human-centered and ethically grounded approaches. Findings also identify future research needs, including the evaluation of genAI tools in diverse public health contexts, assessment of real-world impacts, and exploration of governance frameworks. This review offers an initial foundation for public health organizations to consider potential applications of genAI and develop policies that support its responsible and trustworthy use.",equity | ethics | Generative artificial intelligence | public health | trust,0,2025,behavior,behavior+policy
605,2-s2.0-105021822320,10.1007/s00146-025-02698-9,https://doi.org/10.1007/s00146-025-02698-9,https://scholar.google.com/scholar?q=10.1007/s00146-025-02698-9,re,AI and Society,"Abbas, Fakhar;Chesterman, Simon;Taeihagh, Araz","Building trust in the generative AI era: a systematic review of global regulatory frameworks to combat the risks of mis-, dis-, and mal-information","The rapid evolution of generative artificial intelligence (genAI) technologies such as ChatGPT, DeepSeek, Gemini, and Stable Diffusion offers transformative opportunities while also raising profound ethical, societal, and governance challenges. As these tools become increasingly integrated into digital and social infrastructures, it is vital to understand their potential impact on consumer behavior, trust, information consumption, and societal well-being. Understanding how individuals interact with AI-enhanced content is, in turn, necessary for developing operative regulatory policies to address the growing challenges of mis-, dis-, and mal-information (MDM) on digital platforms. In this study, we systematically analyze global regulatory and policy frameworks as well as AI-driven tools to address the growing risks of MDM on digital platforms and optimize the interplay between humans and genAI moderation. The study highlights the need to balance technological innovation with societal protection and freedom of expression by identifying evolving trends and critical gaps in global policy coherence. We examine how the proliferation of MDM—often accelerated by genAI—distorts the information landscape, induces cognitive biases, and undermines informed decision-making. Our study proposes an integrative strategy that combines technical detection methods with actionable policy recommendations to mitigate MDM risks, reinforce digital resilience, and foster trustworthy genAI governance. The study also explores the potential role of AI itself in combating MDM risks.",AI governance and regulation | Digital resilience | Disinformation | Generative artificial intelligence | Information integrity | Misinformation,0,2025,behavior,behavior+policy
606,2-s2.0-105021047077,10.1080/10447318.2025.2573037,https://doi.org/10.1080/10447318.2025.2573037,https://scholar.google.com/scholar?q=10.1080/10447318.2025.2573037,ar,International Journal of Human Computer Interaction,"Smutny, Zdenek;Sudzina, Frantisek",What Affects Work Performance When Using AI Chatbots? Investigating Mediations and Factors Affecting Performance Expectancy and Intentions to Use ChatGPT,"Generative artificial intelligence (AI) tools are reshaping individual work performance. While many studies explore the adoption of generative AI tools, few examine mediations and factors influencing performance expectancy and intentions to use AI chatbots like ChatGPT. This study builds on Camilleri’s (2024) framework, integrating enhanced UTAUT and IAM models, and presents extended replication. A survey questionnaire (N=787, aged 18–34 y) was analyzed using SmartPLS4. The results show that performance expectancy significantly mediates the relationship between effort expectancy, source trustworthiness, and information quality to intentions to use AI chatbots. Sex differences were found, with men prioritizing the quality of information, while women emphasize the source trustworthiness. Compared to replicated research, distinct cultural and demographic factors influenced adoption outcomes. Despite user-intuitive control similar to internet-mediated human communication, which facilitates adoption among young people, users remain cautious due to risks like hallucinations, social bias, misinformation, or adversarial prompts. The study contributes theoretically and empirically to understanding how AI chatbots affect work-related behavior and decision-making.",generative artificial intelligence tool | information adoption model | large language model | replication study | Unified theory of acceptance and use of technology,0,2025,behavior,behavior+policy
607,2-s2.0-105020665350,10.2196/76340,https://doi.org/10.2196/76340,https://scholar.google.com/scholar?q=10.2196/76340,re,Journal of Medical Internet Research,"Izquierdo-Condoy, Juan S.;Arias-Intriago, Marlon;Tello-De-la-Torre, Andrea;Busch, Felix;Ortiz-Prado, Esteban",Generative Artificial Intelligence in Medical Education: Enhancing Critical Thinking or Undermining Cognitive Autonomy?,"Generative artificial intelligence (GenAI) enables the production of coherent and contextually relevant text by processing large-scale linguistic datasets. Tools such as ChatGPT, Gemini, Claude, and LLaMA are increasingly integrated into medical education, assisting students with a range of tasks, including clinical reasoning, literature review, scientific writing, and formative assessment. Although these tools offer significant advantages in terms of productivity, personalization, and cognitive support, their impact on critical thinking—a cornerstone of medical education—remains uncertain. The aim of this viewpoint paper is to critically assess the influence of GenAI on critical thinking within medical training, examining both its potential to enhance cognitive skills and the risks it poses to cognitive autonomy. Users have reported increased efficiency and improved linguistic output; however, concerns have also been raised regarding the risk of cognitive overreliance. Current evidence presents a mixed picture, indicating both improvements in learner engagement and potential drawbacks such as passivity or susceptibility to misinformation. Without curricular integration that prioritizes ethical use, prompt engineering, and critical evaluation, GenAI may compromise the cognitive autonomy of medical students. Conversely, when thoughtfully embedded into pedagogical frameworks, these tools can act as cognitive enhancers—supporting, rather than replacing, clinical reasoning. Medical education must adapt to ensure that future physicians engage with GenAI in a critical, ethical, and context-aware manner, especially in complex decision-making scenarios. This transformation demands not only technological fluency but also reflective practice and sustained oversight by faculty and academic institutions.",cognitive autonomy | critical thinking | curriculum innovation | generative artificial intelligence | medical education,0,2025,behavior,behavior+policy
608,2-s2.0-105020480286,10.12688/f1000research.169337.1,https://doi.org/10.12688/f1000research.169337.1,https://scholar.google.com/scholar?q=10.12688/f1000research.169337.1,re,F1000research,"ADABARA, IBRAHIM;Olaniyi Sadiq, Bashir;Nuhu Shuaibu, Aliyu;Ibarahim Danjuma, Yale;Venkateswarlu, Maninti","A Review of Agentic AI in Cybersecurity: Cognitive Autonomy, Ethical Governance, and Quantum-Resilient Defense","Agentic Artificial Intelligence (AAI) refers to autonomous, adaptable, and goal-directed systems capable of proactive decision-making in dynamic environments. These agentic systems extend beyond reactive AI by leveraging cognitive architectures and reinforcement learning to enhance adaptability, resilience, and self-sufficiency in cybersecurity contexts. As cyber threats grow in sophistication and unpredictability, Agentic AI is rapidly becoming a foundational technology for intelligent cyber defense, enabling capabilities such as real-time anomaly detection, predictive threat response, and quantum-resilient protocols. This narrative review synthesizes literature from 2005 to 2025, integrating academic, industry, and policy sources across three thematic pillars: cognitive autonomy, ethical governance, and quantum-resilient defense. The review identifies key advancements in neuromorphic architectures, cross-jurisdictional governance models, and hybrid defense systems that adapt to evolving threat landscapes. It also exposes critical challenges, including dual-use risks, governance interoperability, and preparedness for post-quantum security. This work contributes a multi-dimensional conceptual framework linking governance mechanisms to operational practice, maps resilience strategies across conventional and quantum vectors, and outlines a forward-looking roadmap for secure, ethical, and adaptive deployment of Agentic AI in cybersecurity. The synthesis aims to support policymakers, developers, and security practitioners in navigating the accelerating convergence of autonomy, security, and AI ethics.",Agentic Artificial Intelligence | AI Threat Mitigation | Autonomous Cyber Defense | Cognitive Autonomy | Cybersecurity | Ethical Governance | Quantum-Resilient Systems,0,2025,behavior,behavior+policy
609,2-s2.0-105020293541,10.1080/09537325.2025.2577709,https://doi.org/10.1080/09537325.2025.2577709,https://scholar.google.com/scholar?q=10.1080/09537325.2025.2577709,ar,Technology Analysis and Strategic Management,"Marchena Sekli, Giulio;De La Vega, Iván",Addressing challenges and constructing a blueprint for effective generative AI integration in business operations,"This study addresses the critical challenges and proposes a comprehensive blueprint for effectively integrating Generative Artificial Intelligence (GenAI) into business operations. GenAI has emerged as a transformative force, offering significant competitive advantages to early adopters. However, a substantial gap remains in understanding the technical, organisational, and governance challenges associated with GenAI implementation. This research utilises a mixed-methods approach, incorporating a systematic literature review and expert interviews to develop a blueprint for deploying GenAI in organisations. The blueprint emphasises the alignment of GenAI initiatives with business objectives, the establishment of responsible governance framework, and the development of a technical infrastructure. It also highlights the decision-making process regarding the use of low-code/no-code platforms versus pro-code environments, as well as the impact of GenAI on both customer and employee experiences. Additionally, the study underscores the importance of organisational readiness, change management, and continuous improvement to foster a culture that embraces AI-driven innovation. By providing detailed insights into both technical and organisational aspects, this research bridges existing gaps and offers practical guidance for companies seeking to leverage GenAI to enhance their competitive edge. The findings contribute to the broader discourse on GenAI integration, supporting the strategic and operational scalability of GenAI within various industries.",blueprint | business operations | Generative artificial intelligence | management,0,2025,behavior,behavior+policy
611,2-s2.0-105019589261,10.1109/TSMC.2025.3620250,https://doi.org/10.1109/TSMC.2025.3620250,https://scholar.google.com/scholar?q=10.1109/TSMC.2025.3620250,re,IEEE Transactions on Systems Man and Cybernetics Systems,"Ma, Xueling;Shen, Yufeng;Liu, Peide;Zhan, Jianming","Recent Advances, Critical Reflections, and Future Directions in Large-Scale Group Decision-Making: A Comprehensive Survey","This comprehensive survey provides a systematic examination of recent advances, critical reflections, and future directions in large-scale group decision-making (LSGDM), a rapidly evolving field driven by the proliferation of digital platforms and the growing complexity of collective decision scenarios. Building upon a rigorous analysis of 360 peer-reviewed publications from 2014 to 2025, we establish a structured knowledge framework that organizes current research into four core modules: information modeling and representation, dimensionality reduction, behavior management, and consensus model design. Theoretically, our work contributes by synthesizing diverse methodological approaches into a coherent taxonomy, identifying key theoretical gaps in preference modeling, behavioral dynamics, and consensus measurement, while critically examining the disjunction between model sophistication and real-world applicability. From an application perspective, we analyze representative cases across domains, including emergency response, urban planning, and environmental governance, revealing both the transformative potential and practical limitations of current LSGDM methods. Our critical reflections expose fundamental challenges in semantic representation, dynamic clustering assumptions, behavioral intervention effectiveness, and consensus evaluation metrics. Looking forward, we propose a dual-path research framework integrating method-oriented and problem-oriented modeling paradigms, highlighting five transformative technological directions: 1) unified modular information frameworks with adaptive semantic modeling; 2) goal-oriented dynamic clustering techniques; 3) theoretically grounded behavioral models incorporating cognitive and social psychology; 4) AI-enhanced consensus mechanisms leveraging large language models and reinforcement learning; and 5) federated learning architectures for privacy-preserving decentralized decision-making. This survey not only constructs a comprehensive knowledge system for LSGDM research but also provides actionable insights for bridging theoretical innovation with practical implementation challenges, ultimately guiding the development of next-generation group decision support systems that are more scalable, explainable, and human-centered.",Bibliometric analysis | critical reflection | future direction | large-scale group decision-making (LSGDM),0,2025,behavior,behavior+policy
612,2-s2.0-105019561782,10.1109/ACCESS.2025.3622103,https://doi.org/10.1109/ACCESS.2025.3622103,https://scholar.google.com/scholar?q=10.1109/ACCESS.2025.3622103,re,IEEE Access,"Bettahi, Abdelkarim;Beloudha, Fatima Zahra;Harroud, Hamid","Continuous-Time Modeling in Educational Data Mining and Learning Analytics: A Literature Review on Methods, Ethics, and Emerging AI Trends","This literature review consolidates key insights from Educational Data Mining (EDM) and Learning Analytics (LA), charting how AI-driven methods transform teaching, learning, and institutional decision making. Foundational studies have highlighted the potential of personalizing education, detecting at-risk students, and scaling ethical data usage. However, complexities arise from the irregular sampling of learner logs, evolving methodological frameworks, and deeply rooted concerns about equity, privacy, and interpretability. Recent discussions have introduced continuous-time modeling techniques such as Neural Ordinary Differential Equations (Neural ODEs) and Neural Controlled Differential Equations (Neural CDEs) to address irregular data streams, but empirical evidence in educational contexts remains limited. This review synthesizes foundational EDM frameworks, predictive modeling advances, equity-driven approaches, and emerging AI applications (e.g., generative AI), emphasizing their potential to reshape traditional analytics. This review also examines issues, such as fairness, stakeholder engagement, and data governance, which are critical for implementing robust and transparent analytics. By interweaving thematic areas, including socio-economic, psychosocial, and behavioral factors, this review underscores the need for interdisciplinary, ethically grounded research in continuous-time frameworks and beyond. Ultimately, these insights pave the way for a more holistic, human-centered future, where AI in education balances technical innovation with responsible equitable best practices.",AI in education | at-risk students | continuous-time modeling | educational data mining | ethics | explainable AI | fairness | generative AI | higher education | interpretability | K-12 education | learning analytics | neural CDE | neural ODE | predictive analytics | privacy | psychosocial factors | socio-economic indicators | stakeholder engagement,0,2025,behavior,behavior+policy
613,2-s2.0-105019229340,10.1080/0144929X.2025.2573430,https://doi.org/10.1080/0144929X.2025.2573430,https://scholar.google.com/scholar?q=10.1080/0144929X.2025.2573430,ar,Behaviour and Information Technology,"Li, Minghui;Wan, Yan;Zhou, Liufang;Rao, Hengyi",How hedonic and utilitarian generative AI shape ethical decision-making: neural insights,"Generative Artificial Intelligence (GenAI) is increasingly deployed across both utilitarian and hedonic contexts. While technologically beneficial, its hedonic applications raise ethical concerns, as emotion-driven decision-making may impair users’ ethical concerns. Using functional Magnetic Resonance Imaging (fMRI), this study investigated the neural mechanisms underlying ethical decision making in hedonic versus utilitarian GenAI interactions. Results revealed that hedonic GenAI activates brain regions associated with emotional integration and moral conflict (e.g. ventromedial prefrontal cortex and orbitofrontal cortex), whereas utilitarian GenAI engages regions linked to cognitive control and moral reasoning (e.g. dorsolateral prefrontal cortex and precuneus). Emotion-related brain activity positively predicted ethical acceptability, whereas cognition-related activity negatively predicts it. As the first neuroimaging study to compare hedonic and utilitarian GenAI interactions, this study provides a neurophysiological foundation for ethical governance of GenAI.",ethical decision-making | Generative AI | hedonic applications | neural mechanisms | utilitarian applications,0,2025,behavior,behavior+policy
615,2-s2.0-105018181558,10.3389/fendo.2025.1627919,https://doi.org/10.3389/fendo.2025.1627919,https://scholar.google.com/scholar?q=10.3389/fendo.2025.1627919,ar,Frontiers in Endocrinology,"Zahoor, Sheresh;Constantinou, Anthony C.;O’Halloran, Fiona;O’Mahony, Louise;O’Riordan, Mairead;Kgosidialwa, Oratile;Culliney, Linda;Said Alhajri, Mohammed;Hasanuzzaman, Mohammed",Causal insights into gestational diabetes mellitus,"Introduction: Gestational diabetes mellitus (GDM), defined by the onset of hyperglycaemia during pregnancy, remains the most prevalent metabolic complication in pregnancy. It is associated with increased risks of adverse maternal, neonatal, and long-term metabolic outcomes. This study aimed to identify potential causal relationships within clinical data on GDM that could support more targeted and effective interventions. Methods: A clinically curated dataset of patients diagnosed with GDM at a major Irish maternity hospital was analysed, covering the study periods 2014–2016 and 2020. A knowledge graph was constructed by integrating clinical expertise, established literature, and insights generated using the GPT-4 large language model. To complement this, 20 structure learning algorithms were applied to independently infer Causal Bayesian Networks (CBNs). A model-averaging approach was then used to generate a consensus-based causal structure to account for variability across individual models. Results: The integrative model produced a more stable representation of underlying relationships and yielded quantifiable insights to support clinical decision-making. Clinicians involved in the study reported improved confidence in patient care strategies due to the ability to quantify these relationships, facilitating more personalised, evidence-based practice. Key findings from the model-averaged CBN highlighted critical pathways in GDM management, such as the influence of birth weight on neonatal intensive care unit (NICU) admissions and the impact of dietary intervention on maternal glucose regulation. Sensitivity analysis confirmed birth weight, gestational age at delivery, and mode of delivery as major determinants of maternal and neonatal outcomes. Non-modifiable factors, including a history of multiple pregnancies and prior GDM, also contributed to risk stratification. Discussion: This study applied structure learning techniques to observational clinical data to identify clinically relevant relationships. The resulting insights provide a basis for generating hypotheses that could refine intervention strategies and improve patient outcomes in GDM care.",Causal Bayesian Networks | causal discovery | gestational diabetes | healthcare | interventions,0,2025,behavior,behavior+policy
616,2-s2.0-105018028637,10.1109/TCSS.2025.3605278,https://doi.org/10.1109/TCSS.2025.3605278,https://scholar.google.com/scholar?q=10.1109/TCSS.2025.3605278,ar,IEEE Transactions on Computational Social Systems,"Li, Siyu;Yang, Jin;Zhao, Kui;Jia, Dongqing",Understanding Large Language Model Driven Social Bots: A Behavioral Analysis and Impact Assessment,"As the capabilities of large language models (LLMs) emerge, they not only assist in accomplishing traditional tasks within more efficient paradigms but also stimulate the evolution of social bots. Researchers have begun exploring implementation of LLMs as the driving-core of social bots, enabling more efficient and user-friendly completion of tasks such as social behavior decision-making and social content generation. However, there is currently a lack of systematic research on behavioral characteristics of LLMs-driven social bots and their negative impact on social networks. We have curated data from Chirper.ai, a Twitter-like social network populated by LLMs-driven social bots and embarked on an exploratory study. Our findings indicate that: 1) LLMs-driven social bots possess enhanced individual-level camouflage while exhibiting certain collective characteristics; 2) these bots have the ability to exert influence on online communities through toxic behaviors; and 3) existing detection methods are applicable to LLMs-driven social bots but may have certain limitations in effectiveness. Moreover, we organized the data collected in our study into Masquerade-23 dataset, which we have publicly released, thus addressing the data void in subfield of LLMs-driven social bots behavior datasets. Our research outcomes provide primary insights for the research and governance of LLMs-driven social bots within the research community.",Human–bot interaction | large language models (LLMs) | online social networks (OSNs) | social bots | toxic behaviors,0,2025,behavior,behavior+policy
621,2-s2.0-105016754380,10.1177/20552076251380324,https://doi.org/10.1177/20552076251380324,https://scholar.google.com/scholar?q=10.1177/20552076251380324,ar,Digital Health,"Minian, Nadia;Mehra, Kamna;Rose, Jonathan;Veldhuizen, Scott;Zawertailo, Laurie;Ratto, Matt;Ting-A-Kee, Ryan;Melamed, Osnat;Tang, Victor;Selby, Peter",Using the behaviour change wheel framework to develop a rule-based chatbot to support varenicline adherence for smoking cessation,"Introduction: Varenicline is one of the most effective smoking cessation medications; however, non-adherence remains a significant barrier to successful quitting. Conversational agents have the potential to support medication adherence in home and community settings. However, generative AI models pose risks due to hallucinations, making them less reliable for this purpose. Rule-based chatbots provide a more transparent, theory-driven approach to patient support. Thus, we developed ChatV, a rule based chatbot grounded in the Behaviour Change Wheel framework, to enhance varenicline adherence. Methods: ChatV was developed using a three-step process. First, we identified core determinants of varenicline adherence through a rapid review and qualitative interviews with healthcare providers and patients using the Theoretical Domains Framework. Second, we identified the intervention options through group discussions. Third, we identified intervention components using Behaviour Change Techniques (BCTs) Taxonomy v1. We applied the Acceptability, Practicability, Effectiveness, Affordability, Safety, and Equity (APEASE) criteria to determine the final intervention components. Results: We identified 11 key domains relevant to behaviour change, including knowledge, beliefs about capabilities and consequences, memory, attention and decision-making processes, reinforcement, intentions, goals, social influences, environmental context and resources, behaviour regulation, and skill. Applying the APEASE criteria, we refined these to nine theoretical domains and identified 21 BCTs as core components of ChatV. Conclusion: This study demonstrates a structured, theory-informed approach to chatbot development for medication adherence. By integrating evidence-based behaviour change principles with practical considerations, ChatV offers a model for designing rule-based conversational agents in healthcare.",behaviour change techniques | Behaviour change wheel | chatbot | medication adherence | smoking cessation | theoretical domains framework | varenicline,0,2025,behavior,behavior+policy
622,2-s2.0-105016243559,10.16182/j.issn1004731x.joss.25-0135,https://doi.org/10.16182/j.issn1004731x.joss.25-0135,https://scholar.google.com/scholar?q=10.16182/j.issn1004731x.joss.25-0135,ar,Xitong Fangzhen Xuebao Journal of System Simulation,"Jinghua, Piao;Chen, Gao;Fang, Zhang;Jun, Su;Yong, Li",Large-scale Social Simulator: Frontiers and Perspectives,"Social experiments, as a typical research method in social sciences, aim to study specific social phenomena or the impacts of policies by observing the behaviors of individuals, organizations, or social groups in real or simulated environments. However, traditional social experiment methods often face challenges such as random bias, high costs, and ethical risks, making them inadequate to address increasingly complex research demands. Against this backdrop, computational social experiments have emerged, enabling researchers to conduct social experiments within computational simulation environments that are free from random bias, cost-efficient, and ethically manageable. Meanwhile, China is currently undergoing a critical period of transformative development, characterized by economic transition, intensifying social conflicts, diversified demands, and the challenges of globalization. These complex issues have surpassed the capabilities of traditional social experiments, placing higher demands on the scale, complexity, and authenticity of computational social experiments and their simulation environments. To address the dual needs of academic research and national strategies, there is an urgent need to construct large-scale social simulators capable of high-precision and large-scale simulations of complex social systems, supporting diverse computational social experiments and advancing the next generation of social experiments. This paper first introduced the concepts and methods of social experiments and discussed the necessity and application value of constructing large-scale social simulators from the dual perspectives of academic development and national strategic needs. It further reviewed the research progress of large language model technologies in simulating human behavior and analyzed their technical advantages in enhancing the authenticity of social simulations. Based on these insights, this paper proposed an overall framework for large-scale social simulators and validated its authenticity and broad applicability in social experiments in different fields through three typical cases: economic system simulation, social network simulation, and cognitive polarization simulation. Finally, this paper explored the future research directions and development trends of large-scale social simulators in areas such as the advancement of core simulation technologies, the construction of social science experimental platforms, applications in social governance, and the development of standards and policy regulation.",computational social experiment | large language model | large language model-empowered agent | social experiment | social simulation,0,2025,behavior,behavior+policy
623,2-s2.0-105016226006,10.56294/hl2025756,https://doi.org/10.56294/hl2025756,https://scholar.google.com/scholar?q=10.56294/hl2025756,ar,Health Leadership and Quality of Life,"Alba-Leonel, Adela;Mejía Argueta, Miguel Ángel Germán;Papaqui-Alba, Samantha;Sánchez-Ahedo, Roberto;Papaqui-Hernández, Joaquín",Ethical dilemmas of health misinformation and the importance of scientific dissemination,"Introduction: health misinformation represents an increasing ethical challenge in the digital age, as it affects individual and collective decision-making, undermining public health and trust in science. In this context, scientific dissemination becomes a strategic tool to counter the spread of false or misleading information. Objective: to analyze the ethical dilemmas derived from health misinformation and highlight the importance of scientific communication as a mitigation strategy. Method: a systematic literature review was conducted using the PRISMA 2020 methodology. The search included databases such as PubMed, SciELO, Medline, Embase, Cochrane, and Google Scholar, complemented by generative artificial intelligence tools (e.g., ChatGPT-4, Gemini). Studies published between 2020 and 2025 in English and Spanish were considered. Results: a total of 896 documents were identified, of which 50 met the inclusion criteria. The analysis revealed the ethical impact of misinformation in health, such as the erosion of public trust, harmful decision-making, stigmatization, and political manipulation. Scientific dissemination was identified as a key strategy to foster education, critical thinking, media literacy, and community engagement. Conclusions: health misinformation constitutes a pressing ethical dilemma requiring multisectoral responses. Scientific communication emerges as an essential strategy to promote access to reliable information, strengthen public health, and foster a critical and responsible citizenry.",Ethical Dilemmas | Health Misinformation | Scientific Dissemination,0,2025,behavior,behavior+policy
625,2-s2.0-105015077327,10.1109/ACCESS.2025.3604573,https://doi.org/10.1109/ACCESS.2025.3604573,https://scholar.google.com/scholar?q=10.1109/ACCESS.2025.3604573,ar,IEEE Access,"Stoev, Teodor;Flemming, Eva;Strauss, Bernhard;Petrowski, Katja;Spitzer, Carsten;Yordanova, Kristina",Towards Automated Classification of Adult Attachment Interviews in German Language Using the BERT Language Model,"Attachment theory, pioneered by John Bowlby, has become a prominent psychological framework that aids in our comprehension of human behavior within close relationships. The Adult Attachment Interview (AAI), a semi-structured interview, provides a standardized method for assessing adult attachment styles, offering insights into an individual’s attachment patterns, emotional regulation, and relational experiences. However, manual AAI classification is a labour-intensive and highly specialized task. Thus, automating this process can optimize the classification of individual attachment patterns and their psychological and relational implications, thereby increasing efficiency and accuracy in assessing attachment styles. In this work, we investigate the application of a BERT large language model and linguistic features for the automated classification of transcribed Adult Attachment Interviews conducted in German into the three categories: secure, dismissing, and preoccupied. The findings of our study indicate that using BERT embeddings alone can yield results comparable to, and in some cases better than, those achieved with traditional linguistic features. However, this effect should be interpreted with caution, as it does not hold consistently across all settings. Another key conclusion of our study is that augmenting the original AAI dataset with artificially generated interviews produced by state-of-the-art large language models generally improves predictive performance across a range of classification models.",Adult attachment | adult attachment interviews | automated classification | BERT | data augmentation | large language models | text analysis,0,2025,behavior,behavior+policy
626,2-s2.0-105014628029,10.1177/10755470251362368,https://doi.org/10.1177/10755470251362368,https://scholar.google.com/scholar?q=10.1177/10755470251362368,ar,Science Communication,"Fung, Timothy K.F.;Leung, Ho Man;Zhou, Xiyuan;Zheng, Shenting",“What Might Happen With Generative AI?” Examining the Role of Prefactual Thinking in the Cognitive Mediation Model in the Context of Emerging Technologies,"Prefactual thinking, a form of prospective mental simulation, significantly impacts individuals’ decision-making. To understand the influence of media consumption on public opinion regarding emerging technologies, this study, in the context of generative artificial intelligence (AI), examined prefactual thinking as a cognitive process of media consumption, extending the cognitive mediation model. Using quota sampling, we conducted an online survey of 1,129 Hong Kong adult residents. The findings revealed that elaborative processing was positively associated with prefactual thinking, which, in turn, influenced emotional responses. Prefactual thinking and emotional responses shaped benefit-risk perceptions, which influenced individuals’ generative AI opinion. Theoretical and practical implications were discussed.",artificial intelligence | benefit and risk perceptions | cognitive mediation model | cognitive process | emerging technology | media effects | mental simulation | prefactual thinking | public opinion,0,2025,behavior,behavior+policy
627,2-s2.0-105014386112,10.1109/JBHI.2025.3602983,https://doi.org/10.1109/JBHI.2025.3602983,https://scholar.google.com/scholar?q=10.1109/JBHI.2025.3602983,ar,IEEE Journal of Biomedical and Health Informatics,"Javed, Haseeb;Ali, Farman;Shah, Babar;Dilshad, Naqqash;Kwak, Daehan",MediGuard: Protecting Sensitive Healthcare Data with Privacy-Preserving Language Models,"The integration of large language models (LLMs) into digital healthcare has the potential to significantly improve access to accurate and timely medical advice, especially in underserved areas. However, serious privacy concerns hinder the widespread adoption of LLM-based medical consultation systems, as they often require users to disclose private health information, risking unauthorized exposure and non-compliance with regulations. To address these issues, we introduce MediGuard, a new privacy-preserving LLM framework that dynamically protects sensitive healthcare data throughout the consultation process. MediGuard employs adaptive information obfuscation, combined with secure access protocols and robust auditing mechanisms, to process only non-sensitive information while preserving the necessary semantic integrity for precise medical inference and decision-making. Extensive testing across multiple medical question-answering datasets demonstrates that MediGuard consistently outperforms existing methods in both privacy protection and clinical accuracy, even under stringent privacy constraints. Our findings suggest that MediGuard provides safe, trustworthy, and clinically reliable medical consultations, setting a new standard for privacy-aware healthcare AI.",Healthcare Data Protection | Large Language Models (LLMs) | MediGuard | Privacy-preserving Language Models | Secure Medical AI | Sensitive Data Privacy,0,2025,behavior,behavior+policy
628,2-s2.0-105014160331,10.3389/feduc.2025.1662657,https://doi.org/10.3389/feduc.2025.1662657,https://scholar.google.com/scholar?q=10.3389/feduc.2025.1662657,ar,Frontiers in Education,"Alsharefeen, Rami",Faculty as street-level bureaucrats: discretionary decision-making in the era of generative AI,"Introduction: This study examines how university faculty members at an internationalized higher education institution in the UAE navigate the challenges of generative artificial intelligence (Gen-AI) plagiarism through the theoretical lens of Michael Lipsky’s Street-Level Bureaucracy (SLB) framework. Methods: Drawing on qualitative data from semi-structured interviews with 17 faculty members at an internationalized university in the UAE, this paper analyzes how faculty members exercise discretion when confronted with suspected AI-generated content in student work. Results: The findings of the study reveal that faculty, as street-level bureaucrats, develop various coping strategies to manage the additional workload associated with Gen-AI detection, including preventive education, discretionary intervention, and modified assignment designs. Faculty decisions are influenced by tensions between empathy and policy enforcement, skepticism about detection tools, and concerns about institutional processes. The study also highlights a significant gap between institutional expectations and faculty practices, with program chairs critiquing discretionary approaches while faculty defend them as essential for addressing nuanced student contexts. Discussion: This paper argues that institutional policies should acknowledge and accommodate faculty discretion rather than attempt to eliminate it, emphasizing prevention and education over detection and punishment. This research contributes to understanding how front-line academic integrity enforcers shape policy implementation in practice, with significant implications for institutional governance, faculty development, and academic integrity in higher education.",academic integrity | faculty discretion | generative AI | higher education policy | plagiarism | street-level bureaucracy,0,2025,behavior,behavior+policy
629,2-s2.0-105011954162,10.1007/s13369-025-10466-6,https://doi.org/10.1007/s13369-025-10466-6,https://scholar.google.com/scholar?q=10.1007/s13369-025-10466-6,ar,Arabian Journal for Science and Engineering,"Utku, Anil","MILA: An Innovative Approach to Identifying AI-Generated Content Using BERT, CNN, and BiLSTM","AI ethical principles are essential in balancing the social impacts of rapidly developing technology today. The widespread use of AI technologies has heightened the need for ethical and legal regulations in this area. In this process, fundamental principles such as data privacy, accountability, transparency, and human oversight take center stage to enhance the reliability of artificial intelligence and foster social trust. Generative AI refers to machines producing text, images, audio, and video content. However, generative AI brings ethical discussions since it can produce original content. Detecting AI-generated content is becoming increasingly complex due to the ability of AI models to produce increasingly more fluent and meaningful texts. This study created a hybrid MILA model using BERT, CNN, and BiLSTM models to detect AI-generated content. MILA was compared in detail with SVM, XGBoost, CNN, LSTM, and BiLSTM using sentence-level and article-level datasets. Experiments demonstrated that MILA outperformed the compared models, achieving 94.34% accuracy at the sentence-level and 93.62% accuracy at the article-level.",AI-generated content | BERT | BiLSTM | CNN | Deep learning,0,2025,behavior,behavior+policy
632,2-s2.0-105011250627,10.1080/14703297.2025.2535444,https://doi.org/10.1080/14703297.2025.2535444,https://scholar.google.com/scholar?q=10.1080/14703297.2025.2535444,ar,Innovations in Education and Teaching International,"Beardsley, Marc;Santos, Patricia;Amarasinghe, Ishari;Theophilou, Emily;Vujovic, Milica;Hernández-Leo, Davinia",A learning agreement for generative AI use in university courses: A pilot study,"The rapid development of Generative AI (GenAI) tools presents challenges for their ethical and responsible use. This pilot study examines student learning agreements as a governance tool for GenAI use in a first-year engineering course. These agreements included ethical and social considerations that students accepted if they chose to use GenAI. Pre- and post-course surveys and group assignments were analysed. Most students responded positively to the approach, though only one of the ten groups using GenAI explicitly acknowledged its limitations, as required by the agreement. Thematic analysis of student feedback highlighted the need for clearer language, more specific examples and opportunities to revisit the agreement during the course. Overall, the findings suggest that learning agreements can serve as a flexible mechanism to support student autonomy and ethical decision-making when engaging with GenAI tools, helping bridge the gap between rapidly evolving technologies and responsible academic use.",academic integrity | AI ethics | educational strategies: higher education | learning agreement | Responsible AI,0,2025,behavior,behavior+policy
638,2-s2.0-105009627256,10.3389/fcell.2025.1608988,https://doi.org/10.3389/fcell.2025.1608988,https://scholar.google.com/scholar?q=10.3389/fcell.2025.1608988,re,Frontiers in Cell and Developmental Biology,"Zhang, Jiatong;Song, Xiaoxi;Tian, Bocheng;Tian, Mingke;Zhang, Zhichang;Wang, Jing;Fan, Ting",Large language models in the management of chronic ocular diseases: a scoping review,"Large language models, a cutting-edge technology in artificial intelligence, are reshaping the new paradigm of chronic ocular diseases management. In this study, we comprehensively examined the current status and trends in the application of large language models in major blinding chronic ocular diseases such as glaucoma, cataract, and diabetic retinopathy through a systematic scoping review approach. We conducted this review based on the Preferred Reporting Items for Systematic Reviews and Meta-Analyses extended to characterize the application of large language models in the field of chronic ocular diseases. The study reveals that large language models demonstrate comparable efficacy to experts in disease screening, diagnostic decision-making, personalized precision treatment recommendation, and accessibility of healthcare resources by integrating multimodal clinical data. However, the application of the technology still faces a triple challenge: (1) the limitation of model generalization ability due to the multimodal nature of clinical data; (2) the ethical controversy caused by the insufficient interpretability of algorithms; and (3) the lack of a standardized validation framework. Future directions emphasize the need for specialized model training, multimodal algorithm optimization, the establishment of a multinational multicenter clinical validation platform, and the construction of an ethical framework for dynamic regulation. Large language models are expected to evolve from an assisted decision-making tool to a core component of precision medicine for chronic ocular diseases, and ultimately to achieve an ecosystem of energy-efficient full-cycle management of chronic ocular diseases.",chronic ocular diseases | clinical decision support | full process management | large language models | multimodal data,0,2025,behavior,behavior+policy
639,2-s2.0-105009256404,10.2196/72398,https://doi.org/10.2196/72398,https://scholar.google.com/scholar?q=10.2196/72398,re,Journal of Medical Internet Research,"Luo, Xuexing;Li, Yiyuan;Xu, Jing;Zheng, Zhong;Ying, Fangtian;Huang, Guanghui","AI in Medical Questionnaires: Innovations, Diagnosis, and Implications","This systematic review aimed to explore the current applications, potential benefits, and issues of artificial intelligence (AI) in medical questionnaires, focusing on its role in 3 main functions: assessment, development, and prediction. The global mental health burden remains severe. The World Health Organization reports that >1 billion people worldwide experience mental disorders, with the prevalence of depression and anxiety among children and adolescents at 2.6% and 6.5%, respectively. However, commonly used clinical questionnaires such as the Hamilton Depression Rating Scale and the Beck Depression Inventory suffer from several problems, including the high degree of overlap of symptoms of depression with those of other psychiatric disorders and a lack of professional supervision during administration of the questionnaires, which often lead to inaccurate diagnoses. In the wake of the COVID-19 pandemic, the health care system is facing the dual challenges of a surge in patient numbers and the complexity of mental health issues. AI technology has now been shown to have great promise in improving diagnostic accuracy, assisting clinical decision-making, and simplifying questionnaire development and data analysis. To systematically assess the value of AI in medical questionnaires, this study searched 5 databases (PubMed, Embase, Cochrane Library, Web of Science, and China National Knowledge Infrastructure) for the period from database inception to September 2024. Of 49,091 publications, a total of 14 (0.03%) studies met the inclusion criteria. AI technologies showed significant advantages in assessment, such as distinguishing myalgic encephalomyelitis or chronic fatigue syndrome from long COVID-19 with 92.18% accuracy. In questionnaire development, natural language processing using generative models such as ChatGPT was used to construct culturally competent scales. In terms of disease prediction, one study had an area under the curve of 0.790 for cataract surgery risk prediction. Overall, 24 AI technologies were identified, covering traditional algorithms such as random forest, support vector machine, and k-nearest neighbor, as well as deep learning models such as convolutional neural networks, Bidirectional Encoder Representations From Transformers, and ChatGPT. Despite the positive findings, only 21% (3/14) of the studies had entered the clinical validation phase, whereas the remaining 79% (11/14) were still in the exploratory phase of research. Most of the studies (10/14, 71%) were rated as being of moderate methodological quality, with major limitations including lack of a control group, incomplete follow-up data, and inadequate validation systems. In summary, the integrated application of AI in medical questionnaires has significant potential to improve diagnostic efficiency, accelerate scale development, and promote early intervention. Future research should pay more attention to model interpretability, system compatibility, validation standardization, and ethical governance to effectively address key challenges such as data privacy, clinical integration, and transparency.",AI | artificial intelligence | diagnostic accuracy | medical questionnaires | questionnaire development | questionnaire-based prediction,0,2025,behavior,behavior+policy
642,2-s2.0-105007447346,10.55214/25768484.v9i5.7618,https://doi.org/10.55214/25768484.v9i5.7618,https://scholar.google.com/scholar?q=10.55214/25768484.v9i5.7618,ar,Edelweiss Applied Science and Technology,"El-Bayaa, Nourhan;Alzoubi, Yehia Ibrahim;Mishra, Alok","Adoption ChatGPT in higher education settings: Potentials, challenges, and paving the way for future advancements","Several artificial intelligence generative language models have been developed recently. Many people in different contexts have started using them, such as education, industry, and even content creation. This study focuses on investigating how higher education students have been using ChatGPT as an example of a generative artificial intelligence tool. The context of the study was chosen due to the many voices against or in favor of using ChatGPT in higher education institutions. We deployed a mixed method to collect and analyze the data, including open-ended and closed-ended question surveys, to investigate the motivations and future expectations of students who have been using the ChatGPT tool. The research methodology comprises two main components: the initial phase involves conducting statistical analyses on questions about each of the 15 adoption factors. Responses concerning each factor were meticulously compiled and transferred into an Excel spreadsheet. Subsequently, the frequency of responses for each choice was tallied to discern prevailing trends and preferences among respondents. The second phase focuses on analyzing the open-ended questions' responses that forecast the future of ChatGPT as perceived by the participants. The data gathered from open-ended questions was analyzed thematically using Miles and Huberman's approach. Our findings reveal that students generally find using ChatGPT to be a helpful tool in their higher education institutions. The findings show that ease of use, perceived value, trialability, observability, relative advantage, social impact, and network effect are the most important factors behind their adoption decision. The findings also revealed that a significant number of students are still confused about ethical concerns and report the need for regulations when using ChatGPT. These findings are important for educators, policymakers, and technology designers who want to make the most of generative AI in education. Future research, however, is yet to be conducted to understand its ethical implications, long-term effects, and how to best incorporate it into teaching practices.",Adoption | Challenges | ChatGPT | Generative Artificial Intelligence | Higher education,0,2025,behavior,behavior+policy
643,2-s2.0-105005657025,10.1527/tjsai.40-3_B-O93,https://doi.org/10.1527/tjsai.40-3_B-O93,https://scholar.google.com/scholar?q=10.1527/tjsai.40-3_B-O93,ar,Transactions of the Japanese Society for Artificial Intelligence,"Ohori, Kotaro;Goto, Yusuke;Tahara, Keiichiro;Takahashi, Shingo",～Human-in-the-Loop と Machine-in-the-Loop のハイブリッドアプローチ～ Workshop Design for Municipal Policy Making Using Generative AI: A Hybrid Approach of Human-in-the-Loop and Machine-in-the-Loop,"This paper aims to enhance the efficiency of participatory workshops (WS) in municipalities by proposing a hybrid WS support framework that combines Human-in-the-Loop (HITL) and Machine-in-the-Loop (MITL) approaches utilizing generative AI. In the HITL process, generative AI is regarded as workshop participants, with a human facilitator collaborating with the AI to achieve rapid and comprehensive problem identification and organization. In contrast, the MITL process uses outputs generated by the AI as the support for discussions among human participants. This hybrid approach ensures that both human expertise and AI capabilities are optimally utilized. By strategically applying these processes across different WS phases, it becomes possible to efficiently progress through the WS with minimal information loss and achieve the desired outputs. Specifically, in the HITL process, we present a novel methodology using facilitation-based prompts, providing concrete guidance for WS designers. The proposed framework and HITL methodology were applied in actual municipalities, resulting in the successful extraction and organization of problems within a short timeframe, ultimately achieving the objectives of the overall WS process. The application showed that the framework and methodology can significantly reduce the time and resources required for effective WS execution. The findings of this study offer a new perspective on WS design and operation, supporting more efficient and effective policy making. Future challenges include expanding the application scope of the framework and methodology to other WS phases and analytical techniques, and exploring its applicability to other domains. This will enable more organizations to leverage generative AI for effective decision-making.",civic participation | generative AI | human-in-the-loop | machine-in-the-loop | workshop design,0,2025,behavior,behavior+policy
644,2-s2.0-105005516912,10.1177/14413582251340488,https://doi.org/10.1177/14413582251340488,https://scholar.google.com/scholar?q=10.1177/14413582251340488,ar,Australasian Marketing Journal,"Ding, Min;Dong, Songting",Digentity (Digital-Entity) Human Dyad: A Perspective on Human-AI Collaboration and Decision-Making,"The paper introduces the concept of the Digentity Human Dyad (DHD), a novel paradigm envisioning a future partnership between a human and their digentity—a personalized digital entity that embodies an individual’s values, preferences, and ideals. Unlike digital twins or extended digital selves, digentities are shaped by personal aspirational traits and enriched with the accumulated wisdom of humanity, guiding individuals in their decision-making processes. Enabled by advances in Generative AI, digentities will evolve alongside their human counterparts, provide context-aware and personalized advice, and transform decision-making from a purely human-driven process to a collaborative effort. As digentities align with their human counterpart’s goals, they will influence decisions across various aspects of life, including consumption, personal choices, and societal participation. Beyond individual impact, the DHD has transformative implications influencing how businesses, employers, governments, and civic systems engage with individuals. While the DHD presents significant opportunities, it also introduces challenges, such as risks of bias, data privacy, human over-reliance, and the potential for manipulation. The paper urges organizations and institutions to prepare for these shifts, calling for governance frameworks that ensure responsible AI integration and safeguard human autonomy in an era of human-digentity collaboration.",Digentity Human Dyad (DHD) | Generative AI in decision-making | human-AI collaboration | personalized digital entity,0,2025,behavior,behavior+policy
669,2-s2.0-85205002125,10.12026/j.issn.1001-8565.2024.09.11,https://doi.org/10.12026/j.issn.1001-8565.2024.09.11,https://scholar.google.com/scholar?q=10.12026/j.issn.1001-8565.2024.09.11,ar,Chinese Medical Ethics,"Chen, Antian;Lu, Jun;Zhang, Xinqing",Exploration of the impact mechanisms of generative artificial intelligence on doctor-patient shared decision-making,"As large-scale language models become increasingly mature, generative artificial intelligence (GenAI), represented by ChatGPT/GPT-4, is anticipated to be deeply embedded in clinical decision-making. However, the clinical application of GenAI also has potential issues, such as the Moravec paradox. The Ethics and Governance of Artificial Intelligence for Health:Guidance on Large Multi-Modal Models released by the World Health Organization proposed six principles that should be followed when large models are applied in the medical field. The participation of GenAI in clinical decision-making requires the joint engagement of both doctors and patients. Clinical doctors are involved in the research and development, promotion, and application of GenAI, as well as in controlling the direction of technological development. GenAI empowers patients to participate in decision-making, aligning with actual medical scenario and meeting the value selection preferences of patients. Deepen GenAI’s explainability and responsibility allocation system, empower doctor-patient shared decision-making, properly handle the challenges brought by GenAI to traditional information and understanding, and achieve maximum clinical benefits.",clinical application | doctor-patient relationship | ethical challenge | generative artificial intelligence | shared decision-making,0,2024,behavior,behavior+policy
696,2-s2.0-85210402718,10.19873/j.cnki.2096-0212.2024.02.009,https://doi.org/10.19873/j.cnki.2096-0212.2024.02.009,https://scholar.google.com/scholar?q=10.19873/j.cnki.2096-0212.2024.02.009,ar,Contemporary Social Sciences,"Shuchen, Tang;Huiwen, Jiang",Bias in Generative AI Systems: A 3-Layer Response and Liability Determination,"The risk of bias is widely noticed in the entire process of generative artificial intelligence (generative AI) systems. To protect the rights of the public and improve the effectiveness of AI regulations, feasible measures to address the bias problem in the context of large data should be proposed as soon as possible. Since bias originates in every part and various aspects of AI product lifecycles, laws and technical measures should consider each of these layers and take different causes of bias into account, from data training, modeling, and application design. The Interim Measures for the Administration of Generative AI Service (the Interim Measures), formulated by the Office of the Central Cyberspace Affairs Commission (CAC) and other departments have taken the initiatives to govern AI. However, it lacks specific details on issues such as how to prevent the risk of bias and reduce the effect of bias in decision-making. The Interim Measures also fail to take causes of bias into account, and several principles must be further interpreted. Meanwhile, regulations on generative AI at the global level are still in their early stages. By forming a governance framework, this paper could provide the community with useful experiences and play a leading role. The framework includes at least three parts: first, determining the realm of governance and unifying related concepts; second, developing measures for different layers to identify the causes and specific aspects of bias; third, identifying parties with the skills to take responsibility for detecting bias intrusions and proposing a program for the allocation of liabilities among the large-scale platform developers.",AI governance | bias | generative AI,0,2024,behavior,behavior+policy
14,2-s2.0-105016317140,10.1016/j.inffus.2025.103730,https://doi.org/10.1016/j.inffus.2025.103730,https://scholar.google.com/scholar?q=10.1016/j.inffus.2025.103730,ar,Information Fusion,"Li, Zhonghang;Chen, Tianyi;Xu, Yong",AirGPT: Spatio-temporal large language model for air quality prediction,"Air pollution poses a critical threat to public health, ecosystems, and climate stability worldwide. Accurate air quality prediction is essential for informed policy-making, health risk mitigation, and environmental management, enabling proactive responses to pollution events and long-term planning for sustainable urban development. Despite advances, deep learning models for air quality prediction still face three critical challenges: heavy reliance on abundant historical data, difficulty in effectively fusing diverse information sources, and a lack of interpretability. To address these issues, we propose AirGPT, a large language model framework for air quality prediction. AirGPT integrates a specialized spatio-temporal encoder with a novel spatio-temporal instruction-tuning paradigm, enabling it to efficiently model complex spatio-temporal dependencies and perform sophisticated data fusion. Furthermore, our Chain-of-Thought distillation mechanism allows the model to externalize its predictive reasoning in a transparent, human-readable format, thereby enhancing interpretability. Experimental results demonstrate that AirGPT achieves state-of-the-art accuracy on air quality prediction tasks, particularly in data-scarce and zero-shot scenarios. By integrating interpretable reasoning with transparent predictive outputs, AirGPT provides a robust and reliable framework to support informed environmental decision-making. Our source code is available at: https://anonymous.4open.science/r/AirGPT-6ACC",Air quality prediction | Graph neural network | Large language models (LLMs) | Spatio-temporal data mining,0,2026,sustainability,behavior+policy+sustainability
24,2-s2.0-105026580069,10.5267/j.jpm.2025.9.006,https://doi.org/10.5267/j.jpm.2025.9.006,https://scholar.google.com/scholar?q=10.5267/j.jpm.2025.9.006,ar,Journal of Project Management Canada,"Taheripour, Esmaeil;Sadjadi, Seyed Jafar","Project portfolio management in the age of artificial intelligence: A review of challenges, key features, and future research directions","The rapid advancement of artificial intelligence (AI) has revolutionized project portfolio management (PPM), as it has in many other areas, by introducing data-driven methods that improve decision-making, risk assessment, and strategic alignment. Unlike traditional project management, which emphasizes individual project execution, PPM requires balancing multiple initiatives to optimize value creation and resource allocation. This paper presents a systematic review of scientific research on the integration of AI techniques into PPM, focusing on their applications, benefits, and challenges. The review synthesizes findings from 73 peer-reviewed studies covering a wide range of AI methodologies, such as machine learning, deep learning, neural networks, reinforcement learning, natural language processing, and hybrid optimization models. These approaches have been applied in diverse fields, including information technology, construction, healthcare, defense, energy, and telecommunications. Analysis shows that AI significantly improves project portfolio performance by predicting project outcomes, identifying interdependencies, optimizing resource allocation, and supporting adaptive strategies in dynamic environments. In addition, advanced AI tools provide project portfolio managers with predictive and prescriptive analytics, transforming PPM from reactive monitoring to proactive governance. Despite these advances, challenges remain regarding data quality, organizational readiness, and interpretability of AI-based models. Concerns about transparency, ethical implications, and integration with existing management frameworks also hinder wider adoption. However, recent developments indicate a growing trend toward hybrid systems that combine AI with traditional decision-making models, increasing both accuracy and practical applicability. This review contributes to theory and practice by synthesizing current knowledge, highlighting research gaps, and identifying emerging directions such as the use of large language models, ensemble methods, and sustainability-focused project portfolio optimization. The findings highlight the transformative potential of AI in advancing PPM and provide valuable insights for researchers and practitioners seeking to design smarter, more adaptive, and more sustainable project portfolio management strategies.",Artificial intelligence | Deep learning | Machine learning | Neural network | Project portfolio management | Reinforcement learning,0,2026,sustainability,behavior+policy+sustainability
37,2-s2.0-105015498499,10.1016/j.apenergy.2025.126650,https://doi.org/10.1016/j.apenergy.2025.126650,https://scholar.google.com/scholar?q=10.1016/j.apenergy.2025.126650,ar,Applied Energy,"Chen, Xiaowei;Hamim, Omar Faruqe;Moras, Bruno Cesar Krause;Gkritza, Konstantina;Ukkusuri, Satish V.",Generative AI-driven framework for estimating future electric vehicle usage,"In the rapidly advancing field of electric vehicle (EV) adoption and infrastructure planning, the scarcity of detailed and comprehensive datasets poses significant challenges for effective decision-making. This study introduces a cutting-edge framework leveraging generative AI, specifically, Sequential Generative Adversarial Networks, to synthesize realistic survey and travel sequence data. The framework's Data Fusion module integrates socio-demographic attributes with travel behaviors, creating enriched synthetic datasets that capture multi-dimensional insights. Using Indiana as a case study, the research demonstrates key applications, including future EV adoption projections and charging demand estimation for residential and public stations. Results indicate an 18-fold increase in EVs by 2031 under optimistic scenarios, with existing charging stations meeting less than 50 % of demand. By addressing critical data gaps, this generative AI-driven approach provides actionable insights for strategic EV infrastructure development, enabling informed policy-making and promoting sustainable mobility solutions.",Charging demand estimation | Electric vehicle | Future number estimation | Generative AI | Synthetic data generation,0,2025,sustainability,behavior+policy+sustainability
50,2-s2.0-105024544356,10.3390/en18236163,https://doi.org/10.3390/en18236163,https://scholar.google.com/scholar?q=10.3390/en18236163,re,Energies,"Vamvakas, Dimitrios;Papaioannou, Ioannis;Tsaknakis, Christos;Sgouros, Thomas;Korkas, Christos","Generative AI for Sustainable Smart Environments: A Review of Energy Systems, Buildings, and User-Centric Decision-Making","The rapid evolution of Generative Artificial Intelligence (GenAI) is reshaping the energy sector, enabling new levels of adaptability, efficiency, and user-centric interaction. This review systematically maps and critically evaluates the chosen literature across buildings, grids, and urban systems. Through major scientific databases and for the span of five years, from 2021 to 2025, the review aims to identify key application domains, synergies, and research gaps. The analysis on recent advancements illustrates how GenAI enhances energy forecasting, demand–response strategies, anomaly detection, and cyber-resilience in power networks, while also supporting predictive modeling and optimal control in distributed renewable integration. Within smart buildings, GenAI empowers autonomous agents and AI copilots to balance comfort with energy efficiency through adaptive environmental control and user preference modeling. At the grid level, generative models improve renewable generation forecasting, grid stability, and decision support for operators. A further emerging application lies in the generation of synthetic energy data, which supports model training, scenario simulation, and robust decision-making in data-scarce environments. In the broader context of smart cities, GenAI-driven digital twins, multi-agent systems, and conversational interfaces facilitate sustainable planning and energy-aware citizen engagement. A central theme across these applications is the alignment of technological solutions with human needs and sustainability objectives. Key challenges remain in uncertainty quantification, trustworthy deployment, and data governance, underscoring the need for secure, adaptive, and human-centered GenAI systems to drive the next generation of intelligent energy management. This review provides a comprehensive analysis to promote a better understanding of generative models as they are being applied in a variety of scenarios in the energy domain.",energy sector | Generative Artificial Intelligence | Human-in-the-Loop AI | smart buildings,0,2025,sustainability,behavior+policy+sustainability
53,2-s2.0-105023539691,10.13374/j.issn2095-9389.2025.09.22.002,https://doi.org/10.13374/j.issn2095-9389.2025.09.22.002,https://scholar.google.com/scholar?q=10.13374/j.issn2095-9389.2025.09.22.002,ar,Gongcheng Kexue Xuebao Chinese Journal of Engineering,"Ning, Huansheng",The fourth guiding principle for humans in the digital age: an initial exploration and framework construction of cybersophy,"The epistemic, ethical, and existential conditions of human life have been fundamentally reshaped by the accelerating transformation from industrial to digital civilization. Traditional frameworks such as worldview, life outlook, and values, which are conceptualized as the “Three Guiding Principles/Views” that historically guided humanity through agricultural and industrial eras, are increasingly inadequate for addressing the unprecedented dilemmas posed by artificial intelligence, algorithmic governance, deepfakes, immersive virtual reality, and brain–computer interfaces. Against this backdrop, this study introduces Cybersophy as the “Fourth Principle/View,” which is a comprehensive philosophical–practical framework designed to orient human cognition and value judgments in the digital age. Derived from the etymological fusion of Cyber (control, cyberspace) and Sophia (wisdom), Cybersophy is defined as the systematic wisdom through which humans interpret their existence in cyberspace and guide their behavior, identity, and normative commitments. The study situates Cybersophy within the author’s broader intellectual trajectory, including previous research on Cybermatics, Cyber-Syndrome, Cyberology, Cyberlogic, Cyber-Philosophy, and Cyberism. Collectively, these strands provide the technical foundation, symptomatic awareness, disciplinary structuring, methodological critique, and axiological orientation that culminate in Cybersophy as a crystallization of wisdom and practice. Comparative philosophical analysis, conceptual genealogy, and interdisciplinary synthesis are methodologically combined, thereby situating Cybersophy in dialogue with related perspectives such as the information-, data-, and intelligence-view. This comparative framework reveals Cybersophy’s distinctive strength: its ability to encompass ontological, epistemological, ethical, and axiological dimensions of human–technology entanglement in a future-oriented, globally communicable manner. The theoretical framework is articulated through four interdependent dimensions. The cognitive dimension reconceptualizes knowledge as a distributed, human–machine collaborative process, thereby demanding critical digital literacy to counteract algorithmic manipulation and information cocoons. The ethical dimension emphasizes algorithmic justice, data rights, and “technology for good,” thus embedding transparency, fairness, and accountability into digital infrastructures through mechanisms such as value-sensitive design and algorithmic impact assessments. Existentially, what it means to be human in a hybrid virtual–physical reality is reconsidered, further confronting the challenges of fragmented digital identity, embodied interaction in immersive environments like VR (Virtual Reality), AR (Augmented Reality), and BCIs (Brain-Computer Interfaces), and the moral recognition of virtual harms as socially real. In terms of values, Cybersophy aligns itself with digital humanism, ultimately advocating for human dignity, balanced digital well-being, and inclusive governance structures that foster responsible global digital citizenship. Building upon these dimensions, this study constructs a multi-level research framework that translates abstract philosophy into empirical research agendas. Proposed directions include: the study of the influence of large language models on human creativity and decision-making; neurocognitive mechanisms for detecting deepfakes; algorithmic fairness across cultural contexts; data cooperatives as new ownership models; psychological interventions for virtual–real identity conflicts; and criteria for defining digital well-being. This also extends to psychological studies of identity negotiation across virtual and real domains and to the formulation of measurable standards for digital well-being. The following three engineering agendas embody the practical vision of Cybersophy: developing digital mental-state modulation technologies to address issues such as addiction and information overload; establishing ethical boundaries for human enhancement through BCIs and genetic editing; and constructing ethical frameworks for the Metaverse that ensure fairness, safety, and interoperability. Ultimately, Cybersophy offers both a philosophical foundation and a methodological compass for embedding ethics, human dignity, and global responsibility within technological innovation. Moreover, Cybersophy calls for collaboration among philosophers, engineers, social scientists, and the broader public to guide the evolution of digital civilization toward a just, sustainable, and genuinely human-centered future.",cybersophy | cyberspace | digital age | ethics | philosophy,0,2025,sustainability,behavior+policy+sustainability
58,2-s2.0-105020939105,10.1016/j.iswa.2025.200599,https://doi.org/10.1016/j.iswa.2025.200599,https://scholar.google.com/scholar?q=10.1016/j.iswa.2025.200599,re,Intelligent Systems with Applications,"Leon, Maikel",Sentiment analysis: From rule-based lexicons to large language models,"This study provides a comprehensive review of two decades of research in opinion mining and sentiment analysis, addressing the fragmentation of prior work across methodologies, application domains, and data sources. The evolution of the field is traced from pre-1990 rule-based systems to lexicon heuristics, statistical learning, machine learning, deep learning, and the current wave of transformer-driven, multimodal, and generative models. Applications are examined across marketing, finance, politics, and social media, with emphasis on how methodological innovations have improved accuracy and enabled broader adoption. Best practices – including transformer fine-tuning, prompt engineering, zero-shot and few-shot learning, multimodal fusion, and domain adaptation – are analyzed to distill evidence-based guidelines for researchers and practitioners. The synthesis shows how sentiment analysis has shaped critical areas, including brand management, investor decision-making, political discourse, and online user engagement. Findings highlight the effectiveness of transformer-based approaches, particularly when combined with domain adaptation and prompt engineering, in delivering state-of-the-art performance. Beyond methodological and applied insights, the study identifies promising directions for future research, including real-time customer journey analytics, explainability in generative AI, robustness across multiple languages, ethical implications, and sustainability considerations. By consolidating dispersed knowledge into a unified account, this review provides both historical grounding and a structured roadmap that advances theoretical understanding and informs managerial practice.",And transformer models | Large language models | Marketing research | Multimodal sentiment analysis | Opinion mining | Sentiment analysis,0,2025,sustainability,behavior+policy+sustainability
79,2-s2.0-105009095849,10.31893/multirev.2025379,https://doi.org/10.31893/multirev.2025379,https://scholar.google.com/scholar?q=10.31893/multirev.2025379,re,Multidisciplinary Reviews,"Tahvildaria, Mahan","Integrating generative AI in Robo-Advisory: A systematic review of opportunities, challenges, and strategic solutions","The integration of generative AI into financial advisory services marks a significant advancement in portfolio optimization, risk assessment, and decision support and recent developments in large language models (LLMs), such as ChatGPT, have demonstrated the ability to process both structured financial data and unstructured market sentiment, enhancing the accuracy and adaptability of investment recommendations. However, the application of generative AI in robo-advisory systems presents ethical, regulatory, and psychological challenges and this study conducts a systematic literature review to examine the technological benefits of AI-driven financial advisory, while also addressing concerns related to algorithmic bias, explainability, and user trust. The review applies a TOWS-based strategic framework to analyze strengths, weaknesses, opportunities, and threats (SWOT) in the adoption of AI-enhanced robo-advisors. Findings consequentially indicate that explainable AI (XAI) and hybrid AI-human oversight models are critical for mitigating transparency concerns and algorithm aversion. While real-time data processing improves investment insights, the black-box nature of generative AI remains a key barrier to regulatory compliance and consumer adoption. Additionally, regulatory fragmentation across jurisdictions complicates AI governance, necessitating adaptive compliance strategies and cross-border cooperation. The research further highlights that financial literacy and trust-building mechanisms, including user-centric onboarding and transparent risk assessments, are essential for overcoming psychological resistance to algorithmic decision-making. In conclusion, the paper proposes an approach for integrating generative AI into robo-advisory systems, combining advanced financial analytics, XAI, human oversight, and ethical AI governance. Future research should focus on empirical evaluations of hybrid advisory models, regulatory harmonization, and AI-driven financial education tools to ensure responsible adoption. These findings contribute to the growing discourse on sustainable and user-centric AI deployment in financial services, providing strategic recommendations for industry practitioners and policymakers.",artificial intelligence | chatgpt | explainable ai (xai) | financial technology | robo advisor,0,2025,sustainability,behavior+policy+sustainability
90,2-s2.0-105022876235,10.3390/a18110713,https://doi.org/10.3390/a18110713,https://scholar.google.com/scholar?q=10.3390/a18110713,ar,Algorithms,"Karimanzira, Divas;Rauschenbach, Thomas;Hellmund, Tobias;Ritzau, Linda",Improved Flood Management and Risk Communication Through Large Language Models,"In light of urbanization, climate change, and the escalation of extreme weather events, flood management is becoming more and more important. Improving community resilience and reducing flood risks require prompt decision-making and effective communication. This study investigates how flood management systems can incorporate Large Language Models (LLMs), especially those that use Retrieval-Augmented Generation (RAG) architectures. We suggest a multimodal framework that uses a Flood Knowledge Graph to aggregate data from various sources, such as social media, hydrological, and meteorological inputs. Although LLMs have the potential to be transformative, we also address important drawbacks like governance issues, hallucination risks, and a lack of physical modeling capabilities. When compared to text-only LLMs, the RAG system significantly improves the reliability of flood-related decision support by reducing factual inconsistency rates by more than 75%. Our suggested architecture includes expert validation and security layers to guarantee dependable, useful results, like flood-constrained evacuation route planning. In areas that are vulnerable to flooding, this strategy seeks to strengthen warning systems, enhance information sharing, and build resilient communities.",flood forecasting and mapping | flood knowledge graph | large language models | retrieval augmented generation | risk analysis,0,2025,sustainability,behavior+policy+sustainability
124,2-s2.0-105019198988,10.3390/su17198806,https://doi.org/10.3390/su17198806,https://scholar.google.com/scholar?q=10.3390/su17198806,ar,Sustainability Switzerland,"Mondal, Subhra;Uyen, Nguyen Cao Thục;Das, Subhankar;Vrana, Vasiliki G.",Innovation Dynamics and Ethical Considerations of Agentic Artificial Intelligence in the Transition to a Net-Zero Carbon Economy,"As climate action becomes increasingly urgent, nations and institutions worldwide seek advanced technologies for practical mitigation efforts. This study examines how agentic artificial intelligence systems capable of decision-making and learning from experience drive innovation dynamics in climate change mitigation, with a particular focus on ethical considerations during the net-zero transition. The current urgency of climate action demands advanced technologies, yet organisations struggle to effectively deploy agentic AI for climate mitigation due to unclear implementation pathways and ethical consideration. This study examines the relationships among agentic AI capabilities, innovation dynamics, and net-zero transition performance, using survey data from 340 organisations across the manufacturing, energy, and technology sectors, and analysed using structural equation modelling. Based on dynamic capabilities theory, this research proposes a novel theoretical model that examines how agentic AI drives innovation dynamics in climate change mitigation within governance frameworks that encompass transparency, accountability, and environmental justice. Results reveal significant mediation effects of innovation dynamics, dynamic capabilities, and ethical considerations, while environmental context negatively moderates innovation and ethical pathways. Findings suggest that overly restrictive ethical considerations can lead to implementation delays that undermine the urgency of climate action. This study proposes three solutions: (1) adaptive ethical protocols adjusting governance intensity based on climate risk severity, (2) pre-approved ethical templates reducing approval delays by 60%, and (3) stakeholder co-design processes building consensus during development. The research advances dynamic capabilities theory for AI contexts by demonstrating how AI-enabled sensing, seizing, and reconfiguring capabilities create differentiated pathways to climate performance. This study provides empirical validation of the responsible innovation framework, identifies asymmetric environmental contingencies, and offers evidence-based guidance for organisations implementing agentic AI for climate action.",agentic AI | climate innovation | dynamic capabilities theory | ethical considerations,0,2025,sustainability,behavior+policy+sustainability
147,2-s2.0-105014471016,10.1016/j.scs.2025.106761,https://doi.org/10.1016/j.scs.2025.106761,https://scholar.google.com/scholar?q=10.1016/j.scs.2025.106761,ar,Sustainable Cities and Society,"Zhang, Yudi;Lin, Yuming;Tian, Li;Yang, Xin",Leveraging LLM-based multi-agent simulations to boost participatory design education: An experimental exploration in residential area design,"As participatory planning gains importance in sustainable urban development, integrating inclusive stakeholder engagement into design education remains challenging. This study proposes MAPS (Multi-agent AI-augmented Participatory System), a novel pedagogical tool that uses LLM-based agents to simulate stakeholder engagement in urban design studios. Powered by DeepSeek V3 and enhanced with TextGrad, MAPS delivers more realistic, role-consistent negotiation simulations. Through scenarios like roundtable discussions, community voting, and plan evaluation, students interact with diverse virtual stakeholders to practice negotiation, reflect critically, and refine their proposals. A case study conducted in a residential design studio demonstrates that MAPS significantly improves constructivist learning outcomes, including stakeholder understanding, critical reflection, and adaptive decision-making. Evaluation results show increased sensitivity to equity, transparency, and negotiation dynamics. These findings highlight MAPS's potential as a scalable and transferable educational innovation for preparing future designers to navigate complex, multi-stakeholder environments.",Constructivist learning | Large language models | Multi-agent simulation | Participatory design | Planning education,0,2025,sustainability,behavior+policy+sustainability
263,2-s2.0-105025464117,10.1108/DTS-08-2025-0255,https://doi.org/10.1108/DTS-08-2025-0255,https://scholar.google.com/scholar?q=10.1108/DTS-08-2025-0255,re,Digital Transformation and Society,"Kristiani, Nuning;Haryanto, Budhi;Wahyudi, Lilik;Setiawan, Ahmad Ikwan",User readiness and technology adoption in AI-driven smart cities: a systematic review of generative and predictive models for advancing the SDGs,"Purpose – This study examines the integration of generative and predictive artificial intelligence (AI) models within smart cities, focusing on how user readiness and technology adoption influence their contribution to sustainable urban development and governance. Design/methodology/approach – The study applies a systematic literature review following PRISMA guidelines and synthesizes evidence from 50 peer-reviewed studies (2018–2025) indexed in Scopus and Web of Science. It combines bibliometric mapping using VOSviewer with thematic analysis to examine the drivers, barriers and governance mechanisms shaping the adoption of generative, predictive and hybrid applications in urban contexts. Findings – Generative AI fosters participatory engagement, citizen co-design and interactive simulations, advancing SDG 11 (Sustainable Cities and Communities) and SDG 4 (Quality Education) through enhanced digital literacy and inclusive planning. Predictive AI improves operational efficiency, forecasting accuracy and data-driven policymaking, supporting SDG 9 (Industry, Innovation and Infrastructure) and SDG 13 (Climate Action) by promoting sustainable resource use and climate-resilient management. Hybrid AI integrates these strengths, addressing both social and operational aspects of smart city development and aligning with SDG 17 (Partnerships for the Goals) through cross-sector collaboration and shared governance. Collectively, these models contribute to broader sustainability goals, including SDGs 3, 7 and 12. Research limitations/implications – This review acknowledges several key limitations. Reliance on Scopus and Web of Science may exclude regionally significant or domain-specific studies not indexed in these databases. The focus on English-language publications introduces potential language bias, possibly overlooking relevant research from non-English-speaking regions. Restricting the timeframe to 2018–2025 captures recent developments but may omit earlier foundational work or the most recent studies not yet indexed. Differences in research design, policy contexts and sample characteristics also affect comparability and limit generalizability. Future research should broaden data sources, include multilingual literature and adopt mixed-methods and longitudinal approaches to enhance contextual diversity and empirical robustness. Practical implications – The findings provide practical guidance for policymakers, urban planners and technology developers to design AI governance systems that are transparent, accountable and aligned with the SDGs. Integrating generative and predictive AI can enhance operational efficiency, support participatory planning and promote responsible decision-making. The findings inform the development of adaptive policy frameworks that advance SDG 9 (Industry, Innovation and Infrastructure), SDG 11 (Sustainable Cities and Communities) and SDG 13 (Climate Action) through digital literacy initiatives, cross-sector collaboration and data-informed management. Strengthening these practices enables cities to translate AI’s potential into tangible contributions to inclusive and sustainable urban transformation. Social implications – Integrating user readiness and digital literacy into AI adoption is essential for building inclusive and trustworthy smart cities. These efforts support SDG 4 (Quality Education), SDG 10 (Reduced Inequalities) and SDG 16 (Peace, Justice and Strong Institutions). Generative AI encourages citizen participation and collaborative planning, while predictive AI improves service accessibility and data-informed governance. Promoting ethical awareness and community engagement helps narrow digital divides and address bias. Collectively, these elements advance SDG 11 (Sustainable Cities and Communities) and SDG 17 (Partnerships for the Goals) by fostering socially responsive and transparent AI-driven urban development. Originality/value – This review is among the first to integrate perspectives on user readiness and technology adoption with comparative insights into generative and predictive AI in smart cities. It advances understanding of how AI-driven urban innovation supports inclusivity, efficiency and sustainability, while outlining policy directions and a future research agenda for equitable and transparent AI governance.",Artificial intelligence | Smart cities | Sustainable Development Goals | Technology adoption | User readiness,0,2025,sustainability,behavior+policy+sustainability
272,2-s2.0-105024447210,10.1108/GKMC-05-2025-0328,https://doi.org/10.1108/GKMC-05-2025-0328,https://scholar.google.com/scholar?q=10.1108/GKMC-05-2025-0328,re,Global Knowledge Memory and Communication,"Albannai, Najla Abdullah Ahmed;Raziq, Muhammad Mustafa;Bani-Melhem, Shaker;Moazzam, Muhammad",Digital leadership in the age of generative AI: a systematic literature review using thematic analysis,"Purpose – The rise of generative artificial intelligence (AI) tools has presented both possibilities and perils. This research aims to examine how digital leaders build organizational readiness, overcome challenges and achieve successful AI implementation and integration transformation. Design/methodology/approach – The authors conduct a systematic review of the literature at the crossroads of digital leadership and generative AI. A total of 181 papers were obtained from Scopus (2021–2025) based on the search keywords “digital leadership, ” “generative AI, ” “AI-driven workflows” and “AI integration leadership.” The search was limited by means of Boolean operators (AND/OR). To explore common themes among the studies, a thematic synthesis of the material was conducted. Findings – The results highlight the role of digital leadership in instituting generative AI as an element of organizational routines. Digital companies use a combination of AI–human systems. It enhances recruitment and customer experience by promoting sustainability and ethical governance. The findings highlight the importance of modular frameworks, AI models that can be interpreted and adaptive leadership. Generative AI is reshaping the worker relationship through automation and enhanced decision-making, and leaders should be held more responsible for inclusivity and displacement. Effective leadership further enables organizations to create value, strengthen supply chains and build long-term competitive advantage. Originality/value – This paper offers a new perspective for comprehending digital leadership on managing generative AI in organizations. It thus addresses the gap between AI adoption and leadership strategy by offering theoretical insights and practical advice for dealing with disruption from AI and building competitive advantage in a digital age.",AI integration | Digital leadership | Digital transformation | Generative AI,0,2025,sustainability,behavior+policy+sustainability
276,2-s2.0-105024202019,10.1007/s00146-025-02791-z,https://doi.org/10.1007/s00146-025-02791-z,https://scholar.google.com/scholar?q=10.1007/s00146-025-02791-z,ar,AI and Society,"Aeon, Brad",The future of productivity: digital surrogacy,"Digital surrogacy (i.e., the creation of AI-based “clones” that autonomously act in ways consistent with their user’s knowledge, personality, and goals) promises to redefine personal productivity. This paper develops a framework to analyze this emerging phenomenon. First, drawing on cognitive externalism, it conceptualizes surrogates as genuine cognitive extensions, identifying three interlocking ramifications: scaled individuality, which enables identity-faithful replication across multiple contexts; black-box productivity, which delivers unprecedented output while obscuring underlying processes; and autonomy inversion, a trade-off where users relinquish decision-making for cognitive relief. Second, the analysis integrates Self-Determination Theory to argue that the success of digital surrogacy is conditional, creating critical tensions with the basic psychological needs for autonomy, competence, and relatedness. Third, it examines existing legal frameworks such as power of attorney and AI personhood, proposing that surrogates are better understood as legal extensions of the person (“empersonification”), which necessitates novel governance structures. By distinguishing digital surrogacy from related concepts like AI Agents and Digital Twins through its core principle of identity-congruent agency, this paper challenges self-centric productivity models. It concludes that the future of work must account not only for distributed cognition but also for the psychological and legal conditions that make such identity-extended agency sustainable and legitimate.",Artificial intelligence | Cognitive extension | Digital clone | Productivity,0,2025,sustainability,behavior+policy+sustainability
298,2-s2.0-105017471776,10.3389/fspor.2025.1642180,https://doi.org/10.3389/fspor.2025.1642180,https://scholar.google.com/scholar?q=10.3389/fspor.2025.1642180,re,Frontiers in Sports and Active Living,"Westerbeek, Hans;van Schaik, Thomas","Platform power, athlete branding, generative AI, and the future of sport governance—a systematic review","This systematic review examines how elite athletes are leveraging digital platforms, generative artificial intelligence (AI), and blockchain to build autonomous brands, bypass traditional sport gatekeepers, and develop athlete-owned business models. Drawing on 47 peer-reviewed studies (2016–2025), we synthesise evidence across five domains: athlete branding and self-production, disintermediation, platform-enabled empowerment, AI-driven content innovation, and emerging commercial structures. The findings reveal a decisive shift in sport's power balance, with athletes acting as media producers, cultural influencers, and entrepreneurial actors. Digital platforms enable direct-to-fan engagement, while AI tools lower content production costs whilst personalising interactions and extend global reach. Blockchain facilitates decentralised monetisation and data sovereignty, supporting ventures such as athlete-owned leagues and non-fungible tokens. However, these developments embed new dependencies on platform algorithms and volatile digital markets. From a platform capitalism perspective, athlete autonomy is constrained by corporate-controlled infrastructures; from a value co-creation lens, fan relationships become participatory spaces for shared cultural and commercial value creation. The review highlights governance challenges, including ethical implications of synthetic media, data ownership, and the regulation of AI-enabled branding ecosystems. We argue that sport governance must evolve from a control-oriented model to one that positions athletes as co-creators of value and strategic partners in decision-making. Future research should address equity in digital visibility and sustainable athlete-led business ecosystems. Governance mechanisms that reconcile technological opportunity with autonomy protection should be explored as well. Athletes are no longer peripheral actors in sport's commercial order, they are emerging as its architects, with significant implications for the future of sport governance.",athlete branding | digital platforms | disintermediation | emerging business models | generative AI | self-production,0,2025,sustainability,behavior+policy+sustainability
303,2-s2.0-105016998997,10.6041/j.issn.1000-1298.2025.09.019,https://doi.org/10.6041/j.issn.1000-1298.2025.09.019,https://scholar.google.com/scholar?q=10.6041/j.issn.1000-1298.2025.09.019,ar,Nongye Jixie Xuebao Transactions of the Chinese Society for Agricultural Machinery,"Wang, Yaojun;Xu, Guowei;Zhu, Jianjun;Bie, Yuhui",Survey of Research on Large Language Models in Agriculture,"As a core driving force in artificial intelligence, large language models (LLMs) leverage their powerful capabilities in semantic understanding, logical reasoning, and multimodal information processing to achieve deep analysis and intelligent generation from vast unstructured data. In recent years, through their exceptional performance in processing complex agricultural information and aiding precision decision-making, LLM technologies have shown immense potential to enhance knowledge acquisition, empower intelligent pest and disease diagnosis, and optimize production management. They were poised to provide foundational technological support for elevating smart farming to a more advanced stage of cognitive intelligence. The landscape of LLMs was systematically reviewed from the evolution of foundational models to their flourishing application ecosystem. It provided an in-depth analysis of the current research status in agricultural question answering, multimodal applications, and decision support systems, while also identifying challenges such as data scarcity, model reliability, and deployment costs. Furthermore, it was outlined the key solutions centered on retrieval-augmented generation (RAG), multimodal fusion, and agent technology, discussing their critical roles in overcoming model knowledge limitations and integrating multi-source data. Through an analysis of typical application cases like intelligent pest and disease diagnosis and precision crop management, the value and significance of LLMs in empowering modern agriculture were clarified. Finally, it provided an outlook on the future development of LLMs in agriculture. It posited that future technological evolution would focus on the deep coupling of models with knowledge graphs, the comprehensive enhancement of multimodal perceptual capabilities, and the establishment of responsible AI governance frameworks. These advancements were expected to collectively drive the transformation of agricultural intelligence from apassive auxiliary tool into an active decision-making partner, ultimately providing a powerful technological impetus for achievin g refined management and sustainable development in agriculture.",agent | agricultural decision support system | agricultural knowledge question-answering system | large language model for agriculture | multimodal | retrieval-augmented generation,0,2025,sustainability,behavior+policy+sustainability
316,2-s2.0-105011100591,10.1007/s10506-025-09473-7,https://doi.org/10.1007/s10506-025-09473-7,https://scholar.google.com/scholar?q=10.1007/s10506-025-09473-7,re,Artificial Intelligence and Law,"Zhang, Chuyue;Meng, Yuchen",Bridging the divide: technical research and application on legal judgment prediction,"In recent years, the field of Legal Judgment Prediction (LJP) has advanced substantially, driven by machine learning, deep learning, and large language models. This paper investigates the technical challenges and performance disparities in LJP: while current models excel in charge prediction and legal article recommendation, their capabilities in multi-label prediction, sentencing prediction, and generative tasks require further enhancement. A notable gap persists between laboratory research and real-world judicial needs, encompassing issues such as data quality limitations, inadequate model interpretability, algorithmic bias, and ethical risks. To bridge this gap, we propose a dual framework of “technology optimization–institutional adaptation.” On the technical side, our approach emphasizes enhanced data governance, bias detection, privacy protection, and improved interpretability, while on the institutional side, it advocates for ethical oversight and the integration of AI systems within existing judicial processes. Additionally, we underscore the importance of demand-driven algorithmic improvements include resource-aware model compression, case complexity classification, and robust evaluation protocols to achieve sustainable deployment. Our analysis suggests that only through systematic collaboration among researchers, legal experts, and policymakers can LJP realize both technical innovation and judicial credibility, thereby fostering fairness, efficiency, and trust in legal decision-making.",Legal AI | Legal judgment prediction | Research-practice gap | Technology- institutional collaboration,0,2025,sustainability,behavior+policy+sustainability
0,2-s2.0-105026457678,10.1186/s42400-025-00532-9,https://doi.org/10.1186/s42400-025-00532-9,https://scholar.google.com/scholar?q=10.1186/s42400-025-00532-9,ar,Cybersecurity,"Zheng, Tianming;Meng, Fanchao;Yi, Ping;Wu, Yue",Automating fuzz driver generation for deep learning libraries with large language models,"The widespread adoption of deep learning (DL) libraries has raised concerns about their reliability and security. While prior works leveraged large language models (LLMs) to generate test programs for DL library APIs, the hardcoded program behaviors and low code validity rates render them impractical for real-world testing. To address these challenges, we propose FD-FACTORY, a fully automated framework that leverages LLMs to generate fuzz drivers for DL API testing. The fuzz driver programs accept mutated inputs from fuzzing engines to achieve effective code analysis. Inspired by the modular design of industrial production lines, FD-FACTORY decomposes the generation process into eight distinct stages: Preparation, Initial Fuzz Driver Generation, Early Stop Checks, Verification, Issue Diagnosis, Decision Making, Repair Loop, and Deployment. Each stage is handled by dedicated agents or tools to enhance construction efficiency. Experimental results demonstrate that FD-FACTORY achieves 73.67% and 65.33% success rates in generating fuzz drivers for PyTorch and TensorFlow, producing an improvement of 34.66 to - 54.66% than existing approaches. In addition, FD-FACTORY provides more comprehensive coverage tracking by supporting both Python and native C/C++ code. It achieves a total coverage of 308,351 lines on PyTorch and 528,427 lines on TensorFlow, substantially surpassing the results reported by previous approaches. Unlike prior approaches relying on repeated interactions with the LLM servers throughout the entire testing process, our framework confines the use of LLMs strictly to the fuzz driver generation stages before deployment. Once generated, the fuzz drivers can be reused without further LLM involvement, thereby enhancing the practicality and sustainability of LLM-assisted fuzzing in real-world scenarios.",Deep learning library | Fuzz driver generation | Large language model | Vulnerability detection,0,2026,sustainability,behavior+sustainability
4,2-s2.0-105026758709,10.1016/j.ssci.2025.107107,https://doi.org/10.1016/j.ssci.2025.107107,https://scholar.google.com/scholar?q=10.1016/j.ssci.2025.107107,ar,Safety Science,"Kaya, Ömer;Kabakuş, Nuriye",Mapping micro-mobility risk: AI-powered geospatial analysis and predictive modelling,"Micro-mobility vehicles have rapidly become widespread as a sustainable and practical alternative for urban transportation in recent years. In this study, micro-mobility vehicles refer to traditional bicycles, electric bicycles, and electric scooters, which represent the main categories of such modes involved in traffic crashes in Türkiye. Despite their growing popularity, the safety implications of these vehicles have not yet been fully understood, and comprehensive research addressing crash patterns and associated risk factors is required. To this end, this study employs an artificial intelligence-driven geospatial and statistical methodology. Crash reports involving micro-mobility vehicles in Türkiye between 2015 and 2023 were analysed. Seventeen independent variables and 102 sub-variables were identified and integrated into a GIS environment for spatial analysis. The impact levels of risk factors were assessed using six different Large Language Models (DeepSeek, GEMINI, Perplexity, ChatGPT, Copilot, and Poe). Crash risk maps and corresponding weight values were combined to produce an crash suitability map indicating the potential risk of micro-mobility crashes. Furthermore, the significance of these factors across different collision types was tested using a multinomial logistic regression model. To the best of the authors’ knowledge, this is the first study to apply a macro-scale dataset and an AI-enhanced geospatial decision-making approach to analyse micro-mobility crashes. The findings highlight the need for local governments and urban planners to implement targeted safety measures in regions with high crash potential.",generative AI | Micro-mobility risk assessment | Sustainable infrastructure | Traffic safety,0,2026,sustainability,behavior+sustainability
6,2-s2.0-105025666558,10.1016/j.technovation.2025.103465,https://doi.org/10.1016/j.technovation.2025.103465,https://scholar.google.com/scholar?q=10.1016/j.technovation.2025.103465,ar,Technovation,"Çipi, Amali;Ferreira, Neuza C.M.Q.F.;Ferreira, Fernando A.F.;Ferreira, João J.M.;Smarandache, Florentin",Leveraging AI and generative AI in urban design and planning: Unveiling advantages and challenges through problem structuring methods,"The integration of Artificial Intelligence (AI) in general—and its subfield Generative AI (GenAI) in particular—into urban design and planning is revolutionizing traditional methodologies, providing innovative solutions to complex challenges in city development. Despite their transformative potential, existing research underscores a critical need to better understand the multifaceted advantages and challenges associated with these technologies. This study addresses this gap by investigating the causal relationships between the advantages and challenges of AI and GenAI integration in urban design and planning. Leveraging a novel combination of cognitive mapping and neutrosophic DEcision-MAking Trial and Evaluation Laboratory (DEMATEL), the research identifies and evaluates key factors shaping this integration. The findings reveal that dynamic digital city simulations and scenario modeling emerge as the most significant advantages, underscoring their capacity to drive data-informed innovation in urban development. Conversely, ethical concerns surface as the most critical challenge, exhibiting strong interdependencies with other issues, including the “black box” nature of AI systems and the biases embedded in training data. This study provides a comprehensive framework for understanding the interplay between these factors, offering actionable insights to guide both academic research and practical implementation. By addressing a pressing need in the field, the research paves the way for more responsible and effective applications of AI and GenAI in creating smarter, more sustainable urban environments.",Artificial intelligence (AI) | Causality analysis | Generative AI (GenAI) | Problem structuring methods (PSMs) | Urban design | Urban planning,0,2026,sustainability,behavior+sustainability
11,2-s2.0-105022170572,10.1016/j.techsoc.2025.103121,https://doi.org/10.1016/j.techsoc.2025.103121,https://scholar.google.com/scholar?q=10.1016/j.techsoc.2025.103121,ar,Technology in Society,"Nizamani, Mir Muhammad;Zhang, Hai Li;Lai, Zhongping","Human-centered AI: advancing ethical, transparent, and context-aware systems for sustainable development","Human-Centered AI (HCAI) represents a transformative approach to artificial intelligence development, focusing on aligning AI systems with human values, societal needs, and ethical standards. This paper explores the key frameworks, challenges, and opportunities associated with HCAI, emphasizing its application across diverse domains such as healthcare, urban planning, agriculture, and education. HCAI-driven innovations, including Human-Centered Generative AI, Human-AI Co-Creation, and Explainable AI, are enhancing creativity, trust, and decision-making in both individual and collaborative contexts. The paper identifies critical challenges, including technical limitations, ethical concerns, human-AI interaction issues, and data privacy concerns, which must be addressed to ensure effective and ethical AI deployment. It also highlights the role of interdisciplinary research and cross-sector collaboration in overcoming these challenges and advancing HCAI applications. Looking ahead, the integration of AI with big data, longitudinal studies, and real-time evaluations will play a pivotal role in refining AI systems and ensuring their long-term success. By adopting a socio-technical approach and fostering public participation in AI design, HCAI can promote more sustainable, equitable, and human-centric technological development. Ultimately, the paper argues that HCAI has the potential to drive innovation in ways that enhance human capabilities, build trust, and contribute positively to societal well-being.",AI ethics | Bias mitigation | Human-AI collaboration | Interdisciplinary research | User experience,0,2026,sustainability,behavior+sustainability
15,2-s2.0-105026575933,10.1016/j.identj.2025.103979,https://doi.org/10.1016/j.identj.2025.103979,https://scholar.google.com/scholar?q=10.1016/j.identj.2025.103979,ar,International Dental Journal,"Duane, Brett;Ashley, Paul;Larkin, James",Prompt-Driven ChatGPT Carbon Calculator for Dental Practices: Estimation and Tailored Improvement Strategies,"Introduction and aims This study investigates the feasibility of applying ChatGPT, a generative artificial intelligence (AI) language model, to develop a user-friendly carbon footprint calculator tailored for dental practices. Building on a previously developed Excel-based tool, the research aimed to evaluate ChatGPT’s capacity to generate accurate emissions estimates and sustainability recommendations using different prompting strategies. Methods Three prompting variants were tested. Variant 1 employed an unstructured request to assess general responses. Variant 2 used structured data entry with predefined emission factors. Variant 3 combined structured input with instructions to rely exclusively on outputs from a previously validated sustainability tool. ChatGPT-generated results were compared with the Excel benchmark, focusing on accuracy, contextual relevance and alignment with peer-reviewed guidance. Results Unstructured prompts (Variant 1) produced general recommendations of limited contextual relevance. Structured prompts improved both accuracy and specificity. Variant 2 generated tailored outputs using emission factors, while Variant 3 provided detailed, evidence-based recommendations consistent with established literature. Across variants, ChatGPT’s carbon footprint estimates were largely comparable to the Excel benchmark, with only minor discrepancies in waste-related emissions. Conclusion Structured prompting significantly enhances ChatGPT’s performance in generating reliable carbon footprint data and recommendations for dental practices. When supported by transparent emission factors and credible literature, generative AI tools can increase access to environmental data, support sustainability decision-making and facilitate climate action in clinical contexts. However, limitations remain, including risks of inaccurate outputs (‘hallucinations’) and regional generalisations. Effective use requires prompt literacy and open access to validated emission factor databases to maximise impact and reliability. Clinical relevance AI-driven calculators such as ChatGPT can help dental teams without carbon accounting expertise to understand and reduce their environmental impacts, supporting the integration of sustainability into routine clinical practice.",Artificial intelligence in healthcare | Carbon footprint | ChatGPT | Dental practices | Prompt engineering | Sustainability,0,2026,sustainability,behavior+sustainability
16,2-s2.0-105024305351,10.1016/j.envsoft.2025.106823,https://doi.org/10.1016/j.envsoft.2025.106823,https://scholar.google.com/scholar?q=10.1016/j.envsoft.2025.106823,ar,Environmental Modelling and Software,"Rezaei, Hadiseh;Roberts, Keiron P.;Arabikhan, Farzad;Fletcher, Steve;March, Antaya;Couceiro, Fay;Bacon, David;Hutchinson, David J.;Williams, John B.",Artificial intelligence enhanced litter pollution mapping: Integrating citizen science with geospatial and social data,"Citizen science provides extensive litter data, but inconsistent recording limits its use in environmental modelling and decision making. We present a scalable AI-assisted framework that harmonises two major UK datasets, Marine Debris Tracker and Litterati, into a unified, spatially detailed resource. Over 460,000 records (2015–2024) were standardised through a rules-to-embeddings-to-LLM cascade (schema-constrained Llama 3.1) for material classification. Items were clustered by material using K-means at a validated 200 m scale and linked to OpenStreetMap amenities within 500 m to identify accumulation hotspots and contextual features such as parks or transport hubs. Plastic dominated nationally, accounting for 71 percent of entries, while integration with UK Census 2021 data enabled demographic and health analyses where plastic remained highest (68.9 percent). This reproducible framework demonstrates how artificial intelligence can harmonise citizen-science data and enhance spatial modelling to inform targeted pollution prevention and sustainable waste-management strategies.",Cluster analysis | Data enrichment | Data integration | Environmental monitoring | Natural Language Processing (NLP) | Pollution prevention | Text mining,0,2026,sustainability,behavior+sustainability
18,2-s2.0-105027411419,10.1021/acs.est.5c09526,https://doi.org/10.1021/acs.est.5c09526,https://scholar.google.com/scholar?q=10.1021/acs.est.5c09526,ar,Environmental Science Technology,"Chen, Chuke;Li, Nan;Qi, Jianchuan;Chang, Huimin;Shi, Wenjie;Xie, Jinliang;Yuan, Jiayi;Yang, Hang;Guo, Jing;Xu, Changqing;Xu, Ming",Leveraging LLMs for Environmental Complexity: Structured Fine-Tuning Data Sets and Deployment Strategies,"Generative artificial intelligence, especially large language models (LLMs), could accelerate environmental analysis, but deployment is hindered by two gaps: limited structured domain knowledge and unclear strategies matched to environmental decision contexts. Here, this study constructs a textbook-based, China-centered environmental knowledge data set with hierarchical organization to enable reliable fine-tuning and benchmarking. Results show a consistent trade-off that fine-tuned models achieve modest gains in precision (+1%) and response efficiency (+52%) on standardized tasks but exhibit limited adaptability when embedded in agentic workflows (-3%). In contrast, state-of-the-art generalist models consistently outperform in system-level sustainability and interdisciplinary decision tasks (+10%), benefiting from stronger cross-domain reasoning and dynamic tool integration. Together, these findings support a layered LLMs' deployment strategy for environmental intelligence. Specifically, selective fine-tuning for stable, regulatory, and verification tasks, combined with agentic workflows anchored in up-to-date generalist backbone models for dynamic, data-intensive, and interdisciplinary decision-making. This work provides both a reusable data set foundation and a practical framework for deploying LLMs as scalable and reliable decision-support tools in environmental decision.",agentic workflows | environmental complexity | fine-tuning | generative artificial intelligence | large language models,0,2026,sustainability,behavior+sustainability
19,2-s2.0-105027401533,10.1021/acs.est.5c14493,https://doi.org/10.1021/acs.est.5c14493,https://scholar.google.com/scholar?q=10.1021/acs.est.5c14493,re,Environmental Science Technology,"Preuss, Nathan;You, Fengqi",Automating Life Cycle Assessments through Artificial Intelligence Agents and Integrated Assessment Models,"Life cycle assessments (LCA) are a critical decision support tool for environmentally sustainable decision-making, but barriers such as time and resource intensity inhibit widespread application of LCA. To overcome these challenges, LCAs have been partially automated with integrated assessment models (IAM) and artificial intelligence (AI) agents, but existing literature reviews do not describe the potential for automation. We find that AI agents and IAMs offer tantalizing methods to automate all four stages of LCA with many avenues for future research, but adoption in the LCA community outside of the premise tool is minimal, despite the reliable results reported by the authors of several studies. Automated LCA can improve time and resource efficiency across all four stages of LCA, but there is insufficient research to rigorously assess the quality of automated LCA. To overcome the perceived untrustworthiness of automated LCA tools, the LCA community should democratically develop norms for use.",artificial intelligence agents | environmental sustainability | integrated assessment models | large language models | life cycle assessment,0,2026,sustainability,behavior+sustainability
22,2-s2.0-105027211632,10.1108/LODJ-04-2025-0309,https://doi.org/10.1108/LODJ-04-2025-0309,https://scholar.google.com/scholar?q=10.1108/LODJ-04-2025-0309,ar,Leadership and Organization Development Journal,"Jiang, Shan;Macawile, Remson Mark C.;Munir, Tanya","Driving sustainable development through behavioral change: the role of generative AI, digital literacy of leaders and responsible innovation","Purpose – This study investigates the relationship between Generative AI (Gen AI) adoption, leaders’ digital literacy, and responsible innovation practices in shaping organizational culture and behavioral adjustments that directly support sustainable development outcomes (SDOs). The goal is to explore how ethically aligned AI integration, when supported by contextual understanding and workforce readiness, can enhance sustainability efforts. Design/methodology/approach – The quantitative empirical survey collected data from 450 employees working in social media agencies in Pakistan, through convenience sampling technique within 4 months. The study employs moderation-mediation through the process model, using SmartPLS software. Findings – All eight hypotheses were supported. The study finds that SDOs are achievable through the integration of cultural, technological and ethical complexities. Responsible innovation practices and a sustainability-focused culture are critical to ensuring Gen AI contributes positively to organizational sustainable goals. Practical implications – Practitioners and global trainers should invest in workforce upskilling through digital literacy and AI competency equipping employees to engage with AI technologies, driving innovation and sustainability. Moreover, organizations need to focus on sustainable, ethical and socially beneficial outcomes while minimizing the risk. Social implications – Regulators, with the support of AI solutions, can promote community engagement that runs parallel with societal values, fostering trust and collaboration. Furthermore, policy makers need to promote digital literacy for bridging the gap of digital divide and offer equitable access to all stakeholders, enabling them to benefit from technology. Originality/value – This study uniquely integrates Generative AI adoption, leaders' digital literacy, and responsible innovation into a single behavioral framework for sustainable development. By providing empirical evidence from an emerging economy, it advances sustainability literature and offers actionable insights for ethically aligned AI-driven cultural and behavioral transformation.",Cultural and behavioral change | Digital literacy | Generative AI | Leadership role | Responsible innovation practices | Sustainable development outcomes,0,2026,sustainability,behavior+sustainability
23,2-s2.0-105027066424,10.3390/su18010396,https://doi.org/10.3390/su18010396,https://scholar.google.com/scholar?q=10.3390/su18010396,ar,Sustainability Switzerland,"Jang, Dong Seok;Yi, Jae Sik;Jeon, Hyung Bae;Hong, Youn Sik",BioChat: A Domain-Specific Biodiversity Question-Answering System to Support Sustainable Conservation Decision-Making,"Biodiversity knowledge is fundamental to conservation planning and sustainable environmental decision-making; however, general-purpose Large Language Models (LLMs) frequently produce hallucinations when responding to biodiversity-related queries. To address this challenge, we propose BioChat, a domain-specific question-answering system that integrates a Retrieval-Augmented Generation (RAG) framework with a Re-Ranker–based retrieval and routing mechanism. The system is built upon a verified biodiversity dataset curated by the National Institute of Biological Resources (NIBR), comprising 25,593 species and approximately 970,000 structured data points. We systematically evaluate the effects of embedding selection, routing strategy, and generative model choice on factual accuracy and hallucination mitigation. Experimental results show that the proposed Re-Ranker-based routing strategy significantly improves system reliability, increasing factual accuracy from 47.9% to 71.3% and reducing hallucination rate from 34.0% to 24.4% compared with Naive RAG baseline. Among the evaluated LLMs, Qwen2-7B-Instruct achieves the highest factual accuracy, while Gemma-2-9B-Instruct demonstrates superior hallucination control. By delivering transparent, verifiable, and context-grounded biodiversity information, BioChat supports environmental education, citizen science, and evidence-based conservation policy development. This work demonstrates how trustworthy AI systems can serve as sustainability-enabling infrastructure, facilitating reliable access to biodiversity knowledge for long-term ecological conservation and informed public decision-making.",biodiversity information systems | environmental knowledge accessibility | hallucination mitigation in LLMs | Retrieval-Augmented Generation (RAG) | sustainable conservation decision-making,0,2026,sustainability,behavior+sustainability
25,2-s2.0-105022724710,10.1109/TEM.2025.3633709,https://doi.org/10.1109/TEM.2025.3633709,https://scholar.google.com/scholar?q=10.1109/TEM.2025.3633709,ar,IEEE Transactions on Engineering Management,"Dey, Atanu;Jenamani, Mamata;De, Arijit",Consumer Sentiment-Driven Product Ranking Using a Feature-Level Deep Learning Approach: The Case of New and Refurbished Laptops,"Electronic waste (E-waste) is an escalating global challenge, with discarded laptops forming a major share of this growing environmental burden. To support sustainable consumption and informed consumer decision-making, this study proposes an unsupervised deep learning framework that ranks refurbished and new laptop brands based on consumer sentiment extracted from online reviews. The framework identifies not only direct product features called aspects (such as battery, display, or customer support) but also experiential dimensions (such as reliability, performance, or overall satisfaction), providing a holistic view of consumer perception. By leveraging a transformer-based multiheaded attention mechanism and part-of-speech tagging, the model extracts rich five-part sentiment structures: aspect/dimension, category, opinion, irrealis (hypotheticals), and sentiment, collectively represented as ACOIS and DCOIS quintuples. These insights feed into a folksonomy-based consumer brand ranking algorithm, which aggregates sentiment scores to rank laptop brands effectively. Unlike traditional models, this framework requires no labeled training data, increasing its adaptability across domains. Comparative evaluations against state-of-the-art supervised and self-supervised models, including large language models, demonstrate superior performance with F1 score improvements of 9%, 6%, and 4% in extracting product aspects, dimensions, and opinions, respectively. The model is applied to a curated dataset comprising new and refurbished laptops within the same price segment. Results show that 40% of refurbished brands appear in the top 25% of recommendations. We ensured the framework’s robustness check, including McNemar’s statistical testing on six subtasks (5/6 above 0.05 threshold), ablation studies with two alternative attention mechanisms, and validation against several benchmark methods, confirming framework’s stability.",Circular economy (CE) | deep learning (DL) | electronic waste (E-waste) | natural language processing (NLP) | sentiment analysis (SA) | transformer encoding,0,2026,sustainability,behavior+sustainability
26,2-s2.0-105021990949,10.1016/j.asoc.2025.114255,https://doi.org/10.1016/j.asoc.2025.114255,https://scholar.google.com/scholar?q=10.1016/j.asoc.2025.114255,ar,Applied Soft Computing,"Zhihui, Wu;Jinzhao, Chu;Yang, Xiao;Kumar, Sachin;Jie, Feng;Ming-Tai Wu, Jimmy;Qingqi, Pei",A sustainable urban optimization framework driven by a large language model based on multi-party trusted collaboration,"Multi-party data fusion and cross-institutional collaboration can empower large language models (LLMs) to unlock their full potential in sustainable urban data analytics. However, this approach faces critical challenges, including data privacy concerns and a lack of trust among stakeholders. While homomorphic encryption addresses privacy preservation by enabling computations on encrypted data, its inherent cryptographic properties hinder public verification of both the computation process and results, thereby exacerbating trust deficits between collaborating parties and data consumers. To tackle these issues, this paper proposes a large language model-driven urban optimization framework based on multi-party trusted collaboration, which enhances trust in weakly trusted environments and improves LLM performance in urban decision-making. Our framework introduces a publicly verifiable computation protocol based on multi-party homomorphic encryption, which can verify the correctness of ciphertext-based computations while protecting data privacy. This protocol ensures transparent validation of both computational workflows and outputs, establishing trust in multi-party interactions without exposing sensitive information. After completing the joint computation, the encrypted parameter set is decrypted and converted into structured descriptive text using predefined templates, which serves as input to LLMs for urban scenario analysis. Judging from the experimental results, compared to a single data source, the RMSE of this scheme is reduced by 66.25%, indicating that this scheme can effectively improve the prediction accuracy of LLMs. In addition, this scheme can realize efficient and reliable verification of the process and results of multi-party homomorphic encryption calculations under weak trust environment, solving the problem of security verification of multi-party collaboration in a weak trust environment.",Large language models | Multi-party homomorphic encryption | Multi-party trusted collaboration | Sustainable cities | Verifiable computing,0,2026,sustainability,behavior+sustainability
28,2-s2.0-105020069966,10.1016/j.infsof.2025.107913,https://doi.org/10.1016/j.infsof.2025.107913,https://scholar.google.com/scholar?q=10.1016/j.infsof.2025.107913,re,Information and Software Technology,"Sajadi, Amirali;Damevski, Kostadin;Chatterjee, Preetha",Psycholinguistic analyses in software engineering text: A systematic mapping study,"Context: A deeper understanding of human factors in software engineering (SE) is essential for improving team collaboration, decision-making, and productivity. Communication channels like code reviews and chats provide insights into developers’ psychological and emotional states. While large language models excel at text analysis, they often lack transparency and precision. Psycholinguistic tools like Linguistic Inquiry and Word Count (LIWC) offer clearer, interpretable insights into cognitive and emotional processes exhibited in text. Despite its wide use in SE research, no comprehensive mapping study of LIWC’s use has been conducted. Objective: We examine the importance of psycholinguistic tools, particularly LIWC, and provide a thorough analysis of its current and potential future applications in SE research. Methods: We conducted a systematic mapping study of six prominent databases, identifying 43 SE-related papers using LIWC. Our analysis focuses on five research questions: RQ1. How was LIWC employed in SE studies, and for what purposes?, RQ2. What datasets were analyzed using LIWC?, RQ3: What Behavioral Software Engineering (BSE) concepts were studied using LIWC? RQ4: How often has LIWC been evaluated in SE research?, RQ5: What concerns were raised about adopting LIWC in SE? Results: Our findings reveal a wide range of applications, including analyzing team communication to detect developer emotions and personality, developing ML models to predict deleted Stack Overflow posts, and more recently comparing AI-generated and human-written text. LIWC has been primarily used with data from project management platforms (e.g., GitHub) and Q&A forums (e.g., Stack Overflow). Key BSE concepts include Communication, Organizational Climate, and Positive Psychology. 26 of 43 papers did not formally evaluate LIWC. Concerns were raised about some limitations, including difficulty handling SE-specific vocabulary. Conclusion: We highlight the potential of psycholinguistic tools and their limitations, and present new use cases for advancing research on human factors in SE (e.g., bias in human-LLM conversations).",LIWC | Psycholinguistics | Systematic mapping study | Text analysis,0,2026,sustainability,behavior+sustainability
30,2-s2.0-105020022614,10.1016/j.techfore.2025.124400,https://doi.org/10.1016/j.techfore.2025.124400,https://scholar.google.com/scholar?q=10.1016/j.techfore.2025.124400,ar,Technological Forecasting and Social Change,"Li, Yulei;Cao, Dongmei;Hewitt, Michael;Shan, Shan",Using large-language models to analyse social media engagement with the public sector communication on circular economy: Evidence from X,"This study examines how public sector communication on circular economy (CE) initiatives influences social media engagement by analysing message elaboration, emotional tone (positive, negative, neutral), and message purpose (educational, advocacy, and policy-oriented). Grounded in the Elaboration Likelihood Model (ELM), we collected over 20,000 X (formerly Twitter) posts from 2015 to 2024 using Apify and classified them through zero-shot Large Language Model (GPT-4o-mini) analysis, validated against human coders. To establish causal effects rather than correlations, we applied a two-step approach: DirectLiNGAM for causal discovery and DoWhy for causal estimation with robustness tests. Results show that high-elaboration messages foster deeper engagement, negative tones evoke urgency; neutral tones support trust and advocacy-driven responses, while positive tones yield limited effects. Educational messages drive long-term behavioural change through systematic information processing; advocacy messages generate emotional resonance for rapid engagement, and policy-oriented messages enhance transparency but lack significant emotional impact. The study advances ELM by integrating emotional tone and message purpose into sustainability communication. Methodologically, it demonstrates how LLMs combined with causal inference methods can systematically analyse large-scale social media data. Practically, the findings provide actionable guidance for designing effective public campaigns to strengthen citizen engagement with CE goals.",Circular economy | Elaboration likelihood model (ELM) | Large language models (LLMs) | Public sector | Social media engagement | X,0,2026,sustainability,behavior+sustainability
32,2-s2.0-105014874384,10.1002/sd.70196,https://doi.org/10.1002/sd.70196,https://scholar.google.com/scholar?q=10.1002/sd.70196,ar,Sustainable Development,"Xu, Cheng;Sun, Yanqi;Davey, Howard","Harmonizing the Quartet: The Symphony of Edge Computing, Cognitive Computing, Bionic Technology, and Generative AI in Orchestrating Sustainable Business Futures","This paper proposes the “Sustainable Technological Convergence Model” (STCM), a multidisciplinary framework designed to address sustainability challenges within business operations. The model integrates edge computing, cognitive computing, bionic technology, and generative AI to promote clean production and sustainable development, aligning technological innovation with corporate social responsibility. The STCM framework is constructed through a strategic integration of emerging technologies. Edge computing optimizes data processing close to the source, reducing latency and energy usage. Cognitive computing applies advanced algorithms for intelligent decision-making. Bionic technology utilizes insights from cognitive computing to design sustainable solutions inspired by natural systems. Generative AI synthesizes the findings to propose innovative, resource-efficient designs that enhance operational sustainability and promote a circular economy. The STCM enhances business operational efficiency by reducing waste and maximizing resource use, while also strengthening strategic sustainability practices. This framework demonstrates the potential for businesses to gain a competitive advantage by adopting technology-driven solutions that are aligned with environmental stewardship. This paper introduces the novel STCM, a unique integration of advanced technologies designed to meet the dual demands of business efficiency and sustainability. By bridging the gap between digital innovation and ecological conservation, the model offers a robust foundation for future sustainable business strategies.",digital transformation | ecological stewardship through technology | sustainable business models | sustainable technology integration,0,2026,sustainability,behavior+sustainability
33,2-s2.0-105014186886,10.1016/j.rser.2025.116218,https://doi.org/10.1016/j.rser.2025.116218,https://scholar.google.com/scholar?q=10.1016/j.rser.2025.116218,re,Renewable and Sustainable Energy Reviews,"Tirulo, Aschalew;Yadav, Monika;Lolamo, Mathewos;Chauhan, Siddhartha;Siano, Pierluigi;Shafie-khah, Miadreza",Beyond automation: Unveiling the potential of agentic intelligence,"Agentic intelligence encompasses artificial intelligence systems imbued with autonomous capacity, facilitating independent decision-making beyond conventional automation frameworks. This study applies the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) protocol across three authoritative databases and others, examining peer-reviewed literature from 2020 to 2025 (March). From 1800 identified publications, 191 studies met inclusion criteria, revealing research concentrations: 35.1 % (64 studies) address computational scalability, privacy/security vulnerabilities, ethical/legal ramifications, and interpretability constraints; 24.0 % (44) each examine Industry 4.0 transformation and healthcare intervention systems; 9.8 % (18) investigate autonomous cybersecurity architectures; 16.4 % (30) each focus on personalized digital assistance and theoretical foundations; while 14.7 % (27) each explore intelligent energy distribution networks, quantum computational integration with robotics, and sustainability imperatives. The analysis juxtaposes agentic intelligence against traditional automation, elucidating distinctive characteristics within variable environments. Foundational technological enablers, large language models, reinforcement learning algorithms, multi-agent system frameworks, cognitive architectures, and edge-cloud computing integration propel advancements in capabilities. Implementations spanning energy distribution networks, cybersecurity mechanisms, manufacturing ecosystems, healthcare platforms, and digital assistance technologies demonstrate transformative potential. The investigation identifies computational limitations, ethical challenges, and trust-related impediments, providing a comparative assessment of advantages and constraints. Future research trajectories, including quantum computation, are proposed to advance theoretical and practical dimensions. This synthesis provides researchers, practitioners, and policymakers with an authoritative examination of agentic intelligence foundations and implications for advanced autonomous system development.",Agentic intelligence | Artificial intelligence | Large language models | Multi-agent systems | Reinforcement learning | Smart grid,0,2026,sustainability,behavior+sustainability
43,2-s2.0-105025920038,10.28991/ESJ-2025-09-06-030,https://doi.org/10.28991/ESJ-2025-09-06-030,https://scholar.google.com/scholar?q=10.28991/ESJ-2025-09-06-030,re,Emerging Science Journal,"Trovão, Hugo;Mamede, Henrique S.;Trigo, Paulo;Santos, Vitor","Artificial Intelligence in Recruitment: A Multivocal Review of Benefits, Challenges, and Strategies","This study investigates the role of artificial intelligence (AI) in recruitment, with a specific emphasis on small and medium enterprises (SMEs) and cultural diversity, two dimensions frequently underrepresented in existing research. The objective is to evaluate the benefits, challenges, and strategies for the responsible adoption of AI in recruitment. To achieve this, a Multivocal Literature Review (MLR) was conducted, systematically synthesising peer-reviewed studies and grey literature published from 2018 onwards. Following Kitchenham’s systematic review guidelines and Garousi’s multivocal extensions, academic and practitioner perspectives were analysed to capture both theoretical insights and real-world practices. The findings indicate that AI can streamline recruitment processes, improve decision-making accuracy, and enhance candidate experience through tools such as résumé screening, predictive analytics, and generative AI applications. However, issues of algorithmic bias, limited transparency, data quality, regulatory compliance, and workforce scepticism persist, particularly in SMEs that face resource constraints. Although much of the available evidence reflects Western contexts, this review broadens the scope by integrating global perspectives and highlighting how cultural and regional factors influence AI acceptance. The novelty of this study lies in combining academic and industry evidence to propose actionable strategies— such as bias audits, explainable AI frameworks, and human-in-the-loop approaches—for more inclusive, sustainable, and globally relevant adoption of AI in recruitment.",AI Ethics | Artificial Intelligence | Generative AI | Human Resource Management | Large Language Models | Recruitment | SMEs,0,2025,sustainability,behavior+sustainability
45,2-s2.0-105025802930,10.3390/su172411336,https://doi.org/10.3390/su172411336,https://scholar.google.com/scholar?q=10.3390/su172411336,ar,Sustainability Switzerland,"Jabeur, Nafaa",Toward Sustainable Mobility: A Hybrid Quantum–LLM Decision Framework for Next-Generation Intelligent Transportation Systems,"Intelligent Transportation Systems (ITSs) aim to improve mobility and reduce congestion, yet current solutions still struggle with scalability, sensing bottlenecks, and inefficient computational resource usage. These limitations impede the shift towards environmentally responsible mobility. This work introduces ORQCIAM (Orchestrated Reasoning based on Quantum Computing and Intelligence for Advanced Mobility), a modular framework that combines Quantum Computing (QC) and Large Language Models (LLMs) to enable real-time, energy-aware decision-making in ITSs. Unlike conventional ITS or AI-based approaches that focus primarily on traffic performance, ORQCIAM explicitly incorporates sustainability as a design objective, targeting reductions in travel time, fuel or energy consumption, and CO<inf>2</inf> emissions. The framework unifies cognitive, virtual, and federated sensing to enhance data reliability, while a hybrid decision layer dynamically orchestrates QC–LLM interactions to minimize computational overhead. Scenario-based evaluation demonstrates faster incident screening, more efficient routing, and measurable sustainability benefits. Across tested scenarios, ORQCIAM achieved 9–18% reductions in travel time, 6–14% lower estimated CO<inf>2</inf> emissions, and around a 50–75% decrease in quantum-optimization calls by concealing QC activation during non-critical events. These results confirm that dynamic QC–LLM coordination effectively decreases computational overhead while supporting greener and more adaptive mobility patterns. Overall, ORQCIAM illustrates how hybrid QC–LLM architectures can serve as catalysts for efficient, low-carbon, and resilient transportation systems aligned with sustainable smart-city goals.",emissions-aware routing | green ITS | Intelligent Transportation Systems (ITSs) | Large Language Models | Quantum Computing | sustainable transportation,0,2025,sustainability,behavior+sustainability
47,2-s2.0-105024720142,10.3390/su172310623,https://doi.org/10.3390/su172310623,https://scholar.google.com/scholar?q=10.3390/su172310623,re,Sustainability Switzerland,"Mbah, Marcellus Forh;Nugraha, Tsamarah Rana;Kushnir, Iryna",Challenges and Opportunities for Leveraging Generative AI for Sustainability Education: A Critical Review,"The integration of generative artificial intelligence (Gen-AI) into sustainability education is justified by its potential to introduce sustainability perspectives through transformative learning. By encouraging individuals to critically reflect and challenge their prior beliefs and assumptions, Gen-AI can deepen their understanding of sustainability concepts and inspire long-term commitment to sustainable practices. While the broader educational potential of Gen-AI has been widely explored, previous research tends to overlook its specific benefits and implications within the context of sustainability education. This paper addresses this gap by exploring both the opportunities and challenges of employing Gen-AI in the context of sustainability education through a critical review of diverse outputs. A thematic analysis of the outputs reveals a complex interplay between the opportunities and challenges. While Gen-AI offers access to information, personalised learning, fosters creativity, and decision-making support, the associated challenges, such as unequal access, overreliance on use, unreliable outputs, and environmental cost, may undermine the opportunities and the broader efforts to foster sustainability. The originality of this paper lies in providing critical insights for institutions, educators, and policymakers seeking to harness generative AI to advance sustainability education, an area pivotal to the pursuit of a just and sustainable future.",challenges | generative AI | opportunities | sustainability education | transformative learning,0,2025,sustainability,behavior+sustainability
48,2-s2.0-105024698480,10.3390/su172310602,https://doi.org/10.3390/su172310602,https://scholar.google.com/scholar?q=10.3390/su172310602,ar,Sustainability Switzerland,"Huang, Xinjie;Cui, Yi;Zhang, Yang;Cui, Rongrong",From Algorithm to Reality: Exploring Chinese Consumers’ Acceptance of Physicalized AI-Generated Clothing in the Context of Sustainable Fashion,"The rapid advancement of Generative Artificial Intelligence (GenAI) has enhanced fashion design creativity by introducing aesthetics beyond conventional norms. With its unique and novel aesthetics, AI-generated clothing has sparked widespread discussion on social media. However, little is known about how consumers respond when these virtual designs are transformed into wearable physical products. This study examines factors influencing Chinese consumers’ acceptance of physicalized AI-generated clothing (PAGC), which is a sustainable fashion category that improves design efficiency and enables small-scale experimental production. Grounded in the Theory of Consumption Values (TCV), eight variables across four value dimensions—functional, social, emotional, and epistemic—were identified, along with demographic characteristics. Using a non-probability voluntary sampling method, 661 valid responses from Chinese consumers were collected and analyzed through a multinomial logistic regression model. The study found that perceived algorithmic creativity, perceived novelty, and social identity are the three most influential factors on acceptance. Consumers with higher education, lower income, or fashion- and technology-related backgrounds were more likely to accept PAGC. By situating PAGC within the context of sustainable fashion innovation, this study enhances understanding of Chinese consumers’ decision-making and offers managerial insights for fashion brands striving to balance creativity and social responsibility in the GenAI era.",acceptance | Chinese consumers | generative artificial intelligence | multinomial logistic regression | physicalized AI-generated clothing | sustainable fashion innovation | theory of consumption value,0,2025,sustainability,behavior+sustainability
55,2-s2.0-105021839264,10.1038/s41598-025-23617-4,https://doi.org/10.1038/s41598-025-23617-4,https://scholar.google.com/scholar?q=10.1038/s41598-025-23617-4,ar,Scientific Reports,"Kundu, Shakti;Ninoria, Shalini Zanzote;Chaturvedi, Ravi Prakash;Mishra, Annu;Agrawal, Akshat;Batra, Reenu;Dubale, Mitiku;Hashmi, Arshad",Real-time deforestation anomaly detection using YOLO and LangChain agents for sustainable environmental monitoring,"Deforestation continues to pose a major threat to global ecosystems, biodiversity, and climate resilience, demanding intelligent and timely monitoring solutions. This study introduces a novel framework that integrates YOLOv8 (You Only Look Once) object detection with LangChain-based Agentic AI for real-time deforestation anomaly detection. The proposed system leverages YOLOv8’s rapid and accurate visual recognition of deforestation indicators—such as tree stumps, logging machinery, and unauthorized human presence—while enhancing contextual reasoning and decision-making through LangChain agents. Extensive experiments using annotated satellite and drone imagery demonstrate steady improvements in training performance, with box_loss, cls_loss, and distribution focal loss reduced by more than 50%. Despite modest mean Average Precision (mAP50 ≈ 0.07), the integration of LangChain agents enabled dynamic threshold adjustment, reinforcement-learning-based feedback, and GIS-driven reporting, thereby reducing false positives and increasing recall (up to 24%) compared to baseline YOLO models. The framework not only provides actionable, geolocated alerts but also supports adaptive learning for evolving deforestation patterns. By combining the speed of deep learning with the autonomy of agentic AI, this work highlights a scalable, interpretable, and real-time approach for environmental monitoring. The findings establish a foundation for future research in multi-modal data fusion, edge deployment on drones and satellites, and sustainable forest management.",Anomaly detection | Deforestation monitoring | Environmental sustainability | LangChain agent | Precision-Recall analysis | YOLOv8 model,0,2025,sustainability,behavior+sustainability
59,2-s2.0-105020823760,10.1016/j.spc.2025.10.015,https://doi.org/10.1016/j.spc.2025.10.015,https://scholar.google.com/scholar?q=10.1016/j.spc.2025.10.015,ar,Sustainable Production and Consumption,"Wu, Rujing;Tao, Jing;Yu, Suiran",Consensus-based elicitation and analysis of product sustainability requirements for effective strategy formulation in product design,"Integrating sustainability into product design, especially in the early stages, is a critical challenge. Manufacturers must translate broad, strategic sustainability objectives into actionable design requirements and effectively prioritize them from a life-cycle perspective to develop high-impact sustainability strategies. This study addresses this challenge by proposing a novel method framework for the elicitation, evaluation, and analysis of sustainability requirements (SRs). The framework begins with a multi-level sustainability requirement model that translates abstract strategic-level sustainability objectives into specific, actionable SRs, thereby integrating sustainability into the early design process. To further enhance decision-making, the framework incorporates Dempster-Shafer Theory (Evidence Theory) to quantify consensus among expert evaluations, resolve conflicts, and ensure decisions are both accurate and widely accepted. Next, the method integrates Decision-Making Trial and Evaluation Laboratory (DEMATEL) to identify SR interrelationships, Analytical Network Process (ANP) to prioritize them, and Total Adversarial Interpretive Structure Model (TAISM) to develop robust sustainability strategies. Rather than focusing solely on SR weight, the method emphasizes the prioritization of SR combinations that yield higher potential based on their mutual impacts. A case study on sustainable machine tools demonstrates the framework's effectiveness, with SRs comprehensively elicited, expert consensus improving from 0.7985 to 0.9260, and sustainability strategy performance improving by up to 37.6 %. An exploratory effort to integrate generative AI into sustainability requirement evaluation is also undertaken, aiming to significantly enhance decision-making efficiency. This work contributes to sustainable production and consumption by providing a systematic, stakeholder-aligned approach to generating sustainability strategies that prioritize the most impactful sustainability requirement combinations, thus driving more effective, long-term sustainable product design.",DEMATEL-ANP-TAISM | Dempster-Shafer theory | Requirement elicitation | Sustainability requirement | Sustainability strategy,0,2025,sustainability,behavior+sustainability
61,2-s2.0-105018701637,10.1186/s12302-025-01153-2,https://doi.org/10.1186/s12302-025-01153-2,https://scholar.google.com/scholar?q=10.1186/s12302-025-01153-2,ar,Environmental Sciences Europe,"Leal Filho, Walter;Kovaleva, Marina;Ng, Artie W.;Nagy, Gustavo J.;Lütz, Johannes M.;Dinis, Maria Alzira Pimenta",Artificial intelligence and climate change: the potential roles of foundation models,"Artificial intelligence (AI) is being developed fast and applied in several areas including education and healthcare with excellent potential for use in fields that require complex analytics, particularly in the case of climate change. Recent developments in AI, such as ChatGPT and OpenAI, machine vision technologies and deep learning, among others, may be deployed in various contexts, including climate change. Of specific interest is the role played by foundation models (FMs), which may help to augment intelligence on climate change and reduce the social risks of adaptation and mitigation initiatives. This article discusses the potential applications of FMs in climate change research and management and illustrates the need for further studies. FMs, built on large unlabelled data sets and enabled by transfer learning, offer versatility in handling complex tasks. Specifically, FMs can aid in climate data analysis, modelling future scenarios, assessing risks, and supporting decision-making processes. Despite their potential, challenges such as data privacy, algorithm bias, and energy consumption require careful consideration. The article emphasizes the importance of interdisciplinary efforts to address these challenges and maximize the positive impact of FMs in mitigation and adaptation. AI, including advanced models like FMs, holds significant promise for addressing climate change challenges.",Adaptation | Artificial intelligence (AI) | Climate change | Foundation models (FMs) | Mitigation,0,2025,sustainability,behavior+sustainability
66,2-s2.0-105017444476,10.1016/j.futures.2025.103695,https://doi.org/10.1016/j.futures.2025.103695,https://scholar.google.com/scholar?q=10.1016/j.futures.2025.103695,ar,Futures,"Oswald, Yannick",Artificial Utopia: Simulation and artificially intelligent agents for exploring Utopian and democratized futures,"Prevailing top-down systems in politics and economics struggle to keep pace with the pressing challenges of the 21st century, such as climate change, social inequality and conflict. Bottom-up democratization and participatory approaches in politics and economics are increasingly seen as promising alternatives to confront and overcome these issues, often with ‘utopian’ overtones, as proponents believe they may dramatically reshape political, social and ecological futures for the better and in contrast to contemporary authoritarian tendencies across various countries. Institutional specifics and the associated collective human behavior or culture remains little understood and debated, however. In this article, I propose a novel research agenda focusing on ‘utopian’ democratization efforts with formal and computational methods as well as with artificial intelligence – I call this agenda ‘Artificial Utopia’. Artificial Utopias provide safe testing grounds for new political ideas and economic policies ‘in-silico’ with reduced risk of negative consequences as compared to testing ideas in real-world contexts. An increasing number of advanced simulation and intelligence methods, that aim at representing human cognition and collective decision-making in more realistic ways, could benefit this process. This includes agent-based modeling, reinforcement learning, large language models and more. I clarify what some of these simulation approaches can contribute to the study of Artificial Utopias with the help of two institutional examples; the citizen assembly and the democratic firm. Finally, I discuss open questions and future research directions related to the broader Artificial Utopia agenda.",Artificial intelligence | Computational simulation | Democratization | Future studies | Political economy | Utopia,0,2025,sustainability,behavior+sustainability
70,2-s2.0-105013085747,10.1016/j.asoc.2025.113684,https://doi.org/10.1016/j.asoc.2025.113684,https://scholar.google.com/scholar?q=10.1016/j.asoc.2025.113684,ar,Applied Soft Computing,"Sun, Song;Zhong, Zhijie;Yu, Nanlan;Gong, Xinrong;Yang, Kaixiang",HumanMoD: A multi-RAG collaborative LLM for inclusive urban public healthcare services,"The integration of Large Language Models (LLMs) with healthcare systems offers transformative solutions for sustainable public health programs, especially in underserved urban and rural communities where access to professional medical expertise is limited. This paper introduces HumanMoD, a novel LLM framework designed to emulate collaborative clinical workflows of multi-expert medical doctors. Specifically, the proposed Mixture of Doctors module enables parallel diagnostic streams from diverse medical specialties, mimicking the collaborative decision-making of human doctors to ensure comprehensive assessments in resource-constrained environments. The Knowledge-driven Medical Assistant leverages domain-specific knowledge bases to mitigate LLM hallucinations, ensuring that recommendations are rooted in credible medical knowledge. Exquisitely, the Humanoid Health Conductor and LLM-powered Corrector further refine outputs to minimize diagnostic discrepancies, enhancing the reliability of responses for large-scale public health applications such as community health kiosks and mobile health apps serving remote or low-income areas. Unlike fine-tuned models, HumanMoD operates without parameter adjustment, enabling cost-effective deployment in regions with scarce computational resources, thus bridging the healthcare gap for socially vulnerable groups. Experimental results on MedQA and PubMedQA demonstrate that HumanMoD outperforms state-of-the-art models, highlighting its potential to drive equitable healthcare access and support data-driven public health policies in diverse urban and rural settings.",Inclusive healthcare | Knowledge-driven models | Large language models (LLMs) | Multi-RAG collaboration | Public health programs,0,2025,sustainability,behavior+sustainability
78,2-s2.0-105009441292,10.1016/j.ijme.2025.101232,https://doi.org/10.1016/j.ijme.2025.101232,https://scholar.google.com/scholar?q=10.1016/j.ijme.2025.101232,ar,International Journal of Management Education,"Ruark, Terri Iacobucci;Biazzin, Cristiane",Teaching project management with generative AI: A pedagogical model for responsible and sustainable practice,"This study presents an innovative pedagogical approach integrating generative AI into project management education across five MBA courses. The research examines a structured teaching model where students applied AI tools to self-selected “Dream Projects” aligned with their career aspirations. Data analysis of 863 student submissions revealed that AI-enhanced project-based learning transformed the educational experience by repositioning faculty as learning facilitators and enabling students to engage with complex project management challenges more effectively. The teaching approach was organized around five structured modules that systematically incorporated AI applications throughout the project lifecycle, from initiation and planning to execution and closure. Students demonstrated improved decision-making capabilities, particularly in scheduling, risk assessment, and stakeholder communication, with 93 % actively applying AI tools across multiple project phases. The pedagogical model contributes to sustainable development goals by enhancing quality education (SDG 4), preparing students for evolving workplace demands (SDG 8), and developing the technical fluency needed for industrial innovation (SDG 9). This approach demonstrates how higher education can simultaneously cultivate technological competence and ethical judgment while preparing students for an AI-transformed professional landscape.",Experiential learning | Generative AI | Project management education | Sustainable development goals,0,2025,sustainability,behavior+sustainability
85,2-s2.0-105021863791,10.1136/bmjopen-2025-099226,https://doi.org/10.1136/bmjopen-2025-099226,https://scholar.google.com/scholar?q=10.1136/bmjopen-2025-099226,ar,BMJ Open,"Tan, Minghui;Tang, Siyuan;Kan, Shichao;Zhang, Haojie;Wu, Bei;Ni, Zhao;Lin, Chia Chin;Ding, Jinfeng",Enhancing healthcare providers’ advance care planning competence with large language models: protocol for the development of an AI chatbot and its evaluation in a randomised controlled trial,"Introduction Advance care planning (ACP) can support individuals to express their autonomy in the decision-making process for future care. Traditional ACP training for healthcare providers faces significant challenges related to interactivity, accessibility, scalability and sustainability. Cutting-edge generative artificial intelligence (AI) holds promise in enabling intelligent and interactive chatbots for ACP. The present protocol outlines the development and evaluation of a large language model (LLM)-based ACP chatbot for healthcare providers. Methods and analysis The development of the LLM-based ACP chatbot will follow four stages: construction of dialogue data sets, fine-tuning, multi-LLM orchestration and ablation studies. A randomised controlled trial will then evaluate the LLM-based ACP chatbot’s effectiveness in enhancing ACP competence among healthcare providers. A total of 66 healthcare providers will be recruited from China and randomly assigned (1:1) to either: (1) The LLM-based ACP chatbot intervention or (2) An ACP knowledge manual. The primary outcome will be ACP competence, while secondary outcomes will include (1) ACP knowledge, (2) Attitudes/beliefs, (3) Practice willingness, (4) Readiness, (5) Self-efficacy, (6) Processes of change, and (7) Decisional balance. Both primary and secondary outcomes will be assessed to evaluate the immediate impact (postintervention) and short-term impact (3-month followup and 6-month follow-up) of the chatbot on ACP. Ethics and dissemination The research was approved by the Ethical Review Board, Xiangya School of Nursing, Central South University (E202442). Study modifications will be discussed among the research team members until a consensus is reached. Amendments reflecting study modifications will be submitted for institutional review board approval at all sites, updated on the clinical trial registry, and fully detailed and explained in the manuscript reporting the results of the study. All participants will provide written informed consent. The study will be conducted according to the principles outlined in the Declaration of Helsinki. The results of this study will be submitted for publication in peer-reviewed journals and presented at (inter)national conferences.",Clinical Protocols | Digital Technology | MEDICAL EDUCATION & TRAINING | PALLIATIVE CARE,0,2025,sustainability,behavior+sustainability
87,2-s2.0-105020886548,10.15837/ijccc.2025.6.7240,https://doi.org/10.15837/ijccc.2025.6.7240,https://scholar.google.com/scholar?q=10.15837/ijccc.2025.6.7240,ar,International Journal of Computers Communications and Control,"Yadav, Abhishek;Krishankumar, Raghunathan;Ravichandran, Kattur Soundarapandian;Zemlickienė, Vaida;Turskis, Zenonas",Prioritising Strategies to Improve Girls’ Access to Quality Education: A Hybrid Hyperbolic Fuzzy MCDM Framework with Human and AI Expertise,"Access to quality education for girls is one of the key targets of the United Nations’ Sustainable Development Goals. This study has two major goals. First, this study proposes a hybrid decision framework that integrates hyperbolic fuzzy sets, multi-attitudinal variance, soft cluster rectangle, and integrated simple weighted sum product methods to prioritise strategies that improve access to quality education for girls. Second, this study explores the use of generative AI expertise in a multi-criteria decision-making framework that traditionally uses only human experts. The findings reveal ""Effectiveness"" to be the most important criterion when assessing the strategies and ""Health and Hygiene Interventions"" to be the most prioritised strategy. The findings also show a divergence of opinions between the AI experts and human experts in the extremes and alignment of opinions in the non-extremes. The study serves as a foundation for future research on integrating generative AI into decision-making frameworks while also providing policymakers with a structured approach to prioritising strategies for improving girls’ education.",Generative AI | Girls’ Education | Hybrid Decision Framework | Hyperbolic Fuzzy Sets | Soft Cluster Rectangle,0,2025,sustainability,behavior+sustainability
88,2-s2.0-105024011061,10.1002/csc2.70198,https://doi.org/10.1002/csc2.70198,https://scholar.google.com/scholar?q=10.1002/csc2.70198,ar,Crop Science,"Brown, David;Tufan, Hale A.",AI-based data synthesis of crop trait prioritization studies,"Synthesis of data from crop trait prioritization studies (CTPS) can provide insights to support decision-making, such as institutional funding allocation, and trait prioritization in crop improvement programs. This type of data synthesis is constrained by the lack of standardized crop trait terminology and suitable methods to deal with data heterogeneity. Crop trait ontologies provide terminology standardization, but annotating documents to link terms to ontology terms is time-consuming and may therefore miss trait terminology emerging from CTPS due to a data annotation bottleneck that constrains data synthesis. Natural language processing (NLP) techniques based on large language models (LLMs) can help in extracting information from unstructured text with no manual text annotation involved. This study applied NLP to synthesize unstructured text data extracted from CTPS by a recently published scoping review. Results show that (1) the trait vocabulary diversity used in CTPS varies per crop and by gender intentionality of CTPS, (2) crop trait preferences increasingly focus on food quality and climate adaptation traits, and (3) existing crop ontologies provide a good coverage of terms found in CTPS but might require the addition of terms, especially in crops such as cassava and sweet potato. This study demonstrates the utility of applying NLP and LLM to synthesize trait preference data across crops and timescales, potentially modeling an approach for broader utility to breeding programs and crop ontology curators alike.",,0,2025,sustainability,behavior+sustainability
91,2-s2.0-105022872064,10.3390/buildings15224081,https://doi.org/10.3390/buildings15224081,https://scholar.google.com/scholar?q=10.3390/buildings15224081,ar,Buildings,"Shu, Lei;Yeganeh, Armin;Zhao, Dong",Large Language Models for Building Energy Retrofit Decision-Making: Technical and Sociotechnical Evaluations,"Conventional approaches to building energy retrofit decision-making struggle to generalize across diverse building characteristics, climate conditions, and occupant behaviors, and often lack interpretability. Generative AI, particularly Large Language Models (LLMs), offers a promising solution because they learn from extensive, heterogeneous data and can articulate inferences in transparent natural language. However, their capabilities in retrofit decision-making remain underexplored. This study evaluates six widely used LLMs on two objectives: determining the retrofit measure that maximizes CO<inf>2</inf> reduction (a technical task) and minimizes the payback period (a sociotechnical task). We assessed performance across accuracy, consistency, sensitivity, and reasoning. The evaluation used 400 residential buildings from a nationwide, simulation-based database. The results reveal that LLMs vary across cases, with consistently strong technical-task performance but notably weaker performance on the sociotechnical one, highlighting limitations in handling complex economic and contextual trade-offs. The models consistently identify a near-optimal solution for the technical task (Top-5 accuracy reaching 92.8%), although their ability to pinpoint the single best option is limited (Top-1 accuracy reaching 54.5%). While models approximate engineering logic by prioritizing location and geometry, their reasoning processes are oversimplified. These findings suggest LLMs are promising for technical advisory tools but not yet reliable for standalone retrofit decision-making.",artificial intelligence | ChatGPT | DeepSeek | energy efficiency | generative AI | LLM | smart and connected communities | smart buildings | smart construction,0,2025,sustainability,behavior+sustainability
93,2-s2.0-105021584857,10.3390/math13213382,https://doi.org/10.3390/math13213382,https://scholar.google.com/scholar?q=10.3390/math13213382,re,Mathematics,"Luo, Xiaoyi;Wang, Aiwen;Zhang, Xinling;Huang, Kunda;Wang, Songyu;Chen, Lixin;Cui, Yejia",Toward Intelligent AIoT: A Comprehensive Survey on Digital Twin and Multimodal Generative AI Integration,"The Artificial Intelligence of Things (AIoT) is rapidly evolving from basic connectivity to intelligent perception, reasoning, and decision making across domains such as healthcare, manufacturing, transportation, and smart cities. Multimodal generative AI (GAI) and digital twins (DTs) provide complementary solutions. DTs deliver high-fidelity virtual replicas for real-time monitoring, simulation, and optimization with GAI enhancing cognition, cross-modal understanding, and the generation of synthetic data. This survey presents a comprehensive overview of DT–GAI integration in the AIoT. We review the foundations of DTs and multimodal GAI and highlight their complementary roles. We further introduce the Sense–Map–Generate–Act (SMGA) framework, illustrating their interaction through the SMGA loop. We discuss key enabling technologies, including multimodal data fusion, dynamic DT evolution, and cloud–edge–end collaboration. Representative application scenarios, including smart manufacturing, smart cities, autonomous driving, and healthcare, are examined to demonstrate their practical impact. Finally, we outline open challenges, including efficiency, reliability, privacy, and standardization, and we provide directions for future research toward sustainable, trustworthy, and intelligent AIoT systems.",Artificial Intelligence of Things (AIoT) | cloud–edge–end collaboration | digital twin | multimodal fusion | multimodal generative AI (GAI),0,2025,sustainability,behavior+sustainability
97,2-s2.0-105021459036,10.3390/s25216560,https://doi.org/10.3390/s25216560,https://scholar.google.com/scholar?q=10.3390/s25216560,ar,Sensors,"Nahid, Nazmun;Ahad, Md Atiqur Rahman;Inoue, Sozo",Context-Aware Alerting in Elderly Care Facilities: A Hybrid Framework Integrating LLM Reasoning with Rule-Based Logic,"The rising demand for elderly care amid ongoing nursing shortages has highlighted the limitations of conventional alert systems, which frequently generate excessive alerts and contribute to alarm fatigue. The objective of this study is to develop a hybrid, context-aware nurse alerting framework for long-term care (LTC) facilities that minimizes redundant alarms, reduces alarm fatigue, and enhances patient safety and caregiving balance during multi-person care scenarios such as mealtimes. To do so, we aimed to intelligently suppress, delay, and validate alerts by integrating rule-based logic with Large Language Model (LLM)-driven semantic reasoning. We conducted an experimental study in a real-world LTC environment involving 28 elderly residents (6 high, 8 medium, and 14 low care levels) and four nurses across three rooms over seven days. The proposed system utilizes video-derived skeletal motion, care-level annotations, and dynamic nurse–elderly proximity for decision making. Statistical analyses were performed using F1 score, accuracy, false positive rate (FPR), and false negative rate (FNR) to evaluate performance improvements. Compared to the baseline where all nurses were notified (100% alarm load), the proposed method reduced average alarm load to 27.5%, achieving a 72.5% reduction, with suppression rates reaching 100% in some rooms for some nurses. Performance metrics further validate the system’s effectiveness: the macro F1 score improved from 0.18 (baseline) to 0.97, while accuracy rose from 0.21 (baseline) to 0.98. Compared to the baseline error rates (FPR 0.20, FNR 0.79), the proposed method achieved drastically lower values (FPR 0.005, FNR 0.023). Across both spatial (room-level) and temporal (day-level) validations, the proposed approach consistently outperformed baseline and purely rule-based methods. These findings demonstrate that the proposed approach effectively minimizes false alarms while maintaining strong operational efficiency. By integrating rule-based mechanisms with LLM-based contextual reasoning, the framework significantly enhances alert accuracy, mitigates alarm fatigue, and promotes safer, more sustainable, and human-centered care practices, making it suitable for practical deployment within real-world long-term care environments.",alarm fatigue | context-aware systems | fall detection | large language model | long-term care | nurse alerting | nurse care,0,2025,sustainability,behavior+sustainability
98,2-s2.0-105021113843,10.1016/j.trip.2025.101711,https://doi.org/10.1016/j.trip.2025.101711,https://scholar.google.com/scholar?q=10.1016/j.trip.2025.101711,re,Transportation Research Interdisciplinary Perspectives,"Kuruvachalil, Lujain;Karim, Faisal;Masoud, Abdul Rahman;Hasan, Umair;Ali, Luqman;Sulaiman, Faisal Bin;Alosaimi, Faisal;AlJassmi, Hamad",Advancing pavement Management: A comprehensive review of smart models for better decisions,"Pavement management systems have evolved significantly, transitioning from traditional empirical methods to advanced mechanistic-empirical, probabilistic, and machine learning-based models. These advancements enable better integration of environmental, traffic, and material factors, enhancing predictive accuracy for maintenance and rehabilitation (M&R) strategies. This paper presents a comprehensive bibliometric analysis of the field, followed by an extensive review examining three key areas: the evolution of pavement deterioration models, the integration of Life Cycle Assessment (LCA) into decision-making processes, and the application of multi-objective optimization and decision support systems in pavement management. Recent studies in the literature demonstrate that integrated approaches yield substantial benefits, with recent studies documenting up to 30% reductions in maintenance costs and 17% decreases in carbon emissions. However, the review also identifies persistent challenges related to data quality, computational complexity, and organizational capacity constraints. The transformative potential of emerging technologies, particularly Large Language Models (LLM), for enhancing data interpretation, predictive modelling capabilities, and stakeholder communication was explored in this paper. By synthesizing current research, this review maps key trends, research gaps, and future directions for sustainable and resilient pavement management which can provide valuable insights for researchers, practitioners, and policymakers working to develop intelligent, data-driven infrastructure management systems that balance economic, environmental, and performance objectives.",Decision Support Systems | Life Cycle Assessment | Machine Learning | Multi-Objective Optimization | Pavement Deterioration Models | Pavement Management Systems | Sustainable Infrastructure,0,2025,sustainability,behavior+sustainability
101,2-s2.0-105019616626,10.1007/s00170-025-16667-5,https://doi.org/10.1007/s00170-025-16667-5,https://scholar.google.com/scholar?q=10.1007/s00170-025-16667-5,re,International Journal of Advanced Manufacturing Technology,"Shahin, Mohammad;Hosseinzadeh, Ali;Chen, F. Frank","Generative artificial intelligence in manufacturing: applications, case studies, and future directions for next-generation intelligent production systems","The integration of generative artificial intelligence (AI) into manufacturing processes is emerging as a transformative strategy to enhance automation, optimize workflows, and foster innovation in intelligent production systems. Unlike traditional rule-based automation, generative AI leverages advanced machine learning (ML) and deep learning (DL) models to enable autonomous decision-making, adaptive process refinement, and real-time data generation. This paradigm shift facilitates a range of advanced applications, including AI-driven product design optimization, proactive maintenance, intelligent quality control, and dynamic supply chain management. This study explores the potential of generative AI to redefine modern manufacturing by providing scalable, data-driven solutions that minimize downtime, reduce waste, and support sustainable production goals. In particular, we highlight the role of generative models in creating synthetic datasets for model training, enabling real-time defect detection, and supporting hyper-personalized production. The self-learning and pattern recognition capabilities of generative AI empower manufacturing systems to dynamically adapt to evolving operational requirements. To evaluate practical implications, three case studies are presented that demonstrate the implementation and impact of generative AI in diverse manufacturing scenarios. These cases underscore both the opportunities and challenges associated with deployment, including high computational demands, data security concerns, and integration with legacy systems. Ethical considerations such as bias mitigation and model transparency are also discussed as critical components of responsible AI adoption. Overall, this paper provides a comprehensive analysis of generative AI applications in manufacturing, offering insights into how these technologies can support the next generation of intelligent, adaptive, and sustainable production systems.",Deep learning | Generative artificial intelligence | Informatics integration | Intelligent automation | Machine learning | Synthetic data,0,2025,sustainability,behavior+sustainability
103,2-s2.0-105018224613,10.1016/j.jik.2025.100819,https://doi.org/10.1016/j.jik.2025.100819,https://scholar.google.com/scholar?q=10.1016/j.jik.2025.100819,ar,Journal of Innovation and Knowledge,"Gavrila Gavrila, Sorin;de Lucas López, Ana Paloma;Verdugo Molano, Carolina",AI automation at an unprecedented scale: mapping its adoption and specialisation,"This paper investigates how Artificial Intelligence (AI) goes beyond traditional technological roles to drive transformation across industries, organisations, and society. By analysing 2188 academic papers from the arXiv platform (from 2018 until 2025), the study highlights the unexpectedly widespread adoption of AI and its increasing specialisation in tasks and organisational functions. The findings reveal AI's potential to foster innovation, enhance productivity, and address complex challenges. While the focus on academic sources and the exclusion of regional contexts present certain limitations, this research provides critical insights into AI's evolving role and its implications for businesses, employees, and the conduct of government. Purpose/aims of the paper: This study explores how AI has evolved from technical applications to become a key driver of innovation and knowledge creation. It investigates AI's penetration across industries, organisational areas, and tasks, focusing on its ability to solve complex challenges, reshape business workflows, and enable strategic decision-making in diverse contexts. Research methodology: The research employed secondary data analysis of 2188 full-text academic papers sourced from the arXiv platform. Structured keyword extraction, conducted using Large Language Models, identified patterns and relationships between industries, organisational areas, and tasks. Additionally, trends in AI adoption, specialisation, and integration were examined to uncover its transformative impact on organisations and knowledge systems. Findings/conclusions: The findings reveal AI's significant penetration into industries and its increasing specialisation in organisational areas and tasks. Beyond automation, AI fosters task-specific solutions and innovation, addressing organisational challenges and improving productivity. These findings underscore AI's transformative potential to redefine business practices, enhance collaboration, and drive societal progress by pushing the boundaries of innovation and knowledge creation. Discussion: AI's influence has expanded far beyond technical functions, establishing itself as a strategic tool for innovation, cross-disciplinary problem-solving, and knowledge generation. Its integration into diverse sectors reflects its capacity to foster collaboration and address societal and organisational challenges. Adapting to AI's rapid evolution is crucial for businesses, employees, and governments navigating this dynamic landscape. Research limitations: This study relied on 2188 academic papers from the arXiv platform, centring its findings on academic contexts. Moreover, regional and cultural differences in AI adoption were not addressed. Future research should incorporate broader datasets and interdisciplinary approaches to provide a more comprehensive understanding of AI's global impact and socio-economic implications. Practical implications/applications to practice: Organisations can leverage AI to drive productivity, optimise processes, and create innovative solutions across industries. Strategic AI adoption requires investment in workforce reskilling and the ethical implementation of AI systems. Decision-makers must prioritise long-term planning to achieve AI's full potential while ensuring it supports both organisational competitiveness and sustainable development. Social implications/impact on society and/or policy: AI's rapid expansion highlights its potential to address societal challenges, from reducing inequities to fostering global development. However, pressing issues such as ethical use, algorithmic fairness, and data privacy demand urgent attention. Governments must establish equitable frameworks to ensure that AI supports inclusive progress and mitigates potential negative consequences, fostering sustainable societal progress. Originality/what is new about your research?: This study uniquely combines large-scale empirical evidence with theoretical perspectives to analyse AI adoption trends. It highlights AI's penetration into industries, organisational areas, and tasks, emphasising its progression beyond traditional applications to drive task-specific specialisation, reshape innovation processes, and expand the boundaries of knowledge creation.",AI adoption trends | Industry impact | Task specialisation | Workforce transformation,0,2025,sustainability,behavior+sustainability
104,2-s2.0-105017305116,10.1016/j.gsf.2025.102163,https://doi.org/10.1016/j.gsf.2025.102163,https://scholar.google.com/scholar?q=10.1016/j.gsf.2025.102163,ar,Geoscience Frontiers,"Kamran, Muhammad;Faizan, Muhammad;Wang, Shuhong;Armaghani, Danial Jahed;Asteris, Panagiotis G.;Pradhan, Biswajeet","Generative AI with prompt engineering in construction: Enhancing predictive slope stability modelling for safe, sustainable, climate-smart mining practices","Generative AI (GenAI) and prompt engineering are rapidly advancing in industries such as construction and mining, leading to significant improvements in efficiency, accuracy, and decision-making processes. These technologies are transforming the construction sector by automating tasks and optimizing workflows, thereby enhancing productivity and risk management. This study explores the application of Google's Gemini AI tool, a notable breakthrough in GenAI, specifically for predictive modeling of slope stability. The Gemini AI tool is utilized within the Python programming language to generate prompts that incorporate key factors influencing slope stability, with the Google Colab interface facilitating prompt generation and testing. Initially, these prompts are employed for data analysis and visualization, followed by their application in both unsupervised and supervised machine learning approaches. The performance evaluation metrics indicate that the integrated approaches, which combine GenAI and prompt engineering, predict slope stability with a high level of accuracy. The model achieved 99% accuracy, with precision, recall, and F<inf>1</inf>-scores ranging from 0.98 to 1.00 for both stable and unstable slope classes. This innovative methodology seeks to advance the implementation of GenAI in civil and mining engineering, offering more precise and efficient solutions for managing slope stability and supporting safe, sustainable, and climate-smart mining operations.",Construction | Gemini | GenAI | Mining | Prompt engineering | Safety,0,2025,sustainability,behavior+sustainability
113,2-s2.0-105021984776,10.3837/tiis.2025.10.009,https://doi.org/10.3837/tiis.2025.10.009,https://scholar.google.com/scholar?q=10.3837/tiis.2025.10.009,ar,Ksii Transactions on Internet and Information Systems,"Ahmed, Maqbol;Okba, Kazar;Harous, Saad;Sufyan, Mubarak","Synergizing Generative AI and the Internet of Things: Fundamentals, Challenges, and Opportunities","The convergence of Generative Artificial Intelligence (GenAI) and the Internet of Things (IoT) represents a transformative advancement in intelligent system design, offering powerful capabilities in data synthesis, real-time decision-making, predictive analytics, and autonomous operations. This paper presents a comprehensive exploration of the synergistic relationship between GenAI and IoT, examining how their integration can address pressing challenges such as data deluge, latency, resource constraints, scalability, interoperability, and security vulnerabilities in distributed environments. Key enablers including federated learning, on-device inference, knowledge distillation, and model compression are evaluated for their potential to optimize performance in constrained and dynamic IoT ecosystems. The study also investigates critical ethical concerns surrounding privacy, fairness, transparency, environmental sustainability, and accountability, emphasizing the importance of explainable and responsible AI practices. By analyzing current limitations, technical solutions, and emerging opportunities across domains like healthcare, smart cities, cybersecurity, and industrial automation, this work contributes a structured roadmap for future research and deployment. Ultimately, the integration of GenAI with IoT is poised to foster the next generation of adaptive, secure, and human-centered intelligent systems.",Applications | Artificial Intelligence | Generative AI | Internet of Things (IoT) | Synergizing,0,2025,sustainability,behavior+sustainability
114,2-s2.0-105025946860,10.37933/nipes/7.4.2025.SI179,https://doi.org/10.37933/nipes/7.4.2025.SI179,https://scholar.google.com/scholar?q=10.37933/nipes/7.4.2025.SI179,ar,Nipes Journal of Science and Technology Research,"Ongbali, Samson O.;Ajanaku, Oluwashola;Salawu, Enesi Y.;Inegbenebor, Anthony O.",Exploring the Impact of Generative AI on Enhancing Efficiency in Project Planning and Control,"Project planning and control have been entirely transformed by the rapid development of Generative Artificial Intelligence (GAI), which offers creative ways to maximise resource allocation, strengthen risk management, and improve decision-making. This review explores the integration of GAI in project management, highlighting its capabilities in automating scheduling, predicting project risks, and augmenting traditional methodologies. The literature assessment underscores the advantages of AI-driven project management frameworks, including increased efficiency, real-time adaptability, and improved forecasting accuracy. The review demonstrates the transformative impact of AI in real-world settings, while future directions emphasise the role of quantum computing, blockchain, and Industry 5.0 in shaping AI-enhanced project management. Ultimately, this review evaluates the role of GenAI in modern project planning and control, offering valuable insights for industry professionals, researchers, and policymakers. The review affirmed that GenAI increases efficiency, reduces project delivery lead time, minimises risks, and enhances decision-making. The findings highlight the necessity of strategic GenAI adoption to unlock new efficiencies, drive innovation, and ensure sustainable project execution.",and optimization | Generative AI | planning and control | Project management,0,2025,sustainability,behavior+sustainability
115,2-s2.0-105023658813,10.17520/biods.2025179,https://doi.org/10.17520/biods.2025179,https://scholar.google.com/scholar?q=10.17520/biods.2025179,re,Biodiversity Science,"Zhou, Xuanhong;Yang, Jun",Applications and challenges of AI and LLMs in biodiversity conservation research and practices,"Background & Aims: Biodiversity conservation is essential for ecological security and sustainable human development. Nevertheless, the intricate interactions within ecosystems and the impact of external influences like human actions and climate change create substantial hurdles for conservation efforts. The advent of artificial intelligence (AI) and large language models (LLMs) offers new opportunities in this field. This study aims to review how these technologies are being used. Methods: We discussed recent progress in using AI and LLMs for biodiversity conservation research and practice. Our focus was on AI and LLMs in knowledge synthesis and discovery, ecosystem modeling, assessment and monitoring, decision-making, and fieldwork. Results & Conclusion: There is great potential for AI and LLMs in biodiversity conservation research and practices. Despite the promise, challenges such as data quality, model response times, ecosystem heterogeneity, ethical considerations, and data security remain. Future research should focus on developing specialized AI models and building high-quality, multimodal biodiversity datasets to effectively address these challenges.",artificial intelligence | biodiversity conservation | conservation decision-making | knowledge discovery | large language models,0,2025,sustainability,behavior+sustainability
121,2-s2.0-105019799637,10.21926/aeer.2503028,https://doi.org/10.21926/aeer.2503028,https://scholar.google.com/scholar?q=10.21926/aeer.2503028,re,Advances in Environmental and Engineering Research,"Raeissi, Masoume M.;Knapen, Rob",Applications of Generative Large Language Models in Environmental Science: A Systematic Review,"Environmental science addresses critical global challenges, including climate change, biodiversity loss, and sustainability. These complex topics generate a vast amount of both structured and unstructured data, from remote sensing output to policy documents, guidelines, and scientific literature. Effectively processing and utilizing this information is essential for advancing research and supporting decision-making. Large Language Models (LLMs) have shown remarkable capabilities in natural language understanding and generation across various domains. They offer a promising solution for extracting insights and synthesising knowledge and present potential benefits for environmental science research and engineering. This study presents a systematic review of 51 peer-reviewed articles on the use of LLMs within environmental science. We analyze their applications, usage types, and the challenges or limitations identified by researchers. Key trends show that knowledge extraction is the most common application, with climate science being the dominant domain. Our findings map the current landscape, highlight research gaps, and outline open problems that need to be addressed in future work. This review serves as a resource for researchers applying LLMs in environmental contexts, supporting more effective and informed decision making.",environmental science | generative artificial intelligence | Large language models,0,2025,sustainability,behavior+sustainability
135,2-s2.0-105025660644,10.12133/j.smartag.SA202503026,https://doi.org/10.12133/j.smartag.SA202503026,https://scholar.google.com/scholar?q=10.12133/j.smartag.SA202503026,ar,Smart Agriculture,"Zhao, Yingping;Liang, Jinming;Chen, Beizhang;Deng, Xiaoling;Zhang, Yi;Xiong, Zheng;Pan, Ming;Meng, Xiangbao",Applications Research Progress and Prospects of Multi-Agent Large Language Models in Agricultural,"[Significance] With the rapid advancement of large language models (LLM) and multi-agent systems, their integration, multi-agent large language models, is emerging as a transformative force in modern agriculture. Agricultural production involves complex, sequential, and highly environment-dependent processes, including tillage, planting, management, and harvesting. Traditional intelligent systems often struggle with the diversity, uncertainty, and coordination of these stages' demand. Multi-agent LLMs offer a new paradigm for agricultural intelligence by combining deep semantic understanding with distributed collaboration and adaptive coordina-tion. Through role specialization, real-time perception, and cooperative decision-making, they can decompose complex workflows, adapt to changing conditions, and enable robust, full-process automation, making them well-suited to the challenges of modern agri-culture. More importantly, their application marks a critical step toward the digital transformation, precision management, and sustainable development of agriculture. By enabling intelligent decision-making across the entire agricultural lifecycle, they provide both theoretical foundations and practical tools for building next-generation smart and unmanned farming systems. [Progress] The core concepts of multi-agent LLMs are first elucidated, covering the composition and characteristics of multi-agent systems as well as the development and training pipelines of LLMs. Then, the overall architecture of multi-agent systems is presented, encompassing both the environments in which agents operate and their internal structures. The collaborative patterns of multi-agent LLMs are then examined in terms of coordination structures and temporal organization. Following this, interaction mechanisms are discussed from multiple di-mensions, including interactions between agents and the external environment, inter-agent communication, communication protocol frameworks, and communication security. To demonstrate the varying task specializations of different multi-agent frameworks, a comparative benchmark survey table is provided by synthesizing benchmark tasks and results reported in existing studies. The results show that different multi-agent large language model architectures tend to perform better on specific types of tasks, reflecting the influence of agent framework design characteristics such as role assignment strategies, communication protocols, and decision-making mechanisms. Furthermore, several representative architectures of multi-agent LLMs, as proposed in existing studies, are briefly re-viewed. Based on their design features, their potential applicability to agricultural scenarios is discussed. Finally, current research progress and practical applications of LLMs, multimodal large models, and multi-agent LLMs in the agricultural domain are surveyed. The application architecture of agricultural LLMs is summarized, using rice cultivation as a representative scenario to illustrate the collaborative process of a multi-agent system powered by LLMs. This process involves data acquisition agents, data processing agents, task allocation and coordination agents, task execution agents, and feedback and optimization agents. The roles and functions of each kind of agent in enabling automated and intelligent operations throughout the entire agricultural lifecycle, including tillage, planting, management, and harvesting, are comprehensively described. In addition, drawing on existing research on multimodal data processing, the pseudocode is provided to illustrate the basic logic of the data processing agents. [Conclusions and Prospects] Multi-agent LLMs technology holds vast promise in agriculture but still confronts several challenges. First, limited model interpretability, stemming from opaque internal reasoning and high-dimensional parameter mappings, hinders decision transparency, traceability, user trust, and debugging efficiency. Second, model hallucination is significant, probabilistic generation may deviate from facts, leading to erroneous environmental perception and decisions that cause resource waste or crop damage. Third, multi-modal agricultural data acquisition and processing remain complex due to non-uniform equipment standards, heterogeneous data, and insufficient cross-modal reasoning, complicating data fusion and decision-making. Future directions include: (1) enhancing interpretability via chain-of-thought techniques to improve reasoning transparency and traceability; (2) reducing hallucinations by integrating knowledge bases, re-trieval-augmented generation, and verification mechanisms to bolster decision reliability; and (3) standardizing data formats to strengthen cross-modal fusion and reasoning. These measures will improve system stability and efficiency, providing solid support for the advancement of smart agriculture.",agricultural applications | deep learning | intelligent decision-making | large language models | multi-agent | smart agriculture,0,2025,sustainability,behavior+sustainability
136,2-s2.0-105023077516,10.18280/mmep.120906,https://doi.org/10.18280/mmep.120906,https://scholar.google.com/scholar?q=10.18280/mmep.120906,ar,Mathematical Modelling of Engineering Problems,"Sofiyah, Fivi Rahmatus;Dilham, Ami;Lubis, Muhammad Arif;Lubis, Andrew Satria;Marpaung, Jonathan Liviera;Hayatunnufus, ",From Satisfaction to Strategy: A Structural Model for Implementing Generative AI Chatbots in Campus Bureaucracy Toward Sustainable Service Innovation,"The growing demand for digital transformation in higher education has highlighted the limitations of conventional bureaucratic systems. This study aims to develop and evaluate a structural model for implementing generative AI chatbots in campus administration, focusing on their ability to deliver sustainable service innovation. Integrating behavioral modeling and computational logic, the research adopts a mixed-methods approach. A questionnaire was distributed to 300 respondents, and data were analyzed using Partial Least Squares Structural Equation Modeling (SmartPLS). This study integrates 11 latent constructs — including AI capability, system usability, information quality, service availability, privacy and security, institutional support, user satisfaction, service experience, customer relationship management (CRM), administrative efficiency, and digital literacy (as a moderator)—into a validated structural model. The findings reveal that all primary structural paths are statistically significant (p < 0.001). Notably, customer relationship management (CRM) demonstrates a very strong effect on Administrative Efficiency (β = 0.833, p < 0.001; R<sup>2=</sup> 0.694), confirming its central role in translating satisfaction and service experience into organizational outcomes. In addition, the study introduces an operational AI algorithm and a multi-criteria optimization model that simulate trade-offs between CRM and efficiency. These computational insights provide university leaders with practical decision-making tools for aligning chatbot deployment with strategic goals such as cost savings, service scalability, and student retention.",campus bureaucracy | chatbot | customer relationship management (CRM) | generative AI | SmartPLS | sustainable innovation,0,2025,sustainability,behavior+sustainability
137,2-s2.0-105015301327,10.1016/j.scs.2025.106793,https://doi.org/10.1016/j.scs.2025.106793,https://scholar.google.com/scholar?q=10.1016/j.scs.2025.106793,ar,Sustainable Cities and Society,"Arslan, Muhammad;Munawar, Saba;Riaz, Zainab",Empowering SMEs with SustainWater Bot to advance urban water sustainability,"Climate change, population growth, and resource constraints are intensifying pressure on urban water systems (UWSs), prompting a shift toward integrated information management. Due to their agility and reach, small- and medium-sized enterprises (SMEs) are central to this transition. However, many SMEs lack access to robust information systems (ISs) that consolidate government initiatives, industry trends, and broader water-related data, impeding sustainable adoption. This study introduces SustainWater Bot, a chatbot driven by generative artificial Intelligence (GenAI), including large language models (LLMs) and retrieval-augmented generation (RAG). Designed to fill this information gap, SustainWater Bot addresses the shortcomings of conventional LLMs, such as information misalignment, over-complexity, and information deficiencies. RAG enables semantic consolidation of various sources, such as news, government reports, industry insights, academic research, and social media, into an integrated IS. The evaluation results showed that RAG with LLM-based methods outperformed traditional information retrieval (IR) techniques, with Llama3.2:3b achieving top scores in precision (95 %), completeness (95 %), and exact match (90 %). Traditional IR techniques such as term frequency-inverse document frequency (TF-IDF) and best matching 25 (BM25) performed lower but offered quicker responses. SustainWater Bot supports informed decision-making through a question-answering (QA) framework that delivers relevant insights on sustainable urban water initiatives (SUWIs). It is built on open-source technologies and offers SMEs a cost-effective, scalable, and sustainable solution to enhance eco-friendly water practices and operational efficiency.",Large language models (LLMs) | Retrieval-augmented generation (RAG) | Small and medium-sized enterprises (SMEs) | Sustainable transitions | Urban water decision-making,0,2025,sustainability,behavior+sustainability
138,2-s2.0-105018064536,10.3390/fi17090407,https://doi.org/10.3390/fi17090407,https://scholar.google.com/scholar?q=10.3390/fi17090407,ar,Future Internet,"Triantafyllopoulos, Loukas;Kalles, Dimitris",From Divergence to Alignment: Evaluating the Role of Large Language Models in Facilitating Agreement Through Adaptive Strategies,"Achieving consensus in group decision-making often involves overcoming significant challenges, particularly reconciling diverse perspectives and mitigating biases hindering agreement. Traditional methods relying on human facilitators are usually constrained by scalability and efficiency, especially in large-scale, fast-paced discussions. To address these challenges, this study proposes a novel real-time facilitation framework, employing large language models (LLMs) as automated facilitators within a custom-built multi-user chat system. This framework is distinguished by its real-time adaptive system architecture, which enables dynamic adjustments to facilitation strategies based on ongoing discussion dynamics. Leveraging cosine similarity as a core metric, this approach evaluates the ability of three state-of-the-art LLMs—ChatGPT 4.0, Mistral Large 2, and AI21 Jamba-Instruct—to synthesize consensus proposals that align with participants’ viewpoints. Unlike conventional techniques, the system integrates adaptive facilitation strategies, including clarifying misunderstandings, summarizing discussions, and proposing compromises, enabling the LLMs to refine consensus proposals based on user feedback iteratively. Experimental results indicate that ChatGPT 4.0 achieved the highest alignment with participant opinions and required fewer iterations to reach consensus. A one-way ANOVA confirmed that differences in performance between models were statistically significant. Moreover, descriptive analyses revealed nuanced differences in model behavior across various sustainability-focused discussion topics, including climate action, quality education, good health and well-being, and access to clean water and sanitation. These findings highlight the promise of LLM-driven facilitation for improving collective decision-making processes and underscore the need for further research into robust evaluation metrics, ethical considerations, and cross-cultural adaptability.",artificial intelligence | collaborative decision-support systems | consensus-building | cosine similarity | large language models,0,2025,sustainability,behavior+sustainability
145,2-s2.0-105015615214,10.3390/math13172878,https://doi.org/10.3390/math13172878,https://scholar.google.com/scholar?q=10.3390/math13172878,ar,Mathematics,"Anhao, Ferry;Karbassi Yazdi, Amir;Tan, Yong;Ocampo, Lanndon",Integrating Large Language Models into a Novel Intuitionistic Fuzzy PROBID Method for Multi-Criteria Decision-Making Problems,"As vision and mission statements embody the directions set forth by an organization, their connection to the Sustainable Development Goals (SDGs) must be made explicit to guide overall decision-making in taking strides toward the sustainability agenda. The semantic alignment of these strategic statements with the SDGs is investigated in a previous study, although several limitations need further exploration. Thus, this study aims to advance two contributions: (1) utilizing the capabilities of LLMs (Large Language Models) in text semantic analysis and (2) integrating fuzziness into the problem domain by using a novel intuitionistic fuzzy set extension of the PROBID (Preference Ranking On the Basis of Ideal-average Distance) method. First, a systematic approach evaluates the semantic alignment of organizational strategic statements with the SDGs by leveraging the use of LLMs in semantic similarity and relatedness tasks. Second, viewing it as a multi-criteria decision-making (MCDM) problem and recognizing the limitations of LLMs, the evaluations are represented as intuitionistic fuzzy sets (IFSs), which prompted the development of an IF extension of the PROBID method. The proposed IF-PROBID method was then deployed to evaluate the 47 top Philippine corporations. Utilizing ChatGPT 3.5, 7990 prompts with repetitions generated the membership, non-membership, and hesitance scores for each evaluation. Also, we developed a cohort-dependent SDG–vision–mission matrix that categorizes corporations into four distinct classifications. Findings suggest that “highly-aligned” corporations belong to the private and technology sectors, with some in the industrial and real estate sectors. Meanwhile, “weakly-aligned” corporations come from the manufacturing and private sectors. In addition, case-specific insights are presented in this work. The comparative analysis yields a high agreement between the results and those generated by other IF-MCDM extensions. This paper is the first to demonstrate two methodological advances: (1) the integration of LLMs in MCDM problems and (2) the development of the IF-PROBID method that handles the resulting inherently imprecise evaluations.",intuitionistic fuzzy sets | large language models | mission statement | multi-criteria decision-making | PROBID | sustainable development goals | vision statement,0,2025,sustainability,behavior+sustainability
146,2-s2.0-105015528262,10.3390/buildings15172997,https://doi.org/10.3390/buildings15172997,https://scholar.google.com/scholar?q=10.3390/buildings15172997,re,Buildings,"Najafzadeh, Mohammadreza;Yeganeh, Armin",AI-Driven Digital Twins in Industrialized Offsite Construction: A Systematic Review,"The increasing adoption of industrialized offsite construction (IOC) offers substantial benefits in efficiency, quality, and sustainability, yet presents persistent challenges related to data fragmentation, real-time monitoring, and coordination. This systematic review investigates the transformative role of artificial intelligence (AI)-enhanced digital twins (DTs) in addressing these challenges within IOC. Employing a hybrid re-view methodology—combining scientometric mapping and qualitative content analysis—52 relevant studies were analyzed to identify technological trends, implementation barriers, and emerging research themes. The findings reveal that AI-driven DTs enable dynamic scheduling, predictive maintenance, real-time quality control, and sustainable lifecycle management across all IOC phases. Seven thematic application clusters are identified, including logistics optimization, safety management, and data interoperability, supported by a layered architectural framework and key enabling technologies. This study contributes to the literature by providing an early synthesis that integrates technical, organizational, and strategic dimensions of AI-driven DT implementation in IOC context. It distinguishes DT applications in IOC from those in onsite construction and expands AI’s role beyond conventional data analytics toward agentive, autonomous decision-making. The proposed future research agenda offers strategic directions such as the development of DT maturity models, lifecycle-spanning integration strategies, scalable AI agent systems, and cost-effective DT solutions for small and medium enterprises.",building information modeling (BIM) | construction automation | cyber–physical systems (CPS) | modular construction | prefabrication | smart construction | supply chain optimization,0,2025,sustainability,behavior+sustainability
157,2-s2.0-105015142872,10.16097/j.cnki.1009-6744.2025.04.014,https://doi.org/10.16097/j.cnki.1009-6744.2025.04.014,https://scholar.google.com/scholar?q=10.16097/j.cnki.1009-6744.2025.04.014,ar,Jiaotong Yunshu Xitong Gongcheng Yu Xinxi Journal of Transportation Systems Engineering and Information Technology,"Wang, Xiang;Ren, Hao;Tan, Guozhen;Li, Jianping;Wang, Jue;Wang, Yanli",Autonomous Driving Decision-making Method Based on Cooperative Reinforcement Learning of Large Language Model,"Aiming at the problems that the high- level decision- making of the current autonomous driving system lacks specific execution details and continuous learning ability, this paper focuses on applying the Large Language Model (LLM) in refining the decision-making process of autonomous driving. Based on the powerful reasoning ability of the LLM and the exploration ability of Reinforcement Learning (RL), this paper proposes a method of combining the LLM and RL to refine the vehicle decision-making process. First, based on the high-level actions output of the RL, the reasoning ability of the LLM is used to predict the future trajectory points of the host vehicle. Then, the output of the RL model is combined with the current state information to make a safe, collision-free and interpretable prediction of the next state. At last, the above driving decision-making process is vectorized and stored in the memory module as driving experience, and the driving experience is updated regularly to achieve sustainable learning. The trajectory points predicted by the LLM provide a detailed motion path for the Proportional-Integral-Derivative (PID) controller, providing a basis for adjusting the vehicle's acceleration and speed to ensure that the vehicle travels along the predetermined path. In addition, the trajectory prediction can also evaluate and avoid potential collision risks, and create a safe path by analyzing the traffic state and historical data. The results of the closed-loop experiment show that the proposed decision-making method outperforms other models in all evaluation indicators. Compared to the RL, the decision-making method based solely on the LLM, and the LLM-based car-following model, the driving scores are increased by 35.12, 14.33 and 12.28 respectively. The method with the memory module increases the driving score by 25.59 compared to the method without the memory module.",autonomous driving | continual learning | intelligent traffic | large language model | reinforcement learning | trajectory prediction,0,2025,sustainability,behavior+sustainability
158,2-s2.0-105014364959,10.22456/2175-2745.146658,https://doi.org/10.22456/2175-2745.146658,https://scholar.google.com/scholar?q=10.22456/2175-2745.146658,ar,Revista De Informatica Teorica E Aplicada,"Alves, Luis Felipe Medeiro;de Oliveira, José Maria Parente;Bonacin, Rodrigo;Rosa, Ferrucio de Franco",An Ontology of Tobacco Production: Enriching Large Language Model-based Decision Support,"Tobacco (Nicotiana tabacum) production plays a crucial role in the agricultural economy of several regions around the world, especially in developing countries, such as Brazil. However, the lack of well-defined terminology and semantic models harms the development of decision support systems. Conceptualizing the tobacco production domain is challenging due to its ambiguous terminology and the complexity involved in considering environmental, soil, disease, and pest management factors. We present an Ontology of Tobacco Production (OnTop), designed to assist tobacco production in optimizing crop management practices and placing environmental factors within a formal framework. To the best of available knowledge, this study is the first to formalize the tobacco production lifecycle integrated with soil and climate data. It includes symbolic and description logic for reasoning and automation. This paper presents the proposal for the core set (main classes) and the application of OnTop to enrich a Large Language Model (LLM) to provide an ontology-based decision support prompt. OnTop allows actionable recommendations based on environmental, agronomic, and productivity data. The main contributions of this paper are: i) a domain ontology that formalizes knowledge on data-driven tobacco production; and ii) a queryable framework (enriched LLM), which allows experts to obtain complex agronomic answers. OnTop offers an extensible framework for decision making in tobacco farming and paves the way for further innovations in ontologies and LLM-based decision support systems for the agricultural domain.",knowledge representation | large language model | ontology | tobacco,0,2025,sustainability,behavior+sustainability
159,2-s2.0-105013324954,10.5194/gmd-18-4983-2025,https://doi.org/10.5194/gmd-18-4983-2025,https://scholar.google.com/scholar?q=10.5194/gmd-18-4983-2025,ar,Geoscientific Model Development,"Zeng, Yongchao;Brown, Calum;Byari, Mohamed;Raymond, Joanna;Schmitt, Thomas;Rounsevell, Mark",InsNet-CRAFTY v1.0: integrating institutional network dynamics powered by large language models with land use change simulation,"To foster sustainable land use and management, it is crucial - but challenging - to enhance our understanding of how policy interventions influence decision-making actors and how these interactions can be effectively modelled. Key challenges include endowing modelled actors with autonomy, accurately representing their relational network structures, and managing the often unstructured information exchange among them. Large language models (LLMs) offer new ways to address these challenges through the development of agents that are capable of mimicking reasoning, reflection, planning, and action. We present InsNet-CRAFTY (Institutional Network - Competition for Resources between Agent Functional Types) v1.0, a multi-LLM-agent model with a polycentric institutional framework coupled with an agent-based land system model. The institutional framework includes a high-level policymaking institution, two lobbyist organizations, two operational institutions, and two advisory agents. For exploratory purposes, illustrative numerical experiments simulating two competing policy priorities are conducted: increasing meat production versus expanding protected areas for nature conservation. We find that the high-level institution tends to avoid radical changes in budget allocations and adopts incremental policy goals for the operational institutions, but it leaves an unresolved budget deficit in one institution and a surplus in another. This is due to the competing influence of multiple stakeholders, which leads to the emergence of a path-dependent decision-making approach. Despite errors in information and behaviours by the LLM agents, the network maintains overall behavioural believability. The results highlight both the potential and the risks of using LLM agents to simulate policy decision-making. While LLM agents demonstrate high flexibility and autonomy in modelling human decision-making and institutional dynamics, their integration with existing land use models is complex, requiring careful workflow design to ensure reliability. These insights contribute to advancing land system modelling and the broader field of institutional analysis, providing new tools and methodologies for researchers and policymakers.",,0,2025,sustainability,behavior+sustainability
164,2-s2.0-105014279564,10.3390/su17167520,https://doi.org/10.3390/su17167520,https://scholar.google.com/scholar?q=10.3390/su17167520,ar,Sustainability Switzerland,"Ziemba, Paweł;Majewski, Filip",Using the Large Language Model ChatGPT to Support Decisions in Sustainable Transport,"Recently, the popularity of large language models (LLMs) used as artificial intelligence tools supporting humans has been growing. LLMs are applied in many fields, including increasingly for various sustainability-related issues. One of the most popular tools of this type is ChatGPT, which, after being supplied with appropriate knowledge, can act as a domain expert, including in the area of sustainable transport. The article uses this functionality of ChatGPT, feeding it with knowledge about electric vehicles (EVs) available on the Polish market. The aim of the research was to develop a solution based on an LLM, which will act as an advisor when buying an EV. After appropriate modelling of knowledge and feeding it into ChatGPT, an expert system was obtained, which, based on the defined needs of the user, recommends the most suitable EV for them. When answering the system’s questions, the user provides only a description of the decision-making situation at the LLM input (e.g., the locations to which they are travelling, information on the number of family members, etc.). In turn, the appropriately fine-tuned ChatGPT provides a recommendation of vehicles that meet the user’s defined needs. This is a very user-friendly solution because it does not require the user to precisely define the vehicle evaluation criteria or a set of alternatives. This approach also does not require the user to have detailed domain knowledge.",ChatGPT | electric vehicles | expert system | fine-tuning | large language model | sustainability | sustainable decisions | sustainable transport,0,2025,sustainability,behavior+sustainability
168,2-s2.0-105010688570,10.1097/QAD.0000000000004220,https://doi.org/10.1097/QAD.0000000000004220,https://scholar.google.com/scholar?q=10.1097/QAD.0000000000004220,re,AIDS,"Kamitani, Emiko;Koenig, Linda J.;Sullivan, Patrick",Transformative potential of artificial intelligence in US CDC HIV interventions: balancing innovation with health privacy,"Artificial intelligence (AI) holds significant potential to transform HIV prevention and treatment through the application of advanced technologies such as machine learning (ML), deep learning (DL), and generative AI (Gen AI). These technologies can enhance the monitoring, management, and analysis of vast and complex HIV-related datasets, enabling more timely predictions of potential risks and improving HIV care strategies. AI is poised to streamline HIV prevention interventions by increasing workforce efficiency, supporting expanded accessibility and sustainability of preexposure prophylaxis (PrEP) care in nontraditional settings, and supporting clinical decision-making. Additionally, when utilized within HIV care systems, AI can help close gaps in diagnosis, treatment, and continuous care engagement. However, to optimize AI’s potential in HIV prevention, careful implementation is crucial. Challenges such as reducing bias, ensuring ethical standards (including health privacy standards) are maintained, and mitigating risks like AI hallucinations must be addressed. Thoughtful integration, community consultation, and continuous evaluation will be critical to ensuring that AI plays a beneficial role in HIV prevention and drives innovations that lead to more equitable health outcomes. This editorial review explores AI’s transformative potential, focusing on the US CDC’s key public health strategies for HIV prevention. When aligning with public health strategies – particularly in countries supported by initiatives like President’s Emergency Plan for AIDS Relief (PEPFAR) – AI can contribute significantly to global efforts to end the HIV epidemic. It offers a vision for AI’s future application in HIV prevention, emphasizing the need for a holistic and syndemic approach to improving HIV prevention worldwide.",artificial intelligence | deep learning | HIV | machine learning | public health,0,2025,sustainability,behavior+sustainability
173,2-s2.0-105008154199,10.1021/acs.jchemed.5c00212,https://doi.org/10.1021/acs.jchemed.5c00212,https://scholar.google.com/scholar?q=10.1021/acs.jchemed.5c00212,ar,Journal of Chemical Education,"Kim, Ji",Integrating Artificial Intelligence (AI) Chatbots and Green Chemistry Principles in the Synthesis of Cyclohexene,"This activity presents a redesigned undergraduate organic chemistry laboratory activity that integrates green chemistry principles and generative artificial intelligence (AI) tools to enhance student learning. Conducted at a two-year college, the activity challenged students to synthesize cyclohexene from cyclohexanol using safer, more sustainable catalysts. Students utilized AI chatbots─such as ChatGPT, Gemini, and Microsoft Copilot─to explore greener alternatives to traditional reagents, aligning their experimental choices with the 12 Principles of Green Chemistry and evaluating their selections with ChemForward and instructor feedback. Catalysts including Amberlyst-15 and dried orange peels were tested, with varying yields, emphasizing the practical challenges and benefits of eco-conscious substitutions. The activity fostered skills in digital literacy, sustainability, and scientific inquiry while promoting awareness of the ethical implications of AI in laboratory decision-making. Survey responses and student reflections showed increased engagement and a deeper understanding of green chemistry. This approach offers a replicable, cost-effective model for embedding sustainability and technology into STEM education while encouraging evidence-based reasoning and critical thinking.",Collaborative/Cooperative Learning | Elimination Reactions | Hands-On Learning | Microscale Lab | Organic Chemistry | Second-Year Undergraduate,0,2025,sustainability,behavior+sustainability
188,2-s2.0-105008785064,10.1145/3735513,https://doi.org/10.1145/3735513,https://scholar.google.com/scholar?q=10.1145/3735513,ar,Digital Government Research and Practice,"Ae Chun, Soon;Noveck, Beth Simone",Introduction to the Special Issue on ChatGPT and other Generative AI Commentaries Part 2: GenAI Augmented Government 4.0,"This special issue, part 2, continues the discussion from the previous issue on GenAI and other AI-augmented Government 4.0. It shows the current adoption and potential of GenAI-based transformation in the public sector. It also highlights risks and challenges of GenAI from different perspectives. The duality of GenAI as a creative and productive assistant in the public administration and service delivery, and as a structured analytical tool for decision-making support can make GenAI a favorite tool of trade and a catalyst for public sector transformation. However, rigorous testing and empirical findings are required for the sustainability of the GenAI Augmented Transformation in the public sector.",ChatGPT | Generative AI | Large Language Models | public domain innovations,0,2025,sustainability,behavior+sustainability
197,2-s2.0-85208108968,10.1108/EJTD-03-2024-0044,https://doi.org/10.1108/EJTD-03-2024-0044,https://scholar.google.com/scholar?q=10.1108/EJTD-03-2024-0044,ar,European Journal of Training and Development,"Lundgren, Henriette;Papanagnou, Dimitrios;Morrone, Casey;Vaid, Urvashi;Ghei, Ridhima;Bierowski, Abagayle;Watkins, Karen E.;Marsick, Victoria J.",From research to resources: developing a case-based learning curriculum for navigating clinical uncertainty,"Purpose: This study aimed at rethinking ways in which educators from different fields can collaborate to respond to the rapidly evolving demands of health professions education (HPE). The goal was to investigate how a research-to-resources approach can be applied to engage in knowledge translation (KT) of research findings for the benefit of introducing medical students to uncertainty in the clinical learning environment. Design/methodology/approach: An interdisciplinary team of medical educators, human resource development (HRD) scholars and emergency medicine fellows engaged in iterative cycles of action research (AR) to develop, pilot and refine case-based learning resources on clinical uncertainty. The team leveraged prior research on physicians’ decision-making during COVID-19, experimented with generative AI tools, and collected feedback from medical students to guide resource development. Findings: The findings of this study are twofold. On the one hand, the authors reflect on the lessons learned of developing case-based learning with the help of generative AI. While student feedback indicated that the case helped normalize and process experiences with uncertainty, key challenges included adapting research data to create relevant, sustainable learning resources and designing effective discussion prompts. On the other hand, the authors provide insights into the opportunities and challenges of our interdisciplinary collaboration. The authors show that knowledge utilization is not simple, but complex, and that more work needs to be done to effectively disseminate resources as part of the desired uncertainty curriculum. Practical implications: This study attempts to apply a KT framework for bridging the research-practice gap in HPE through interdisciplinary collaboration and AR. It provides lessons learned for developing case-based curricula on complex topics like uncertainty. The findings highlight the need for adaptive KT processes when dealing with rapidly evolving healthcare contexts. Originality/value: This paper offers a novel example of research-to-resource KT in medical education, integrating perspectives from HRD and leveraging emerging technologies. It contributes to understanding how interdisciplinary teams can collaborate to create timely, evidence-based educational resources for navigating uncertainty in professional practice. The study also provides insights into the challenges and opportunities of translating complex research findings into practical learning tools to tackle real-world challenges in HPE.",Case-based learning | Clinical uncertainty | Curriculum development | Health professions education | Interdisciplinary teamwork | Research to resources,0,2025,sustainability,behavior+sustainability
215,2-s2.0-105012509306,10.1177/23794607251346311,https://doi.org/10.1177/23794607251346311,https://scholar.google.com/scholar?q=10.1177/23794607251346311,ar,Behavioral Science and Policy,"Lopez-Lopez, Ezequiel;Herzog, Stefan M.",Surfacing citizens’ policy perspectives at scale in the age of large language models,"To address policy challenges such as climate change or pandemics effectively, policymakers require insights into the views of the general public. However, traditional large-scale quantitative methods like surveys and aggregated social media analytics lack nuance, while qualitative approaches such as interviews are labor intensive and thus limited to small samples. We discuss how artificial intelligence tools known as large language models (LLMs) could be leveraged to surface the detailed views of large numbers of citizens on policy issues. In particular, we showcase an LLM-supported method designed to provide both quantitative and qualitative insights from large samples of respondents who provide free-text responses to open-ended questions. We propose that such approaches could help policymakers efficiently integrate citizens’ input into their decision-making processes and give them timely, nuanced insights that complement those produced by established methods of obtaining large-scale public input.",citizen perspectives | large language models (LLMs) | policymaking,0,2025,sustainability,behavior+sustainability
216,2-s2.0-105010229517,10.1103/PRXEnergy.4.023003,https://doi.org/10.1103/PRXEnergy.4.023003,https://scholar.google.com/scholar?q=10.1103/PRXEnergy.4.023003,ar,Prx Energy,"Mohanty, Trupti;Sayeed, Hasan M.;Mohanty, Chitrasen;Sparks, Taylor D.","Comprehensive Insights into Global Mineral Commodities: Analysis, Visualization, and Intelligent Assistance","With the growing emphasis on sustainability, criticality, and availability in materials research, providing actionable information about mineral commodities is crucial for informed decision-making and strategic planning by researchers, policy makers, and industry stakeholders. While the United States Geological Survey (USGS) offers valuable information on mineral-commodity summaries, their unstructured nature makes analysis challenging. To address this, we present a comprehensive data-analytics application (https://mineral-ai.net/) that processes the past 10 years of USGS mineral-commodity summaries into actionable insights. The application offers country-specific insights into global elemental production and reserves, along with quantitative metrics such as the Herfindahl-Hirschman index (HHI) to evaluate market concentration, identifying risks and opportunities in resource availability. It also features an artificial-intelligence assistant powered by a large language model (LLM) and a retrieval-augmented generation (RAG) system, enabling users to query various aspects of raw materials, including reserves, production, market share, usage, price, substitutes, recycling, and more. We evaluated multiple open-source LLMs for the RAG task and selected the best-performing model, llama-3, to implement in the system. This application provides valuable support for material scientists in assessing sustainability, criticality, and market risks, thereby aiding in the development of new materials. We demonstrate its application in energy materials, and by describing the application architecture and providing open access to the code, we aim to enable data-driven advancements in materials research.",,0,2025,sustainability,behavior+sustainability
217,2-s2.0-105004193800,10.2166/hydro.2025.248,https://doi.org/10.2166/hydro.2025.248,https://scholar.google.com/scholar?q=10.2166/hydro.2025.248,ar,Journal of Hydroinformatics,"Strogonov, Vadim;Pollert, Jaroslav",Artificial intelligence-enhanced web application approach to data management in the WIDER UPTAKE project,"The paper describes a web application developed for managing and presenting experiment data of the WIDER UPTAKE project funded by Horizon Europe. The project's goal is to promote water-smart and sustainable solutions among stakeholders in multiple countries. The application enhances data management and stakeholder engagement through the use of a third-party large language model. It integrates data from demonstration case studies with real-time sensor measurements and laboratory tests, into a comprehensive cloud-based platform. It facilitates data visualization, regulatory compliance checks, and risk assessments for chemical and microbial hazards. The application significantly aided in the coordination and communication of project findings among stakeholders. Key functionalities include interactive diagrams, risk assessment tools, and automated report generation using artificial intelligence (AI). The AI-generated reports, while maintaining confidentiality of data in most cases, provided clear and informative summaries of data compliance with regulatory standards. The web application extended stakeholder engagement, democratized access to complex data, and supported decision-making processes for implementing sustainable water management solutions. However, the development encountered significant challenges surrounding transparency, fairness, accountability, and privacy, which impedes the refinement and scalability of this approach for broader use. Future research should focus on overcoming these obstacles to ensure a more effective and ethical application.",circular economy | data management | large language models | sustainable water management | water reuse | web application,0,2025,sustainability,behavior+sustainability
220,2-s2.0-105004553171,10.1515/zwf-2024-0166,https://doi.org/10.1515/zwf-2024-0166,https://scholar.google.com/scholar?q=10.1515/zwf-2024-0166,ar,ZWF Zeitschrift Fuer Wirtschaftlichen Fabrikbetrieb,"Larichev, Vlad;Masek, Jennifer;Chouhan, Prashant;Spiess, Daniel",Generative AI and Agentic Architecture in Engineering and Manufacturing Potentials and Practice of Scalable AI Solutions,"The integration of Generative AI (GenAI) and Agentic Architecture offers potential for scalability, automation, and improved decision-making in engineering and manufacturing. These technologies contribute to efficiency and process optimization but face challenges such as data fragmentation and interoperability. This paper examines the role of Agentic Architecture in addressing these issues, presenting scalable AI solutions, practical use cases, and strategic considerations for sustainable AI-driven innovation in industrial applications.",Agentic Architecture | Artificial Intelligence | Engineering Manufacturing | Generative AI,0,2025,sustainability,behavior+sustainability
257,2-s2.0-105026603866,10.1108/JFMM-08-2024-0303,https://doi.org/10.1108/JFMM-08-2024-0303,https://scholar.google.com/scholar?q=10.1108/JFMM-08-2024-0303,ar,Journal of Fashion Marketing and Management,"Sorooshian, Shahryar;Rahamaddulla, Syed Radzi;Ahmad, Mohd Hanafiah Bin",Generative artificial intelligence-powered approach to multiple criteria selection of advertising 4.0 services suppliers: case of sustainable fashion industry,"Purpose – On both digital capability and sustainability, advertising 4.0 service providers are pivotal for brands that compete. However, choosing the right partner requires a structured, data-driven approach. The purpose of this article is to propose a novel approach to assist sustainable fashion businesses in selecting the best advertising 4.0 services suppliers. Design/methodology/approach – The study proposed a multi-step approach that included artificial intelligence (AI) -generated insights as well as expert validation. Generative AI developed the initial decision criteria, which served as a comprehensive and advanced starting point. These criteria were refined through expert focus groups to ensure their comprehensiveness and applicability. A multi-criteria decision-making technique, ordinal priority approach (OPA), utilized to rank the existing service providers. To validate the proposed approach and identify the best advertising 4.0 provider, we went through every step of the model and successfully ranked alternative advertising service suppliers in a fashion industry case study. Findings – A user-friendly advertising 4.0 provider selection model was developed for the fashion industry with a sustainability competitive advantage, including Twenty-two comprehensive criteria for market knowledge, sustainability practices, and technical competence. Among the alternative service suppliers obtainable by the case company, this study revealed alternative 2 as the best-match advertising 4.0 partner. As a result of this case study applicability validation, the proposed framework is potentially beneficial for all industries, mainly the fashion sector, because it enables them to make informed decisions that are consistent with their strategic goals. Originality/value – This article is among the pioneers to integrate artificial intelligence for criteria generation with expert validation and OPA optimization, producing a replicable generative AI-assisted MCDM framework. It promotes the concept of advertising 4.0 and contributes to the literature on service supplier selection, particularly in the sustainable fashion sector.",Advertising 4.0 | ChatGPT | Fashion | Industrial revolution 4.0 | Industrial revolution 5.0 | Multi-criteria decision-making (MCDM) | Sustainability,0,2025,sustainability,behavior+sustainability
261,2-s2.0-105025477752,10.1108/EJIM-03-2025-0389,https://doi.org/10.1108/EJIM-03-2025-0389,https://scholar.google.com/scholar?q=10.1108/EJIM-03-2025-0389,ar,European Journal of Innovation Management,"Nevi, Giulia;Palazzo, Maria;Ferri, Maria Antonella;Dezi, Luca",Redefining identity: corporate evolution in the AI era,"Purpose – This study explores how artificial intelligence (AI) is reshaping corporate identity (CI), focusing on its transformative impact across product, client, media, content, relationship with stakeholders' level as the corporate core nature. It examines the critical shifts AI introduces, unveiling new challenges and tensions within firms' core structures. Design/methodology/approach – Using a qualitative approach, the study analyzes companies listed on the Italian FTSE MIB through seven interviews from six financial firms with key AI leaders. Data triangulation was applied to ensure robust, reliable findings. Findings – The results indicate that AI has become a strategic asset, playing a pivotal role in the evolution of CI, especially at the content and client level. This transformation leads to a shift in business models, catering to a new type of consumer, such as Promptumer or Promptvestor, in the financial services sector. Companies are also expanding their boundaries, managing digital intelligent ecosystems and operating through sophisticated channels, including AI-driven dashboards and virtual agents. AI is reaffirmed as a strategic enabler, acting as an accelerator and multiplier of opportunities. Research limitations/implications – The study is limited to companies listed on the Italian FTSE MIB, which may affect the generalizability of the findings. Future research could expand the scope to include companies from other regions and sectors. Practical implications – Effective change management, development of technological skills, personalization of customer experiences and adherence to digital ethics and sustainability are crucial for firms. Businesses must navigate the evolving tension between their current and future identities, integrating new roles and new dimensions guided by the ownership value, AI and stakeholders, while maintaining a balance between co-creation, innovation and their core values of trust and stability. Originality/value – This research offers novel insights into how AI is metamorphosing CI, emphasizing the role of cognitive connection and sustainability in the digital age. We propose a conceptual model that introduces the AI Signature as a new dimension in identity analysis and we define a new role for Customer and users that, from Prosumer translates toward a Promptuser – Promptumer. As firms become increasingly data-driven and adaptive, AI supports more ethical, efficient and sustainable decision-making. To enhance managerial relevance, we also present the CI Canvas, a practical tool for managers, consultants and organizations navigating CI transformation. In the new AI era, firms may be valued not only for their product offerings but for how their systems reason, act and engage in dialogue, making AI not only a new vector of identity but a distinctive corporate signature.",AI transformation | Artificial intelligence | Corporate change | Corporate identity | Corporate identity canvas | Firms evolution,0,2025,sustainability,behavior+sustainability
262,2-s2.0-105025467662,10.1108/IJLM-01-2025-0062,https://doi.org/10.1108/IJLM-01-2025-0062,https://scholar.google.com/scholar?q=10.1108/IJLM-01-2025-0062,ar,International Journal of Logistics Management,"Modgil, Sachin;Singh, Rohit Kumar;Mathiyazhagan, K.;Żywiołek, Justyna",Role of generative AI towards sustainable procurement,"Purpose – This study examines the impact of Generative Artificial Intelligence (GAI) on sustainable procurement, highlighting its potential to improve operational efficiencies, ensure compliance with sustainability standards and mitigate risks associated with complex supply chains. Design/methodology/approach – The study employs a quantitative design, informed by exploratory interviews. We used structural equation modelling to investigate the roles of GAI in dynamic pricing, behavioural nudging, life cycle assessment, carbon footprint tracking and compliance checking. Findings – The study offers theoretical contributions viewing sustainable procurement as a strategic resource and how digital tools like GAI can help extending resource-based view (RBV) in developing unique capabilities in carbon tracking, low-carbon sourcing and compliance. Adopting RBV, organizations can develop adaptive procurement system and position procurement as a core drive of sustainable competitive advantage. Practically, organizations can leverage GAI to navigate the challenges of modern supply chains more effectively, promoting sustainability while maintaining competitive advantage. This study highlights the pivotal role of GAI in advancing sustainable procurement practices and its importance in the broader discourse on sustainability and technological innovation in supply chains. Originality/value – The integration of GAI into sustainable procurement practices presents a transformative opportunity for organizations to align their supply chain processes with their sustainability goals. Our findings suggest that practice managers can make use of GAI to achieve sustainable procurement by enabling data-driven decision-making, promoting transparency among supplier networks and facilitating stakeholder engagement. Our study contributes to extending the existing debate of how generative AI can influence sustainable procurement.",Data-driven decision making | Generative artificial intelligence | Supply chain management | Sustainable procurement | Technological innovation,0,2025,sustainability,behavior+sustainability
265,2-s2.0-105024921454,10.1007/s42952-025-00356-w,https://doi.org/10.1007/s42952-025-00356-w,https://scholar.google.com/scholar?q=10.1007/s42952-025-00356-w,ar,Journal of the Korean Statistical Society,"Yang, Munil;Kim, Kwangho;Kim, Dongha",From prediction to action: a framework for business closure analysis and LLM-based consulting strategy generation,"To effectively support the sustainability of small businesses in dynamic and uncertain commercial environments, there is a growing need for AI systems that are both interpretable and actionable. Despite this need, few frameworks exist that effectively bridge predictive modeling and actionable strategy generation. In this study, we present an integrated framework that combines counterfactual explanation algorithms and large language models (LLMs) to support high-quality consulting strategies for business closure prevention. Using commercial district data from Seoul (2022–2023), we train a high-performing closure prediction model with key variables derived by the SHAP algorithm. We then apply the DiCE algorithm to generate counterfactual instances that balance interpretability and diversity. These instances are subsequently translated into actionable business strategies using prompt-engineered LLMs. Our results demonstrate that the integration of counterfactual reasoning with carefully designed LLM prompts enables scalable and transparent consulting support for small business decision-making. This research contributes a novel pipeline that bridges predictive modeling with policy-relevant strategy generation.",Business closure prediction | Commercial district analysis | Counterfactual explanation | Large language models | Prompt engineering,0,2025,sustainability,behavior+sustainability
266,2-s2.0-105024826348,10.1002/sd.70544,https://doi.org/10.1002/sd.70544,https://scholar.google.com/scholar?q=10.1002/sd.70544,ar,Sustainable Development,"Pospieszny, Przemek;Brodowicz, Dominika P.","Toward Agentic Environments: GenAI and the Convergence of AI, Sustainability, and Human-Centric Spaces","In the past few years, the evolution of artificial intelligence (AI), particularly generative AI (GenAI) and large language models (LLMs), has made human-computer interactions more frequent, easier, and faster than ever before. This brings numerous benefits in terms of enhancing efficiency, accessibility, and convenience in various sectors from banking to health. AI tools and solutions applied in computers and communication devices support decision-making processes and managing operations of users on the individual level as well as organisationally, including resource allocation, workflow automation, and real-time data analysis. However, the current use of AI carries a substantial environmental footprint due to its reliance on high-computational cloud resources. In such a context, this paper introduces the concept of agentic environments, a sustainability-oriented AI framework that goes beyond reactive systems by leveraging GenAI, multi-agent systems, and edge computing to minimize the negative impact of technology. These types of environments can contribute to the optimization of resource use, enhanced quality of life, and prioritization of sustainability while at the same time safeguarding user privacy through decentralized, edge-driven AI solutions. Based on both secondary and primary data gathered during a focus group and semi-structured interviews with AI professionals from leading technology companies, the authors provide a conceptual framework of agentic environments and discuss it in the context of three lenses, including personal sphere, professional and commercial use, and urban operations. The findings include the potential of agentic environments to foster sustainable ecosystems, mainly due to the optimisation of resource usage and securing the privacy of data. The study outlines recommendations for implementing edge-driven deployment models to reduce dependency on currently widely applied high-energy cloud solutions.",AI agents | ambient intelligence | generative AI | sustainability | sustainable ecosystems,0,2025,sustainability,behavior+sustainability
268,2-s2.0-105024659655,10.1108/TCJ-04-2025-0148,https://doi.org/10.1108/TCJ-04-2025-0148,https://scholar.google.com/scholar?q=10.1108/TCJ-04-2025-0148,ar,Case Journal,"Arif, Farrah",From vision to sales: the marketing struggles of an eco-friendly cleaning brand,"Research methodology – The case was developed using primary sources, chiefly based on interviews conducted with the protagonist. It was tested with MSc Marketing students during a hackathon, where participants were tasked with developing and delivering a comprehensive digital marketing strategy to the protagonist. The names of the competitors are fudged to avoid any ethical issues. ChatGPT was used to improve the language for stylistic purposes. Case overview/synopsis – Cate Hickling, founder of Forest&Co., launched a line of eco-friendly, pet-safe cleaning products to challenge greenwashing in the market. Despite strong branding and positive Amazon reviews, sales lagged due to ineffective digital marketing and limited consumer awareness. With a £50, 000 budget and a compelling product, Cate now faces a critical challenge: how to build brand differentiation, engage customers authentically and optimize digital touchpoints. This case invites students to craft a focused digital strategy that balances education, trust-building and strategic platform use – positioning Forest&Co. as a credible voice in a saturated, often misleading eco-product landscape. Complexity academic level – This case study is designed for Digital Marketing courses at both undergraduate and postgraduate levels, offering students practical insights into digital branding, strategic customer engagement and value co-creation in niche markets. Through Cate Hickling’s journey with Forest&Co., students explore key concepts such as authentic differentiation in crowded digital spaces, optimization of digital touchpoints across the customer journey and the strategic use of user-generated content to build trust. Grounded in theories like Digital Brand Engagement, Customer Journey Mapping and UGC-driven Value Co-Creation, the case encourages critical thinking and real-world application. It is equally well-suited for Entrepreneurship classes, where it supports discussions on branding, resource-constrained decision-making and market positioning for socially driven ventures. Keywords – Digital marketing, Marketing, Entrepreneurship, Sustainability, Social media strategy",Digital marketing | Entrepreneurship | Marketing | Social media strategy | Sustainability,0,2025,sustainability,behavior+sustainability
269,2-s2.0-105024604690,10.1109/ACCESS.2025.3642631,https://doi.org/10.1109/ACCESS.2025.3642631,https://scholar.google.com/scholar?q=10.1109/ACCESS.2025.3642631,re,IEEE Access,"Farhoudi, Mohammad;Shokrnezhad, Masoud;Taleb, Tarik","Service Registration, Indexing, Discovery, and Selection: An Architectural Survey Toward a GenAI-Driven Future","The emergence of sixth-generation (6G) networks marks a paradigm shift: by unifying an edge-to-cloud computing continuum with ultra-high-performance networking, 6G will enable capabilities far beyond today’s boundaries. As use-case diversity grows exponentially and user adoption drives traffic to unprecedented and highly dynamic levels, novel service orchestration mechanisms are indispensable. In this paper, we adopt an architectural viewpoint, examining Service Registration, Indexing, Discovery, and Selection (SRIDS) as fundamental elements of 6G service provision. We first establish the theoretical foundations of SRIDS in 6G by defining its core concepts, detailing its end-to-end workflow, reviewing current standardization efforts, and projecting its future design objectives, including reliability, scalability, automaticity and adaptability, determinism, efficiency, sustainability, semantic-awareness, security, privacy, and trust. We then perform a comprehensive literature review and gap analysis encompassing both existing surveys and recent research efforts, identifying conceptual and methodological gaps that hinder unified SRIDS in 6G. Next, we introduce a taxonomy that classifies SRIDS mechanisms into centralized, distributed, decentralized, and hybrid architectures, and systematically examine the relevant studies within each category. Each work is evaluated against the extracted design objectives. Building on these findings, we propose a hybrid architectural framework, combining centralized data management to ensure consistency and agility with distributed coordination to enhance scalability in emerging 6G use cases. The framework incorporates innovative technologies, such as Generative Artificial Intelligence (GenAI). We conclude by highlighting open challenges and suggesting directions for future research.",6G networks | edge-cloud continuum | generative AI | security and trust | semantic-awareness | service discovery | service indexing | Service orchestration | service provisioning | service registration | service selection,0,2025,sustainability,behavior+sustainability
270,2-s2.0-105024464359,10.1002/sd.70511,https://doi.org/10.1002/sd.70511,https://scholar.google.com/scholar?q=10.1002/sd.70511,ar,Sustainable Development,"Ellahi, Rizwan Matloob;Wang, Ke;Qureshi, Jawaid Ahmed;Wood, Lincoln C.",Harnessing Generative AI Decision Support for Environmental and Social Supply Chain Sustainability,"This study examines the mediating role of Generative AI–based decision support systems in promoting environmental and social sustainability within supply chains. Grounded in resource-based and stakeholder theories, the research highlights management commitment and technological readiness as critical internal drivers shaping sustainability outcomes. A structural model was developed and validated using survey data collected from supply chain professionals in the logistics sector. Findings reveal that both management commitment and technological readiness significantly influence supply chain sustainability, while AI-driven decision support systems partially mediate these relationships. The results suggest that integrating Generative AI into decision-making processes enhances firms' ability to achieve sustainability objectives. By linking internal drivers with advanced technologies, this study contributes to understanding how organizations can leverage emerging tools to meet green supply chain goals. The findings also provide practical implications for managers seeking to strengthen sustainability initiatives through technology adoption and improved decision-making.",AI-driven decisions | decision support systems | environmental sustainability | generative AI | green supply chain | supply chain sustainability | sustainability performance,0,2025,sustainability,behavior+sustainability
271,2-s2.0-105024448237,10.1108/EL-05-2025-0171,https://doi.org/10.1108/EL-05-2025-0171,https://scholar.google.com/scholar?q=10.1108/EL-05-2025-0171,ar,Electronic Library,"Chong, Sin Er;Looi, Kim Hoe;Shahudin, Faizah","Beyond the prompt: exploring technostress, flow and personality in generative AI behaviors","Purpose – This study aims to investigate the dual psychological responses of users toward generative AI tools, focusing on technostress as a critical stimulus and examining its impact on user flow, continuance intention (CI) and switching intention (SI). It also explores the moderating role of autotelic personality (AP) to understand individual differences in coping with generative AI-induced demands. Design/methodology/approach – Integrating the stimulus-organism-response (SOR) model and flow theory, a three-wave time-lagged survey design was used to mitigate common method bias and capture temporal dynamics in user behavior. Data were collected from 333 valid respondents across three time points. Findings – The results reveal that technostress reduces flow experience and CI while increasing SI. AP significantly moderates these relationships, such that individuals with high autotelic traits demonstrate psychological resilience, maintaining flow and continuance while resisting switching, even under high technostress. Practical implications – The findings yield several valuable practical insights for GenAI developers and digital library designers who integrate GenAI in information services, offering actionable strategies to enhance user engagement, reduce technostress and promote sustainable adoption in information-rich contexts. Originality/value – By embedding flow theory within the SOR framework, this study offers a novel theoretical lens to explain users’ emotional ambivalence in AI-mediated environments. It contributes to emerging scholarship on technostress, intrinsic motivation and post-adoption behavior, responding to recent calls in the Electronic Library for understanding GenAI’s broader implications on digital engagement.",AI | Artificial intelligence | Autotelic personalities | Continuance intentions | Flow theory | GenAI | Generative AI | SOR model | Switching intentions | Technostress,0,2025,sustainability,behavior+sustainability
273,2-s2.0-105024421942,10.1108/K-08-2024-2112,https://doi.org/10.1108/K-08-2024-2112,https://scholar.google.com/scholar?q=10.1108/K-08-2024-2112,ar,Kybernetes,"Feng, Yu;Wang, Zehao;Chen, Yinda;Zhao, Hua",LLM agent driven online auction mechanism for agricultural products,"Purpose – The study aims to address persistent inefficiencies in agricultural product trading—namely, information asymmetry, market opacity, and trading inefficiency—that hinder supply chain profitability and disrupt market stability. It explores how intelligent systems, empowered by large language models (LLMs), can enhance transaction transparency, optimize decision-making, and improve market performance. Design/methodology/approach – This research integrates large-scale language models (LLMs) into an online auction framework through dynamically adaptive intelligent agent systems. These agents simulate real-world market behaviors and leverage machine learning algorithms to enhance auction decision-making. An empirical evaluation is conducted using three experimental groups, with performance assessed across multiple quantitative metrics. Statistical significance is tested using Tukey’s HSD post-hoc analysis. Findings – The results reveal that the LLM-based agent system significantly outperforms the other two benchmark approaches on all performance indicators. The system demonstrates superior capability in mitigating the effects of information asymmetry, improving pricing accuracy, and facilitating more efficient and transparent transactions. Research limitations/implications – Geographic and temporal data limitations may impact generalizability; further research is needed. Practical implications – The proposed model offers actionable insights for designing next-generation online trading platforms in the agricultural sector. By embedding LLMs into intelligent agent systems, market participants—including farmers and buyers—can benefit from enhanced information flow, reduced transaction costs, and more balanced supply-demand interactions. Social implications – Promotes fair transactions, reducing market information asymmetry for sustainable agricultural development. Originality/value – This study is among the first to incorporate LLMs into auction-based agricultural trading systems, demonstrating the transformative potential of AI in reshaping market mechanisms. The research bridges artificial intelligence with smart agriculture, contributing a novel framework that advances both theoretical understanding and practical innovation in digital agriculture and e-marketplace design.",Agricultural supply chain intelligence | Agricultural trading innovation | AI technology application | Intelligent agent systems,0,2025,sustainability,behavior+sustainability
274,2-s2.0-105024418197,10.1108/JOCM-03-2025-0278,https://doi.org/10.1108/JOCM-03-2025-0278,https://scholar.google.com/scholar?q=10.1108/JOCM-03-2025-0278,ar,Journal of Organizational Change Management,"Mutahar, Ahmed M.;Al-Sharafi, Mohammed A.;Shyyab, Yaser;Zouria, Ayoub",Antecedents of sustainable generative AI use among HEIs employees: examining net benefits through the lens of IS success and innovativeness,"Purpose – This study aims to explore and identify key antecedents influencing the sustainable use of Generative artificial intelligence (GenAI) among employees within higher education institutions (HEIs) in the UK, utilizing the DeLone and McLean Information Systems Success Model (DMISSM) extended with the construct of individual innovativeness. Furthermore, it examines the resulting net benefits, including enhanced competence, decision quality and productivity. Design/methodology/approach – A quantitative, cross-sectional research design was adopted. Data were collected from 242 employees working in academic and administrative roles within UK higher education (HE), using an online survey. Partial least squares-structural equation modeling (PLS-SEM) was employed to test the hypotheses and validate the proposed conceptual framework. Findings – The study confirms that system and information quality, user satisfaction and individual innovativeness significantly influence employees' sustainable use of GenAI tools. Sustainable use, in turn, has a substantial positive impact on employees' net benefits, particularly in terms of productivity, competence and decision-making quality. Originality/value – This research makes novel theoretical contributions by integrating innovativeness into the DMISSM, offering fresh insights into GenAI adoption dynamics within HE. Practically, the findings underscore crucial considerations for HEIs aiming to effectively leverage GenAI to improve employee performance and achieve broader Sustainable Development Goals (SDGs).",Generative AI | Higher education institutions | IS success model | Net benefits | Sustainable Development Goals | Sustainable use,0,2025,sustainability,behavior+sustainability
275,2-s2.0-105024258776,10.1177/18479790251399882,https://doi.org/10.1177/18479790251399882,https://scholar.google.com/scholar?q=10.1177/18479790251399882,ar,International Journal of Engineering Business Management,"Ahmed, Quba;Sumbal, Muhammad Saleem;Lee, Carman K.M.",Exploring the role of generative AI to enhance knowledge management capabilities for improved supply chain resilience in large-scale initiatives,"Recently, large-scale projects have become complex, facing frequent disruptions due to geopolitical instability, environmental challenges, and resource limitations, threatening supply chain resilience. Traditional supply chain methods are insufficient for managing these dynamic risks, highlighting the need for innovative strategies. In this context, knowledge management (KM) has played a key role in effective decision-making and operational efficiency, supported by the rapid progress of artificial intelligence, especially Generative AI (GenAI), which enhances organizations’ ability to anticipate, respond to, and recover from supply chain disruptions. This study aims to explore the role of GenAI in improving KM processes to strengthen supply chain resilience (SCR) in large-scale projects. It addresses the gap in integrating GenAI, KM, and SCR in large initiatives. The research uses a qualitative approach, including semi-structured interviews with 23 “elite workers,” Focusing on the China-Pakistan Economic Corridor (CPEC) and document reviews, which were analyzed using CAQDAS ATLAS.ti. The study also employs quantitative analysis to examine challenges and disruptions in CPEC supply chains. According to the dynamic capability view, it proposes a framework that describes how trust and organizational culture moderate the use of GenAI tools to develop approaches and KM processes for enhancing SCR in large-scale initiatives. The research advances theoretical understanding by integrating GenAI into the KM domain and contributes to SCR literature by defining the dynamic capabilities in megaprojects. It is among the earliest studies exploring the impact of GenAI initiatives in mega projects with a focus on supply chain resilience. Practically, it provides actionable insights for policymakers and practitioners to implement the proposed framework, fostering sustainable, resilient supply chains in dynamic environments and ensuring long-term success.",CPEC | dynamic capability view | elite workers | generative AI | knowledge management | megaprojects | organizational culture | supply chain resilience | trust,0,2025,sustainability,behavior+sustainability
277,2-s2.0-105023897989,10.1002/bse.70280,https://doi.org/10.1002/bse.70280,https://scholar.google.com/scholar?q=10.1002/bse.70280,ar,Business Strategy and the Environment,"Bag, Surajit;Rahman, Muhammad Sabbir;Routray, Susmi;Sreedharan, V.  Raja","Human-Centric Generative AI in Circular Supply Chains: Theoretical Insights From Ethics, Dynamic Capabilities, and Resource Conservation","In response to growing calls for ethical, sustainable, and digitally enabled supply chains, this study investigates how the responsible deployment of generative AI (GenAI) enhances circular supply chain performance (CSP). Anchored in ethical theory, the dynamic capability view (DCV), and conservation of resources (COR) theory, we develop a multitheoretic framework examining how firms' digital humanism orientation and procurement innovation mindset shape responsible GenAI use. We further theorize how this responsible GenAI use activates AI-augmented supplier development for circularity (AISD) as a dynamic capability, which mediates the relationship between responsible GenAI use and CSP. Contextual stressors, specifically, polycrisis experience and precarious behavior among supply chain professionals, are introduced as moderators that may undermine these relationships. The model is tested using time-lagged survey data from firms in India and South Africa, analyzed via covariance-based structural equation modeling. Findings support all proposed relationships across both country contexts. The study contributes by (1) extending ethical theory into GenAI-enabled circular supply chains, (2) conceptualizing responsible GenAI use and AISD as firm-level second-order and first-order dynamic capabilities that enhance sustainability outcomes, and (3) revealing how crisis-driven human behavior conditions the efficacy of responsible GenAI in complex supply chain environments. Our results offer actionable insights for building ethically grounded, technologically enabled, and contextually responsive circular supply chains, especially relevant for emerging economies navigating digital transformation under resource constraints.",business strategy | circular supply chain | environment | generative AI | sustainability | technology | value chains,0,2025,sustainability,behavior+sustainability
278,2-s2.0-105022734733,10.1108/SASBE-07-2025-0397,https://doi.org/10.1108/SASBE-07-2025-0397,https://scholar.google.com/scholar?q=10.1108/SASBE-07-2025-0397,ar,Smart and Sustainable Built Environment,"Sequeira, Marisa Martins;Oliveira, Tiago;Neves, Catarina",Adopting generative AI for house design: a multi-stage model of user perception and environmental attitudes,"Purpose – This study aims to explore the factors influencing consumer adoption and purchase intention of generative artificial intelligence (GAI) tools in the context of residential design. It aims to understand how technological, emotional and environmental factors shape user behavior toward emerging artificial intelligence (AI) design technologies. Design/methodology/approach – A stage-based structural model was developed by integrating the artificially intelligent device use acceptance and task-oriented artificial intelligence acceptance frameworks. The model includes technological, psychological and social drivers, with perceived well-being as an emotional outcome and environmental awareness as a moderating variable. Data were collected via an online survey from 304 participants and analyzed using partial least squares structural equation modeling. Findings – Perceived competence, performance expectancy and interaction convenience significantly influence user adoption. Perceived well-being plays a critical role in enhancing purchase intention, while higher effort expectancy is associated with greater inclination to revert to traditional design methods. Environmental awareness moderates several key relationships, reinforcing the role of sustainability in consumer decision-making. Originality/value – This research extends traditional AI adoption models by incorporating emotional outcomes and environmental consciousness. It offers new insights into how consumers evaluate GAI tools for home design and provides practical implications for developers and marketers targeting the sustainable housing sector.",Generative artificial intelligence | House design | Purchase intention | Sustainable housing | Well-being,0,2025,sustainability,behavior+sustainability
280,2-s2.0-105022442423,10.13530/j.cnki.jlis.2025044,https://doi.org/10.13530/j.cnki.jlis.2025044,https://scholar.google.com/scholar?q=10.13530/j.cnki.jlis.2025044,ar,Journal of Library Science in China,"Han, Yi;Li, Jiachen",The Mechanism of Intelligent Outsourcing and Risks Crossing in Information Resources Management,In the historical development of information resources management intelligent outsourcing based on human intelligence has a long history. The flourishing development of artificial intelligence AI especially generative AI has profoundly changed the academic research and work methods in the field of information resources management. As a result intelligent outsourcing mediated by smart devices has emerged on a large scale. It is a historical issue to face the phenomenon of intelligent outsourcing whether based on human intelligence or intelligent devices to enhance the cognitive decision-making. It is also a challenge to analyze the formation mechanism of intelligent outsourcing in-depth and explore its possible risks and risks crossing which the discipline of information resources management urgently needs to address. This article explains from a historical perspective that intelligent outsourcing is an inevitable trend in historical development. The internal mechanism of intelligent outsourcing is analyzed in depth within the disciplinary vision mission and goals of information resources management. Selective dissimilation of information an agent-based retrieval method conducted by professional librarian and information scientists opened the way for intelligent outsourcing mediated by machine devices. Intelligent outsourcing mediated by intelligent devices can be divided into three types 1 information acquisition which provides organized or existing raw materials 2 perceptual computing which provides details of ongoing processes or events and 3 cognitive decision-making which provides problem solutions based on information analysis. With the improvement of intelligence level the iteration of human-machine relationship will shape a new digital civilization inevitably introducing potential technological risks. Based on this some intelligent outsourcing risks such as outsourcing dependency knowledge fragmentation cognitive hollowing subject marginalization and cliff divide are presented. These risks may be caused by the lack and differentiation of knowledge structure and key competencies. Accordingly the risk crossing logic is analyzed from history reality theory and technology and strategies and methods to deal with intelligent outsourcing risks are proposed from subject key ability cultivation and social environment construction. Although intelligent outsourcing mediated by intelligent devices poses spillover risks it is the direction of human civilization evolution and provides new paths and opportunities for maximizing social information welfare. The discipline of information resources management should adhere to the historical tradition keenly grasp the historical development trend and become an active provider and practitioner of intelligent outsourcing products and technologies. It should ensure that the risks of intelligent outsourcing remain under human control in practice guaranteeing its orderly and sustainable development while fostering harmonious coexistence between human and machine intelligence. 1 fig. 21 refs.,Information resources management | Intelligent intermediary | Intelligent outsourcing | Processes mechanism | Risks crossing,0,2025,sustainability,behavior+sustainability
282,2-s2.0-105021642373,10.1080/17543266.2025.2584821,https://doi.org/10.1080/17543266.2025.2584821,https://scholar.google.com/scholar?q=10.1080/17543266.2025.2584821,ar,International Journal of Fashion Design Technology and Education,"Campuzano, Elizabeth Pinon;Chakraborty, Swagata",SustainTima: a task-oriented text-based conversational AI agent for sustainable fast fashion brands,"Due to the innate associations of fast fashion brands with negative environmental and social impacts, these brands are facing scepticism toward the veracity of their sustainability-related claims. Using IBM’s Watson Assistant program, we have developed SustainTima, an artificially intelligent conversational agent that can provide information about a fast fashion brand’s environmental and social sustainability-related policies and initiatives. This is a task-oriented chatbot which is trained to respond to text-based queries related to a fast fashion brand’s sustainability-related policies and initiatives. Although in a prototype stage, SustainTima paves the path for the sustainable fast fashion brands in using chatbots in mitigating scepticism toward the sustainability-related claims of fast fashion brands.",Artificial intelligence | chatbot | environmental sustainability | fast fashion | social sustainability,0,2025,sustainability,behavior+sustainability
284,2-s2.0-105021256883,10.1002/ep.70166,https://doi.org/10.1002/ep.70166,https://scholar.google.com/scholar?q=10.1002/ep.70166,re,Environmental Progress and Sustainable Energy,"Srivastava, Ankur;Meena, Pradeep Kumar;Burande, Chaitanya Girish;Nayak, Chitresh;Wagle, Chandrika S.;Jhalani, Amit","Empowering sustainable energy systems with AI: Opportunities, challenges, and strategic solutions","This article presents a prospective analysis of the application of artificial intelligence (AI), specifically machine learning (ML), in sustainable energy systems. It highlights three significant areas of application: modeling and forecasting, managing energy operations, and detecting faults or unusual activities. As we move toward cleaner, more distributed, and more complex energy systems, new challenges arise—like forecasting demand, coordinating operations, securing energy grids, and planning for the future. AI has the potential to address many of these issues by improving the way we integrate renewable sources, manage energy storage, and detect or prevent system failures, including cyber threats. However, using AI in this field is not without its downsides. For instance, most AI tools need vast data to work well, often lack decision-making transparency, and struggle when applied to new or different situations. To overcome these hurdles, this article proposes four key strategies: (1) creating synthetic energy data using generative AI, (2) combining AI with physical system knowledge to improve reliability, (3) applying AI to manage complex, interconnected energy systems better, and (4) building multi-layered cybersecurity systems powered by AI. Altogether, the article offers a fresh look at how AI might shape the future of energy in a smarter, safer, and more sustainable direction.",artificial intelligence (AI) | cybersecurity in smart grids | energy forecasting and management | machine learning (ML) | renewable energy integration | sustainable energy systems,0,2025,sustainability,behavior+sustainability
289,2-s2.0-105019613750,10.1109/TFUZZ.2025.3621215,https://doi.org/10.1109/TFUZZ.2025.3621215,https://scholar.google.com/scholar?q=10.1109/TFUZZ.2025.3621215,ar,IEEE Transactions on Fuzzy Systems,"Ding, Hong Wei;Chen, Zhen Song;Yang, Yi;Ding, Weiping",Modeling Contexts in Trade-off Total Cost and Customer Satisfaction VRP via Large Language Models,"The Vehicle Routing Problem (VRP) is among the most extensively studied combinatorial optimization problems in operations research. As a critical variant, the Sustainable Vehicle Routing Problem (SVRP) integrates multidimensional cost considerations, including environmental, economic, and social dimensions. When modeling optimization problems, it is crucial to acknowledge that decision-making does not take place in a vacuum or in isolation from reality. Currently, systematic a priori and a posteriori modeling methods based on fuzzy propositions provide conditions for embedding contextual constraints into mathematical models, yet manual construction of such models remains challenging. To address this, this study proposes an automatic modeling method based on large language model (LLM), designs a dedicated prompt template to embed the context constraints, and realizes the output of complete code from natural language input, and meanwhile extends the a priori modeling method to the constrained multi-objective optimization framework to construct a Bi-objective SVRP centered on both customer satisfaction and total cost based on the original SVRP. Experiments are conducted under the sustainability and fairness contexts of decision-makers, drivers, and customers, with ten generation tests performed on four different LLMs, achieving a maximum solvability rate of 0.9 for a single instance; after transferring the optimal results to four data instances, most results still maintain solvability, with true values ranging from near 0 to fully meeting the threshold requirements, and supplementary experiments also analyze differences in parameters, operational costs, and algorithms. Finally, multiple experiments validate the effectiveness of the proposed method and simultaneously reveal the discrepancies introduced by different LLMs and algorithms.",Bi-objective optimization | Decision-making | Fuzzy proposition | Large language model | Modeling contexts,0,2025,sustainability,behavior+sustainability
290,2-s2.0-105018933978,10.3389/fmed.2025.1632925,https://doi.org/10.3389/fmed.2025.1632925,https://scholar.google.com/scholar?q=10.3389/fmed.2025.1632925,ar,Frontiers in Medicine,"Palm, Viktoria;Leutz-Schmidt, Patricia;Mathy, René Michael;Schwaiger, Benedikt Jakob;Kauczor, Hans Ulrich;Jang, Hyungseok;Sedaghat, Sam",Utilization of large language models in decision-making for sustainability in radiology,"Introduction: Radiology has a significant environmental impact, but guidance on how to effectively implement sustainable practices in this field is limited. This study investigated the performance of large language models (LLMs) in providing sustainability advice for radiology. Methods: Four state-of-the-art LLMs, namely ChatGPT-4.0 (CGT), Claude 3.5 Sonnet (CS), Gemini Advanced (GA), and Meta Llama 3.1 405b (ML), were evaluated based on their answers to 30 standardized questions covering sustainability topics such as energy consumption, waste management, digitalization, best practices, and carbon footprint. Three experienced readers rated their response for quality (OQS), understandability (US), and implementability (IS) using a 4-point scale. A mean quality score (MQS) was derived from these three attributes. Results: The overall intraclass correlation was good (ICC = 0.702). Across the 30 questions on sustainability in radiology, all four LLMs showed good to very good performances, with the highest ratings being achieved in understandability (CGT/GA/ML 3.91 ± 0.29; CS 3.99 ± 0.11), underlining the excellent language skills of these models. CS emerged as the top performer across most topics, with an MQS of 3.95 ± 0.22, frequently achieving the highest scores. ML showed the second highest performance with an MQS of 3.84 ± 0.37, followed by CGT with an MQS of 3.78 ± 0.42 and GA with an MQS of 3.73 ± 0.44. Accordingly, CGT and GA showed comparable results, while GA consistently received lower mean scores than the other LLMs. None of the LLMs provided answers that were rated insufficient. Conclusion: Our findings highlight the potential of LLMs such as Claude 3.5 Sonnet, ChatGPT-4.0, Meta Llama 3.1, and Gemini Advanced to advance sustainable practices in radiology, with thoughtful model selection further enhancing their positive impact due to model variations.",ChatGPT | green radiology | large language model | radiology | sustainability,0,2025,sustainability,behavior+sustainability
292,2-s2.0-105018215395,10.1109/ACCESS.2025.3618282,https://doi.org/10.1109/ACCESS.2025.3618282,https://scholar.google.com/scholar?q=10.1109/ACCESS.2025.3618282,ar,IEEE Access,"Syum Gebre, Tewodros;Endale Ashebir, Simachew;Blay, Jeffrey;Anokye, Matilda;Pandey, Venktesh;Hashemi-Beni, Leila",Real-Time Traffic Insights With Physics-Informed Neural Networks: Integrating the Aw-Rascle Model and LLMs,"Traffic congestion and inefficiencies in transportation networks pose significant challenges to road safety, travel times, and environmental sustainability. Traditional traffic management systems, typically reliant on sparse sensor data and rigid models, often fail to provide accurate, reliable, and user-friendly insights. This paper introduces a novel Physics-Informed Neural Network-Based Traffic State Estimator (PINN-TSE), framework that integrates the Aw-Rascle traffic flow model with advanced machine learning and natural language processing (NLP) techniques. By combining physics-informed modeling with data-driven learning, the framework ensures accurate and physically consistent predictions of traffic density and velocity. A multicomponent loss function balances data fidelity with physical constraints, while Large Language Models (LLMs) generate contextualized and interpretable traffic insights through a chat-based web interface. The system is designed to handle diverse user queries from precise spatio-temporal inputs to broad, general inquiries, making it highly adaptable for real-world deployment. Validated on real-world data from the US-101 highway, PINN-TSE demonstrated strong performance in capturing shockwave dynamics and transitions between traffic regimes. It achieved mean absolute errors (MAE) of 2.4 vehicles per mile (vpm) for density and 3.98 mph for velocity, representing improvements of 60% and 73%, respectively, over purely data-driven models. Furthermore, the shockwave speed error was reduced to 8%, significantly improving the reliability of traffic dynamic predictions. The system’s ability to provide actionable insights, such as identifying congestion hotspots and suggesting alternative routes, highlights its practical utility in real-world traffic management. This work makes three key contributions: 1) a robust PINN-TSE framework that embeds physical laws into neural networks, 2) an intuitive LLM-powered interface for real-time traffic interaction, and 3) a demonstration of its effectiveness in real-world settings. By bridging the gap between complex traffic data and human decision-making, this study advances the field of intelligent transportation systems, offering a transformative solution to safer, more efficient, and sustainable traffic management.",adaptive diffusion | adaptive loss function | Aw-Rascle model | driver reaction time | hybrid modeling | intelligent transportation systems | large language model (LLM) | machine learning (ML) | NGSIM dataset | Physics-informed neural network (PINN) | shockwave dynamics | spatio-temporal modeling | traffic flow modeling | traffic information systems | traffic management | traffic state estimation,0,2025,sustainability,behavior+sustainability
293,2-s2.0-105017865519,10.57239/prn.25.03310028,https://doi.org/10.57239/prn.25.03310028,https://scholar.google.com/scholar?q=10.57239/prn.25.03310028,ar,Perinatal Journal,"Tianshu, Wang;Sukumaran, Sheiladevi",Integrating AI-based image generation in design education: A mixed-methods quasi-experimental study on academic performance improvement,"This study investigates the effectiveness of integrating AI-based image generation technologies in illustration design education and their impact on students’ academic performance and creative development. Aligned with Sustainable Development Goal 4 (Quality Education), which emphasizes relevant skills for future employment, this research addresses a critical need to adapt educational practices to evolving technological landscapes. Employing a mixed-methods quasi-experimental design, 100 undergraduate students from a university in Changchun, China, were divided into an experimental group (n=50) and a control group (n=50). Over an eight-week period, the experimental group engaged with tools such as Midjourney, DALL•E, Adobe Illustrator, Photoshop, and ChatGPT to support visual ideation, conceptual development, and creative rendering. In contrast, the control group received conventional instruction with no AI integration, though both groups followed the same curriculum content. Quantitative results revealed a significant increase in academic achievement and creative performance in both groups, but the experimental group showed substantially greater gains. The experimental group’s post-test mean score rose from M = 55.16 (SD = 7.76) to M = 72.42 (SD = 10.37), with a large effect size (Cohen’s d = 3.32), indicating a strong educational impact of AI-based instruction. Qualitative data from student interviews revealed that AI tools improved idea generation efficiency, expanded stylistic exploration, and enhanced confidence in design decision-making. However, students also expressed concerns about potential overreliance on AI and the challenge of maintaining creative authenticity. These findings suggest that AI-assisted learning environments can substantially enrich illustration education when applied thoughtfully. The study underscores the need for pedagogical strategies that integrate technology while preserving the critical, hands-on, and expressive elements central to art and design learning, ultimately contributing to a more equitable and high-quality educational experience for future creative professionals.",Academic performance | Artificial Intelligence | China | Higher education | Illustration design | Quasi-experimental | SDG | Sustainable Development Goals (SDGs),0,2025,sustainability,behavior+sustainability
299,2-s2.0-105017321830,10.1109/ACCESS.2025.3613246,https://doi.org/10.1109/ACCESS.2025.3613246,https://scholar.google.com/scholar?q=10.1109/ACCESS.2025.3613246,re,IEEE Access,"Leiva-Araos, Andrés;Kalasapudi, Vamsi Sai;Jiang, Aiyin;Kaushal, Hemani","Evaluating Smart Building Features for Fire, Electrical, and Life Safety: A Rapid Human-LLM Framework for Literature Review and Research Mapping","The rapid integration of smart technologies into modern buildings is fundamentally transforming fire, electrical, and life safety (FELS) systems. This paper introduces a hybrid Human–Large Language Model (LLM) framework designed to efficiently conduct large-scale literature reviews, systematically map existing research, and identify critical knowledge gaps in smart building safety. Leveraging advanced LLMs for high-throughput summarization, topic modeling, and gap analysis, combined with expert validation, this method ensures both scalability and domain-specific rigor. The study analyzes 1,409 publications retrieved from Scopus, culminating in a refined corpus of 83 high-quality articles categorized into nine thematic clusters, including advanced sensing technologies, automation, enhanced connectivity, digital twins, cybersecurity, standard compliance, sustainability, specialized applications, and decision-making in disaster response. Detailed gap analyses reveal significant challenges related to real-world validation of AI-based systems, interoperability among IoT devices, cybersecurity vulnerabilities, and the need for dynamic evacuation and hazard modeling. The resulting knowledge map and research roadmap provide actionable insights for researchers, practitioners, and policymakers aiming to advance safer, smarter, and more resilient built environments. The proposed framework demonstrates how AI-assisted methodologies can accelerate knowledge synthesis while preserving analytical depth, offering a scalable solution for rapidly evolving interdisciplinary research domains.",AI-assisted literature review | disaster response systems | fire safety | knowledge map | large language models (LLM) | research gap analysis | Smart buildings,0,2025,sustainability,behavior+sustainability
301,2-s2.0-105017173528,10.1108/JIEB-09-2024-0130,https://doi.org/10.1108/JIEB-09-2024-0130,https://scholar.google.com/scholar?q=10.1108/JIEB-09-2024-0130,ar,Journal of International Education in Business,"Molina, Luisa Fernanda Manrique;Ramirez, Camilo Andres;Durán, William Fernando",Navigating the ethical landscape: exploring heteronomous and autonomous strategies in integrating generative AI tools in management education,"Purpose – This study aims to explore the integration of generative artificial intelligence (AI) tools within a mandatory management course in higher education, emphasizing responsible management education (RME) and its alignment with the United Nations Sustainable Development Goals. The research uses Kohlberg’s Theory of Moral Development as a framework for understanding how ethical consistency influences the responsible use of generative AI in educational settings. Design/methodology/approach – A quasi-experimental design was used, involving a sample of 150 business administration undergraduates. The study examined the impact of moral consistency on students’ ethical use of generative AI tools in coursework. Strategies for integrating these tools into instructional design were analyzed, with a focus on promoting autonomous and ethically grounded decision-making. Findings – The research reveals those students with higher levels of moral consistency exhibit more ethical behavior in their use of generative AI. Instructional strategies that emphasize autonomy led to better integration of these technologies in educational contexts. Research limitations/implications – Future research could explore diverse student populations and AI applications in other disciplines. Long-term implications of ethical AI usage on professional practices also warrant further investigation. Practical implications – The findings provide educators with effective strategies for promoting ethical AI use in business education. Originality/value – This study contributes to the discourse on RME by offering actionable strategies for educators to incorporate ethical considerations into their teaching. It highlights the importance of autonomous strategies in preparing students to navigate ethical challenges posed by AI technologies.",Business higher education | ChatGPT | Ethical decision-making | Generative AI | Higher education interventions | Kohlberg’s theory of moral development,0,2025,sustainability,behavior+sustainability
310,2-s2.0-105013784936,10.1109/ACCESS.2025.3600564,https://doi.org/10.1109/ACCESS.2025.3600564,https://scholar.google.com/scholar?q=10.1109/ACCESS.2025.3600564,ar,IEEE Access,"Luo, Jiacheng;Zhang, Kewei;Du, Jiang",Exploring the Impact Mechanism of AIGC-Driven Social Media Marketing Content on Consumer Decision-Making Behavior: A Two-Stage Hybrid Approach,"The swift rise of ChatGPT and the growing integration of AI-generated content (AIGC) technologies are reshaping the digital marketing landscape in profound ways. These advancements are not only changing how social media marketing content is produced, but also altering its underlying characteristics. Despite this shift, there remains a noticeable gap in empirical research on how businesses and brands can effectively harness AIGC to drive consumer engagement. This study draws on the Stimulus-Organism-Response (SOR) theoretical framework to examine how AI-generated content influences consumer cognition, builds trust, and ultimately shapes decision-making behavior. Based on 348 valid survey responses, we employed a mixed-methods approach that integrates Partial Least Squares Structural Equation Modeling (PLS-SEM) with Artificial Neural Network (ANN) analysis. The findings indicate that entertainment, interactivity, trend relevance, electronic word-of-mouth, and visual appeal all positively influence both perceived value and trust. In contrast, customization was found to enhance perceived value only. Both perceived value and trust were shown to significantly increase consumers' purchase intentions. The ANN model further supported the PLS-SEM results, confirming consistency across methods. Among the predictors, entertainment (β =0.176, ni =86.28%) was most influential for perceived value, EWOM (β=0.192, ni =85.94%) played a key role in shaping trust, and perceived value (β =0.344, ni =99.19%) had the strongest impact on purchase intention. These insights contribute to a deeper theoretical understanding of social media marketing and consumer behavior, while also offering actionable recommendations for businesses aiming to refine their content strategies in an AIGC-driven environment. Additionally, the study highlights promising directions for the evolution of digital consumption and the long-term sustainability of brand development.",AI-generated content (AIGC) | artificial neural network (ANN) | purchase intention | social media marketing content (SMMC) | SOR theory,0,2025,sustainability,behavior+sustainability
311,2-s2.0-105013765684,10.1109/ACCESS.2025.3599922,https://doi.org/10.1109/ACCESS.2025.3599922,https://scholar.google.com/scholar?q=10.1109/ACCESS.2025.3599922,re,IEEE Access,"Amjad, Furqan;Korotko, Tarmo;Rosin, Argo",Review of LLMs Applications in Electrical Power and Energy Systems,"This paper presents a comprehensive review of the applications, challenges, and future directions of Large Language Models (LLMs) in the Electrical Power Domain (EPD). Leveraging transformer-based architectures such as GPT, BERT, and LLaMA, LLMs have shown transformative potential across power system applications including load forecasting, fault diagnosis, regulatory compliance, question answering, risk assessment, and intelligent data analysis. Through a systematic analysis of over 45 studies, the review highlights measurable benefits such as up to 20% improvement in load forecasting accuracy, 30% reduction in operational response time, and 40% decrease in manual workload for regulatory tasks. LLMs have demonstrated strong adaptability through zero-shot and few-shot learning and are capable of processing multimodal inputs for real-time decision-making. However, limitations such as high computational costs, lack of domain-specific datasets, limited explainability, and concerns around regulatory alignment hinder widespread deployment. To address these gaps, the paper outlines research opportunities including domain-specific fine-tuning, scalable deployment strategies, multimodal integration, and the development of unified benchmarks such as ElecBench. Overall, the integration of LLMs in power systems represents a significant step toward more intelligent, reliable, and sustainable energy management.",Artificial intelligence | electrical power domain | fault diagnosis | grid management | large language models | load forecasting | natural language processing | power systems | predictive analytics | renewable energy integration | smart grids | transformer models,0,2025,sustainability,behavior+sustainability
329,2-s2.0-105005978146,10.3389/frsc.2025.1571613,https://doi.org/10.3389/frsc.2025.1571613,https://scholar.google.com/scholar?q=10.3389/frsc.2025.1571613,ar,Frontiers in Sustainable Cities,"Constant, Axel;Albarracin, Mahault;Perin, Marco;Thiruvengada, Hari;Friston, Karl J.",Agentic rulebooks using active inference: an artificial intelligence application for environmental sustainability,"Artificial intelligence (AI) is increasingly proposed as a solution to environmental sustainability challenges, with applications aimed at optimizing resource utilization and energy consumption. However, AI technologies also have significant negative environmental impacts. This duality underscores the need to critically evaluate AI's role in sustainable practices. One example of AI's application in sustainability is the Occupant Controlled Smart Thermostat (OCST). These systems optimize indoor temperature management by responding to dynamic signals, such as energy price fluctuations, which reflect power grid stress. Accordingly, regulatory frameworks have mandated performance standards for such technologies to ensure effective demand responsiveness. While OCSTs are effective in managing energy demand through predefined norms like price signals, their current designs often fail to accommodate the complex interplay of conflicting priorities, such as user comfort and grid optimization, particularly in uncertain climatic conditions. For instance, extreme weather events can amplify energy demands and user needs, necessitating a more context sensitive approach. This adaptability requires OCSTs to dynamically shift between multiple normative constraints (i.e., norms), such as prioritizing userdefined temperature settings over price-based energy restrictions when contextually appropriate. In this paper, we propose an innovative approach that combines the theory of active inference from theoretical neuroscience and robotics with a rulebook formalism to enhance the decision-making capabilities of autonomous AI agents. Using simulation studies, we demonstrate how these AI agents can resolve conflicts among norms under environmental uncertainty. A minimal use case is presented, where an OCST must decide whether to warm a room based on two conflicting rules: a “price” rule that restricts energy use above a cost threshold and a “need” rule that prioritizes maintaining the user's desired temperature. Our findings illustrate the potential for advanced AI-driven OCST systems to navigate conflicting norms, enabling more resilient and user-centered solutions to sustainable energy challenges.",active inference | artificial intelligence | environmental sustainability | internet of things | Occupant Controlled Smart Thermostat,0,2025,sustainability,behavior+sustainability
331,2-s2.0-105004992414,10.12720/jait.16.4.594-612,https://doi.org/10.12720/jait.16.4.594-612,https://scholar.google.com/scholar?q=10.12720/jait.16.4.594-612,ar,Journal of Advances in Information Technology,"Nguyen, Lan T.K.;Connolly, James;Nguyen, Hoa N.",A Systematic Review of Improving Knowledge Management with Generative AI and Large Language Models,"The development of Generative Artificial Intelligence (GAI) and Large Language Models (LLMs) has transformed the field of Knowledge Management (KM) by enabling precision in transferring knowledge as well as improving decision-making processes and operational efficiency. This paper systematically reviews 58 peer-reviewed publications from 2019 to early 2024 to comprehensively understand how these technologies impact knowledge management practices across numerous industries. The roles of GAI and LLMs were examined by using the Prisma methodology. VOSviewer and Power BI were used to visualize and analyze the data. Our research identified impacts and identified related gaps, including the need for advanced anonymities of techniques, AI-related technology development, and robust ethical mechanisms. In detail, trust emerges as a key factor that impacts and encompasses technological, organizational, and interpersonal dilemmas to empower knowledge management processes. This review emphasizes the crucial importance of strategic data management and cross-disciplinary approaches in addressing and responding to existing challenges. By bridging the gaps in ethics and trust-building in the practical adoption of these technologies, organizations can utilize GAI and LLMs to create an impactful and transparent KM system while maintaining sustainable and inclusive KM practices. Further, this paper provides a detailed investigation on the transformative potential of GAI and LLMs in KM and proposes strategies for future research to address existing gaps and optimize and broaden the fields of applications.",Generative Artificial Intelligence (GAI) | Knowledge Management (KM) | knowledge sharing | Large Language Models (LLMs),0,2025,sustainability,behavior+sustainability
356,2-s2.0-85208417057,10.36961/si32432,https://doi.org/10.36961/si32432,https://scholar.google.com/scholar?q=10.36961/si32432,ar,Zuckerindustrie,"Murugaiah, Mahesh Kumar",Knowledge management using large language models in sugar industry,"The sugar industry faces the dual challenge of an aging workforce and the pressing need to digitize operations for enhanced efficiency. The traditional knowledge, accrued over decades, risks being lost if not effectively transferred to the newer generations, while the industry's modernization beckons a digital overhaul. Harnessing Large Language Models (LLMs) like Llama3, Gemma2, and GPT-4o for Retrieval Augmented Generation (RAG) emerges as a viable solution to address these challenges. By encapsulating the veteran expertise in a digital framework and making it read-ily accessible through RAG, a seamless knowledge transfer is facilitated. Concurrently, the digitalization of operational processes is accelerated, fostering a culture of data-driven decision-making and innovation. The application of LLM for RAG not only ensures the preservation and accessibility of critical industry knowledge but also positions the sugar industry on a modernization trajectory, promising enhanced operational efficiencies, sustainability, and a competitive edge in the evolving market landscape.",digitization | GenAI | knowledge management | LLM | RAG,0,2024,sustainability,behavior+sustainability
1,2-s2.0-105026891685,10.1016/j.techsoc.2026.103219,https://doi.org/10.1016/j.techsoc.2026.103219,https://scholar.google.com/scholar?q=10.1016/j.techsoc.2026.103219,ar,Technology in Society,"Laviola, Francesco;Cucari, Nicola",From promise to concern: Public perceptions of AI in ESG frameworks over time,"This study investigates how public sentiment toward Artificial Intelligence (AI) has evolved at the intersection of Environmental, Social, and Governance (ESG) frameworks and the rising field of Corporate Digital Responsibility (CDR) over the past 25 years. Drawing on a dataset of 33,628 news articles published between 2000 and 2025, we conduct a large-scale longitudinal sentiment analysis to identify discursive patterns in the perception of AI's role across the ESG dimensions. Our findings reveal substantial variation across the three pillars. While sentiment toward AI in governance contexts shows a consistently positive trend, associated with increased expectations for transparency, monitoring, and compliance, environmental sentiment exhibits a sharp downturn after 2022, reflecting concerns over the carbon footprint of generative AI technologies. The social dimension displays fluctuating sentiment, influenced by debates on automation, fairness, and ethical accountability. These differentiated trajectories suggest that AI legitimacy is a domain-specific and socially negotiated construct, rather than a uniform outcome of technological advancement. Public discourse, as captured in news media, functions as an anticipatory indicator of emerging regulatory tensions and reputational risks, offering valuable foresight for corporate and institutional decision-makers. This study contributes to the literature on technology and society by highlighting the role of sentiment dynamics in shaping AI governance and sustainability strategies. It provides both theoretical insights into the social construction of technological legitimacy and practical implications for the design of responsive, context-sensitive ESG policies in the age of digital transformation.",Artificial intelligence | Corporate digital responsibility | Corporate governance | ESG | Natural language processing | Sentiment analysis,0,2026,sustainability,policy+sustainability
2,2-s2.0-105024239626,10.1007/s40558-025-00352-0,https://doi.org/10.1007/s40558-025-00352-0,https://scholar.google.com/scholar?q=10.1007/s40558-025-00352-0,ar,Information Technology and Tourism,"Carić, Hrvoje;Mandić, Ante;Sever, Ivan",A six-phase AI-expert framework for evaluating policy coherence in sustainable tourism,"This study introduces a six-phase AI–expert evaluation framework, grounded in computational interpretivism, to assess the coherence between national and international sustainable tourism policies, using the Croatian Strategy for Sustainable Tourism as a case study. Leveraging Anthropic Claude 3.5 Sonnet, a state-of-the-art generative AI model, the framework integrates natural language processing, vector-based similarity search, and expert validation to extract key policy areas, formulate evaluation questions, and assess alignment with the European Union’s principal tourism policy documents: the Transition Pathway for Tourism, European Agenda for Tourism 2030, and EU Strategy for Sustainable Tourism. The analysis produced a validated set of 68 binary and 27 qualitative evaluation questions, developed through iterative AI–expert collaboration and verified through quantitative similarity measures (Jaccard coefficients of 0.714 for key areas and 0.904 for topics). Three domain experts independently validated all phases, achieving substantial inter-rater reliability (Fleiss’ κ = 0.717). Results confirm that AI can substantially enhance efficiency, scalability, and transparency in policy analysis, while expert oversight remains indispensable for contextual interpretation, ethical validation, and policy relevance. The study advances theoretical understanding of hybrid human–AI epistemologies and contributes a replicable, auditable model for policy coherence evaluation in complex governance systems. Beyond tourism, the framework demonstrates how AI-assisted analysis can strengthen evidence-based policymaking, supporting adaptive governance and cross-level policy alignment in sustainability-driven sectors.",AI-driven policy analysis | Generative artificial intelligence | Human-AI collaboration | Multi-level governance | National and international policy alignment | Policy coherence | Tourism governance,0,2026,sustainability,policy+sustainability
3,2-s2.0-105027395087,10.1016/j.ins.2026.123084,https://doi.org/10.1016/j.ins.2026.123084,https://scholar.google.com/scholar?q=10.1016/j.ins.2026.123084,ar,Information Sciences,"Kmiecik, Mariusz","Integrating third-party logistics (3PL), forecast accuracy and emission management in triadic supply chains − a large language model-based approach","This article presents an innovative and sustainable approach to enhancing triadic collaboration in supply chains by integrating forecast accuracy and transport emission management with the support of Large Language Models (LLMs). The study analyzed operational, forecasting, and environmental data from 22 triads managed by a single 3PL provider over a three-month period. The Gemini model was applied to detect anomalies, generate strategic recommendations, and support SQL-based data aggregation, enabling a holistic assessment of triadic structures. The results demonstrate that closed and concentred triads are associated with higher forecast accuracy, while forecast quality alone does not directly determine emission efficiency. The LLM successfully identified hidden inefficiencies and suggested structural transformations, such as shifting from derived to concentred or from open to closed triads, which were positively validated by an expert panel. The findings are interpreted through Resource-Based View, Dynamic Capabilities, and Network Governance, highlighting that LLMs function not only as analytical tools but also as integrators of resources and coordination mechanisms. The study contributes to theory by bridging forecasting, sustainability, and governance perspectives, and to practice by offering actionable guidelines for logistics managers. While limited by its single-case scope and the absence of financial data, the research provides a replicable methodological framework and opens avenues for applying LLMs in managing both operational performance and sustainability in supply chains.",Artificial intelligence | Dynamic capabilities | Gemini | Network governance | Resource-based view | Third-party logistics (3PL) | Triadic collaboration,0,2026,sustainability,policy+sustainability
5,2-s2.0-105025722014,10.1016/j.techfore.2025.124498,https://doi.org/10.1016/j.techfore.2025.124498,https://scholar.google.com/scholar?q=10.1016/j.techfore.2025.124498,ar,Technological Forecasting and Social Change,"Sun, Zhe;Liu, Lei;Zhao, Liang;Alofaysan, Hind;Gupta, Bhumika",Generative AI and ESG opportunism in supply chains: A utilitarian perspective on unintended consequences for sustainability,"Existing research has overwhelmingly emphasized the positive effects of generative artificial intelligence (AI) on corporate environmental, social, and governance (ESG) performance, while largely neglecting the risk of dimensional imbalance in ESG resource allocation and its potential contagion across supply chains. Drawing on utilitarian theory, this study introduces the novel concept of ESG opportunism and empirically examines the impact of generative AI adoption on its emergence and intensity. Results show that generative AI significantly heightens firms' opportunistic ESG behavior by increasing agency costs and weakening internal controls. This relationship is further amplified by stringent government environmental regulations and strong green investor preferences yet attenuated by greater analyst attention and higher-quality information disclosure. Moreover, a clear supply chain spillover effect is identified: generative AI adoption by focal firms transmits and intensifies ESG opportunism among both upstream suppliers and downstream customers. By challenging the dominant optimistic narrative surrounding generative AI's ESG implications, this study offers timely and critical insights for establishing responsible generative AI governance throughout global supply chains.",ESG opportunism | Generative AI | Supply chain spillover | Utilitarian theory,0,2026,sustainability,policy+sustainability
7,2-s2.0-105025170397,10.1016/j.array.2025.100592,https://doi.org/10.1016/j.array.2025.100592,https://scholar.google.com/scholar?q=10.1016/j.array.2025.100592,ar,Array,"Albaroudi, Elham;Mansouri, Taha;Hatamleh, Mohammad;Alameer, Ali","HitHire: The future of ethical, fair, and sustainable AI recruitment – A governance framework","Artificial Intelligence (AI) is transforming recruitment but remains susceptible to algorithmic bias and environmental inefficiencies. This paper presents HitHire, a pilot fairness- and sustainability-aware AI hiring platform tailored to the Saudi Arabian context and aligned with Vision 2030 goals. HitHire integrates large language models (LLMs), adversarial debiasing, Shapley Additive Explanations (SHAP), and real-time carbon tracking to ensure transparent and equitable candidate ranking. Evaluated on 350 anonymized CVs across four job roles (web development, finance, human resources, and data science) using a 70/20/10 train/test/validation split, HitHire achieves notable improvements in fairness metrics—Statistical Parity Difference (SPD) for gender = 0.0156 and Disparate Impact (DI) for nationality = 1.2387—while maintaining strong predictive performance (F1 = 0.96 compared to a baseline of 0.80). The system achieves over a 40% reduction in operational CO<inf>2</inf> emissions, with inference energy consumption of 0.003 kWh per query. In a three-month pilot study involving 23 HR professionals within a large Saudi organization, 87% of participants rated system trust at 4 out of 5 or higher. These findings contribute to national digital ethics strategies such as the Saudi Green Initiative, which emphasizes carbon neutrality and sustainable innovation.",Adversarial Debiasing | AI governance | Algorithmic Bias | Ethical recruitment | Explainable AI | Fairness in AI | Human-in-the-Loop systems | Saudi Vision 2030 | SHAP explainability | Sustainable AI,0,2026,sustainability,policy+sustainability
8,2-s2.0-105025052344,10.1016/j.sca.2025.100188,https://doi.org/10.1016/j.sca.2025.100188,https://scholar.google.com/scholar?q=10.1016/j.sca.2025.100188,re,Supply Chain Analytics,"Bahroun, Zied;Saihi, Afef;As'ad, Rami;Tanash, Moayad",A systematic analysis of generative artificial intelligence for supply chain transformation,"Global supply chains face persistent disruptions from geopolitical shocks, sustainability pressures, and volatile demand, creating an increasing need for resilient and transparent operations. Generative Artificial Intelligence (GAI), including Large Language Models (LLMs), Generative Adversarial Networks (GANs), and multimodal generative systems, is emerging as a new decision layer that can generate scenarios, synthetic data, and actionable textual insights rather than only point predictions. This Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA)-guided systematic review analyzes 98 peer-reviewed studies on GAI applications in Supply Chain Management (SCM) and, to the best of the authors’ knowledge, provides the first combined thematic and Supply Chain Operations Reference (SCOR) model-based mapping of these applications. Publication activity shows a sharp upward trend, with fewer than five papers published before 2021 and 45 published in 2024 alone. Nearly four-fifths of the reported applications focus on the Plan and Enable processes, while the Make and Return processes account for only 4 % and 1 % of the coded functions, respectively. Although LLM- and Generative Pre-trained Transformer (GPT)-based models underpin over 40 % of the implementations, approximately 45 % of the studies do not fully specify their underlying architectures, indicating methodological immaturity. Reported benefits are concentrated in demand forecasting and risk analysis, supplier screening, logistics visibility, and sustainability analytics; however, most evidence remains at the prototype level and rarely reports system-wide Key Performance Indicators (KPIs). The review concludes with a targeted research agenda that emphasizes longitudinal evaluation, hybrid GAI-driven optimization with digital twin architectures, and governance-by-design frameworks to support the responsible and scalable adoption of GAI in supply chains.",Decision support system | Digital transformation | Generative artificial intelligence | Predictive planning | Supply chain management | Sustainable supply chains,0,2026,sustainability,policy+sustainability
10,2-s2.0-105022610104,10.1016/j.compenvurbsys.2025.102380,https://doi.org/10.1016/j.compenvurbsys.2025.102380,https://scholar.google.com/scholar?q=10.1016/j.compenvurbsys.2025.102380,re,Computers Environment and Urban Systems,"Wang, Yan;Fu, Yanjie;Lyles, Ward",Generative AI for spatial regeneration planning: Integrating urban planning theories and ethics,"Generative Artificial Intelligence (GenAI) is rapidly emerging as a promising tool for urban planning, particularly spatial regeneration planning (SRP) aimed at ongoing redevelopment in urban areas. Driven by increasing availability of urban spatial data and a strong interest in technological innovation, GenAI models can generate diverse, context-sensitive planning scenarios beyond the limits of conventional approaches. However, the application of GenAI to SRP also raises pressing concerns: Are planning problems appropriately defined and rigorously modeled? How closely do model design and data processing align with established planning theories and ethics? What strategies can mitigate the risk of perpetuating spatial disadvantages embedded in historical data? How do we meaningfully evaluate GenAI's real-world impact? And how can GenAI be governed to ensure equity, transparency, and meaningful collaboration among all planning stakeholders? This Review critically assesses the intersection of SRP theories and GenAI, identifying key vulnerabilities along the modeling process, from problem formulation and data selection to model training, evaluation, and governance. We propose key technical pathways for developing GenAI-based SRP that are grounded in planning theories and ethics, aiming to advance both the rigor and societal relevance of spatial planning research for sustainable, smart, and resilient cities.","Generative artificial intelligence | Spatial planning | Sustainable, smart and resilient cities | Urban analytics | Urban regeneration",0,2026,sustainability,policy+sustainability
12,2-s2.0-105017475128,10.1177/10659129251381778,https://doi.org/10.1177/10659129251381778,https://scholar.google.com/scholar?q=10.1177/10659129251381778,ar,Political Research Quarterly,"Cayton, Adam;Crisher, Brian Benjamin","Disaster, Distributive Politics, and the Persistence of Partisan Divides in Climate Policy","Can district interests mitigate partisan differences over climate policy? While debates over climate policy are highly partisan, local economic and national defense interests may create cross-cutting pressures that reduce polarization. Here, we analyze whether district characteristics mitigate partisan differences on climate change, particularly public opinion and exposure of military installations to weather-related damage. Using two studies—one using a large language model to measure the positions lawmakers take in congressional email newsletters and another employing a survey experiment testing framing effects—we assess whether national defense and economic concerns mitigate partisan divisions. Our findings suggest that Republicans representing districts where severe weather events threaten local military infrastructure express more support for “pro-climate” policy than other Republicans, and that Democrats representing environmentally conservative districts express less support. However, our experiment found no evidence that the issue frame influences voters’ opinions.",climate policy | congress | disaster risk | framing | polarization | political communication,0,2026,sustainability,policy+sustainability
17,2-s2.0-105023114437,10.1016/j.copsyc.2025.102216,https://doi.org/10.1016/j.copsyc.2025.102216,https://scholar.google.com/scholar?q=10.1016/j.copsyc.2025.102216,re,Current Opinion in Psychology,"Hornsey, Matthew J.;Smith, Aimee E.;Pearson, Samuel;Bretter, Christian;Nylund, Jarren L.",Using conversational AI to reduce science skepticism,"Mistrust of the scientific consensus around issues such as climate change and vaccination is mainstream, compromising our ability to respond to existential global threats. In the wrong hands, Generative AI can spread misinformation with unprecedented scale and psychological sophistication. However, large language models (LLMs) have also shown considerable promise for reducing misinformation and conspiracy theories, potentially revolutionizing science communication. This review summarizes the rapidly evolving frontier of empirical research on how conversational AI such as ChatGPT can be used to defuse mistrust of science around hot-button scientific issues. These studies find negligible evidence that LLM responds to human queries by reproducing conspiracy theories or misinformation about scientific topics. Rather, conversations with LLMs typically reduce participants’ levels of science skepticism and misinformation endorsement. We conclude that LLMs (in their current form) have potential to complement existing science communication strategies, provided their use is accompanied by safeguards that preserve informational integrity and public trust.",,0,2026,sustainability,policy+sustainability
20,2-s2.0-105027426172,10.3390/su18010236,https://doi.org/10.3390/su18010236,https://scholar.google.com/scholar?q=10.3390/su18010236,ar,Sustainability Switzerland,"Jakubczak, Jacek Krzysztof;Chmielewska-Muciek, Dorota;Iwanicka, Katarzyna","Evaluating Multimodal AI for Greenwashing Detection: A Comparative Analysis of ChatGPT, Claude, and Gemini in ESG Reports","The rapid expansion of sustainability reporting under the EU Corporate Sustainability Reporting Directive (CSRD) has intensified concerns about greenwashing, particularly in visual communication within ESG reports. Recent advances in multimodal artificial intelligence offer new possibilities for automated detection, yet their reliability in non-English corporate reporting contexts remains unclear. This study evaluates the greenwashing detection capabilities of three leading multimodal AI systems—ChatGPT 5.1, Claude 4.5 Sonnet, and Gemini 2.5 Flash—using a purposively selected sample of 20 Polish ESG reports benchmarked against ESRS-aligned performance scores from the national “Ranking ESG”. A standardized auditing prompt was applied across all tools to generate comparable assessments of visual greenwashing. Contrary to theoretical expectations and all four hypotheses, the models did not demonstrate negative correlations between performance and AI-detected greenwashing; instead, high-performing firms frequently received higher greenwashing scores. Dimensional analyses showed inconsistent and often contradictory evaluations across Environmental, Social, and Governance pillars, while inter-tool reliability proved extremely low (Krippendorff’s α ≈ 0). These findings indicate that current multimodal AI systems conflate communication sophistication with deceptive intent and lack sufficient contextual understanding for ESG assurance. The study highlights significant methodological limitations and outlines directions for developing domain-specific, ESRS-aligned AI tools for greenwashing detection.",automated auditing | ESG communication | greenwashing | multimodal AI | sustainability reporting,0,2026,sustainability,policy+sustainability
21,2-s2.0-105027253113,10.1177/14648849261416556,https://doi.org/10.1177/14648849261416556,https://scholar.google.com/scholar?q=10.1177/14648849261416556,ar,Journalism,"Dragomir, Marius;Nemeth, Robert","Buying time, not markets: The limits of donor funding in Hungary’s captured media system","Independent journalism faces converging pressures from media capture, volatile donor priorities, and platform-driven markets accelerated by generative AI. This article presents 5 years (2020–2025) of first-hand evidence from a donor-funded program to support journalism in Hungary that combined core funding, mentoring, and organizational development for independent local outlets. A longitudinal mixed-methods design disaggregates sustainability into money (revenue diversity, cash flow), management (absorptive capacity, governance, leadership), and market position (audience growth, brand trust, sales capability). Findings show that philanthropic funding is only conditionally conducive to sustainability under capture. Grants enabled survival, professionalization, and audience gains, but rarely produced durable revenue diversity in markets distorted by politicized state advertising, advertiser risk-aversion, and low willingness to pay for news. The program’s clearest contributions were transitional: financing operational and managerial upgrades, supporting product and audience experiments, and providing temporary insulation from hostile conditions. These gains materialized primarily where absorptive capacity and leadership were already strong. Donor-backed networking delivered only partial results, and abrupt donor exit exposed the fragility of post-grant trajectories. The overarching lesson is that donor intervention must be understood as a long-term investment in a difficult-to-visualize public good, namely democratic resistance and opposition, that yields indirect civic returns and, over time, creates the preconditions for tangible market and policy change. Anything less will fail to achieve meaningful or lasting impact.",financing | Journalism | media competition | media financing | media management | news media | regulation,0,2026,sustainability,policy+sustainability
31,2-s2.0-105015139846,10.1016/j.jss.2025.112599,https://doi.org/10.1016/j.jss.2025.112599,https://scholar.google.com/scholar?q=10.1016/j.jss.2025.112599,ar,Journal of Systems and Software,"Moreschini, Sergio;Arvanitou, Elvira Maria;Kanidou, Elisavet Persefoni;Nikolaidis, Nikolaos;Su, Ruoyu;Ampatzoglou, Apostolos;Chatzigeorgiou, Alexander;Lenarduzzi, Valentina",The Evolution of Technical Debt from DevOps to Generative AI: A multivocal literature review,"Background: The rapid integration of Artificial Intelligence (AI) – including Machine Learning (ML) and Generative AI – into software systems is reshaping the software development lifecycle. As AI-driven systems become more dynamic and complex, traditional approaches to Technical Debt (TD) management face increasing limitations. Simultaneously, AI-assisted development introduces new forms of TD, particularly in relation to maintainability, explainability, and data governance. Objective: This study aims to explore how Technical Debt Management (TDM) must adapt in the context of AI-enhanced software development. It investigates (1) the evolution of TD in AI-driven systems, and (2) the implications of using AI technologies within the software engineering process. Methods: We conducted a multivocal literature review, combining insights from both peer-reviewed research and industry sources. Following established guidelines, we systematically analyzed 61 primary sources, categorized TD types and management activities, and identified key challenges and practices emerging in the AI era. Results: Our findings reveal that data-related, infrastructure, and pipeline-related TD are particularly prevalent in ML systems. Machine Learning Operations (MLOps) practices are increasingly recognized as essential for managing such debt, especially in relation to dynamic data dependencies and model retraining. In parallel, AI-generated artifacts and automated pipelines introduce new governance and maintainability challenges. Conclusion: Technical Debt in AI systems demands continuous, automated, and cross-functional management strategies. As software evolves in response to data and usage, new operational paradigms – grounded in practices like MLOps and Small Language Model Operations (SLMOps) – will be vital to ensure long-term software sustainability. This study provides a foundational map for researchers and practitioners navigating the intersection of AI and TD management.",Multivocal literature review | Technical debt,0,2026,sustainability,policy+sustainability
34,2-s2.0-105026510088,10.29121/shodhkosh.v6.i2s.2025.6742,https://doi.org/10.29121/shodhkosh.v6.i2s.2025.6742,https://scholar.google.com/scholar?q=10.29121/shodhkosh.v6.i2s.2025.6742,ar,Shodhkosh Journal of Visual and Performing Arts,"Sharma, Tripti;Jabez, J.;Agarwal, Varsha;Sachdeva, Ankit;Velvizhi, K.;Kaur, Ashmeet",MANAGEMENT OF INTELLECTUAL PROPERTY IN AI-GENERATED ARTWORKS,"The recent rapid evolution of AI-generated artworks has provoked the essence of creativity and raised challenging questions concerning the manner in which intellectual property (IP) is understood, obtained, and implemented under the circumstances of the human-machines cooperation. The paper shall discuss the evolving character of authorship, ownership, and creative input concerning the generative AI systems and how the traditional mechanisms of copyright occasionally fail to work in favor as far as the algorithmically generated material is concerned. The questions of ambiguity in relation to human intervention in prompt-based generation, the obscurity of the position of training data on the generation products, and the impossibility to make a distinction between the concepts of inspiration, derivation, and infringement on machine-generated forms are the key ones. These concerns are compounded by ethical concerns particularly where there is no consent in the dataset on the use of copyrighted content or culturally sensitive content. In the paper, the new risk-reduction strategies, including the transparency of datasets, provenance records, watermarking systems, and hybrid licensing systems that apportion rights by the layers of contributor of builders, users, and platforms, are addressed. The paper will outline the legal, ethical, and technical considerations of the issue by saying that sustainable AI art IP management should be based on the multi-disciplinary approach that would guarantee the innovation and equitability, as well as maintain cultural respect and safeguard the inventors. The findings indicate that there is a need to have single global standards, consentual data regulations and future-oriented legal definitions that are befitting to capture the fact of the human-AI co-creation. Together, these solutions would offer a path to an IP framework that would assist in supporting the expanding creative frontier that is being established by AI technologies.",AI-Generated Art | Authorship | Copyright Law | Data Ethics | Dataset Governance | Licensing Frameworks | Platform Policy | Provenance Tracking,0,2025,sustainability,policy+sustainability
35,2-s2.0-105022181032,10.1016/j.scs.2025.106994,https://doi.org/10.1016/j.scs.2025.106994,https://scholar.google.com/scholar?q=10.1016/j.scs.2025.106994,ar,Sustainable Cities and Society,"Cheng, Mingjun;Jin, Hong;Zhao, Qinfeng;Wang, Yurun;Wu, Yanxi;Huang, Shan;Yue, Wenze","Deep learning for optimizing urban governance by ""sensing-processing-responding"" cycle: Recent advances, future prospects and challenges","With accelerating urbanization, traditional governance models are increasingly strained. Deep learning (DL) offers powerful solutions, but its application in urban governance lacks a systematic framework and faces significant hurdles. This paper addresses these gaps through a systematic review of 329 articles published from 2016 to 2025. We introduce a novel Sensing-Processing-Responding framework to classify the technological pathways of DL in urban governance. This framework organizes applications into three core stages: (1) Sensing technologies (e.g., CNNs) for dynamic data acquisition; (2) Processing technologies (e.g., RNNs, Transformers) for predictive modeling and analysis; and (3) Responding technologies (e.g., LLMs) for automated decision support. Our analysis reveals that while DL is widely applied in traffic forecasting, environmental monitoring, and disaster response, its deployment is constrained by key challenges. We found a significant gap between research and practice, with only 7.6% of studies demonstrating real-world application. Furthermore, it concerns data privacy and model interpretability limit public acceptance, although our review indicates that fewer than 10% of studies involve high-risk personal data. Future progress depends on integrating emerging technologies like multimodal large models and multi-agent systems. We conclude by advocating for a paradigm shift from focusing purely on accuracy to prioritizing public value, fairness, and transparency. This study provides a comprehensive roadmap for developing more intelligent, resilient, and sustainable urban governance systems.",Deep learning | Large models | Literature review | Sensing-Processing-Responding framework | Sustainable development | Urban governance,0,2025,sustainability,policy+sustainability
41,2-s2.0-105026076871,10.3390/jtaer20040284,https://doi.org/10.3390/jtaer20040284,https://scholar.google.com/scholar?q=10.3390/jtaer20040284,ar,Journal of Theoretical and Applied Electronic Commerce Research,"Lou, Liguo;Jiao, Yongbing;Koh, Joon;Dai, Weihui",Exploring the Drivers of Content Entrepreneurs’ Compliance with Generative AI Policies: A Mixed-Methods Approach,"Social media-based content entrepreneurship is evolving rapidly and emerging as a significant and growing form of employment. Generative AI (GenAI) offers content entrepreneurs a powerful tool for content creation; however, the technology can be abused to produce deepfakes, rumors, plagiarism, and other injurious content. This triggers value co-destruction across the creator economy and society, making it particularly crucial to enhance content entrepreneurs’ compliance with GenAI policies. Aiming to develop an effective governance framework, this study adopts a mixed-methods approach, beginning with exploratory interviews to uncover factors affecting GenAI policy compliance intention. Subsequently, it employs confirmatory quantitative research with a survey to validate the proposed research model. The results indicate that both the deterrence triad (i.e., perceived sanction certainty, severity, and celerity) and perceived social norm strengthen GenAI policy compliance intention. Meanwhile, perceived social norm weakens the impact of perceived sanction certainty on policy compliance intention. Furthermore, peer communication enhances policy compliance intention by increasing perceptions of sanction certainty and celerity as well as social norm. These findings contribute to the sustainable development of content entrepreneurship and effective GenAI governance, fostering a symbiotic creator economy.",content entrepreneurship | deterrence theory | GenAI abuse | mixed-methods approach | peer communication | perceived social norm | policy compliance intention,0,2025,sustainability,policy+sustainability
42,2-s2.0-105025969078,10.3390/forecast7040061,https://doi.org/10.3390/forecast7040061,https://scholar.google.com/scholar?q=10.3390/forecast7040061,ar,Forecasting,"Chao, Yu;Elias, Nur Fazidah;Yahya, Yazrina;Jenal, Ruzzakiah",Research on Dynamic Hyperparameter Optimization Algorithm for University Financial Risk Early Warning Based on Multi-Objective Bayesian Optimization,"Financial sustainability in higher education is increasingly fragile due to policy shifts, rising costs, and funding volatility. Legacy early-warning systems based on static thresholds or rules struggle to adapt to these dynamics and often overlook fairness and interpretability—two essentials in public-sector governance. We propose a university financial risk early-warning framework that couples a causal-attention Transformer with Multi-Objective Bayesian Optimization (MBO). The optimizer searches a constrained Pareto frontier to jointly improve predictive accuracy (AUC↑), fairness (demographic parity gap, DP_Gap↓), and computational efficiency (time↓). A sparse kernel surrogate (SKO) accelerates convergence in high-dimensional tuning; a dual-head output (risk probability and health score) and SHAP-based attribution enhance transparency and regulatory alignment. On multi-year, multi-institution data, the approach surpasses mainstream baselines in AUC, reduces DP_Gap, and yields expert-consistent explanations. Methodologically, the design aligns with LLM-style time-series forecasting by exploiting causal masking and long-range dependencies while providing governance-oriented explainability. The framework delivers earlier, data-driven signals of financial stress, supporting proactive resource allocation, funding restructuring, and long-term planning in higher education finance.",causal attention transformer | dynamic hyperparameter tuning | fairness-aware learning | financial risk early warning | interpretability (SHAP analysis) | Multi-Objective Bayesian Optimization | sparse kernel surrogate models,0,2025,sustainability,policy+sustainability
44,2-s2.0-105025899295,10.3390/su172411348,https://doi.org/10.3390/su172411348,https://scholar.google.com/scholar?q=10.3390/su172411348,ar,Sustainability Switzerland,"Zhu, Yun;Chen, Qinghan;Zhong, Ma",Using Generative Artificial Intelligence to Evaluate the Quality of Chinese Environmental Information Disclosure in Chemical Firms,"Environmental information disclosure plays a critical role in corporate sustainability, yet existing evaluation approaches often rely on subjective judgment or limited textual features. This study proposes a structured framework for assessing the environmental information disclosure quality (EIDQ) of chemical enterprises and develops a generative artificial intelligence (GAI)-driven automated scoring system to enhance evaluation consistency. Using 190 Environmental, Social, and Governance (ESG) reports from 38 Chinese chemical firms between 2020 and 2024, we applied a multi-stage process combining indicator construction, DeepSeek-V3.2–based large language model (LLM) scoring, and cross-model validation. The results show that EIDQ exhibited a steady upward trend over the study period, reflecting a shift toward more quantitative and verifiable disclosure practices. The AI-generated scores demonstrated a high degree of alignment with human expert evaluations, and robustness tests confirmed the method’s transferability across different large language models. These findings provide methodological evidence for the feasibility of AI-assisted EIDQ assessment and offer practical implications for corporate sustainability reporting and regulatory oversight.",automated evaluation | chemical enterprises | environmental information disclosure quality | generative artificial intelligence | large language models,0,2025,sustainability,policy+sustainability
49,2-s2.0-105024689435,10.3390/su172310569,https://doi.org/10.3390/su172310569,https://scholar.google.com/scholar?q=10.3390/su172310569,ar,Sustainability Switzerland,"Jeršič, Nika;Turkanović, Muhamed;Beranič, Tina",Towards a Sustainable Cybersecurity Governance: Threat Modelling with Large Language Models,"With the increased complexity of applications and systems, threat modelling struggles to keep pace with the evolution of risks. This article addresses this challenge by exploring how large language models (LLMs) can be leveraged to create comprehensive threat models across different risk assessment methodologies. We examine whether a single generic prompt can support frameworks such as LINDDUN, PASTA, and STRIDE, despite their different requirements. Through this comparative analysis, we identify components that enable AI-based assessments, while acknowledging that privacy, regulatory, and dynamic risks require adaptation of the frameworks. Our findings show that a universal guideline is feasible for broad applications, but adaptation is necessary for effective use. Overall, LLM-based threat modelling improves the accessibility, repeatability, and effectiveness of risk analysis and supports stronger and more sustainable practices.",cybersecurity | large language models | resilient infrastructure | SDG 9 | sustainability | threat modelling,0,2025,sustainability,policy+sustainability
51,2-s2.0-105024539995,10.3390/electronics14234629,https://doi.org/10.3390/electronics14234629,https://scholar.google.com/scholar?q=10.3390/electronics14234629,ar,Electronics Switzerland,"Sun, Hongyan;Weingärtner, Tim",A Blockchain-Based Architecture for Energy Trading to Enhance Power Grid Stability,"The integration of renewable energy sources (RES) and distributed energy resources (DER) into local energy markets is transforming modern power grids toward a decentralized architecture. To enhance the efficiency of decentralized energy trading, blockchain technology has been widely adopted in constructing peer-to-peer energy trading platforms, providing incentives for renewable energy generation and utilization. However, the rapid growth of small-scale suppliers and intermittent DERs introduces significant challenges to grid stability, including supply–demand imbalances and voltage fluctuations. To address these challenges, we propose a blockchain-based energy trading system architecture designed to enable a self-regulating, sustainable, and resilient grid. The proposed system architecture achieves grid stability through three key components: (i) precise endpoint control via AI Agents with lightweight forecasting models integrated into existing hardware systems, (ii) flexible distributed control through an efficient incentive mechanism, named Proof of Prediction, based on a blockchain-based automated trading process, and (iii) macro-level coordination via global regulation roles. We implemented a prototype of the proposed architecture on the Ethereum Blockchain and applied it to a microgrid-scale distributed automated trading environment. Our evaluation results show that using the architecture we proposed achieves a peak-shaving rate of up to 29.6%, while maintaining the overall supply–demand deviation of around 5% on average, demonstrating its strong potential as a foundation for building stable and modern power grids.",AI agent | blockchain | incentive mechanisms | power grid stability,0,2025,sustainability,policy+sustainability
54,2-s2.0-105022504813,10.1016/j.sftr.2025.101494,https://doi.org/10.1016/j.sftr.2025.101494,https://scholar.google.com/scholar?q=10.1016/j.sftr.2025.101494,re,Sustainable Futures,"Mousavian Anaraki, Seyed Alireza;Croce, Danilo;Basili, Roberto",Large language models for sustainability reporting: A systematic review and research agenda,"Sustainability reporting refers to the activities by which large companies describe their efforts to maximize the benefits on universal criteria about economic, social, and environmental impacts. This promotes transparency among stakeholders and is considered essential in supporting governance and compliance with international regulations by improving today's business landscape. Among other problems, inaccurate company disclosures, known as Greenwashing, can affect the quality of reports and their unstructured nature poses serious limitations to economic analysts during company evaluation. Efficiently gathering and aligning available reports and other complementary data for a unified framework is an important perspective on modern sustainability analysis. Recent advances in Natural Language Processing (NLP), particularly the rise of transformer-based Large Language Models (LLMs), have enabled new capabilities in semantic information extraction, automated classification, and the detection of misleading claims within unstructured corporate sustainability disclosures. This survey provides a systematic review of NLP and LLM-based approaches in sustainability reporting, with particular attention to methodological trends and unresolved challenges. Adopting a structured review methodology that integrates scientometric mapping and meta-synthesis, we offer an evidence-based taxonomy and a synthesis of current practices, highlighting key gaps and future research directions. The findings highlight past explorations and future directions, demonstrating that LLMs offer remarkable accuracy and innovative solutions for challenges related to traditional sustainability reporting current practices.",Greenwashing | Information extraction | Large language models | Meta-synthesis | Scientometric | Sustainability reporting,0,2025,sustainability,policy+sustainability
57,2-s2.0-105021066473,10.1038/s41467-025-64723-1,https://doi.org/10.1038/s41467-025-64723-1,https://scholar.google.com/scholar?q=10.1038/s41467-025-64723-1,ar,Nature Communications,"Lu, Shirley;Serafeim, George;Xu, Simon;Awada, Marc Antonio",Tracking business opportunities for climate solutions using AI in regulated accounting reports,"The transition to a low-carbon economy offers substantial business opportunities, yet most research focuses on risks. This study develops a metric to identify firms advancing “climate solutions” by applying large language models to 39,710 10-K filings from 4,483 U.S. firms (2005-2022). The metric reveals a rising emphasis on climate solutions, validated by its responsiveness to policy shocks (e.g., Inflation Reduction Act) and correlation with green revenues and innovation indicators. We apply the measure to three inquiries: (i) firms engaged in climate solutions experience higher revenue growth, especially in sectors with strong intellectual property protection and technologies with high abatement potential; (ii) a modest political divide exists, with firms located in states with predominantly Republican voting patterns exhibiting lower climate solutions—a gap that narrows for low-cost technologies; and (iii) seemingly unrelated industries converge around shared technologies, reflected in higher stock return synchronicity. These results illustrate the value of AI-based analysis of regulatory filings for uncovering climate-related business opportunities.",,0,2025,sustainability,policy+sustainability
62,2-s2.0-105018585909,10.1016/j.eneco.2025.108954,https://doi.org/10.1016/j.eneco.2025.108954,https://scholar.google.com/scholar?q=10.1016/j.eneco.2025.108954,ar,Energy Economics,"He, Ling Yun;Wang, Liang",Can artificial intelligence curb greenwashing? Firm-level evidence based on large language model,"Amid growing scrutiny of corporate environmental disclosures, concerns have intensified regarding the prevalence of greenwashing. Although the rapid advancement of artificial intelligence (AI) has drawn increasing attention for its transformative potential in corporate governance, its implications for environmental disclosure have only begun to receive scholarly attention and warrant further investigation. This paper investigates the impact of artificial intelligence adoption on corporate greenwashing using a panel dataset of Chinese A-share listed firms from 2011 to 2022. Leveraging a novel AI adoption index derived from a fine-tuned large language model (LLM), we conduct empirical tests to assess the relationship between AI use and firms’ greenwashing strategies. Our findings reveal that AI adoption significantly reduces the incidence of greenwashing, which remains robust across multiple validation checks. Decomposition analysis across different technological categories shows that planning and decision systems constitute the most influential strand of AI in curbing greenwashing. Mechanism analysis indicates that this effect operates through enhanced operational efficiency, improved human capital structure, and increased green innovation. Additional heterogeneity analysis across subsamples reveals that the deterrent impact exhibits greater intensity in firms characterized by non-state-owned firms, polluting sectors, and technology-intensive enterprises. By highlighting the governance potential of AI in promoting credible environmental disclosure, this study provides new empirical evidence on the intersection of digital transformation and corporate sustainability.",AI classification | Artificial intelligence | Greenwashing | Heterogeneous firm | Large language model,0,2025,sustainability,policy+sustainability
64,2-s2.0-105018502345,10.1007/s43621-025-01918-y,https://doi.org/10.1007/s43621-025-01918-y,https://scholar.google.com/scholar?q=10.1007/s43621-025-01918-y,re,Discover Sustainability,"Geiger, Christophe;Di Lazzaro, Francesca",Sustainability as a guiding principle for copyright reform: regulating the use of generative AI in the field of research and education,"This article analyzes the complex relationship between Generative AI (Gen AI), sustainability, and copyright, focusing on the use of copyrighted materials for research and education using a combined theoretical and conceptual methodology. On one hand, Gen AI can be transformative by enabling broader access to content, for example, by overcoming language barriers, compiling information in very large datasets, and enabling customized educational experiences [See O. A. Acar, “With Generative AI We Can Reimagine Education” (World Economic Forum, 19 February 2024). https://www.weforum.org/agenda/2024/02/with-generative-ai-we-can-reimagine-education-and-the-sky-is-the-limit/. Accessed 19 March 2025] that strengthen incentives to learn [T. Ingkavara et al., “The Use of a Personalized Learning Approach to Implementing Self-Regulated Online Learning”, Computers and Education: Artificial Intelligence 2022, Vol. 3, 100086], thus helping to level the playing field in research and education. These functions contribute to fulfilling the right to education as provided by the Sustainable Development Goals (SDGs) of the United Nations, specifically, SDG4, and the right to research, as embodied in the human rights framework. On the other hand, Gen AI output poses risks in terms of false or lack of attribution to creators, lack of scientific integrity and manipulation of works, and prejudicing the moral interests of authors, which form part of the human rights framework. This article offers preliminary suggestions on how sustainability can be used as a guiding principle to find the right balance between facilitated access to knowledge for education and research and compliance with the moral rights of authors when dealing with Gen AI. The two pillars of this approach are (1) the set-up of a transparent and “human-centric” copyright framework regulating Gen AI and (2) an appropriate governance structure that can easily provide relief in case of moral rights violations prejudicial to research and education, as well as ethical innovation more broadly.",,0,2025,sustainability,policy+sustainability
68,2-s2.0-105015428493,10.1016/j.sftr.2025.101231,https://doi.org/10.1016/j.sftr.2025.101231,https://scholar.google.com/scholar?q=10.1016/j.sftr.2025.101231,ar,Sustainable Futures,"Fildisi, Buket;Vakaj, Edlira;Dridi, Amna;Imran, Ali Shariq;Azad, R. Muhammad Atif",Integrating AI-driven analytics for enhanced ESG mapping: Aligning local and global perspectives,"Sustainability remains a central global challenge, requiring a nuanced understanding of how global policy frameworks align with localised priorities. However, analysing diverse data sources for sustainability assessment remains a key challenge, as globally issued formally structured reports often lack localised granularity, while unstructured local data lacks structure and standardisation. Existing approaches fail to systematically integrate these heterogeneous sources, limiting their effectiveness in identifying actionable sustainability insights. This study presents an Artificial Intelligence (AI)-driven framework that leverages Natural Language Processing (NLP) techniques to integrate structured and unstructured sustainability data. We applied Latent Dirichlet Allocation (LDA), BERTopic, Generative AI (GenAI), and FinBERT-based cosine similarity to extract macroeconomic trends from formal reports — Executive Summary of IMF's Global Stability Reports — while identifying localised sustainability strategies from Greenstone's UK-based newsletters on sustainable practice. GenAI outperformed topic models in producing more coherent, diverse, and contextually relevant topics. To further enhance GenAI's performance, we applied MIPROv2 — a Bayesian optimisation-based prompt tuning method — which improved topic distinctiveness across data sources. Our key contribution lies in aligning global and territorial sustainability discourses through AI-enhanced topic modelling. The findings demonstrate an integrated methodology that connects global policy directives with region- and industry-specific insights. This approach uncovers underexplored opportunities in the social and governance dimensions of ESG, enabling data-driven and adaptable strategies. By synthesising insights across multiple data sources, this research enables policymakers, financial institutions, and industry leaders to bridge sustainability knowledge gaps, align local priorities with global objectives, and drive innovative, targeted solutions.",ESGs | GenAI | Natural language processing (NLP) | Sustainable development | Sustainable innovations | Topic modelling,0,2025,sustainability,policy+sustainability
69,2-s2.0-105015364747,10.1016/j.jrt.2025.100136,https://doi.org/10.1016/j.jrt.2025.100136,https://scholar.google.com/scholar?q=10.1016/j.jrt.2025.100136,ar,Journal of Responsible Technology,"Dwi, Mariyono",Ethical and psychological implications of generative AI in digital afterlife technologies: A systematic literature review on responsible inclusive innovation,"Rapid advances in generative artificial intelligence (GenAI) have given birth to digital afterlife technologies (DeathTech), which enable the preservation of the voices, memories, and personalities of deceased individuals. This study is a systematic review of 45 scientific articles (2020–2025) using a thematic-SWOT analysis approach and the Responsible Inclusive Innovation (RII) framework, to explore how cultural schemas, inclusive design, and governance models influence the acceptance of DeathTech across cultures. Key findings suggest that ritual adaptation and spiritual meanings are critical to the acceptance of this technology. Jewish and Japanese communities show high acceptance through cultural integration, while Hindu and Luhya communities experience ontological dissonance. Design failures such as linguistic exclusion and ritual incongruence impact marginalized groups. In addition, regulatory gaps exist, especially in post-death privacy protection and algorithmic bias. This study proposes a triadic framework for the development of ethical and equitable DeathTech: cultural mediation, inclusive design, and pluralistic governance. This contribution enriches the study of digital thanatology and provides recommendations for culturally and socially sustainable innovation.",Cultural schemas | DeathTech | Digital afterlife | Ethical governance | Generative AI | Grief management | Inclusive design | Ritual adaptation,0,2025,sustainability,policy+sustainability
73,2-s2.0-105010338979,10.1016/j.sftr.2025.100929,https://doi.org/10.1016/j.sftr.2025.100929,https://scholar.google.com/scholar?q=10.1016/j.sftr.2025.100929,ar,Sustainable Futures,"Bao, Suomiya","Cross-cultural attitudes toward generative AI in Art: Implications for sustainable creativity in the U.S., Japan, and China","This study investigates the perceptions and attitudes toward generative AI art across three major global economies: the United States, Japan, and China. As leaders in AI development, these countries exhibit distinct viewpoints regarding the integration of AI into the creative process. The investigation was conducted using an online questionnaire, which gathered responses from participants in the three countries. The survey consisted of questions that assessed participants’ experiences with AI tools, their views on AI-generated art in various forms, and their ethical concerns regarding its use. The results indicate that participants in China are generally more optimistic about the value of AI-generated art, prioritizing the quality of the final product over ethical concerns. In contrast, participants in the U.S. and Japan emphasize the importance of human creativity and express skepticism about AI art, primarily due to ethical concerns such as misinformation and intellectual property issues. While Chinese participants focus on data privacy and intellectual property protection, U.S. participants are more concerned with misinformation and fake content. Japan, despite having the least experience with AI tools, presents attitudes that often fall between the positions of the U.S. and China. This study provides valuable insights into cross-cultural differences in attitudes toward AI art, offering guidance for educators, policymakers, and AI developers on integrating AI into the art and design sectors in a sustainable, ethical, and culturally adaptive manner.",Art | Attitude | Culture | Generative AI,0,2025,sustainability,policy+sustainability
86,2-s2.0-105025165031,10.28945/5645,https://doi.org/10.28945/5645,https://scholar.google.com/scholar?q=10.28945/5645,ar,Journal of Information Technology Education Research,"Huda, Nizlel;Anwar, Khairul;Novferma, ;Kurniawan, Wawan",CHATGPT SCAFFOLDING IN SUPPORTING METACOGNITION FOR LIMIT CONCEPTS IN GUIDED INQUIRY MATHEMATICS LEARNING,"Aim/Purpose This study aims to investigate how ChatGPT-mediated scaffolding supports students’ metacognitive skills (planning, monitoring, and evaluating strategies) in understanding limit concepts in calculus within a guided-inquiry learning en-vironment. Background Guided inquiry fosters conceptual understanding in calculus, yet students often struggle with metacognitive regulation. While AI tools like ChatGPT offer inter-active scaffolding, their impact on students’ self-regulated learning and prob-lem-solving strategies in abstract topics, such as limits (a fundamental concept in calculus), remains underexplored. This study addresses this gap by evaluating ChatGPT’s function as a metacognitive guide in mathematics learning. Methodology A convergent mixed-methods design was implemented with 75 students of mathematics education at Universitas Jambi over a period of four weeks. Participants engaged in guided inquiry activities on limits, using ChatGPT for problem-solving and reflection. Data was collected through pre- and post-metacognitive assessments, screen recordings of ChatGPT-student interactions, and reflective journals. Quantitative data were analyzed using paired t-tests, while qualitative data were thematically coded to identify patterns in metacognitive engagement. Contribution This study advances understanding of AI’s capacity to foster self-regulated learning and critical thinking in mathematics, providing a framework for inte-grating generative AI as a metacognitive partner in guided inquiry pedagogy. Findings Results indicate significant improvements in metacognitive skills, particularly in monitoring and evaluation strategies. Qualitative analysis revealed that ChatGPT’s iterative feedback encouraged students to critically analyze solu-tions, particularly in identifying boundary conditions in limit problems. How-ever, 28% of students passively accepted AI-generated answers without deeper scrutiny, highlighting variability in engagement levels. Recommendations for Practitioners Educators should integrate ChatGPT as a reflective tool in guided inquiry, de-signing structured activities that require students to justify or challenge AI-gen-erated outputs. Providing explicit training in critical questioning techniques can enhance AI’s pedagogical value. Recommendations for Researchers Future research should explore long-term retention of metacognitive skills de-veloped through AI scaffolding and adaptive AI models for optimizing ChatGPT-student interactions in mathematics education. Impact on Society The implications of this research extend beyond the classroom, potentially re-shaping mathematics education in higher education. This approach could de-mocratize access to personalized mathematical support, reduce educational ine-qualities, and prepare students for an AI-augmented professional landscape. However, careful consideration must be given to ethical implementation and the preservation of authentic mathematical thinking skills. Future Research Further studies should examine (1) the sustainability of AI-enhanced metacog-nitive development, (2) cross-cultural differences in AI scaffolding effective-ness, and (3) improved AI-driven adaptive learning strategies for mathematics education.",AI ethics | ChatGPT | guided inquiry | limit concepts | mathematics learning | metacognition | scaffolding patterns,0,2025,sustainability,policy+sustainability
89,2-s2.0-105023088182,10.3390/su17229963,https://doi.org/10.3390/su17229963,https://scholar.google.com/scholar?q=10.3390/su17229963,ar,Sustainability Switzerland,"Li, He;Sun, Liang;Kim, Seongnyeon",Effects of Customized Generative AI on Student Engagement and Emotions in Visual Communication Design Education: Implications for Sustainable Integration,"Generative Artificial Intelligence (GAI) is advancing rapidly and is increasingly integrated into visual communication design education. How to effectively and sustainably leverage GAI to support visual communication design teaching has thus become a critical issue faced by educators. While prior studies have focused on GAI’s impact on student learning outcomes and creativity, limited research has explored its effects on emotions and student engagement. This study aims to investigate the impact of customized GAI integration on visual communication design students’ learning engagement and to qualitatively explore the emotions that occur throughout the learning process. Using a quasi-experimental design, 96 students were randomly assigned to either a control group using traditional instruction or an experimental group using a customized GAI. Student engagement was measured using pre- and post-assessment scales, and semi-structured interviews were conducted to analyze students’ emotional changes. The results show that customized GAI integration effectively enhanced students’ cognitive, emotional, and behavioral engagement. Moreover, students experienced diverse and dynamic emotions during the learning process, which influenced their engagement. This study provides empirical support for the application of GAI in visual communication design education, highlighting the importance of balancing technology integration with emotional regulation, thereby informing the responsible and sustainable integration of GAI in design education.",customized GAI | emotions | student engagement | sustainable integration | visual communication design,0,2025,sustainability,policy+sustainability
92,2-s2.0-105022314835,10.1371/journal.pone.0335547,https://doi.org/10.1371/journal.pone.0335547,https://scholar.google.com/scholar?q=10.1371/journal.pone.0335547,ar,Plos One,"Walker, Viviane;Angst, Mario",Promises and pitfalls of using LLMs to identify actor stances in political discourse,"Empirical research in the social sciences is often interested in understanding actor stances; the positions that social actors take regarding normative statements in societal discourse. In automated text analysis applications, the classification task of stance detection remains challenging. Stance detection is especially difficult due to semantic challenges such as implicitness or missing context but also due to the general nature of the task. In this paper, we explore the potential of Large Language Models (LLMs) to enable stance detection in a generalized (non-domain, non-statement specific) form. Specifically, we test a variety of different general prompt chains for zero-shot stance classifications. Our evaluation data consists of textual data from a real-world empirical research project in the domain of sustainable urban transport. For 1710 German newspaper paragraphs, each containing an organizational entity, we annotated the stance of the entity toward one of five normative statements. A comparison of four publicly available LLMs show that they can achieve adequate performance. However, results heavily depend on the prompt chain method, LLM, and vary by statement. Our findings have implications for computational linguistics methodology and political discourse analysis, as they offer a deeper understanding of the strengths and weaknesses of LLMs in performing the complex semantic task of stance detection. We strongly emphasise the necessity of domain-specific evaluation data for evaluating LLMs, considering trade-offs between model complexity and performance, as well as honestly weighing drawbacks of LLM application against traditional, valid approaches, such as manually annotating representative text samples.",,0,2025,sustainability,policy+sustainability
94,2-s2.0-105021535750,10.3390/su17219793,https://doi.org/10.3390/su17219793,https://scholar.google.com/scholar?q=10.3390/su17219793,ar,Sustainability Switzerland,"Sharif, Hanan;Atif, Amara;Nagra, Arfan Ali",Deepfake-Style AI Tutors in Higher Education: A Mixed-Methods Review and Governance Framework for Sustainable Digital Education,"Deepfake-style AI tutors are emerging in online education, offering personalized and multilingual instruction while introducing risks to integrity, privacy, and trust. This study aims to understand their pedagogical potential and governance needs for responsible integration. A PRISMA-guided, systematic review of 42 peer-reviewed studies (2015–early 2025) was conducted from 362 screened records, complemented by semi-structured questionnaires with 12 assistant professors (mean experience = 7 years). Thematic analysis using deductive codes achieved strong inter-coder reliability (κ = 0.81). Four major themes were identified: personalization and engagement, detection challenges and integrity risks, governance and policy gaps, and ethical and societal implications. The results indicate that while deepfake AI tutors enhance engagement, adaptability, and scalability, they also pose risks of impersonation, assessment fraud, and algorithmic bias. Current detection approaches based on pixel-level artifacts, frequency features, and physiological signals remain imperfect. To mitigate these challenges, a four-pillar governance framework is proposed, encompassing Transparency and Disclosure, Data Governance and Privacy, Integrity and Detection, and Ethical Oversight and Accountability, supported by a policy checklist, responsibility matrix, and risk-tier model. Deepfake AI tutors hold promise for expanding access to education, but fairness-aware detection, robust safeguards, and AI literacy initiatives are essential to sustain trust and ensure equitable adoption. These findings not only strengthen the ethical and governance foundations for generative AI in higher education but also contribute to the broader agenda of sustainable digital education. By promoting transparency, fairness, and equitable access, the proposed framework advances the long-term sustainability of learning ecosystems and aligns with the United Nations Sustainable Development Goal 4 (Quality Education) through responsible innovation and institutional resilience.",academic integrity | AI ethics in education | AI literacy | deepfake AI tutors | detection of deepfakes | digital sustainability | online education governance | privacy and fairness in AI | SDG 4 quality education | sustainable education | synthetic media in education,0,2025,sustainability,policy+sustainability
95,2-s2.0-105021516028,10.3390/su17219423,https://doi.org/10.3390/su17219423,https://scholar.google.com/scholar?q=10.3390/su17219423,ar,Sustainability Switzerland,"Zhang, Wen;Guo, Bin;Zhao, Wei;He, Yutong;Wang, Xinyu",Making Smart Cities Human-Centric: A Framework for Dynamic Resident Demand Identification and Forecasting,"Smart cities offer new opportunities for urban governance and sustainable development. However, at the current stage, the construction and development of smart cities generally exhibit a technology-driven tendency, neglecting real resident demand, which contradicts the “human-centric” principle. Traditional top-down methods of demand collection struggle to capture the dynamics and heterogeneity of public demand. At the same time, government service platforms, as one dimension of smart city construction, have accumulated massive amounts of user-generated data, providing new solutions for this challenge. This paper aims to construct a big data-driven analytical framework for dynamically identifying and accurately forecasting core resident demand. The study uses Xi’an City, Shaanxi Province, China, as a case study, utilising user messages from People.cn spanning 2011 to 2023. These messages cover various domains, including urban construction, healthcare, education, and transportation, as the data source. The People.cn message board is China’s most significant nationwide online political platform. Its institutionalised feedback mechanism ensures data content focuses on highly representative specific grievances, rather than the broad emotional expressions on social media. The study employs user messages from People.cn from 2011 to 2023 as its data source, encompassing urban construction, healthcare, education, and transportation. First, a large language model (LLM) was used to preprocess and clean the raw data. Subsequently, the BERTopic model was applied to identify ten core demand themes and construct their monthly time series, thereby overcoming the limitations of traditional methods in short-text semantic recognition. Finally, by integrating variational mode decomposition (VMD) with support vector machines (SVMs), a hybrid demand forecasting model was established to mitigate the risk of overfitting in deep learning when forecasting small-sample time series. The empirical results show that the proposed LLM-BERTopic-VMD-SVM framework exhibits excellent performance, with the goodness-of-fit (R2) on various demand themes ranging from 0.93 to 0.96. This study proposes an effective analytical framework for identifying and forecasting resident demand. It provides a decision-support tool for city managers to achieve proactive and fine-grained governance, thereby offering a viable empirical pathway to promote the transformation of smart cities from technology-centric to human-centric.",BERTopic model | resident demand forecasting | resident demand identification | smart cities | VMD-SVM model,0,2025,sustainability,policy+sustainability
102,2-s2.0-105019337218,10.1007/s10584-025-04046-8,https://doi.org/10.1007/s10584-025-04046-8,https://scholar.google.com/scholar?q=10.1007/s10584-025-04046-8,ar,Climatic Change,"Hicks, Carolyn;Davidson, Kathryn;Lau, Jey Han;Nguyen, Thi Minh Phuong",Implications of declaration of climate emergency on Australian local government policy in the State of Victoria: policy analysis utilising an LLM-based retriever-reader pipeline,"The 2015 Paris Agreement acknowledges the shift to a more polycentric climate governance system where non-state actors are developing climate policies and each develops to suit its unique needs and circumstances. Shifts in the policy landscape towards achieving the ambitious net zero carbon target of 2050 are difficult to assess due to the variation in scope, approach and format of policies from the numerous non-state actors. We have set out to test the use of a large language model (LLMs) in a retriever-reader pipeline to apply an existing conceptual framework to a dataset of climate policy documents. We do so by developing a tool called PALLM which we applied to local government climate policies in Victoria, Australia to detect the presence of “climate emergency mode”. Our contribution is firstly, a new tool for high-level, large-scale policy analysis. Secondly, through using this tool, we make evidentiary contribution with a large-scale analysis of over 90 policy documents. Lastly, we contribute new knowledge and conclude that local governments that have declared a climate emergency have a greater presence of the climate emergency mode. This demonstrates that such a declaration has an influence on local governments’ policies, and goes beyond symbolic politics. Our analysis also identifies attributes that need more attention from local governments in their climate emergency movement, such as equity. Ultimately, our results demonstrate that the use of LLMs with policy-informed conceptual frameworks enables a more nuanced large-scale policy analysis, providing a detailed and sophisticated view of the climate policy landscape.",Climate emergency | Climate policies | Large language model | Policy analysis | Polycentric climate governance,0,2025,sustainability,policy+sustainability
109,2-s2.0-105012612086,10.1016/j.frl.2025.108096,https://doi.org/10.1016/j.frl.2025.108096,https://scholar.google.com/scholar?q=10.1016/j.frl.2025.108096,ar,Finance Research Letters,"Li, Yang",Can large language models (LLMs) replace human reading? Empirical evidence from sustainability reports,"This study explores the divergence between human reading and Large Language Model (LLM)-based reading in the context of sustainability reports. To capture this distinction, a saliency map representing human gaze is computed, illustrating how attention is directed not only by textual content but also by visual elements such as images, charts, and layout, which are typically overlooked by LLMs. The research first adopts an LLM-based framework to assess firms’ stated commitment to Environmental, Social, and Governance (ESG) practices as conveyed in their sustainability reports. The resulting LLM-generated scores are then empirically tested for their association with firm's ESG disclosure rating evaluated by a third-party. In the second stage, the study examines how visual salience moderates the relationship between LLM-based reading and ESG disclosure rating. The findings reveal that: (1) LLMs can effectively extract ESG performance-related signals from reports; and (2) discrepancies between human and LLM-based reading, captured through visual salience, significantly influence the effectiveness of LLM-based assessments. These results suggest that while LLMs can be a powerful tool for analyzing ESG disclosures, their limitations in handling visual information warrant careful consideration in contexts where visual elements play a key communicative role.",ESG commitments | Large language model | Sustainability | Visual salience,0,2025,sustainability,policy+sustainability
118,2-s2.0-105020094745,10.3390/su17209063,https://doi.org/10.3390/su17209063,https://scholar.google.com/scholar?q=10.3390/su17209063,re,Sustainability Switzerland,"Naji, Khalid K.;Gunduz, Murat;Mohamed, Amr;Alomari, Awad","Generative AI for Sustainable Project Management in the Built Environment: Trends, Challenges, and Future Directions","Generative Artificial Intelligence (GAI) is gaining increasing attention as a catalyst for advancing sustainability within project management for buildings and infrastructure. This paper systematically reviews 173 peer-reviewed publications, including 142 journal and conference papers, to examine the current research landscape. Bibliometric mapping and thematic synthesis reveal expanding applications of GAI in project planning, design optimization, risk management, and sustainability assessment, but adoption remains fragmented across regions and domains. This review identifies persistent challenges that constrain large-scale implementation, including data variability and interoperability gaps, high computational demand, limited regulatory alignment, and ethical and governance concerns, coupled with the absence of standardized evaluation metrics. In response, this paper outlines future research prospects through a structured agenda that emphasizes scalable and generalizable AI models, real-time integration with IoT and digital twins, explainable and secure AI systems, and policy-aligned governance frameworks. These priorities aim to strengthen environmental, social, and economic sustainability outcomes in the built environment. By clarifying current progress and knowledge gaps, this review supports both scholars and practitioners in strengthening the role of GAI in the built environment.",artificial intelligence | deep learning | emerging technologies | Generative AI | project management | sustainability,0,2025,sustainability,policy+sustainability
119,2-s2.0-105020039564,10.3390/smartcities8050163,https://doi.org/10.3390/smartcities8050163,https://scholar.google.com/scholar?q=10.3390/smartcities8050163,ar,Smart Cities,"Dong, Tao;Tadi, Massimo;Tesfaye, Solomon Tamiru",Unveiling Hidden Green Corridors: An Agent-Based Simulation (ABS) of Urban Green Continuity for Ecosystem Services and Climate Resilience,"Highlights: What is the main finding? This paper introduces a novel method to evaluate urban green infrastructure performance by combining multi-species agent simulation and space syntax analysis. Specifically, the results of the Agent-based simulation of ecological behaviors reveal hidden green networks that are not aligned with existing green space layouts. Moreover, the spatial overlaps between pollinator intensity and thermal vulnerability expose coupled ecological–climatic risks in urban areas. What are the implications of the main findings? Integrating dynamic ecological behavior simulation with temporal performance monitoring enables more precise identification of priority intervention zones for green infrastructure planning. The dual-agent framework combining ABS and AI interpretation provides a scalable approach for diagnosing and designing urban ecological resilience. Urban green spaces are essential for mitigating the heat island effect, supporting ecosystem services, and maintaining biodiversity. The distribution, fragmentation, and connection of the green spaces significantly impact the behavior of species in cities, serving as key indicators of environmental resilience and ecological benefits. However, current studies, as well as planning standards, often prioritize green spaces independently through their coverage or density, overlooking the importance of continuity and its impact on thermal regulation and accessibility. In this research, urban “hidden green corridors” refer to the unrecognized but functionally significant pathways that link fragmented green spaces through ecological behaviors, which enhance both biological and human habitats. This research focuses on developing an agent-based simulation (ABS) model based on the Physarealm plugin in Rhino, which can assess the effectiveness of these hidden corridors in different urban settings by integrating geographic information systems (GIS) and space syntax. Based on three case studies in Italy (Lambrate District, Bolognina, and Ispra), the simulation results are further interpreted through the AI agentic workflow “SOFIA”, developed by IMM Design Lab, Politecnico di Milano, and compared using manual analysis as well as mainstream large language models (ChatGPT 4.0 Web). The findings indicate that the “hidden green corridors” are essential for urban heat reduction, enhancement of urban biodiversity, and strengthening ecological flows.",agent-based simulation (ABS) | AI for science (AI4S) | climate crisis | ecosystem services | geoAI | geographic information systems (GIS) | green continuity | spatial diagnostics | sustainable development | sustainable urban design | urban green spaces,0,2025,sustainability,policy+sustainability
120,2-s2.0-105019999746,10.1200/CCI-25-00112,https://doi.org/10.1200/CCI-25-00112,https://scholar.google.com/scholar?q=10.1200/CCI-25-00112,re,JCO Clinical Cancer Informatics,"Benson, Ryzen;Kenny, Clodagh;Ashraf Ganjouei, Amir;Zhao, Michelle;Darawsheh, Rami;Qian, Alexander;Hong, Julian C.","Large Language Models in Population Oncology: A Contemporary Review on the Use of Large Language Models to Support Data Collection, Aggregation, and Analysis in Cancer Care and Research","Over the past 5 years, large language models (LLMs) have emerged and continued to improve in their generative abilities and are now capable of generating human-understandable text and performing complex data analyses. As these models continue to improve in their capabilities, they are increasingly used to support population oncology, including clinical information extraction, cancer care education, and clinical decision support. This narrative review provides a high-level description of the use of LLMs in cancer with an overview of the current literature, along with research gaps. Despite increasing interest in using LLMs for cancer care, prevention, and research, applied methods in cancer still lag advancements published in the computer science literature. Therefore, we recommend that cancer-focused LLM research and applications better incorporate technical advancements and techniques found in the computer science literature. Additionally, standardized evaluation metrics and approaches need to be better studied and adopted in oncology, along with data governance and computational infrastructure to support state-of-the-art model integration and the use of real-world data. Finally, we describe the need for researchers to incorporate principles and frameworks from implementation and dissemination science to promote LLM-based tool adaptation, effectiveness, fit, and sustainability.",,0,2025,sustainability,policy+sustainability
122,2-s2.0-105019363470,10.1002/pra2.1248,https://doi.org/10.1002/pra2.1248,https://scholar.google.com/scholar?q=10.1002/pra2.1248,ar,Proceedings of the Association for Information Science and Technology,"Gao, Yan;Dai, Qinquan;Wu, Guang",Exploring the Themes of Chinese Artificial Intelligence Policy: An LDA Topic Modeling Approach,"As a representative of next-generation artificial intelligence, generative AI is profoundly transforming contemporary societal structures. As a pivotal player, China serves as both a primary application market and a key innovator in AI technology, with its developmental trajectory significantly shaped by national policy frameworks. This study employs Latent Dirichlet Allocation (LDA) topic modeling to systematically analyze 78 valid and currently implemented AI policy documents in China. The research aims to identify core focus areas in China's current AI policy landscape and provide insights for sustainable development of AI. Analytical results highlight seven key policy themes: (1) technological innovation and industrial integration, (2) social governance and mechanism evaluation, (3) model training and disciplinary methodologies, (4) software algorithms and data security, (5) pilot zone construction and innovation development, (6) infrastructure and intelligent service systems, and (7) AI research project implementation. Based on these findings, the study concludes with targeted policy recommendations.",AI Policies | Chinese Artificial Intelligence | Information Governance | LDA Topic Modeling,0,2025,sustainability,policy+sustainability
123,2-s2.0-105019357097,10.1002/pra2.1261,https://doi.org/10.1002/pra2.1261,https://scholar.google.com/scholar?q=10.1002/pra2.1261,ar,Proceedings of the Association for Information Science and Technology,"Kim, Yuheun;Liu, Qiaoyi;Hemsley, Jeff",LLM-Supported Content Analysis of Motivated Reasoning on Climate Change,"Public discourse around climate change remains polarized despite scientific consensus on anthropogenic climate change (ACC). This study examines how “believers” and “skeptics” of ACC differ in their YouTube comment discourse. We analyzed 44,989 comments from 30 videos using a large language model (LLM) as a qualitative annotator, identifying ten distinct topics. These annotations were combined with social network analysis to examine engagement patterns. A linear mixed-effects model showed that comments about government policy and natural cycles generated significantly lower interaction compared to misinformation, suggesting these topics are ideologically settled points within communities. These patterns reflect motivated reasoning, where users selectively engage with content that aligns with their identity and beliefs. Our findings highlight the utility of LLMs for large-scale qualitative analysis and highlight how climate discourse is shaped not only by content, but by underlying cognitive and ideological motivations.",Climate Change | Content Analysis | Prompt Engineering | Social Media Data | Social Network Analysis,0,2025,sustainability,policy+sustainability
125,2-s2.0-105019172692,10.3390/su17198920,https://doi.org/10.3390/su17198920,https://scholar.google.com/scholar?q=10.3390/su17198920,ar,Sustainability Switzerland,"Chen, Xin",Sustainable Agile Identification and Adaptive Risk Control of Major Disaster Online Rumors Based on LLMs and EKGs,"Amid the increasing frequency and severity of major disasters, the rapid spread of online misinformation poses substantial risks to public safety, effective crisis management, and long-term societal sustainability. Current methods for managing disaster-related rumors rely on static, rule-based approaches that lack scalability, fail to capture nuanced misinformation, and are limited to reactive responses, hindering effective disaster management. To address this gap, this study proposes a novel framework that leverages large language models (LLMs) and event knowledge graphs (EKGs) to facilitate the sustainable agile identification and adaptive control of disaster-related online rumors. The framework follows a multi-stage process, which includes the collection and preprocessing of disaster-related online data, the application of Gaussian Mixture Wasserstein Autoencoders (GMWAEs) for sentiment and rumor analysis, and the development of EKGs to enrich the understanding and reasoning of disaster events. Additionally, an enhanced model for rumor identification and risk control is introduced, utilizing Graph Attention Networks (GATs) to extract node features for accurate rumor detection and prediction of rumor propagation paths. Extensive experimental validation confirms the efficacy of the proposed methodology in improving disaster response. This study contributes novel theoretical insights and presents practical, scalable solutions for rumor control and risk management during crises.",adaptive risk control | EKGs | GMWAEs | LLMs | sustainable agile identification,0,2025,sustainability,policy+sustainability
126,2-s2.0-105018966311,10.3390/su17198770,https://doi.org/10.3390/su17198770,https://scholar.google.com/scholar?q=10.3390/su17198770,ar,Sustainability Switzerland,"Yang, Yongkang;Huang, Lingyun;Lin, Weiyi;Li, Yilin;Xu, Yaopeng;Cheng, Liying",Enhancing Sustainable English Writing Instruction Through a Generative AI-Based Virtual Teacher Within a Co-Regulated Learning Framework,"English writing proficiency is pivotal to sustainable academic success and employability. In Chinese higher education, however, conventional instruction often constrains students’ self-regulation and access to individualized feedback. Drawing on self-regulated learning (SRL) and co-regulated learning (CoRL), this study investigates whether a CoRL-guided generative AI virtual teacher (CoRL-VT), designed as a “more capable other,” is associated with enhanced undergraduate writing outcomes relative to standard AI support. Using a 12-week quasi-experimental design with two intact classes (N = 61) in Anhui, China, we compared a control condition (standard AI) with an intervention (CoRL-VT). Writing proficiency was assessed via IELTS Writing Task 2 at pre- and post-test; three certified examiners scored all scripts with strong agreement (ICC = 0.87). Analyses adjusting for baseline yielded an estimated group difference favoring CoRL-VT. Teacher interview testimony aligned with the quantitative pattern, noting clearer macro-organization, richer lexical choices, and more teacherly formative feedback among CoRL-VT students. Taken together, these findings offer exploratory, descriptive evidence consistent with the potential of structured, CoRL-informed AI scaffolding in sustainable writing pedagogy and outline design principles for replicable CoRL-VT implementations in resource-conscious contexts.",co-regulated learning | English academic writing | generative AI | self-regulated learning | technology-enhanced sustainable pedagogy | virtual teacher,0,2025,sustainability,policy+sustainability
139,2-s2.0-105017391949,10.3390/publications13030030,https://doi.org/10.3390/publications13030030,https://scholar.google.com/scholar?q=10.3390/publications13030030,ar,Publications,"Chen, Xiaoting;Maddi, Abdelghani;Wang, Yanyan","How China Governs Open Science: Policies, Priorities, and Structural Imbalances","This article investigates the architecture and institutional distribution of policy tools supporting open science (OS) in China. Based on a corpus of 199 policy documents comprising 25,885 policy statements, we apply an AI-assisted classification to analyze how the Chinese government mobilizes different types of tools. Using Qwen-plus, a large language model developed by Alibaba Cloud and fine-tuned for OS-related content, each policy statement is categorized into one of fifteen subcategories under three main types: supply-oriented, environment-oriented, and demand-oriented tools. Our findings reveal a strong dominance of supply-oriented tools (63%), especially investments in infrastructure, education, and public services. Demand-oriented tools remain marginal (11%), with little use of economic incentives or regulatory obligations. Environment-oriented tools show more balance but still underrepresent key components like incentive systems and legal mandates for open access. To deepen the analysis, we introduce a normalized indicator of institutional focus, which captures the relative emphasis of each policy type across administrative levels. Results show that supply-oriented tools are concentrated at top-level institutions, reflecting a top-down governance model. Demand tools are localized at lower levels, highlighting limited strategic commitment. Overall, China’s OS policy mix prioritizes infrastructure over incentives, limiting systemic transformation toward a more sustainable open science ecosystem.",open access | open science governance | open science policy | policy tools,0,2025,sustainability,policy+sustainability
142,2-s2.0-105015963732,10.3390/foods14173004,https://doi.org/10.3390/foods14173004,https://scholar.google.com/scholar?q=10.3390/foods14173004,ar,Foods,"Khanna, Abhirup;Jain, Sapna;Sah, Anushree;Dangi, Sarishma;Sharma, Abhishek;Tiang, Sew Sun;Wong, Chin Hong;Lim, Wei Hong",Generative AI and Blockchain-Integrated Multi-Agent Framework for Resilient and Sustainable Fruit Cold-Chain Logistics,"The cold-chain supply of perishable fruits continues to face challenges such as fuel wastage, fragmented stakeholder coordination, and limited real-time adaptability. Traditional solutions, based on static routing and centralized control, fall short in addressing the dynamic, distributed, and secure demands of modern food supply chains. This study presents a novel end-to-end architecture that integrates multi-agent reinforcement learning (MARL), blockchain technology, and generative artificial intelligence. The system features large language model (LLM)-mediated negotiation for inter-enterprise coordination, Pareto-based reward optimization balancing spoilage, energy consumption, delivery time, and climate and emission impact. Smart contracts and Non-Fungible Token (NFT)-based traceability are deployed over a private Ethereum blockchain to ensure compliance, trust, and decentralized governance. Modular agents—trained using centralized training with decentralized execution (CTDE)—handle routing, temperature regulation, spoilage prediction, inventory, and delivery scheduling. Generative AI simulates demand variability and disruption scenarios to strengthen resilient infrastructure. Experiments demonstrate up to 50% reduction in spoilage, 35% energy savings, and 25% lower emissions. The system also cuts travel time by 30% and improves delivery reliability and fruit quality. This work offers a scalable, intelligent, and sustainable supply chain framework, especially suitable for resource-constrained or intermittently connected environments, laying the foundation for future-ready food logistics systems.",blockchain | cold-chain logistics | generative AI | multi-agent reinforcement learning | sustainable food systems,0,2025,sustainability,policy+sustainability
143,2-s2.0-105015853624,10.1360/TB-2025-0185,https://doi.org/10.1360/TB-2025-0185,https://scholar.google.com/scholar?q=10.1360/TB-2025-0185,re,Chinese Science Bulletin,"Shen, Jianfeng;Huang, Ru;Min, Dong;Che, Hui;Li, Baoshan;Liu, Lihong;Zhang, Zhi;Cheng, Jing;Wang, Shan",The foundational cornerstone for healthcare AI models: constructing multimodal corpora in the health sector,"The rapid advancement and widespread adoption of generative artificial intelligence (AI) technologies have demonstrated significant potential across a variety of sectors. However, in the medical domain-characterized by complexity, high precision, and specialized knowledge requirements-the application of general-purpose large language models (LLMs) is often constrained by limitations in domain adaptability. While general LLMs leverage self-supervised learning based on large-scale open-domain corpora, such data sources typically lack the granularity, specificity, and semantic precision necessary for healthcare and biomedical applications. Consequently, the efficacy and reliability of these models in clinical and healthcare-related scenarios remain limited. In contrast, vertical domain-specific large models (often referred to as vertical foundation models) offer promising solutions to overcome these challenges. These models are designed with a focus on domain specialization, incorporating expert-curated corpora, fine-grained medical ontologies, and targeted task formulations. This specialized approach enables vertical models to achieve higher accuracy, better contextual understanding, and more effective task performance in scenarios where general models fail to deliver sufficient precision. This paper conducts a comprehensive analysis of existing health and medical corpus construction practices, both domestically and internationally, identifying critical gaps in data structure, standardization, and adaptability to AI tasks. Building upon this analysis, we propose a standardized construction framework centered on a “Disease-Scenario Association Matrix”. This framework facilitates the multidimensional mapping between disease classifications-based on standards such as ICD-10 and adjusted for domestic needs-and medical application scenarios, which are guided by authoritative references such as the “Guidelines for AI Application Scenarios in the Health Industry” issued by national health authorities. The matrix serves as a dynamic, task-driven mechanism that connects disease characteristics to specific healthcare scenarios, enabling targeted corpus development for high-priority use cases. To ensure data utility, quality, and long-term sustainability, we further introduce a corpus standards system encompassing four critical dimensions: data acquisition, quality evaluation, annotation protocols, and privacy protection. Data collection protocols are aligned with international standards such as HL7 and FHIR to ensure structural and semantic interoperability. Quality assessment frameworks are developed based on criteria such as completeness, accuracy, timeliness, and consistency, integrating both automated and manual validation mechanisms. Annotation systems are designed with hierarchical and rule-based structures, leveraging domain-specific pre-trained models such as BioBERT and U-Net for semi-automated labeling, followed by expert review for validation. Meanwhile, privacy protection is achieved through a combination of data de-identification, encryption, federated learning, and access control strategies to ensure full compliance with data governance and ethical standards. Finally, a dynamic feedback and quality control loop is incorporated into the corpus development process to enable continuous updates, refinement, and expansion. By integrating these mechanisms into a multi-level, task-adaptive architecture, this framework lays the methodological and theoretical foundation for constructing a high-quality, multimodal AI corpus tailored to the unique demands of the healthcare sector. This corpus will support the development and deployment of vertical domain large models, unlocking new capabilities for intelligent diagnostics, clinical decision support, and precision medicine.",corpus | generative artificial intelligence | health industry | large language model | multimodal corpora | vertical large model,0,2025,sustainability,policy+sustainability
144,2-s2.0-105015690604,10.1371/journal.pclm.0000706,https://doi.org/10.1371/journal.pclm.0000706,https://scholar.google.com/scholar?q=10.1371/journal.pclm.0000706,ar,Plos Climate,"Al Khourdajie, Alaa",The role of artificial intelligence in climate change scientific assessments,"Climate change scientific assessments prepared by the Intergovernmental Panel on Climate Change (IPCC) face interconnected dual challenges: the exponential growth of literature, hindering synthesis efficiency, and the increasing length of its reports, impeding accessibility. Building upon the emerging discussion of adopting artificial intelligence (AI) tools in scientific assessments, this essay develops specific operational and governance frameworks to guide the IPCC’s integration of these tools. It makes three distinct contributions. First, it develops a systematic framework for AI-augmented evidence synthesis, detailing how machine learning (ML) can be integrated into each stage of the assessment workflow. Second, it provides a critical analysis of Large Language Models' (LLMs) use for reports communication through the lens of ‘addressable’ versus ‘inherent’ limitations, clarifying which risks require technical solutions versus those that demand robust governance. Finally, it proposes a novel governance structure for the IPCC based on two institutional roles, the ‘producer’ and the ‘assessor’ of AI products, to ensure scientific integrity is maintained. This essay provides a clear path for the responsible, expert-led integration of AI, ensuring it serves to augment, not replace, human expertise.",,0,2025,sustainability,policy+sustainability
148,2-s2.0-105013784905,10.1016/j.egyai.2025.100580,https://doi.org/10.1016/j.egyai.2025.100580,https://scholar.google.com/scholar?q=10.1016/j.egyai.2025.100580,ar,Energy and AI,"Wang, Jieshu;Solís, Patricia",Identifying latent workforce capacities for extreme heat resilience: An artificial intelligence assisted approach,"Extreme heat events, intensified by climate change, pose critical challenges to public health, infrastructure, and workforce resilience. Despite the urgency of these challenges, there is no systematic framework to identify workforce adaptive capacities that can help build regional heat resilience. This study introduces a novel large language model assisted approach, using task-level data from the O*NET dataset, to identify workforce capacities that enhance heat resilience. By defining heat-solution tasks as activities mitigating heat impacts, protecting public health, or improving infrastructure, we classify heat-solution occupations and dual-impact occupations, which are both vulnerable to heat and critical to heat resilience. A case study of the state of Arizona in the United States analyzed 16,398 tasks across 663 occupations, identifying 110 heat-solution occupations (about 14 % of Arizona’ workforce) and 31 dual-impact occupations. The study reveals how energy-relevant occupations, such as HVAC technicians, solar installers, and retrofit specialists, contribute to climate adaptation, linking occupational roles to the clean energy transition and resilient infrastructure. By leveraging large language models, our method provides a scalable, AI-powered tool to analyze workforce data and identify capacities necessary for energy efficiency and hazard resilience. The findings not only demonstrate the potential of large language models in workforce analysis but also contributed to shaping Arizona's first Extreme Heat Preparedness Plan. This study offers a scalable method to uncover latent capacities and informs policies on workforce development, safety regulations, and climate-resilient infrastructure, serving as a model for other regions facing similar challenges.",Climate adaptation | Extreme heat | Heat resilience | Heat-solution occupations | Labor markets | Occupations | Sustainability | Workforce,0,2025,sustainability,policy+sustainability
167,2-s2.0-105013166289,10.3390/buildings15152710,https://doi.org/10.3390/buildings15152710,https://scholar.google.com/scholar?q=10.3390/buildings15152710,ar,Buildings,"Cai, Binqing;Ye, Zhukai;Chen, Shiwei",Intelligent ESG Evaluation for Construction Enterprises in China: An LLM-Based Model,"Environmental, social, and governance (ESG) evaluation has become increasingly critical for company sustainability assessments, especially for enterprises in the construction industry with a high environmental burden. However, existing methods face limitations in subjective evaluation, inconsistent ratings across agencies, and a lack of industry-specificity. To address these limitations, this study proposes a large language model (LLM)-based intelligent ESG evaluation model specifically designed for the construction enterprises in China. The model integrates three modules: (1) an ESG report information extraction module utilizing natural language processing and Chinese pre-trained language models to identify and classify ESG-relevant statements; (2) an ESG rating prediction module employing XGBoost regression with SHAP analysis to predict company ratings and quantify individual statement contributions; and (3) an ESG intelligent evaluation module combining knowledge graph construction with fine-tuned Qwen2.5 language models using Chain-of-Thought (CoT). Empirical validation demonstrates that the model achieves 93.33% accuracy in the ESG rating classification and an R<sup>2</sup> score of 0.5312. SHAP analysis reveals that environmental factors contribute most significantly to rating predictions (38.7%), followed by governance (32.0%) and social dimensions (29.3%). The fine-tuned LLM integrated with knowledge graph shows improved evaluation consistency, achieving 65% accuracy compared to 53.33% for standalone LLM approaches, constituting a relative improvement of 21.88%. This study contributes to the ESG evaluation methodology by providing an objective, industry-specific, and interpretable framework that enhances rating consistency and provides actionable insights for enterprise sustainability improvement. This research provides guidance for automated and intelligent ESG evaluations for construction enterprises while addressing critical gaps in current ESG practices.",construction industry | ESG rating | Intelligent Evaluation | LLM,0,2025,sustainability,policy+sustainability
171,2-s2.0-105012090747,10.1136/bmjopen-2024-095062,https://doi.org/10.1136/bmjopen-2024-095062,https://scholar.google.com/scholar?q=10.1136/bmjopen-2024-095062,ar,BMJ Open,"Fan, Zhixin;Yin, Jia;Zhang, Zhibin;Wei, Xiaolin;Yang, Ding;Sun, Qiang",Cross-sectoral synergy governance programme for antimicrobial resistance control in China using a 'One Health' approach: Study protocol for a mixed-methods study,"Introduction Antimicrobial resistance (AMR) is a critical global public health concern, particularly acute in rural China. Counties, which cover extensive rural regions, face major challenges in AMR governance and thus require priority attention. Yet, AMR governance efforts across sectors are fragmented, with notable gaps in translating policy objectives into sustainable, practical governance measures. This programme will entail a series of studies focusing on county-level cross-sectoral synergy governance for AMR, aiming to identify optimal synergy governance strategies to curb AMR. Methods and analysis The study comprises three phases: (1) understanding and exploring the state of cross-sectoral synergy governance and its internal mechanisms; (2) empirically evaluating AMR synergy governance capability using a developed evaluation indicator tool; and (3) identifying optimal AMR synergy governance strategies through a simulation and prediction model. Phase I involves conducting a content analysis of policy documents and semistructured interviews to understand and explore the state of cross-sectoral synergy governance and internal mechanisms. An evaluation indicator tool for AMR synergy governance capability will be developed through a two-round modified Delphi survey, hierarchical analysis process and percentage weighting method, with a typical case analysis being used for empirical evaluation in phase II. Phase III entails developing a simulation and prediction model using a series of artificial intelligence technologies, such as distributed Scrapy crawler technology, large language models, generative adversarial networks and deep multilayer models, all aimed at identifying optimal AMR synergy governance strategies. Ethics and dissemination This study was approved by the ethics committee of the Centre for Health Management and Policy Research, Shandong University (No. ECSHCMSDU20240904). The results of the studies will be submitted for publication in peer-reviewed journals, presented at national and international academic conferences.",antimicrobial resistance | China | one health | simulation prediction | synergy governance,0,2025,sustainability,policy+sustainability
177,2-s2.0-105011663205,10.3390/drones9070451,https://doi.org/10.3390/drones9070451,https://scholar.google.com/scholar?q=10.3390/drones9070451,ar,Drones,"Zhai, Zhenduo;Liu, Zhiguang;Zhang, Yang;Zhao, Andrew;Shang, Yi",New Methods for Waterfowl and Habitat Survey Using AI and Drone Imagery,"Monitoring waterfowl populations is essential for informing habitat management, conservation strategies, and sustainable harvest regulations. Many target species such as mallards and northern pintails are keystone components of wetland ecosystems, serving as ecological indicators due to their sensitivity to environmental changes. The integration of drone technology and artificial intelligence (AI) is significantly transforming the field of wildlife conservation and habitat monitoring. Existing methods for waterfowl monitoring face critical challenges such as low accuracy in identifying overlapping image regions and limited segmentation accuracy in complex habitats. To address these issues, this paper presents an end-to-end system and several new methods for efficiently and accurately identifying waterfowl populations in their natural habitats using AI and drone imagery. We applied advanced deep learning models to drone imagery for detecting and counting waterfowl. To handle overlapping regions in consecutive images, we developed a bird-location-based method that quickly and accurately identifies overlaps. For habitat segmentation, we proposed an effective approach combining Meta’s Segment Anything Model (SAM) with a ResNet50 classifier. Additionally, we used ChatGPT to generate clear, easy-to-read reports summarizing detection results. Experimental results show that our bird detection model (Faster R-CNN) achieved 86.57% mAP, our habitat segmentation method reached 85.1% accuracy (average F1 score: 81.8%), and our overlap detection method maintained an error rate below 5% with faster performance compared to traditional techniques. These outcomes highlight the practical effectiveness of our integrated pipeline for wildlife conservation and habitat monitoring.",computer vision | deep learning | generative AI | habitat recognition | image segmentation | overlap region detection | waterfowl detection,0,2025,sustainability,policy+sustainability
181,2-s2.0-105011603479,10.3390/su17146554,https://doi.org/10.3390/su17146554,https://scholar.google.com/scholar?q=10.3390/su17146554,ar,Sustainability Switzerland,"de Pedro Noriega, Luis;Bobo-Pinilla, Javier;Delgado-Iglesias, Jaime;Reinoso-Tapia, Roberto;Gallego, Ana María;Quirós-Alpera, Susana",AI in Biodiversity Education: The Bias in Endangered Species Information and Its Implications,"The use of AI-generated content in education is significantly increasing, but its reliability for teaching natural sciences and, more specifically, biodiversity-related contents still remains understudied. The need to address this question is substantial, considering the relevance that biodiversity conservation has on human sustainability, and the recurrent presence of these topics in the educational curriculum, at least in Spain. The present article tests the existence of biases in some of the most widely used AI tools (ChatGPT-4.5, DeepSeek-V3, Gemini) when asked a relevant and objective research question related to biodiversity. The results revealed both taxonomic and geographic biases in all the lists of endangered species provided by these tools when compared to IUCN Red List data. These imbalances may contribute to the perpetuation of plant blindness, zoocentrism, and Western centrism in classrooms, especially at levels where educators lack specialized training. In summary, the present study highlights the potential harmful impact that AI’s cultural and social biases may have on biodiversity education and Sustainable Development Goals-aligned learning and appeals to an urgent need for model refinement (using scientific datasets) and teacher AI literacy to mitigate misinformation.",AI bias | biodiversity education | endangered species | geographic bias | sustainable development goals (SDGs) | taxonomic bias,0,2025,sustainability,policy+sustainability
186,2-s2.0-105025940417,10.34659/eis.2025.93.2.963,https://doi.org/10.34659/eis.2025.93.2.963,https://scholar.google.com/scholar?q=10.34659/eis.2025.93.2.963,ar,Economics and Environment,"Frešová, Zora Mária",HIDDEN GREENS – AI'S ROLE IN SUSTAINABILITY THROUGH OPINION MINING,"This research explores the intersection of artificial intelligence (AI) and sustainability discourse, primarily focusing on public opinion expressed on the Reddit platform. Using unsupervised machine learning and large language models (LLMs), we conduct opinion mining and sentiment analysis on a diverse range of Reddit discussions related to sustainability, employing both fine-grained analysis and traditional statistical methods like bigram and frequency analysis. Our findings reveal key trends in public perception and evolving attitudes towards sustainability, highlighting areas of concern and potential opportunities for intervention. Additionally, we demonstrate how AI can significantly expedite model development, enabling rapid responses to shifts in public opinion. This agility is crucial for aligning sustainability initiatives with the values and concerns of diverse stake-holders. While acknowledging the limitations of Reddit as a representative sample of global opinion and the need for further validation of AI's capabilities in specific sustainability contexts, this study provides valuable insights into the dynamic relation-ship between AI and sustainability discourse. By understanding public sentiment and leveraging AI's potential for rapid adaptation and analysis, we can inform more effective strategies for addressing environmental challenges and promoting a sustainable future.",artificial intelligence | Flan T5 XL | Gemma 9 B | opinion mining | sentiment analysis | sustainability,0,2025,sustainability,policy+sustainability
191,2-s2.0-105010694639,10.13865/j.cnki.cjbmb.2025.06.1272,https://doi.org/10.13865/j.cnki.cjbmb.2025.06.1272,https://scholar.google.com/scholar?q=10.13865/j.cnki.cjbmb.2025.06.1272,re,Chinese Journal of Biochemistry and Molecular Biology,"Bu, You Quan;Cao, Yong Fu;Chang, Zeng Yi;Chen, Hong Yu;Chen, Xiao Wei;Chen, Yuan Yuan;Chen, Zhu Cheng;Deng, Rui;Ding, Jie;Fan, Zhong Kai;Gao, Guo Quan;Gao, Xu;Hu, Lan;Hu, Xiao Qing;Jia, Hong Ti;Kong, Ying;Li, En Min;Li, Ling;Li, Yu Hua;Liu, Jun Rong;Liu, Zhi Qiang;Luo, Ya Ping;Lv, Xue Mei;Pei, Yan Xi;Peng, Xiao Zhong;Tang, Qi Qun;Wan, You;Wang, Yong;Wang, Ming Xu;Wang, Xian;Xie, Guang Kuan;Xie, Jun;Yan, Xiao Hua;Yin, Mei;Yu, Zhong Shan;Zhou, Chun Yan;Zhu, Rui Fang",Expert Consensus on the Ethical Requirements for Generative AI-Assisted Academic Writing,"With the rapid development of generative artificial intelligence (GAI) technologies, their widespread application in academic research and writing is continuously expanding the boundaries of scientific inquiry. However, this trend has also raised a series of ethical and regulatory challenges, including issues related to authorship, content authenticity, citation accuracy, and accountability. In light of the growing involvement of AI in generating academic content, establishing an open, controllable, and trustworthy ethical governance framework has become a key task for safeguarding research integrity and maintaining trust within the academic community. This expert consensus outlines ethical requirements across key stages of AI-assisted academic writing-including topic selection, data management, citation practices, and authorship attribution. It aims to clarify the boundaries and ethical obligations surrounding AI use in academic writing, ensuring that technological tools enhance efficiency without compromising integrity. The goal is to provide guidance and institutional support for building a responsible and sustainable research ecosystem.",academic writing | ethical requirements | generative artificial intelligence (GAI),0,2025,sustainability,policy+sustainability
201,2-s2.0-105007139444,10.3787/j.issn.1000-0976.2025.05.015,https://doi.org/10.3787/j.issn.1000-0976.2025.05.015,https://scholar.google.com/scholar?q=10.3787/j.issn.1000-0976.2025.05.015,re,Natural Gas Industry,"Yang, Tao;Luo, Liangcai;Song, Yong;Li, Feng;Duan, Yarui;Zou, Cunyou;Cao, Yan;Shi, Mingyu;Huo, Lijun;Han, Rubing;Wu, Xiao",Connecting minds and transforming energy to shape a sustainable energy future: Overview of 2024 Abu Dhabi International Petroleum Exhibition and Conference,"The 2024 Abu Dhabi International Petroleum Exhibition and Conference (2024 ADIPEC) with ""connecting minds, transforming energy"" as the theme was held at the Abu Dhabi National Exhibition Center from November 4<sup>th</sup> to 7<sup>th</sup>, 2024. At this conference, global participants reached several consensuses on the transformation of energy industry while showing many cutting-edge achievments made in petroleum industry and green low-carbon technologies, which are mainly embodied in the following 8 aspects. First, global energy demand is growing continuously, and the construction of a safe, reliable and sustainable energy system needs the joint effort of diversified energies. Second, the prediction that the global oil demand will reach the peak value in 2030 is questionable, and natural gas will continue to play a key role in accelerating the energy transition and ensuring energy supply safety. Third, artificial intelligence (AI) will be an important means to promote the improvement of petroleum enterprises' productivity, and its deep integration with energy industry will bring a new opportunity for the realization of decarbonization. Fourth, the acceleration of energy transition and the decarbonization are the mainstream understanding in the industry, and the potential of hydrogen energy as revolutionary energy carrier remains to be tapped. Fifth, a big leap will be made in geoscientific research towards refinement and intelligence. Sixth, drilling and completion technologies will steadily advance to integration, automation and intelligence. Seventh, marine engineering supporting deepwater development has been developing quickly, and engineering efficiency has been improved significantly. Eighth, the innovative development of EOR technologies and methods and the rapid progress of unconventional resource development technologies have brought new growth points. In conclusion, domestic petroleum industry should accelerate the efforts in: (1) planning energy safety and low-carbon transformation comprehensively, and strengthening multi-energy integration and innovation continuously; (2) promoting the deep integration of technological innovation and industrial innovation through ""innovation driving + scenario guiding""; (3) developing and applying AI techniques such as generative AI and agent AI in the field of energy; (4) encouraging multi-channel and multi-form deep participation in global energy science and technology governance.",2024 ADIPEC | Artificial intelligence (AI) | Energy transition | Hydrogen energy | Natural gas | Oil,0,2025,sustainability,policy+sustainability
210,2-s2.0-105002129786,10.1108/JFMM-05-2024-0184,https://doi.org/10.1108/JFMM-05-2024-0184,https://scholar.google.com/scholar?q=10.1108/JFMM-05-2024-0184,ar,Journal of Fashion Marketing and Management,"Blazkova, Tereza;Pedersen, Esben Rahbek Gjerdrum;Andersen, Kirsti Reitan Reitan",Sentiments and sustainability: stakeholder perceptions of sustainable fashion on social media,"Purpose: This study aims to deepen the understanding of what stakeholders talk about when it comes to sustainable fashion on social media and how. Sustainable fashion is a broad umbrella term, which can distract attention from the differences between the individual subtopics and the sentiments ascribed to them. However, little systematic research exists on how the stakeholder activity and dominant sentiments vary across different sustainable fashion topics. Design/methodology/approach: This study is based on a social media analysis of 19,179 tweets authored by 1,819 distinct stakeholders on Twitter (now “X”) from 2007 to 2022. A large language model, a type of artificial intelligence (AI) that focuses on understanding and generating human language, is used to conduct a sentiment analysis of six stakeholder groups and 81 keywords linked to sustainable fashion. Two case examples are used to highlight the differences in stakeholder perceptions of sustainable fashion. Findings: The social media analysis demonstrates how subcategories of sustainable fashion significantly differ in terms of stakeholder interest, activity and sentiments. For instance, tweets on circular economy and relevant subcategories (closed loop, recycling, upcycling, etc.) are popular, whereas issues linked to environmental, social and governance (ESG) and due diligence receive little attention on social media. While sentiments toward sustainable fashion are in general positive, discussions on topics such as labor rights issues are consistently associated with negative sentiments across most stakeholder groups. Originality/value: This study contributes to the literature by demonstrating how stakeholders and sentiments vary across different topics linked to sustainable fashion on social media, which has become one of the main channels for communicating sustainability content. The findings thereby shed new light on dominant stakeholder positions regarding a wide variety of sustainable fashion topics.",Sentiment analysis | Social media | Stakeholder | Sustainability | Sustainable fashion | Twitter | X,0,2025,sustainability,policy+sustainability
211,2-s2.0-105016130651,10.13998/j.cnki.issn1002-1248.25-0167,https://doi.org/10.13998/j.cnki.issn1002-1248.25-0167,https://scholar.google.com/scholar?q=10.13998/j.cnki.issn1002-1248.25-0167,ar,Journal of Library and Information Science in Agriculture,"Zhang, Tao;Lyu, Qianhui",Generative AI Governance Practices in Europe and the United States and the Enlightenment for China,"[Purpose/Significance] Generative artificial intelligence (GAI) is currently advancing at an astonishing pace. GAI has unleashed remarkable potential in various fields and is significantly fueling social and economic development. However, this rapid progress has also given rise to a plethora of complex issues, including but not limited to data security breaches, privacy violations, the spread of false information, and intellectual property infringements. Existing research primarily focuses on the governance of AI in general, leaving a gap in in-depth exploration of GAI. This study aims to fill this void by meticulously comparing the governance approaches of Europe and the United States in the realm of GAI. Through this comparison, the study aims to provide valuable insights for China to refine its own governance system. This is not only crucial for China's domestic technological development and social stability but also plays a pivotal role in promoting the harmonization of the global governance framework for GAI.[Method/Process] This research adopts a multi-faceted approach. It commences with a comprehensive review of relevant literature, gathering insights from a wide range of academic sources to understand the current state-of-the-art in GAI governance in Europe and the United States. Additionally, it deploys the case-study method, examining real-world examples such as the development of OpenAI's GPT series in the US and the implementation of the EU's AI Act. By analyzing these cases, it can vividly illustrate the practical implications and impacts of different governance strategies, thus enabling a more in-depth and accurate comparison. [Results/Conclusions] We found that the European Union adopts a regulatory path centered on data protection and ensures the fairness and sustainability of technological development through a strict legal framework. However, this strong regulatory model may stifle innovation vitality to some extent. The United States adopts a governance model oriented towards market accountability, emphasizing technological innovation leadership and free development. It stimulates market vitality through industry self-discipline and flexible regulation, but there is a hidden danger of insufficient ethical risk control. Based on these findings, this paper recommends that China adopt a balanced approach. China should integrate elements of both the U.S. and E.U. models to foster innovation while ensuring ethical and legal compliance. Future research could explore ways to adapt these governance models to emerging trends such as integrating GAI with other emerging technologies and addressing the unique governance challenges posed by cross-border data flows.",AI ethics | AI governance | comparison between Europe and the United State | generative AI | governance practice,0,2025,sustainability,policy+sustainability
226,2-s2.0-85216200080,10.11114/smc.v13i1.7316,https://doi.org/10.11114/smc.v13i1.7316,https://scholar.google.com/scholar?q=10.11114/smc.v13i1.7316,ar,Studies in Media and Communication,"Zhang, Shangmingzhu;Hashim, Hasrul;Hassim, Nurzihan Binti","Cultural Policy and the Sustainable Development of 12-Episode Web Series in China: Monetization, Copyright, and Global Expansion","China’s web series market has rapidly transformed entertainment, offering interactive experiences distinct from traditional film and television. Despite its rapid growth, the industry faces key challenges in monetization, copyright protection, and international distribution. This study explores how current policies shape the sustainable development of Chinese web series, supporting growth while imposing constraints. Data was gathered through semi-structured interviews with creators and audiences and analyzed using content analysis. A novel coding approach was used, combining traditional manual methods with advanced large language model (LLM) assistance to uncover detailed insights. Applying Tony Bennett’s cultural policy theory (2001), the findings reveal that although government policies have supported market expansion, they also pose challenges—particularly for independent creators—due to limited monetization channels, insufficient copyright protection, and restrictive regulations on content. Audience feedback shows a strong willingness to pay for high-quality web series, yet free and pirated content options continue to undermine paid models. To navigate these complexities, the study recommends policy reforms that encourage market diversity, stronger copyright protection through digital technologies, and greater support for cross-cultural collaborations to expand global reach. Striking a balance between regulation and creative freedom is crucial for driving the sustainable growth of China’s web series industry.",chinese cultural policy | cross-cultural communication | Large Language Models (LLM) | sustainability | web series,0,2025,sustainability,policy+sustainability
236,2-s2.0-85218916652,10.1093/pnasnexus/pgaf034,https://doi.org/10.1093/pnasnexus/pgaf034,https://scholar.google.com/scholar?q=10.1093/pnasnexus/pgaf034,ar,Pnas Nexus,"Wang, Yifei;Eshghi, Ashkan;Ding, Yi;Gopal, Ram",Echoes of authenticity: Reclaiming human sentiment in the large language model era,"This paper scrutinizes the unintended consequences of employing large language models (LLMs) like ChatGPT for editing user-generated content (UGC), particularly focusing on alterations in sentiment. Through a detailed analysis of a climate change tweet dataset, we uncover that LLM-rephrased tweets tend to display a more neutral sentiment than their original counterparts. By replicating an established study on public opinions regarding climate change, we illustrate how such sentiment alterations can potentially skew the results of research relying on UGC. To counteract the biases introduced by LLMs, our research outlines two effective strategies. First, we employ predictive models capable of retroactively identifying the true human sentiment underlying the original communications, utilizing the altered sentiment expressed in LLM-rephrased tweets as a basis. While useful, this approach faces limitations when the origin of the text - whether directly crafted by a human or modified by an LLM - remains uncertain. To address such scenarios where the text's provenance is ambiguous, we develop a second approach based on the fine-tuning of LLMs. This fine-tuning process not only helps in aligning the sentiment of LLM-generated texts more closely with human sentiment but also offers a robust solution to the challenges posed by the indeterminate origins of digital content. This research highlights the impact of LLMs on the linguistic characteristics and sentiment of UGC, and more importantly, offers practical solutions to mitigate these biases, thereby ensuring the continued reliability of sentiment analysis in research and policy.",fine-tuning | human sentiment | large language models | LLM-induced biases | mitigation strategies,0,2025,sustainability,policy+sustainability
247,2-s2.0-105021503226,10.4108/airo.10075,https://doi.org/10.4108/airo.10075,https://scholar.google.com/scholar?q=10.4108/airo.10075,ar,Eai Endorsed Transactions on AI and Robotics,"Silva-Atencio, Gabriel","Generative AI's Sociotechnical Evolution: Scaling Limits, Governance Gaps, and Sustainable Pathways","This study provides a comprehensive sociotechnical analysis of the development of generative artificial intelligence (GenAI) by analysing 50 systems (2014–2023) and interviewing 25 global experts in the area. Three separate architectural epochs are identified by the research, and each is distinguished by unique scale patterns. Additionally, it demonstrates that performance peaks at 200B parameters, when a 1% increase in Fréchet Inception Distance (FID) scores corresponds to an 8× increase in processing power. There are non-linear trade-offs between increasing skills and conserving energy, according to quantitative studies. According to qualitative study, there are significant disparities in the speed at which different industries adopt new technologies. Global South nations are more affected than others (88% lack frameworks), with implementation delays of 2.3 years and governance delays of 4.2 years. A validated optimization matrix showing that new building designs can make things 3.8 times more efficient but are hard to put into practice, (1) extended scaling laws that include energy and adoption metrics, and (3) sector-specific policy tools to close the 72% policy gaps in education and the 92% accuracy-adoption paradox in healthcare. The results indicate that institutional readiness, rather than mere technical expertise, affects real-world outcomes, challenging deterministic narratives of progress. They also provide us helpful ways to develop artificial intelligence (AI) that follow the rules of Green AI.",Artificial intelligence | energy efficiency | generative models | governance latency | scaling laws | sociotechnical systems,0,2025,sustainability,policy+sustainability
258,2-s2.0-105026266520,10.1007/s11192-025-05494-w,https://doi.org/10.1007/s11192-025-05494-w,https://scholar.google.com/scholar?q=10.1007/s11192-025-05494-w,ar,Scientometrics,"Badullovich, Nicholas;Stede, Manfred;Aktaș, Berfin;Mirzakhmedova, Nailia;Saint-Dizier, Patrick",Manual and automatic paragraph-level analysis of climate change framing in academic journal editorials,"Framing is an extensively used research method in the context of climate change communication research. Frames are an essential part of communication by which a speaker can put boundaries on complex issues and create a tailored lens through which to communicate while remaining true to reality. Though there is a rich literature looking at frames present in a variety of media and social media content, rather little attention has been given so far to scientific editorials. We extend upon previously published research on climate change related editorials from the journals Nature and Science by extending it with new data, new coding structures, new analyses, and results on automatic classification. Specifically, we show that applying frame analysis not as regularly done on text level but on the level of paragraphs (and moving to the level of individual sentences when necessary) leads to a more nuanced account of the underlying communication strategies. Next, in addition to analysing customary issue frames, we also code the rhetorical dimensions present in the paragraphs, informed by Entman’s four frame functions. In analysing the resulting data, we find a pervasive use of the Governance and Scientific issue frames in both journals, and for the rhetorical dimension a dominance of frames that represent the Describe Problem and the Moral Judgement perspectives. Finally, as an add-on to the qualitative work, we assess the capabilities of automatic text classification methods for our three tasks of determining (i) the degree of paragraph topicality, (ii) the issue frames, and (iii) the rhetorical frames. We compare various supervised und unsupervised methods and find that a RoBERTa model achieves decent performance on the frequent classes, while the rare classes pose problems. Similarly, zero-shot learning with LLMs is not yet able to provide a reliable classification, showcasing the results close to those of an SVM baseline. At the end of the paper, we situate our approach in the quest for even more fine-grained analyses and computational models of framing.",Automatic text classification | Climate change | Framing | Journal editorials,0,2025,sustainability,policy+sustainability
259,2-s2.0-105026210471,10.1177/10920617251405473,https://doi.org/10.1177/10920617251405473,https://scholar.google.com/scholar?q=10.1177/10920617251405473,ar,Journal of Integrated Design and Process Science,"Haiping, Yu;Ping, Sun;Wanru, Gao;Baoshan, Luo",Transforming Engineering Education Through Enhancing AI Literacy of College Teachers,"Amidst the rapid evolution of intelligent technology clusters—including large language models, virtual reality, and educational big data—this paper proposes the imperative to enhance AI literacy among college teachers as a cornerstone of digital competence development. We propose a three-tiered competency framework, named ‘Tool Application → Behavior Transformation → Innovative Design’, to transition educators from technical operators to intelligent instructional designers. Current challenges include outdated perceptions of AI, uneven technical proficiency, inadequate training resources, and limited pedagogical integration. To address these, we construct a multidimensional AI literacy framework spanning five domains: 1) cognitive understanding of AI fundamentals, 2) pedagogical integration through instructional design, 3) discipline-specific applications via industry collaboration, 4) ethical governance, and 5) educational innovation. Implementation strategies emphasize blended training models, tiered skill development, hands-on tool practice, case-based learning, and ethical education. A dual-perspective evaluation system (teacher-student feedback loops) assesses training efficacy and instructional outcomes. The study establishes an innovative dual-core driven platform architecture comprising the Teacher Development Cloud Platform and the Subject-Specific Tool Box, aiming to enhance teaching capabilities and discipline-specific application competencies. The research provides actionable pathways for advancing educators’ AI competencies, supporting digital transformation in higher education, and fostering sustainable ‘AI + Education’ ecosystems. Findings underscore the critical role of structured competency development in bridging technological potential with pedagogical innovation.",AI literacy | engineering education transformation | innovative instructional design | university faculty competence,0,2025,sustainability,policy+sustainability
260,2-s2.0-105025539154,10.1080/21670811.2025.2602870,https://doi.org/10.1080/21670811.2025.2602870,https://scholar.google.com/scholar?q=10.1080/21670811.2025.2602870,ar,Digital Journalism,"O’Neill, Saffron;White, Veronica;Cann, Tristan J.B.;Simon, Felix M.;Johnstone-Hack, Alastair;Puttock, Simon;Hayes, Sylvia;Blewett, Oliver;Camargo, Chico;Coan, Travis;Gonzalez Espinosa, Francisco;Malla, Ranadheer;Qureshi, Sarwat;Westwood, Ned",How Does GenAI “See” Climate Change: Exploring the Challenges and Opportunities of GenAI for Climate Visual Journalism,"Visualising climate change is a challenge for journalists. Climate images can be clichéd, disconnected and even divergent from information communicated by other modalities (such as text); and can represent a missed opportunity to engage audiences. Generative AI could potentially provide transformative opportunities to visually illustrate climate news. However, risks may include reinforcing stereotyped, inaccurate or unethical visual content, with knock-on effects on audience trust and public informedness. Working as a transdisciplinary team of social scientists, computer scientists and journalists, we co-produced three studies designed to represent a spectrum of potential future engagement with generative AI technology. We prompted five generative AI tools (ChatGPT, Stable Diffusion, Midjourney, Microsoft Copilot, Generative AI by Getty Images) with seven typical climate news topics (climate change, flooding, heatwave, migration, Net Zero, COP26, nature) via three prompt styles (simple, detailed, story). These results indicate that there are substantial barriers for generative AI tools to create meaningful images for climate-related stories. We reflect on the implications of these results for both researchers and journalists; in terms of the evolving eye-witnessing role of photojournalism in an age of AI and misinformation, and in how such images may act to constrain transformative climate action.",aesthetics | Climate change | discourse | generative AI | image | photojournalism | prompt engineering | visual communication,0,2025,sustainability,policy+sustainability
267,2-s2.0-105024814968,10.1002/ise3.70026,https://doi.org/10.1002/ise3.70026,https://scholar.google.com/scholar?q=10.1002/ise3.70026,ar,International Studies of Economics,"Zhu, Qiannan;Zhang, Zhengyu",The Impact of Artificial Intelligence on Energy Conservation and Emission Reduction: Evidence From China's Listed Firms,"Artificial intelligence (AI) plays an increasingly pivotal role in advancing sustainable economic development. While existing literature predominantly examines the environmental impact of AI technologies from national or sectoral perspectives, this study provides a micro-level analysis of its effects on energy conservation and emission reduction (ECER) performance, utilizing a dataset of Chinese listed firms. We employ a large language model (LLM)-based intelligent scoring system to capture firms' ECER performance from publicly available environmental disclosures, and construct two-pronged measures of AI technological capabilities encompassing both innovation and adoption dimensions. The empirical analysis demonstrates that AI technologies significantly enhance ECER performance among Chinese listed firms, with results remaining robust to various alternative specifications and robustness tests. Mechanism analysis reveals that AI facilitates environmental improvements through the enhancement of productive efficiency and the promotion of green innovation. Heterogeneity analysis further indicates that AI-driven environmental effects are more pronounced among state-owned enterprises, mature-stage firms, firms in polluting industries, sectors with lower competitive intensity, labor-intensive and capital-intensive industries, and firms located in cities with stringent environmental regulations. These findings offer novel firm-level empirical evidence on AI's environmental implications, contributing to a more comprehensive understanding of the technology-environment nexus in emerging economies and laying a theoretical foundation for targeted AI-related environmental policy interventions.",artificial intelligence | energy conservation and emission reduction | green innovation | LLM-based intelligent scoring system | productive efficiency,0,2025,sustainability,policy+sustainability
279,2-s2.0-105022456393,10.1002/joe.70019,https://doi.org/10.1002/joe.70019,https://scholar.google.com/scholar?q=10.1002/joe.70019,re,Global Business and Organizational Excellence,"Islam, Md Asadul;Somu, Subbulakshmi;Aldaihani, Faraj Mazyed Faraj",The Rise of Agentic AI: Synthesis of Current Knowledge and Future Research Agenda,"Agentic artificial intelligence (AAI) represents a significant evolution in the field of AI, moving beyond traditional and generative systems toward models characterized by autonomy, adaptivity, proactiveness, and decision agency. Unlike earlier AI paradigms that were reactive or limited to narrow tasks, AAI integrates reasoning, memory, planning, and tool orchestration to pursue complex objectives with minimal human oversight. Using a systematic literature review method, this study synthesizes current knowledge on AAI by examining its conceptual foundations, practical applications, and emerging research directions. Conceptually, AAI is distinguished from automation, generative AI, and multi-agent systems through its unique capacity to operate as a socio-technical partner in organizational and societal contexts. In practice, AAI is being applied across sectors such as healthcare, finance, manufacturing, education, and sustainability, enabling organizations to enhance decision support, optimize processes, and improve resilience in global business contexts. However, these advancements present significant challenges, including governance, transparency, accountability, workforce transformation, and integration with legacy systems. On the research front, four major streams dominate current scholarship: human–AI collaboration and co-agency; balancing AI autonomy with human control; governance and trust; and societal and ethical implications. To unify these insights, this paper develops an antecedent–mechanism–outcome framework linking technological, organizational, and societal enablers to the mechanisms and outcomes of AAI adoption. Building on this synthesis, a future research agenda is proposed that emphasizes conceptual refinement, responsible integration, methodological innovation, and interdisciplinary collaboration. Overall, the study contributes to both academic and managerial understanding in the global business context by highlighting AAI as both a driver of business strategy and a potential enabler of organizational excellence and sustainable development.",agentic artificial intelligence | autonomy and adaptivity | business strategy | human–AI collaboration | sustainability,0,2025,sustainability,policy+sustainability
281,2-s2.0-105021874221,10.1177/20427530251399872,https://doi.org/10.1177/20427530251399872,https://scholar.google.com/scholar?q=10.1177/20427530251399872,ar,E Learning and Digital Media,"Al-Saadi, Zakia;Mkadmi, Abderrazak;Elsawy, Elsayed",AI in the educational process in Oman’s higher education: Realities and prospects,"The research seeks to investigate the reality of using artificial intelligence software in higher education institutions in the Sultanate of Oman, examine their effects on the learning process, and determine the challenges that academic institutions face to use these technologies. A descriptive qualitative method was used, collecting data through semi-structured interviews with technical administrators and teaching staff from public and private universities. Data were coded based on the Braun and Clarke approach, whereby interviews were transcribed into written transcripts and then coded in accordance with predetermined aims. The findings indicated that AI tools like ChatGPT and Gemini are being utilized to a greater extent in some of the universities in Oman, especially in lesson planning. Nevertheless, their utilization is still restricted in some universities due to inadequate infrastructure and technical capabilities. The study also revealed that the apps help enhance education by offering students personalized assistance, but instructors need more training to use them effectively. The study concluded that there is a pressing need to create educational infrastructure and develop advanced training programs for professors and students to enhance the effectiveness of using artificial intelligence. It also called for policy and control making to safeguard individual data and making regulations to ensure the secure and sustainable utilization of these technologies according to the attainment of Oman Vision 2040 for enhancing higher education and enhancing students’ skills.",artificial intelligence | digital transformation educational technology | educational challenges | higher education | sultanate of Oman,0,2025,sustainability,policy+sustainability
283,2-s2.0-105021318352,10.3389/frai.2025.1691468,https://doi.org/10.3389/frai.2025.1691468,https://scholar.google.com/scholar?q=10.3389/frai.2025.1691468,ar,Frontiers in Artificial Intelligence,"Shen, Lihao;Li, Zhengrong;Liang, Yongqing;Feng, Yiqiang;Zhang, Zhanyu",Artificial intelligence adoption and corporate ESG performance: evidence from a refined large language model,"Introduction: The convergence of artificial intelligence (AI) and Environmental, Social, and Governance (ESG) objectives has attracted growing academic and policy interest but remains empirically underexplored due to challenges in accurately measuring firm-level AI adoption. Methods: This study refines the LLM-based framework by employing a domain-adapted model (Qwen2.5-72B) and a granular classification scheme to distinguish genuine “Applied” AI technologies from rhetorical mentions in corporate disclosures. Using data from Chinese A-share listed firms between 2009 and 2022, we construct a credible indicator of AI adoption and examine its impact on ESG performance. Results and discussion: The results reveal a robust positive relationship between AI adoption and ESG outcomes, primarily driven by enhanced green innovation and improved internal control quality. These effects are more pronounced among large and technology-intensive firms. Consistent with the Resource-Based View and the Technology–Organization–Environment framework, our findings underscore the importance of complementary assets and absorptive capacity in realizing the sustainability potential of AI. This study provides credible evidence on how and for whom AI fosters corporate sustainability, introduces a transparent approach to measuring authentic technology adoption, and highlights the emerging “digital ESG divide” with implications for targeted policy interventions.",artificial intelligence | corporate sustainability | ESG performance | Large Language Models (LLMs) | technological integration,0,2025,sustainability,policy+sustainability
285,2-s2.0-105021256110,10.1007/s11846-025-00949-z,https://doi.org/10.1007/s11846-025-00949-z,https://scholar.google.com/scholar?q=10.1007/s11846-025-00949-z,ar,Review of Managerial Science,"Hernández-Tamurejo, Álvaro;Bužinskienė, Rita;Barbosa, Belém;Miceikienė, Astrida;Saura, Jose Ramon",Generative artificial intelligence use in the workplace: implications for management practice,"Generative artificial intelligence (GenAI) promises substantial productivity gains for organisations, yet unresolved questions about data management and privacy continue to shape managers’ and employees’ confidence. This study examines workplace adoption of GenAI and shows how trust, conditioned by perceptions of data-management integrity, information transparency, and privacy risk, influences acceptance. This mixed-method study tests, using a survey-based structural equation model plus interviews focused on managerial practices among daily GenAI practitioners, two core insights: (i) trust is the strongest predictor of intention to use GenAI, and (ii) trust depends chiefly on manager’s and employees’ belief that organisational data are handled reliably and objectively through management routines. Perceptions of transparency or privacy risk exert no direct influence on either trust or usage. Building on these results, the study delineates four managerial domains: data-management process, information transparency, privacy risk, and trust, alongside twenty future research questions designed to understand how GenAI is linked to managerial practices. For practice, the findings recommend monitoring, calibrated disclosure, and adaptive privacy protocols as concrete managerial levers to strengthen GenAI acceptance. The evidence highlights trustworthy data governance, not abstract explainability, as the foundation of sustainable GenAI adoption. The study also provides a roadmap of actionable management practices to guide its implementation in modern workplaces.",AI data management | AI transparency | AI trust | Artificial intelligence | Generative AI | Management practice | Privacy,0,2025,sustainability,policy+sustainability
286,2-s2.0-105020870872,10.1108/IJPHM-10-2024-0103,https://doi.org/10.1108/IJPHM-10-2024-0103,https://scholar.google.com/scholar?q=10.1108/IJPHM-10-2024-0103,ar,International Journal of Pharmaceutical and Healthcare Marketing,"Abramova, Ruta;Filatova, Mariia;Sazonava, Maryia;Serikova, Kseniya",Ethical and practical aspects of AI implementation in the pharmaceutical industry,"Purpose – This study aims to analyze and evaluate strategies that enable pharmaceutical companies to effectively integrate artificial intelligence (AI) and big data to build and maintain trust among stakeholders. Design/methodology/approach – This study used a systematic literature review to investigate strategies for integrating AI and big data in the pharmaceutical industry, focusing on trust, ethics and regulation (Booth et al., 2016). The authors conducted a comprehensive search in PubMed, EBSCOhost, Scopus, Web of Science and university libraries, targeting peer-reviewed articles from the past decade. Search terms combined “AI, ” “pharmaceutical industry, ” “big data” and related keywords (Moher et al., 2009). Data analysis involved coding, categorization and content analysis to identify themes and patterns (Braun, and Clarke, 2006). The coding process used deductive and inductive approaches, with inter-coder reliability assessed for consistency (Krippendorff, 2018). Tools such as ChatGPT and PRISMA guidelines ensured a structured and transparent review (Moher et al., 2009). Data triangulation enhanced reliability by combining multiple sources. This rigorous methodology provides a robust foundation. Findings – Ensuring compliance with data protection regulations such as GDPR and addressing ethical concerns around the use of AI are critical to building and maintaining consumer trust. This dissertation presents case studies demonstrating the successful application of AI across industries and highlights the importance of its adoption. Originality/value – Data privacy, algorithmic bias and lack of transparency in the work of AI can undermine the trust of stakeholders, including consumers, regulators and investors. Pharmaceutical companies, seeking to integrate AI, face a choice: how to create a sustainable system that will ensure both efficiency and trust.",Artificial intelligence | Big data | Data privacy | Health care | L65 | M30 | M31 | M38 | Marketing | O30 | Pharmaceutical market | SLR methodology,0,2025,sustainability,policy+sustainability
287,2-s2.0-105020372551,10.1109/MITP.2025.3614987,https://doi.org/10.1109/MITP.2025.3614987,https://scholar.google.com/scholar?q=10.1109/MITP.2025.3614987,ar,IT Professional,"Routray, Sudhir K.;Mohanty, Sasmita",Artificial Intelligence in the Middle East and Africa: Needs and Requirements,"The Middle East and Africa (MEA) region presents a unique set of needs and opportunities for generative artificial intelligence (AI), driven by economic diversification, digital transformation, and social challenges. Key sectors such as health care, education, finance, and governance require AI-driven solutions tailored to linguistic, cultural, and infrastructural nuances. In the Middle East, AI is central to national visions like Saudi Arabias Vision 2030 and the United Arab Emiratess (UAEs) AI strategy, strengthening innovation in smart cities and cybersecurity. Africa, with its diverse economies and growing tech hubs, demands AI for localized content creation, agricultural optimization, and financial inclusion. Addressing data scarcity, ethical AI deployment, and skill development remains critical for Africa. A region-specific approach to generative AI can enhance economic growth, societal well-being, and sustainable development in MEA.",,0,2025,sustainability,policy+sustainability
288,2-s2.0-105020285819,10.1007/s40888-025-00384-z,https://doi.org/10.1007/s40888-025-00384-z,https://scholar.google.com/scholar?q=10.1007/s40888-025-00384-z,ar,Economia Politica,"Becchetti, Leonardo;Solferino, Nazaria",Political biases in chatgpt: insights from comparative analysis with human responses,"We investigate the political and ideological positioning of ChatGPT, a leading large language model (LLM), by comparing its responses to political economy questions from the European Social Survey (ESS) with those of representative human samples. The questions focus on environmental sustainability, civil rights, income inequality, and government size. We analyze two distinct dimensions of bias: an absolute bias, measured as the deviation of ChatGPT’s answers from the positions of ESS respondents who locate themselves at the center, and a self-perception bias, captured by the difference between ChatGPT’s self-reported left-right placement and the ideological stance which can be inferred from its substantive answers. Our results reveal a significant left-leaning absolute bias in ChatGPT’s responses, particularly on environmental and civil rights issues, which exceeds its own declared center-left self-placement. These findings highlight the importance of transparency regarding AI biases to mitigate unintended ideological influences on users. We conclude by discussing the implications for AI governance, debiasing approaches, and the educational use of language models.",ChatGPT | Large language models (LLMs) | Political bias,0,2025,sustainability,policy+sustainability
291,2-s2.0-105018507461,10.1007/s40684-025-00783-4,https://doi.org/10.1007/s40684-025-00783-4,https://scholar.google.com/scholar?q=10.1007/s40684-025-00783-4,ar,International Journal of Precision Engineering and Manufacturing Green Technology,"Byeon, Mingyo;Park, Jingyu;Kim, Jin Hyuk;Kyung, Sejin;Lee, Min Woo;Kim, Jaehyun;Lee, Changsoo;Choi, Chulhwan",Decarbonization Strategies in Semiconductor Manufacturing: Reducing Greenhouse Gas Emission and Energy Consumption in the CVD Process,"As the semiconductor industry strives to adopt sustainable practices, environmental, social, and governance (ESG) considerations have become increasingly important. The decarbonization initiatives discussed here highlight the importance of energy efficiency, resource optimization, and collaborative efforts to achieve sustainability targets while ensuring operational excellence. The exploration of alternative gases has allowed significant progress to be made in reducing the environmental footprint within the semiconductor industry, such as the use of F<inf>2</inf> for NF<inf>3</inf> chamber cleaning, and the optimization of liquefied natural gas (LNG) use for abatement systems. These initiatives have played a vital role in aligning with sustainability goals and effectively reducing greenhouse gas (GHG) emissions. This study also examines the power consumption of semiconductor manufacturing equipment, focusing on the deposition process. To reduce power consumption, power usage of spin operation types was decreased by adjusting the speed of the equipment front end module (EFEM) fan, load lock module (LLM) pump, and process module (PM) pump. Also, power consumption of heat types was minimized by turning off the LLM heater and the PM fore-line heat jacket. Overall, this study emphasizes the importance of ESG principles and decarbonization initiatives in the semiconductor industry, and highlights the need for sustainable practices, energy efficiency, and resource optimization to meet global sustainability targets while maintaining operational excellence. Collaboration among industry stakeholders is critical to achieve these goals, and ensure a more sustainable future.",Decarbonization | Deposition | Electrical power saving | ESG | Greenhouse gas reduction | Semiconductor manufacturing,0,2025,sustainability,policy+sustainability
294,2-s2.0-105017818061,10.1007/s10956-025-10257-6,https://doi.org/10.1007/s10956-025-10257-6,https://scholar.google.com/scholar?q=10.1007/s10956-025-10257-6,ar,Journal of Science Education and Technology,"Sui, Chi Jung;Chang, Chun Yen;Yen, Miao Hsuan",STEM-5E Socio-Scientific Argumentation with Generative AI-Driven Scaffolding: Exploring the Interplay between Epistemic Beliefs and Learning Outcomes,"This study addresses the limitations of traditional STEM education by integrating socio-scientific issues within the STEM-5E instructional framework, using generative AI-driven scaffolding for self-regulated learning (GAISSR). We investigated how different types of GAISSR affect students' argumentation performance over time and how students’ epistemic beliefs about generative AI (GenAI) relate to their improvement in argumentation skills. Ninety-four eighth-grade students participated, randomly assigned to metacognitive GAISSR, cognitive GAISSR, or a control group. The curriculum involved three consecutive tasks on energy policy issues related to climate change. A linear mixed model was used to analyze changes in students' argumentation performance over time, while epistemic beliefs and self-regulation were assessed via adapted questionnaires. Findings revealed a significant interaction between scaffolding type and task sequence; cognitive scaffolding initially improved performance but did not sustain gains, whereas metacognitive scaffolding supported continued improvement by the final task. Additionally, students who demonstrated improvement reported significantly stronger beliefs in the certainty, source, and structural coherence of GenAI-generated content compared to peers who did not improve. These results suggest metacognitive scaffolding promotes deeper, enduring argumentation skills, and students’ epistemic beliefs about GenAI significantly influence their learning outcomes.",Argumentation | Epistemic beliefs | Generative AI | SSI,0,2025,sustainability,policy+sustainability
295,2-s2.0-105017711877,10.4018/IJBAN.388757,https://doi.org/10.4018/IJBAN.388757,https://scholar.google.com/scholar?q=10.4018/IJBAN.388757,ar,International Journal of Business Analytics,"Jonnala, Sridhar;Parida, Pramod Kumar;Thomas, Nisha Mary",EU AI Act Underrepresented and Insufficient to Address the Risk and Vulnerabilities of Generative AI,"This study conducts a systematic evaluation of the European Union Artificial Intelligence Act, assessing its regulatory alignment with the rapidly evolving risk landscape posed by Generative AI systems. Employing large language models within a governance-oriented analytical framework, the analysis critically examines the extent to which the Act addresses foundational concerns such as algorithmic fairness, model explainability, environmental sustainability, and financial stability. While the Act advances transparency and accountability, analysis reveals notable limitations in operational guidance and alignment with high-level ethical principles. Overall, the Act represents a positive foundation, yet targeted enhancements are essential for enabling responsible innovation and ensuring that Generative AI advances align with societal and economic values. The proposed framework also enables practical self-audits and supports future regulatory design, making it a valuable tool for both public and private stakeholders.",AI Governance | AI Regulations | AI Risks | Ethical AI | EU AI Act | Foundation Models | Generative AI | Responsible AI,0,2025,sustainability,policy+sustainability
300,2-s2.0-105017182153,10.1108/DTA-02-2025-0151,https://doi.org/10.1108/DTA-02-2025-0151,https://scholar.google.com/scholar?q=10.1108/DTA-02-2025-0151,ar,Data Technologies and Applications,"Cheng, Chiang Yu;Hsu, Chin Hsiung",Substitution or complementarity? Understanding the role of ChatGPT in transforming news media traffic in the United States and Taiwan,"Purpose – This study investigates whether ChatGPT-driven traffic (CGT) acts as a substitute or complement to traditional news media platforms in the United States and Taiwan. By analyzing website traffic patterns and incorporating cross-cultural and platform-specific factors, the research aims to determine how generative AI tools influence news consumption dynamics. The study also examines the moderating effects of website scale and specialization (generalist vs. niche) to provide a nuanced understanding of AI’s role in reshaping digital media ecosystems. Findings offer insights for media organizations, policymakers, and AI developers on adapting to evolving content distribution and engagement trends. Design/methodology/approach – This study employs a quantitative research approach using Partial Least Squares Structural Equation Modeling (PLS-SEM) to examine the impact of ChatGPT-driven traffic (CGT) on total website traffic (TWT). A dataset of 80 news websites (40 from the U.S. and 40 from Taiwan) was analyzed, incorporating website scale and specialization (generalist vs. niche) as moderating variables. Traffic data were sourced from SimilarWeb, capturing monthly visits over six months. Multi-group analysis (MGA) was conducted to compare effects across different platform sizes and national contexts, offering insights into ChatGPT’s role as a substitute or complement in news media ecosystems. Findings – The study reveals that ChatGPT-driven traffic (CGT) generally complements news media by increasing website visits, but its impact varies by country and website scale. In Taiwan, ChatGPT acts as a traffic driver, especially for smaller and niche platforms. In contrast, large U.S. websites experience substitution effects, suggesting AI-driven content may reduce direct visits. Website scale is a key factor, with smaller platforms benefiting more from AI referrals. These findings highlight the need for adaptive strategies in media organizations and call for regulatory considerations to balance AI’s role in content distribution and news ecosystem sustainability. Research limitations/implications – This study relies on third-party traffic data (SimilarWeb), which may not fully capture user interactions and engagement depth. The analysis is limited to a six-month period, potentially missing long-term trends in AI-driven news consumption. Additionally, the findings focus on the U.S. and Taiwan, limiting generalizability to other media markets with different regulatory and technological landscapes. The study examines traffic patterns but does not explore user trust, perception, or content credibility in AI-generated summaries. Future research should incorporate longitudinal data, qualitative insights, and additional geographic contexts to provide a more comprehensive understanding of AI’s impact on news ecosystems. Practical implications – News organizations, especially smaller and niche platforms, should optimize content for AI-driven referrals to enhance visibility and engagement. Large U.S. platforms facing substitution effects must focus on exclusive content and direct user engagement to maintain traffic. Policymakers should ensure transparent referral attribution and explore fair revenue-sharing models between AI platforms and news publishers. AI developers should collaborate with media outlets to create sustainable content distribution frameworks, balancing efficiency with news ecosystem sustainability. Understanding ChatGPT’s role in media consumption can help stakeholders adapt strategies, refine monetization models, and foster AI-media partnerships for long-term industry resilience. Social implications – The rise of AI-driven news consumption impacts public access to information, media trust, and digital literacy. In Taiwan, ChatGPT enhances access to niche content, potentially fostering information diversity. In the U.S., substitution effects may contribute to reduced engagement with primary news sources, affecting media sustainability and journalism quality. AI-generated summaries could influence public opinion formation, raising concerns about bias and misinformation. Policymakers must promote transparency and ethical AI use to ensure balanced news dissemination. Media literacy initiatives are essential to help users critically engage with AI-curated content while preserving credible journalism and democratic discourse. Originality/value – This study provides a novel cross-cultural analysis of ChatGPT-driven traffic (CGT) in the U.S. and Taiwan, offering new insights into AI’s role in news consumption dynamics. By integrating website scale and specialization (generalist vs. niche), it refines the substitution-complementarity framework in the context of generative AI. Unlike prior research focusing on social media and search engines, this study uniquely examines AI-driven referrals using empirical traffic data. The findings contribute to digital media strategy, policy discussions, and AI adoption research, guiding news organizations, regulators, and AI developers in navigating the evolving AI-media ecosystem.",AI-driven content distribution | Cross-cultural analysis | Digital platforms | Generative AI | News media traffic | Substitution-complementarity framework,0,2025,sustainability,policy+sustainability
302,2-s2.0-105017156843,10.1108/JCOM-10-2024-0204,https://doi.org/10.1108/JCOM-10-2024-0204,https://scholar.google.com/scholar?q=10.1108/JCOM-10-2024-0204,ar,Journal of Communication Management,"Duarte, Alexandre;Dias, Patrícia",How artificial intelligence is changing organizations: Portuguese CEOs’ perspective,"Purpose – The rapid advancement of artificial intelligence (AI) is reshaping organizational landscapes, prompting chief executive officers (CEOs) to navigate its integration for enhanced productivity and strategic advantage. As the adoption of any new technology within organizations is closely interconnected with strategic communication, leadership discourse and change management, this study aims to obtain a deeper understanding of the processes and implications of AI adoption by organizations through the perspectives of CEOs. Design/methodology/approach – This exploratory study follows a qualitative approach, based on in-depth interviews with a purposive panel of 17 CEOs from diverse sectors in Portugal. Findings – A diverse array of specific AI tools is employed, ranging from native AI-based platforms like ChatGPT to AI-integrated solutions such as Canva and Adobe. While initially leveraged for streamlining routine tasks, AI’s scope has expanded to encompass strategic functions like data analysis, market research and content production. CEOs highlight increased productivity as a primary benefit, but concerns about AI’s impact on critical thinking, privacy and ethical considerations loom. Some CEOs stress the need for workforce reskilling and upskilling to navigate AI-driven transformations, while others emphasize the importance of global regulations to address ethical dilemmas. Practical implications – This research offers contributions to both academia and practice. From an academic perspective, it enriches the literature on AI adoption by incorporating the underexplored dimension of leadership, particularly the CEO’s role and by integrating theoretical frameworks such as the technology acceptance model, diffusion of innovation and technology-organization-environment. This multidimensional approach provides a more holistic understanding of the drivers, barriers and ethical challenges associated with AI adoption in organizational contexts. For practitioners, especially CEOs and organizational leaders, the findings provide actionable insights into leveraging AI effectively while navigating its risks. It emphasizes the importance of adopting a strategic vision, fostering a culture of continuous learning and prioritizing ethical stewardship. Originality/value – This study affords an in-depth look at the perspectives of those making decisions about how AI is being adopted in Portuguese organizations. While underscoring the pivotal role of CEOs in shaping effective, sustainable and ethically sound AI strategies for organizational success in the evolving digital landscape, it also increases awareness about challenges and risks.",Artificial intelligence (AI) | Chief executive officers (CEOs) | Communication | Ethics | Management | Strategy,0,2025,sustainability,policy+sustainability
305,2-s2.0-105016718346,10.1177/2046147X251377853,https://doi.org/10.1177/2046147X251377853,https://scholar.google.com/scholar?q=10.1177/2046147X251377853,ar,Public Relations Inquiry,"Christensen, Emma",The socio-ecological costs of AI: Toward socially responsible and sustainable communication practices,"The adoption of generative artificial intelligence (GAI) among communication practitioners and researchers surged after the launch of ChatGPT in November 2022. This adoption has long been called for, driven by expectations of efficiency and productivity gains as well as concerns about being outpaced by adjacent fields. As the initial hype around GAI fades, a more balanced understanding of AI’s promises and perils can emerge. While previous research on the perils of AI has emphasized ethical concerns such as job displacement, the potential spread of mis- and disinformation, immoral communication, and intensified social injustice, one critical issue remains largely unaddressed: the socio-ecological harm of AI use. While often perceived as immaterial, AI relies on a vast physical infrastructure, demanding the extraction and depletion of non-renewable resources, consuming extreme amounts of energy and water, and generating significant ‘e-waste’. This paper brings these overlooked costs of AI to the forefront, urging practitioners to critically engage in exploring pathways for fostering socially responsible and environmentally sustainable AI practices.",communication practice | ethics | Generative artificial intelligence | socio-ecological impact | sustainable AI practice,0,2025,sustainability,policy+sustainability
315,2-s2.0-105011169651,10.4018/IJSWIS.385572,https://doi.org/10.4018/IJSWIS.385572,https://scholar.google.com/scholar?q=10.4018/IJSWIS.385572,ar,International Journal on Semantic Web and Information Systems,"Tsang, Y. P.;Wu, C. H.;Wang, Yue;Ip, W. H.",Semantic-Driven Internet of Behaviours for Enhancing Supply Chain ESG Capabilities Through Generative AI,"Pursuing sustainable development goals requires enterprises to enhance their environmental, social, and governance (ESG) capabilities. In logistics and supply chain management, where small and medium enterprises dominate, integrating ESG practices is challenging and often favors larger companies with established frameworks. This study introduces an ESG recommendation system based on generative artificial intelligence (GERS) to provide accessible, tailored ESG guidance. Leveraging large language models and an ESG knowledge base, GERS offers actionable recommendations, particularly benefiting small and medium enterprises. Evaluated through a case study with a Hong Kong Logistics Association ESG assessment programme, expert panels confirmed the quality of its recommendations. Results demonstrate the GERS’s ability to generate ESG improvement plans, enhancing capabilities efficiently. This research highlights the transformative potential of generative artificial intelligence in fostering sustainability, showcasing its role in creating adaptive, context-aware services that drive collaborative learning and sustainable practices in supply chains.",GenAI | Large Language Model | Recommendation System | Sustainability | Sustainable Development Goals,0,2025,sustainability,policy+sustainability
320,2-s2.0-105010310041,10.1109/JIOT.2025.3588189,https://doi.org/10.1109/JIOT.2025.3588189,https://scholar.google.com/scholar?q=10.1109/JIOT.2025.3588189,ar,IEEE Internet of Things Journal,"Arora, Ruchika;Damarla, Ramesh Babu",Generative AI-Augmented Federated Learning for Vehicle Routing in Supply Chain Management With Human Resource Management and Low-Carbon Emission in IIoT,"The growing complexity of the Industrial Internet of Things (IIoT) has facilitated multivehicle routing, workforce planning, and carbon-sensitive logistics, necessitating the use of intelligent real-time optimization frameworks. The conventional federated learning (FL)–based vehicle routing schemes cannot dynamically react to traffic conditions, energy efficiency needs, and human resource management (HRM) regulations. To address these challenges, this research introduces a generative AI-enriched FL (GAI-FL) paradigm, using conditional variational autoencoders (CVAEs) and adaptive FL (AFL) to optimize vehicle routing performance, HR workload assignment, and sustainability goals. The proposed scheme combines context conditioned latent codes to optimize route choice, driver job allocation, and vehicle scheduling under low-carbon emission constraints and workforce maximization. Realistic simulations confirm that the proposed model outperforms conventional FL-based schemes in delivery efficiency, workforce utilization, and fuel savings. In comparison to AFL, synchronous FL (SFL), and FL, the suggested CVAE-AFL scheme achieves 35% performance improvement in delivery time, 32% reduced carbon emissions, and 25% enhanced transportation cost efficiency. Further, the proposed model enhances the balancing of the driver workload by 28% to meet workload fairness and avoid employee fatigue. The dynamic allocation of the workload, reduced energy consumption, and harmonization of workforce management policy ensures a sustainable, scalable, and AI-aided logistics solution.",Adaptive federated learning (AFL) | conditional variational autoencoder (CVAE) | human resource management (HRM) | Industrial Internet of Things (IIoT) | supply chain | vehicle routing problem (VRP),0,2025,sustainability,policy+sustainability
330,2-s2.0-105005584820,10.1177/14614448251338511,https://doi.org/10.1177/14614448251338511,https://scholar.google.com/scholar?q=10.1177/14614448251338511,ar,New Media and Society,"Stilinovic, Milica;Bailo, Francesco;Hutchinson, Jonathon",Creative Underspheres and democratic challenges: Exploring the implications of generative AI misuse,"This article introduces the concept of the Undersphere – a networked community brought together via creative exchange – to highlight how the increased proliferation of Generative AI poses risks not yet acknowledged by policymakers within emerging AI regulatory frameworks. Employing a single case study methodology – namely, exploring exchanges made on r/StableDiffusion, a known subgroup on Reddit – it illustrates the conceptual parameters of the Undersphere, outlines the potential for creative harm within the GenAI space, and counters these elements against the AI regulatory frameworks found within the EU AI Act. It concludes that a risk management framework that provides a more fluid approach to addressing risks, such as those found in governance frameworks aimed at eradicating climate change, could be better positioned to address insecurities manifesting from the GenAI space.",AI governance | AI policy | digital policymaking | generative AI | risk | Underspheres,0,2025,sustainability,policy+sustainability
332,2-s2.0-105004454017,10.1080/01972243.2025.2498507,https://doi.org/10.1080/01972243.2025.2498507,https://scholar.google.com/scholar?q=10.1080/01972243.2025.2498507,ar,Information Society,"Yang, Aimei",Exploring the stability and social influence dynamics in climate change deniers’ disinformation network: A longitudinal study,"In this study we examine network stability and networked influence among climate change deniers. Using social network analysis, pre-trained large language models, and a machine-learning algorithm for network influence estimation, we analyze big data on the co-evolution of deniers’ networking and messaging strategies over a decade. The findings reveal that the deniers’ network remains highly stable in terms of network size and core group composition, despite turbulent subgroup dynamics. In terms of networked influence, a core group of deniers remains highly influential. Additionally, the most engaging topics remain highly stable and are frequently used by deniers. Moreover, deniers’ topic choices significantly shape their level of networked influence. When deniers share disinformation focusing on the social/economic harm of environmental policies, attacking opposition, and questioning climate change science, such antagonistic topics help boost their influence level. Finally, deniers’ influence level could also be boosted by their account type. Among deniers, conservative media is the most influential.",Climate change denial | deep learning | disinformation networks | machine learning | natural language processing | network stability | networked influence | social network analysis,0,2025,sustainability,policy+sustainability
374,2-s2.0-85217970104,10.13998/j.cnki.issn1002-1248.24-0447,https://doi.org/10.13998/j.cnki.issn1002-1248.24-0447,https://scholar.google.com/scholar?q=10.13998/j.cnki.issn1002-1248.24-0447,re,Journal of Library and Information Science in Agriculture,"Liu, Jia",Innovation and Risk Avoidance of Smart Library Services Based on Generative Artificial Intelligence,"[Purpose/Significance] With the rapid advancement of information technology, library services are undergoing transformative changes. The emergence of generative artificial intelligence (Generative AI) presents unprecedented opportunities and challenges for innovation in smart library services. By enhancing service efficiency and user experience, generative AI supports core library functions, such as personalized recommendations, intelligent question answering, and automatic summarization. This research explores the implications of applying generative AI technology to library services, with the goal of understanding its transformative impact on the field and addressing its potential risks. Unlike traditional studies that focus primarily on functionality, this study emphasizes the ethical, technical, and management risks associated with the use of generative AI in libraries. The study occupies an important place in the advancement of knowledge in this area and contributes to the development of sustainable, user-centered library services capable of addressing significant contemporary challenges related to information accessibility and data security. [Method/ Process] This study uses a systematic literature review and case analysis to examine the current state of generative AI applications in smart libraries. A comprehensive approach is taken to understand how generative AI can enhance library services in areas such as personalized recommendation systems, intelligent Q&A, and automated summarization. The study draws on both theoretical and empirical sources, utilizing qualitative analysis to examine trends in the use of generative AI in different types of library services. This review also includes a thorough examination of the potential risks associated with implementing these technologies. Technical risks include data security vulnerabilities and model bias, while ethical risks focus on the issues surrounding user privacy, misinformation, and intellectual property rights. Management risks are also discussed, including the challenges of maintaining system stability and ensuring regulatory compliance. The multi-dimensional risk framework developed in this study provides a robust structure for analyzing these complex challenges and serves as a foundation for future empirical research in smart library applications. [Results/ Conclusions] The research reveals that while generative AI can significantly improve the quality of library services and user satisfaction, it also poses significant risks. These include challenges related to data security, model bias, ethical standards, and management complexity. To address these, the study proposes a number of risk mitigation strategies. Key recommendations include strengthening data security through advanced encryption and access controls, increasing model transparency to build user confidence, and ensuring system stability through rigorous testing and monitoring. In addition, the study advocates for the establishment of ethical guidelines that prioritize user privacy, transparency, and content accuracy. It also underscores the need for ongoing regulatory adjustments to keep pace with technological advances. The study concludes by identifying limitations, such as the lack of quantitative data and real-time experiments, and suggests areas for future research. Future studies should focus on empirically validating the proposed framework, exploring the long-term impact of generative AI on library services, and developing best practices for balancing innovation with ethical responsibility. The continued evolution of generative AI is likely to deepen its integration with smart libraries, enabling innovative service models that meet the diverse and dynamic needs of users while safeguarding against potential risks. This research provides a foundational reference for library managers and policymakers seeking to implement generative AI responsibly and sustainably, and to promote the progressive transformation of library services in the information age.",data analysis | generative artificial intelligence | personalized recommendation service | smart library | user satisfaction,0,2024,sustainability,policy+sustainability
375,2-s2.0-85188193296,10.1016/j.mcpsp.2024.100433,https://doi.org/10.1016/j.mcpsp.2024.100433,https://scholar.google.com/scholar?q=10.1016/j.mcpsp.2024.100433,re,Medicina Clinica Practica,"Delcea, Caterina;Buzea, Catalin Adrian","The medicine of the past, present, and future generations: From Sir William Osler to ChatGPT","Innovation and discovery are the drivers of progress in medicine, which is an ever-changing science. Core concepts in current medical practice include patient-centered and high-value care, evidence-based and personalized medicine, and digital health, that is gaining momentum. Rampant progress is seen in technology development, artificial intelligence, machine learning, large language models such as ChatGPT. Their use in medicine has promising perspectives, conditioned by adequate regulations, based on ethical principles and human-rights, to ensure safety of patient data, fact accuracy, and general applicability. The future of medicine should aim for universal health coverage, facilitated by digital medicine and guided by empathy and compassion. Human interaction will remain a mainstay in medical practice, and ideally technology will provide the much-needed time for doctor–patient bonding. Climate change, cyber security, and access to basic care are some of the challenges to be resolved in the years to come. Future medical care should find the balance between high tech and high touch and aim to for global availability.",Artificial intelligence | ChatGPT | Empathy | Evidence-based medicine | Large language models | Patient-centered care,0,2024,sustainability,policy+sustainability
378,2-s2.0-105020751901,10.7238/d.v0i34.433260,https://doi.org/10.7238/d.v0i34.433260,https://scholar.google.com/scholar?q=10.7238/d.v0i34.433260,ar,Digithum,"Martínez-Valverde, Sara",The art of machines: artificial intelligence imaginaries in advertising creativity,"The study examines the role of AI in advertising creativity from a sociotechnical and posthumanist perspective. By reviewing the literature on sociotechnical imaginaries and assemblage theory, it identifies the narratives shaping AI adoption in advertising agencies and describes the human-machine agencements. Building on this theoretical foundation, a typology of generative AI integration is proposed in three modes – tool, prosthesis, and dialogical mind – which highlights opportunities and challenges such as productive optimization, potential cognitive dependency, creative homogenization and the reproduction of algorithmic biases. The findings underscore the need for critical and ethical frameworks to safeguard creative autonomy and prevent inequalities. These conclusions offer guidance for developing practices and regulations that foster sustainable human-machine collaboration in the advertising field.",advertising creativity | artificial intelligence | assembly theory | human-machine collaboration | sociotechnical imaginaries,0,2024,sustainability,policy+sustainability
388,2-s2.0-85214913006,10.12795/IC.2024.I21.14,https://doi.org/10.12795/IC.2024.I21.14,https://scholar.google.com/scholar?q=10.12795/IC.2024.I21.14,ar,IC Revista Cientifica De Informacion Y Comunicacion,"Alonso, Elisa;Terrero, José Antonio Rosado",A FRAMING ANALYSIS OF ELECTORAL NEWS GENERATED AND TRANSLATED USING GENERATIVE ARTIFICIAL INTELLIGENCE (CHATGPT-3),"The impact of AI (Artificial Intelligence) has become stronger in all fields of knowledge and human activity – including journalism and translation- since the release of various generative AI conversational systems such as ChatGPT-3 for citizens from November 2022. This paper aims to contribute to the debate on the application of this kind of technology throughout a study on the creation of political news in Spanish and their translation into English using ChatGPT-3. For this purpose, a corpus analysis approach based on the Framing Theory and a mixed methodology (quantitative and qualitative) using the CAQDAS (Computer-Aided Qualitative Data Analysis Software) tool, Atlas.ti, was used. In January 2024, ChatGPT-3 was asked to create some news items about a topic for which it has no information: The Spanish General Elections of July 23, 2023. Using different prompts, it was asked to create some news about a possible electoral victory of different Spanish political parties (PP, PSOE, VOX and SUMAR) in these elections – as if it was a real event - to be published in different Spanish newspapers (El País, ABC, La Razón, La Vanguardia, El Mundo). A total of 68 news items were generated and translated by the same AI into English, forming a corpus of 136 news items. It has been identified the framings that AI prioritises in this study: The electoral victory of the parties is narrated in a context of a positive emotion, almost euphoric and utopian (political-fiction), with large majorities, an overwhelming citizen participation, and positive reading by political analysts regarding the electoral triumph, no matter which party was called as the winner and for which newspaper it was to be published. AI creates news items in which the framing codes linked to political actions (mostly related to economy, social policy, and sustainability) stand out. ChatGPT-3 can create news items that resembles the genre of the usual news, but they are more superficial. AI tries to emulate elements such as the use of sources (authoritative voices, figures, or data) in order to give credibility to the pieces of news that it creates. However, it does not always do so accurately, due to its lack of pragmatic knowledge. Moreover, it has also been observed that the translations of news items into English are, in general terms, literal and correct versions of the Spanish ones, in which the technique of direct translation has been applied unfailingly.",AI | Framing | Journalism | Politics | Translation,0,2024,sustainability,policy+sustainability
